{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Itzultzailea.ipynb","provenance":[],"collapsed_sections":["9rdLDL7fUm3e","g6AfI7Jb1kww","ui5oLIqWEFzJ","vsFGi5mi-MRg","0G1Nt_aTsJJo","nFTzchG_t7RD","Vs6nosOxt_w_","xJe6Etpuzp3a","6CO2-_FB0FmL","EcPcPX9wohC5","PktR3ccHglIi","mzHlakocIC3u","wTL7w8NpW6pk","J5wSaAlypVa7","3pOdmxe2sywU","v-wQFwXADiA2"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SVIJtI9Q7vGK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1598092390345,"user_tz":-120,"elapsed":3850,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"36c83aad-f6cd-4df7-afd5-5daf53bf8686"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Aug 22 10:33:05 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88vOeoOz8anO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"status":"ok","timestamp":1598092405692,"user_tz":-120,"elapsed":19100,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"8c98bfc8-b7a9-42cc-be1b-8777e7cd78ee"},"source":["!pip install youtokentome\n","!pip install pyonmttok\n","!pip install unidecode"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting youtokentome\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 6.9MB/s \n","\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n","Installing collected packages: youtokentome\n","Successfully installed youtokentome-1.0.6\n","Collecting pyonmttok\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/fc/aaa5096a948f2923d5e012409586274956368e00a6a4008412fb2807882d/pyonmttok-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 7.3MB/s \n","\u001b[?25hInstalling collected packages: pyonmttok\n","Successfully installed pyonmttok-1.18.5\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 7.4MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hGmtugi1qXGe","colab_type":"code","colab":{}},"source":["import os\n","os.environ['CUDA_HOME'] = '/usr/local/cuda-10.1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUKN4WQMp-JF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598092408723,"user_tz":-120,"elapsed":22032,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4ff3e2ff-3063-43e9-e3d9-358069f73f10"},"source":["!echo $CUDA_HOME"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/cuda-10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Npsx3vvRlruS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598092428393,"user_tz":-120,"elapsed":41634,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"e1d28a8d-c97c-4951-b3e1-7635bd2372f8"},"source":["!git clone https://github.com/NVIDIA/apex\n","%cd apex\n","!pip install -v --no-cache-dir ./\n","#!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n","%cd .."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'apex'...\n","remote: Enumerating objects: 7431, done.\u001b[K\n","remote: Total 7431 (delta 0), reused 0 (delta 0), pack-reused 7431\u001b[K\n","Receiving objects: 100% (7431/7431), 13.90 MiB | 3.44 MiB/s, done.\n","Resolving deltas: 100% (5024/5024), done.\n","/content/apex\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-yuj4o78i\n","Created temporary directory: /tmp/pip-req-tracker-ncwg_q_x\n","Created requirements tracker '/tmp/pip-req-tracker-ncwg_q_x'\n","Created temporary directory: /tmp/pip-install-cjfupvcy\n","Processing /content/apex\n","  Created temporary directory: /tmp/pip-req-build-gsy2a5pg\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-ncwg_q_x'\n","    Running setup.py (path:/tmp/pip-req-build-gsy2a5pg/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","\n","\n","    torch.__version__  = 1.6.0+cu101\n","\n","\n","    running egg_info\n","    creating /tmp/pip-req-build-gsy2a5pg/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-gsy2a5pg/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-gsy2a5pg/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-gsy2a5pg/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-gsy2a5pg/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    writing manifest file '/tmp/pip-req-build-gsy2a5pg/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-gsy2a5pg/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-gsy2a5pg has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-ncwg_q_x'\n","Building wheels for collected packages: apex\n","  Created temporary directory: /tmp/pip-wheel-bsnkb6fr\n","  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-bsnkb6fr\n","  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-gsy2a5pg/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-gsy2a5pg/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-bsnkb6fr --python-tag cp36\n","\n","\n","  torch.__version__  = 1.6.0+cu101\n","\n","\n","  /tmp/pip-req-build-gsy2a5pg/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  running bdist_wheel\n","  running build\n","  running build_py\n","  creating build\n","  creating build/lib\n","  creating build/lib/apex\n","  copying apex/__init__.py -> build/lib/apex\n","  creating build/lib/apex/pyprof\n","  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n","  creating build/lib/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n","  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n","  creating build/lib/apex/parallel\n","  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n","  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n","  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n","  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n","  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n","  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n","  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n","  creating build/lib/apex/contrib\n","  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n","  creating build/lib/apex/optimizers\n","  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n","  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n","  creating build/lib/apex/amp\n","  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n","  copying apex/amp/amp.py -> build/lib/apex/amp\n","  copying apex/amp/__version__.py -> build/lib/apex/amp\n","  copying apex/amp/compat.py -> build/lib/apex/amp\n","  copying apex/amp/_initialize.py -> build/lib/apex/amp\n","  copying apex/amp/opt.py -> build/lib/apex/amp\n","  copying apex/amp/wrap.py -> build/lib/apex/amp\n","  copying apex/amp/__init__.py -> build/lib/apex/amp\n","  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n","  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n","  copying apex/amp/handle.py -> build/lib/apex/amp\n","  copying apex/amp/utils.py -> build/lib/apex/amp\n","  copying apex/amp/frontend.py -> build/lib/apex/amp\n","  copying apex/amp/scaler.py -> build/lib/apex/amp\n","  creating build/lib/apex/normalization\n","  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n","  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n","  creating build/lib/apex/reparameterization\n","  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n","  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n","  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n","  creating build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n","  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n","  creating build/lib/apex/mlp\n","  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n","  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n","  creating build/lib/apex/RNN\n","  copying apex/RNN/models.py -> build/lib/apex/RNN\n","  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n","  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n","  copying apex/RNN/cells.py -> build/lib/apex/RNN\n","  creating build/lib/apex/pyprof/nvtx\n","  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n","  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n","  creating build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n","  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n","  creating build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n","  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n","  creating build/lib/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n","  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n","  creating build/lib/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n","  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n","  creating build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n","  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n","  creating build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n","  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n","  creating build/lib/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n","  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n","  creating build/lib/apex/amp/lists\n","  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n","  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n","  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n","  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n","  installing to build/bdist.linux-x86_64/wheel\n","  running install\n","  running install_lib\n","  creating build/bdist.linux-x86_64\n","  creating build/bdist.linux-x86_64/wheel\n","  creating build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n","  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n","  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n","  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n","  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n","  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n","  creating build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n","  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n","  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n","  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n","  creating build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n","  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n","  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n","  creating build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n","  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n","  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n","  creating build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n","  creating build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n","  running install_egg_info\n","  running egg_info\n","  creating apex.egg-info\n","  writing apex.egg-info/PKG-INFO\n","  writing dependency_links to apex.egg-info/dependency_links.txt\n","  writing top-level names to apex.egg-info/top_level.txt\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  writing manifest file 'apex.egg-info/SOURCES.txt'\n","  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.6.egg-info\n","  running install_scripts\n","  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n","  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n","  creating '/tmp/pip-wheel-bsnkb6fr/apex-0.1-cp36-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n","  adding 'apex/__init__.py'\n","  adding 'apex/RNN/RNNBackend.py'\n","  adding 'apex/RNN/__init__.py'\n","  adding 'apex/RNN/cells.py'\n","  adding 'apex/RNN/models.py'\n","  adding 'apex/amp/__init__.py'\n","  adding 'apex/amp/__version__.py'\n","  adding 'apex/amp/_amp_state.py'\n","  adding 'apex/amp/_initialize.py'\n","  adding 'apex/amp/_process_optimizer.py'\n","  adding 'apex/amp/amp.py'\n","  adding 'apex/amp/compat.py'\n","  adding 'apex/amp/frontend.py'\n","  adding 'apex/amp/handle.py'\n","  adding 'apex/amp/opt.py'\n","  adding 'apex/amp/rnn_compat.py'\n","  adding 'apex/amp/scaler.py'\n","  adding 'apex/amp/utils.py'\n","  adding 'apex/amp/wrap.py'\n","  adding 'apex/amp/lists/__init__.py'\n","  adding 'apex/amp/lists/functional_overrides.py'\n","  adding 'apex/amp/lists/tensor_overrides.py'\n","  adding 'apex/amp/lists/torch_overrides.py'\n","  adding 'apex/contrib/__init__.py'\n","  adding 'apex/contrib/groupbn/__init__.py'\n","  adding 'apex/contrib/groupbn/batch_norm.py'\n","  adding 'apex/contrib/multihead_attn/__init__.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n","  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n","  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n","  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n","  adding 'apex/contrib/optimizers/__init__.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n","  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n","  adding 'apex/contrib/optimizers/fused_adam.py'\n","  adding 'apex/contrib/optimizers/fused_lamb.py'\n","  adding 'apex/contrib/optimizers/fused_sgd.py'\n","  adding 'apex/contrib/sparsity/__init__.py'\n","  adding 'apex/contrib/sparsity/asp.py'\n","  adding 'apex/contrib/sparsity/sparse_masklib.py'\n","  adding 'apex/contrib/xentropy/__init__.py'\n","  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n","  adding 'apex/fp16_utils/__init__.py'\n","  adding 'apex/fp16_utils/fp16_optimizer.py'\n","  adding 'apex/fp16_utils/fp16util.py'\n","  adding 'apex/fp16_utils/loss_scaler.py'\n","  adding 'apex/mlp/__init__.py'\n","  adding 'apex/mlp/mlp.py'\n","  adding 'apex/multi_tensor_apply/__init__.py'\n","  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n","  adding 'apex/normalization/__init__.py'\n","  adding 'apex/normalization/fused_layer_norm.py'\n","  adding 'apex/optimizers/__init__.py'\n","  adding 'apex/optimizers/fused_adagrad.py'\n","  adding 'apex/optimizers/fused_adam.py'\n","  adding 'apex/optimizers/fused_lamb.py'\n","  adding 'apex/optimizers/fused_novograd.py'\n","  adding 'apex/optimizers/fused_sgd.py'\n","  adding 'apex/parallel/LARC.py'\n","  adding 'apex/parallel/__init__.py'\n","  adding 'apex/parallel/distributed.py'\n","  adding 'apex/parallel/multiproc.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm.py'\n","  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n","  adding 'apex/parallel/sync_batchnorm.py'\n","  adding 'apex/parallel/sync_batchnorm_kernel.py'\n","  adding 'apex/pyprof/__init__.py'\n","  adding 'apex/pyprof/nvtx/__init__.py'\n","  adding 'apex/pyprof/nvtx/nvmarker.py'\n","  adding 'apex/pyprof/parse/__init__.py'\n","  adding 'apex/pyprof/parse/__main__.py'\n","  adding 'apex/pyprof/parse/db.py'\n","  adding 'apex/pyprof/parse/kernel.py'\n","  adding 'apex/pyprof/parse/nvvp.py'\n","  adding 'apex/pyprof/parse/parse.py'\n","  adding 'apex/pyprof/prof/__init__.py'\n","  adding 'apex/pyprof/prof/__main__.py'\n","  adding 'apex/pyprof/prof/activation.py'\n","  adding 'apex/pyprof/prof/base.py'\n","  adding 'apex/pyprof/prof/blas.py'\n","  adding 'apex/pyprof/prof/conv.py'\n","  adding 'apex/pyprof/prof/convert.py'\n","  adding 'apex/pyprof/prof/data.py'\n","  adding 'apex/pyprof/prof/dropout.py'\n","  adding 'apex/pyprof/prof/embedding.py'\n","  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n","  adding 'apex/pyprof/prof/linear.py'\n","  adding 'apex/pyprof/prof/loss.py'\n","  adding 'apex/pyprof/prof/misc.py'\n","  adding 'apex/pyprof/prof/normalization.py'\n","  adding 'apex/pyprof/prof/optim.py'\n","  adding 'apex/pyprof/prof/output.py'\n","  adding 'apex/pyprof/prof/pointwise.py'\n","  adding 'apex/pyprof/prof/pooling.py'\n","  adding 'apex/pyprof/prof/prof.py'\n","  adding 'apex/pyprof/prof/randomSample.py'\n","  adding 'apex/pyprof/prof/recurrentCell.py'\n","  adding 'apex/pyprof/prof/reduction.py'\n","  adding 'apex/pyprof/prof/softmax.py'\n","  adding 'apex/pyprof/prof/usage.py'\n","  adding 'apex/pyprof/prof/utility.py'\n","  adding 'apex/reparameterization/__init__.py'\n","  adding 'apex/reparameterization/reparameterization.py'\n","  adding 'apex/reparameterization/weight_norm.py'\n","  adding 'apex-0.1.dist-info/LICENSE'\n","  adding 'apex-0.1.dist-info/METADATA'\n","  adding 'apex-0.1.dist-info/WHEEL'\n","  adding 'apex-0.1.dist-info/top_level.txt'\n","  adding 'apex-0.1.dist-info/RECORD'\n","  removing build/bdist.linux-x86_64/wheel\n","\u001b[?25hdone\n","  Created wheel for apex: filename=apex-0.1-cp36-none-any.whl size=192848 sha256=9b0b99111fb8c3c7645a418677b649e85b857ac453325ae227703891f9253e5d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-yuj4o78i/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n","  Removing source in /tmp/pip-req-build-gsy2a5pg\n","Successfully built apex\n","Installing collected packages: apex\n","\n","Successfully installed apex-0.1\n","Cleaning up...\n","Removed build tracker '/tmp/pip-req-tracker-ncwg_q_x'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aE2E1HaU8x1T","colab_type":"code","colab":{}},"source":["import copy\n","import math\n","import random\n","import re\n","import time\n","\n","from apex import amp\n","import nltk\n","import numpy as np\n","import youtokentome as yttm\n","import pyonmttok\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import unidecode"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tum1ZTIDZlGu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598092453352,"user_tz":-120,"elapsed":66470,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4b215a20-ea8a-4b5c-975e-b35aa3e1b290"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4cdQ3L6n88e2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598092622495,"user_tz":-120,"elapsed":1207,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"79e13a2b-c9c5-457c-9106-f217eabc5edb"},"source":["%cd 'drive/My Drive/Colab Notebooks'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WdFXG9B9Qg4G","colab_type":"code","colab":{}},"source":["pad = 0\n","sos = 2\n","eos = 3\n","\n","#zenbat_handitu_helb = 6\n","#zenbat_handitu_jat = 4\n","\n","max_seq_len = 120\n","vocab_size = 20000\n","d_model = 512    # Hitza adierazteko bektoreen luzera\n","N = 6            # Geruza kopurua\n","heads = 8        # Attention-head kopurua\n","\n","batch_size = 90#128\n","batch_size_val = 50\n","epochs = 40\n","zenbatero_idatzi = 100\n","#dev_kop = 1000\n","#zenbatero_balidatu = 1000\n","#zenbatero_gorde = 10000\n","\n","fp16 = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTFAiFrRNBK5","colab_type":"code","colab":{}},"source":["bpe_hirurak = yttm.BPE(model='HACOSDatuak/bpe_hirurak.model')\n","#bpe_hirurak = yttm.BPE(model='EhuHac/bpe_hirurak2.model')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9rdLDL7fUm3e","colab_type":"text"},"source":["# Transformer-a"]},{"cell_type":"code","metadata":{"id":"4-wZnIAbq4my","colab_type":"code","colab":{}},"source":["class Embedder(nn.Module):\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","    def forward(self, x):\n","        return self.embed(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K99OLL1FqkDV","colab_type":"code","colab":{}},"source":["class PositionalEncoder(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","        self.d_model = d_model\n","        # Orain dagoen moduan, max_seq_len aldagai globalak definituta egon\n","        # behar du\n","        pe = torch.zeros(max_seq_len, d_model)\n","        for pos in range(max_seq_len):\n","            for i in range(0, d_model, 2):\n","                pe[pos, i] = \\\n","                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n","                pe[pos, i + 1] = \\\n","                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n","                \n","        pe.unsqueeze_(0) # Lista -> [Lista]. in-place egiteak ezer aldatzen du?\n","        # batch_size dimentsioa gehitzeko\n","        # Zergatik tentsoreekin bai eta zenbakiekin (d_model) ez?\n","        self.register_buffer('pe', pe)\n"," \n","    \n","    def forward(self, x):\n","        # Hasierako embedding-ak pisu handiagoa izateko, suposatzen da:\n","        x = x * math.sqrt(self.d_model)\n","        seq_len = x.size(1)\n","        # Bi adibideetan hemen Variable torch.tensor-en ordez:\n","        # x = x + torch.tensor(self.pe[:,:seq_len], requires_grad=False).cuda()\n","        #print(\"Size x: \" + str(x.size()))\n","        #print(\"Size pe: \" + str(self.pe.size()))\n","        x = x + self.pe[:,:seq_len] # <- Hau bakarrik eginda zer aldatzen da?\n","        # Bai beste adibidean eta honen GitHub-eko kodean: \n","        # return self.dropout(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44Q3yHDQRLHx","colab_type":"code","colab":{}},"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, heads, d_model, dropout = 0.1):\n","        super().__init__()\n","        \n","        self.d_model = d_model\n","        self.d_k = d_model // heads\n","        # Suposatzen da tamainak ez duela zertan hori izan behar, baina\n","        # multi-head izateagatik kalkulu gehiago egitea saihesten du\n","        self.h = heads\n","        \n","        # Attention head guztiak batera:\n","        self.q_linear = nn.Linear(d_model, d_model)\n","        self.v_linear = nn.Linear(d_model, d_model)\n","        self.k_linear = nn.Linear(d_model, d_model)\n","        self.dropout = nn.Dropout(dropout)     \n","        self.out = nn.Linear(d_model, d_model)  # Artikuluko WO matrizea\n","    \n","    def forward(self, q, k, v, mask=None):\n","        \n","        # Encoder-etan, q, k eta v-tik gauza bera iritsiko zaio, \n","        # sarrera embedding-arekin (edo aurreko geruzako irteera). \n","        # Decoder-etan, 1.an, irteerako aurrekoak hiruretatik (edo aurreko \n","        # geruzakoa).\n","        # 2.ean, q-tik 1.aren emaitza, eta k eta v-tik encoder-aren irteera.\n","        \n","        bs = q.size(0)\n","        \n","        # Buru guztiak elkartuta k, q eta v lortu, eta gero buruak banatu\n","        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n","        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n","        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n","        \n","        # sl = sentence length\n","        \n","        # transpose to get dimensions bs * h * sl * d_k\n","        # Artikuluan d_k beharrean d_model jartzen du\n","       \n","        k = k.transpose(1,2)\n","        q = q.transpose(1,2)\n","        v = v.transpose(1,2)\n","\n","        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n","        # Dimentsioak: bs*h*sl*d_k\n","        \n","        # concatenate heads and put through final linear layer\n","        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n","        # Uste dut reshape() egitea edo contiguous() + view() berdina dela\n","        \n","        # Dimentsioak = bs*sl*d_model (d_model = d_k*heads delako, \n","        # bestela handiagoa izan zitekeen)\n","        \n","        output = self.out(concat)\n","        \n","        # Dimentsioak = bs*sl*d_model\n","    \n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ziy35eSfSW7n","colab_type":"code","colab":{}},"source":["def attention(q, k, v, d_k, mask=None, dropout=None):\n","    \n","    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n","    # Lehenengo 2 dimentsioak, bs eta h, independente mantentzen dira\n","    # Beste 2ekin, sl eta d_k, matrize-biderketa normala, \n","    # batch eta head bakoitzean. Emaitza: bs*h*sl*sl, hitz bakoitzeko esaldiko \n","    # beste hitz bakoitzari eman beharreko \"garrantzia\".\n","    \n","    if mask is not None:\n","        mask = mask.unsqueeze(1) # Head-i dagokion dimentsioa sortzeko\n","        #print(\"Maskara \" + str(mask.size()))\n","        #print(\"Scores \" + str(scores.size()))\n","        #print(mask)\n","        scores = scores.masked_fill(mask == 0, -1e4)\n","        #print(\"Scores: \")\n","        #print(scores)\n","        # Maskaran dagokion balioa 0 denean, mask == 0 True (1), \n","        # -1e9 jartzen du, -1 000 000 000 (-inf 'illustrated' artikuluan)\n","        # Zergatik? Nonbaitetik etor daitezke negatiboak?\n","    scores = F.softmax(scores, dim=-1)\n","    # softmax azkeneko dimentsioan zehar\n","    \n","    #print(\"Scores softmax: \")\n","    #print(scores)\n","    \n","    if dropout is not None:\n","        scores = dropout(scores)\n","        \n","    output = torch.matmul(scores, v)\n","    # Dimentsioak: bs*h*sl*d_k\n","    \n","    #print(\"Output: \")\n","    #print(output)\n","    \n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDQQ6PumDEav","colab_type":"code","colab":{}},"source":["# Posizioka exekutatuko da. Posizio desberdinek parametroak partekatuta,\n","# baina geruza desberdinek ez\n","class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n","        super().__init__() \n","        # d_ff = ezkutuko geruzaren tamaina, originalean 2048\n","        self.linear_1 = nn.Linear(d_model, d_ff)\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear_2 = nn.Linear(d_ff, d_model)\n","    def forward(self, x):\n","        x = self.dropout(F.relu(self.linear_1(x)))\n","        x = self.linear_2(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbXVxdymOQGc","colab_type":"code","colab":{}},"source":["class Norm(nn.Module):\n","    def __init__(self, d_model, eps = 1e-6):\n","        super().__init__()\n","    \n","        self.size = d_model # forward-en ez da erabiltzen. Zertarako gorde?\n","        # Normalizazioa doitzeko parametroak. Zergatik?\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","        self.eps = eps\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True) # dimentsioak = bs*sl*1\n","        std = x.std(dim=-1, keepdim=True)\n","        norm = self.alpha * (x - mean) / (std + self.eps) + self.bias\n","        return norm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuSuRjScmR4Z","colab_type":"code","colab":{}},"source":["def get_clones(module, N):\n","    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XK8nHCq3mfGH","colab_type":"code","colab":{}},"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout = 0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.attn = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        \n","    def forward(self, x, mask):\n","        # Zergatik normalizazioak hor eta ez artikuluan bezala?\n","        x2 = self.norm_1(x)\n","        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n","        x2 = self.norm_2(x)\n","        x = x + self.dropout_2(self.ff(x2))\n","        return x\n","    \n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","        \n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        self.dropout_3 = nn.Dropout(dropout)\n","        \n","        self.attn_1 = MultiHeadAttention(heads, d_model)\n","        self.attn_2 = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model) #.cuda()\n","  \n","    def forward(self, x, e_outputs, src_mask, trg_mask):\n","          # e_outputs: encoder-aren irteera\n","          # src_mask: paddind-erako maskara, encoder-ean erabiltzen dena,\n","          #    e_outputs-i aplikatzeko\n","          # trg_mask: nopeek_mask gehitzen dio besteari\n","          x2 = self.norm_1(x)\n","          x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n","          x2 = self.norm_2(x)\n","          x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs,\n","          src_mask))\n","          x2 = self.norm_3(x)\n","          x = x + self.dropout_3(self.ff(x2))\n","          return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHaKLhJmqSB8","colab_type":"code","colab":{}},"source":["class DualDecoderLayer(nn.Module):\n","    def __init__(self, d_model, heads, dropout=0.1):\n","        super().__init__()\n","        self.norm_1 = Norm(d_model)\n","        self.norm_2 = Norm(d_model)\n","        self.norm_3 = Norm(d_model)\n","        self.norm_4 = Norm(d_model)\n","        \n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","        self.dropout_3 = nn.Dropout(dropout)\n","        self.dropout_4 = nn.Dropout(dropout)\n","        \n","        self.attn_1 = MultiHeadAttention(heads, d_model)\n","        self.attn_2 = MultiHeadAttention(heads, d_model)\n","        self.attn_3 = MultiHeadAttention(heads, d_model)\n","        self.ff = FeedForward(d_model)\n","  \n","    def forward(self, x, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask):\n","          # e1_outputs: SRC encoder-aren irteeera\n","          # e2_outputs: MT encoder-aren irteera\n","          # src1_mask: SRCko esaldien maskara\n","          # src2_mask: MTko esaldien maskara\n","          x2 = self.norm_1(x)\n","          x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n","          x2 = self.norm_2(x)\n","          x = x + self.dropout_2(self.attn_2(x2, e2_outputs, e2_outputs,\n","          src2_mask))\n","          x2 = self.norm_3(x)\n","          x = x + self.dropout_3(self.attn_3(x2, e1_outputs, e1_outputs,\n","          src1_mask))\n","          x2 = self.norm_4(x)\n","          x = x + self.dropout_4(self.ff(x2))\n","          return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvgpEMZ2BUzh","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model) # Ez dio max_seq pasatzen\n","        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, src, mask):\n","        x = self.embed(src)\n","        x = self.pe(x)\n","        for i in range(N):\n","            x = self.layers[i](x, mask)\n","        return self.norm(x)\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e_outputs, src_mask, trg_mask):\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n","        return self.norm(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"audCdi1Dvv9v","colab_type":"code","colab":{}},"source":["class DualDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.embed = Embedder(vocab_size, d_model)\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(DualDecoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask):\n","        x = self.embed(trg)\n","        x = self.pe(x)\n","        for i in range(self.N):\n","            x = self.layers[i](x, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask)\n","        return self.norm(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRsP6XaNeBa2","colab_type":"code","colab":{}},"source":["class SharedEncoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.pe = PositionalEncoder(d_model) # Ez dio max_seq pasatzen\n","        self.layers = get_clones(EncoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, src, mask):\n","        # src Embedder-etik pasata jaso behar du\n","        x = self.pe(src)\n","        for i in range(N):\n","            x = self.layers[i](x, mask)\n","        return self.norm(x)\n","      \n","class SharedDualDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(DualDecoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask):\n","        # trg Embedder-etik pasata jaso behar du\n","        x = self.pe(trg)\n","        for i in range(self.N):\n","            #print('2a:', i, torch.cuda.memory_allocated(0))\n","            x = self.layers[i](x, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask)\n","        return self.norm(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbz52PWLr2yB","colab_type":"code","colab":{}},"source":["class SharedDecoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.N = N\n","        self.pe = PositionalEncoder(d_model)\n","        self.layers = get_clones(DecoderLayer(d_model, heads), N)\n","        self.norm = Norm(d_model)\n","    def forward(self, trg, e1_outputs, src1_mask, trg_mask):\n","        # trg Embedder-etik pasata jaso behar du\n","        x = self.pe(trg)\n","        for i in range(self.N):\n","            #print('2a:', i, torch.cuda.memory_allocated(0))\n","            x = self.layers[i](x, e1_outputs, src1_mask, trg_mask)\n","        return self.norm(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuB8xQ6NDBHi","colab_type":"code","colab":{}},"source":["class Transformer(nn.Module):\n","    def __init__(self, src_vocab, trg_vocab, d_model, N, heads):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab, d_model, N, heads)\n","        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","    def forward(self, src, trg, src_mask, trg_mask):\n","        e_outputs = self.encoder(src, src_mask)\n","        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_ub0qLbvTy9","colab_type":"code","colab":{}},"source":["class DualTransformer(nn.Module):\n","    def __init__(self, src1_vocab, src2_vocab, trg_vocab, d_model, N, heads):\n","        super().__init__()\n","        self.encoder1 = Encoder(src1_vocab, d_model, N, heads)\n","        self.encoder2 = Encoder(src2_vocab, d_model, N, heads)\n","        self.decoder = DualDecoder(trg_vocab, d_model, N, heads)\n","        self.out = nn.Linear(d_model, trg_vocab)\n","    def forward(self, src1, src2, trg, src1_mask, src2_mask, trg_mask):\n","        e1_outputs = self.encoder1(src1, src1_mask)\n","        e2_outputs = self.encoder2(src2, src2_mask)\n","        d_output = self.decoder(trg, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtfnLWURfQjU","colab_type":"code","colab":{}},"source":["class SharedDualTransformer(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.embed = Embedder(vocab_size, d_model)       \n","        self.encoder = SharedEncoder(vocab_size, d_model, N, heads)\n","        self.decoder = SharedDualDecoder(vocab_size, d_model, N, heads)\n","        self.out = nn.Linear(d_model, vocab_size)\n","    def forward(self, src1, src2, trg, src1_mask, src2_mask, trg_mask):\n","        emb = self.embed(src1)\n","        e1_outputs = self.encoder(emb, src1_mask)\n","        emb = self.embed(src2)\n","        e2_outputs = self.encoder(emb, src2_mask)\n","        emb = self.embed(trg)\n","        d_output = self.decoder(emb, e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxqdFL38rXc9","colab_type":"code","colab":{}},"source":["class SharedTransformer(nn.Module):\n","    def __init__(self, vocab_size, d_model, N, heads):\n","        super().__init__()\n","        self.embed = Embedder(vocab_size, d_model)       \n","        self.encoder = SharedEncoder(vocab_size, d_model, N, heads)\n","        self.decoder = SharedDecoder(vocab_size, d_model, N, heads)\n","        self.out = nn.Linear(d_model, vocab_size)\n","    def forward(self, src1, trg, src1_mask, trg_mask):\n","        emb = self.embed(src1)\n","        e1_outputs = self.encoder(emb, src1_mask)\n","        emb = self.embed(trg)\n","        d_output = self.decoder(emb, e1_outputs, src1_mask, trg_mask)\n","        output = self.out(d_output)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DOKdI8iHgcE7","colab_type":"text"},"source":["# Parametro kopurua"]},{"cell_type":"code","metadata":{"id":"tVVvkyk-gi0b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595068860506,"user_tz":-120,"elapsed":2022,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"8274dab2-b87e-43b1-a621-33a2b0d195bc"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(count_parameters(model))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["70950432\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gkrjpdHLiMTh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595069254577,"user_tz":-120,"elapsed":1993,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"247f4dfc-1b79-4f5d-9ead-3024f48ab303"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","print(count_parameters(model))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["64640544\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g6AfI7Jb1kww","colab_type":"text"},"source":["# Garbiketa"]},{"cell_type":"markdown","metadata":{"id":"OVANBl7550w_","colab_type":"text"},"source":["## Azentuak euskarazko hitzetan"]},{"cell_type":"code","metadata":{"id":"kEgbzuyP1phM","colab_type":"code","colab":{}},"source":["with open('EhuHac/EhuHac-eu.txt') as fitx:\n","    hitzak = fitx.read().split()\n","\n","hiztegia = dict()\n","for hitza in hitzak:\n","    if hitza in hiztegia:\n","        hiztegia[hitza] += 1\n","    else:\n","        if re.search('[áéíóúàèìòùÁÉÍÓÚÀÈÌÒÙ]', hitza):\n","            hiztegia[hitza] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aq-KrKIs4Csd","colab_type":"code","colab":{}},"source":["hiztegia_list = list(hiztegia.items())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h64HQgUeJ6Sg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1579795634790,"user_tz":-60,"elapsed":9834,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"b29548d0-a794-47d4-f851-b5e3487ac62a"},"source":["len(hiztegia_list)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1483"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"JJHAmoRFMr3m","colab_type":"text"},"source":["300-400, 700->1300"]},{"cell_type":"code","metadata":{"id":"lUBVFweFEpd7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1579795742219,"user_tz":-60,"elapsed":1640,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"1d2479bd-ba29-458d-c0ef-8856026db65f"},"source":["hiztegia_list[700:1300]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('matiné', 1),\n"," ('barátom.', 1),\n"," ('Három', 1),\n"," ('éljen!', 1),\n"," ('Písek,', 1),\n"," ('Kontuszówka', 1),\n"," ('\"à', 4),\n"," ('fénrich,', 1),\n"," ('Holarjó,', 1),\n"," ('holarjó,', 1),\n"," ('Khún', 1),\n"," ('biró', 1),\n"," ('anyát,', 1),\n"," ('Márját,', 1),\n"," ('atyádot,', 1),\n"," ('világot!.', 1),\n"," ('Napló\"', 1),\n"," ('Napló\",', 1),\n"," ('Napló\"-n:', 1),\n"," ('Savanyú', 1),\n"," ('áld', 1),\n"," ('\"Zdrávstvuitte,', 1),\n"," ('kraitsová', 1),\n"," ('porypaná,', 1),\n"," ('vám', 1),\n"," ('-\"Velké', 1),\n"," ('rechnungsfeldvébl-ak.', 1),\n"," ('rechnungsfeldvébl', 3),\n"," ('-Rechnungsfeldvébl', 2),\n"," ('rechnungsfeldvébl-ak', 2),\n"," ('rechnungsfeldvébl-a', 2),\n"," ('Klófatsch.', 1),\n"," ('feldmäßigschießübungách', 1),\n"," ('ezagútu.', 1),\n"," ('izangó', 1),\n"," ('Nicolás', 1),\n"," ('Loubère-k', 1),\n"," (\"D'où\", 1),\n"," ('là?', 1),\n"," ('pénitence', 1),\n"," ('Caporál-a', 1),\n"," ('generál-a', 1),\n"," ('caporál-a-agertu', 1),\n"," ('generál', 6),\n"," ('generál,', 1),\n"," ('-Generál', 1),\n"," ('\"Generál', 2),\n"," ('caporál', 1),\n"," ('Capitán', 3),\n"," ('-Caporál', 1),\n"," ('Caporál', 1),\n"," ('capitán', 5),\n"," ('Capitán-a', 1),\n"," ('Patrón-esan', 1),\n"," ('Sèvreseko', 1),\n"," ('Rémusatek', 1),\n"," ('sémou\"', 1),\n"," ('Bérangerren', 1),\n"," ('\"Copégoro\"', 1),\n"," ('\"Copégoro\"ri,', 1),\n"," ('Cádiz', 1),\n"," ('phénix', 1),\n"," ('gaieté', 1),\n"," ('établissement', 1),\n"," ('-Où', 1),\n"," ('nuèn', 164),\n"," ('ninduèn', 24),\n"," ('genuèn', 22),\n"," ('zizkidatèn', 4),\n"," ('nintzèn', 65),\n"," ('nengoèn', 9),\n"," ('nerabilèn', 2),\n"," ('nentzàn', 1),\n"," ('zukeèn', 41),\n"," ('nituèn', 63),\n"," ('zirèn', 150),\n"," ('Débats', 6),\n"," ('zebilèn', 5),\n"," ('zidàn', 54),\n"," ('Doncièresen,', 1),\n"," ('neukàn', 20),\n"," ('ziharduèn', 8),\n"," ('bazuèn', 2),\n"," ('zituèn', 165),\n"," ('zitzaiòn', 50),\n"," ('zièn', 26),\n"," ('zutèn', 113),\n"," ('zekarkiotèn', 2),\n"," ('zegoèn', 82),\n"," ('zeukatèn', 9),\n"," ('ziòn', 100),\n"," ('nintzatekeèn', 1),\n"," ('zekiketèn', 1),\n"," ('zeramàn', 20),\n"," ('zeudekeèn', 4),\n"," ('d´Orléans-en,', 1),\n"," ('zeritzòn', 5),\n"," ('genituèn', 21),\n"," ('zerabilèn', 6),\n"," ('zetozèn', 4),\n"," ('zekièn', 5),\n"," ('zitzaigùn', 3),\n"," ('Sacré-Coeur-en', 1),\n"," ('\"Sevignék', 1),\n"," ('geniòn', 2),\n"," ('zezakeèn', 40),\n"," ('Molé-ren,', 1),\n"," ('ziezaiokeèn', 6),\n"," ('zituztèn', 35),\n"," ('genizkiòn', 4),\n"," ('zeukàn', 51),\n"," ('zirudièn', 21),\n"," ('nukeèn', 15),\n"," ('zekidakeèn', 1),\n"," ('Céline,', 1),\n"," ('Célinek,', 1),\n"," ('Célinek', 3),\n"," ('Moléren', 1),\n"," ('Célinek.', 1),\n"," ('Maulévrierek', 1),\n"," ('Maulévrier', 1),\n"," ('Céline', 1),\n"," ('zituzkeèn', 11),\n"," ('nezakeèn', 5),\n"," ('Molièreren', 1),\n"," ('zidatèn', 18),\n"," ('niòn', 7),\n"," ('ziezaizkiokeèn', 1),\n"," ('erregeenganako-zeukàn', 1),\n"," ('berak-granité-aketa', 1),\n"," ('zituzketèn', 4),\n"," ('Tréviseko', 1),\n"," ('zitezkeèn', 9),\n"," ('zitzaidàn', 29),\n"," ('zekartèn', 2),\n"," ('zetorkièn', 1),\n"," ('zeriòn', 6),\n"," ('zetorkidàn', 1),\n"," ('zitzaizkidàn', 11),\n"," ('zezaketèn', 9),\n"," ('zizkidàn', 12),\n"," ('zizkiòn', 34),\n"," ('zietèn', 6),\n"," ('zekarzkidàn', 2),\n"," ('zekarzkiòn', 1),\n"," ('zeritzàn', 8),\n"," ('zitekeèn', 21),\n"," ('nintzaiòn', 3),\n"," ('Léoniek,', 1),\n"," ('ziekeèn', 3),\n"," ('nindutèn', 8),\n"," ('Flesché-ren', 1),\n"," ('Léonie', 4),\n"," ('zetxezkiòn', 3),\n"," ('Vichy-Célestins', 1),\n"," ('geundèn', 6),\n"," ('Léoniek', 5),\n"," ('ginèn', 10),\n"," ('zèn\"', 1),\n"," ('zenuèn', 2),\n"," ('zuèn\"', 1),\n"," ('Théodorek', 3),\n"," ('ginderamatzàn', 2),\n"," ('zitzaizkiòn', 13),\n"," ('zirauèn', 4),\n"," ('zihoazèn', 3),\n"," ('zeniòn', 1),\n"," ('zeutzàn', 2),\n"," ('Léonieri', 2),\n"," ('Théodoreren', 1),\n"," ('zebiltzàn', 5),\n"," ('zegièn', 2),\n"," ('zeukakeèn', 1),\n"," ('lavallière', 2),\n"," ('Légrandinen', 1),\n"," ('Théodore', 4),\n"," ('Théodoreri', 3),\n"," ('ziruditèn', 7),\n"," ('zigùn', 7),\n"," ('zeudèn', 28),\n"," ('César', 1),\n"," ('Opéra-Comiqueren', 1),\n"," ('Comédie', 1),\n"," ('nizkiòn', 4),\n"," ('Théâtre-Français-etik', 1),\n"," ('zitzaiokeèn', 3),\n"," ('nintzaièn', 5),\n"," ('zirudikeèn', 3),\n"," ('nièn', 7),\n"," ('nizkiokeèn', 1),\n"," ('zegozkièn', 1),\n"," ('nindukeèn', 2),\n"," ('zihoakiòn', 3),\n"," ('ziotèn', 23),\n"," ('niharduèn', 4),\n"," ('Méséglise', 20),\n"," ('Pasiphaé\".', 1),\n"," ('Père', 1),\n"," ('Lévrier', 1),\n"," ('Pères\"', 1),\n"," ('\"À', 1),\n"," ('Israélite', 1),\n"," ('Hébron,', 1),\n"," ('vallé', 1),\n"," ('élue.', 1),\n"," ('zuketèn', 4),\n"," ('Pasiphaéren', 1),\n"," ('nerabiltzàn', 1),\n"," ('zekartzàn', 1),\n"," ('Phèdre-z,', 1),\n"," ('nizkièn', 3),\n"," ('Phèdre-n,', 1),\n"," ('zerabiltzàn', 3),\n"," ('-Amédée', 2),\n"," ('Hélier,', 1),\n"," ('Éloi,', 1),\n"," ('Saint-Assise-lès-Combrayko', 1),\n"," ('méchants', 1),\n"," ('s´écoule', 1),\n"," ('Léonierentzat,', 1),\n"," ('zegokigùn', 1),\n"," ('gintuèn', 1),\n"," ('zerizkiòn', 2),\n"," ('zeukakèen', 1),\n"," ('zatekeèn', 12),\n"," ('zegokeèn', 6),\n"," ('zegozkiòn', 4),\n"," ('Léonie-esan', 1),\n"," ('geneukàn', 3),\n"," ('Fabrék', 1),\n"," ('Léonierengana,', 1),\n"," ('zerabiltzakeèn', 1),\n"," ('Léonie-zioen', 1),\n"," ('Méséglise-la-Vineuse', 2),\n"," ('Méséglise-la-Vineusetik,', 1),\n"," ('\"Méséglisetik', 1),\n"," ('Méséglise,', 1),\n"," ('Méséglisera', 1),\n"," ('neramàn', 2),\n"," ('Élysées', 2),\n"," ('-Léonie-esan', 1),\n"," ('Léonieri,', 1),\n"," ('zetxezkièn', 1),\n"," ('Saint-André-des-Champs-eko', 1),\n"," ('Saint-André-des-Champseko', 4),\n"," ('Léonie,', 1),\n"," ('Saint-André-des-Champs', 3),\n"," ('Théodorerena', 1),\n"," ('Léonieren', 1),\n"," ('zeuzkàn', 11),\n"," ('zekarrèn', 1),\n"," ('zegokiòn', 6),\n"," ('ziezadaketèn', 2),\n"," ('Méségliseko', 2),\n"," ('nituzkeèn', 3),\n"," ('ninduketèn', 2),\n"," ('neritzòn', 1),\n"," ('zegokiokeèn', 2),\n"," ('zebilkeèn', 2),\n"," ('jubé-galeria', 1),\n"," ('Léonie-,', 1),\n"," ('cloisonnée', 1),\n"," ('bazekièn', 2),\n"," ('ziezadakeèn', 1),\n"," ('Léongo', 1),\n"," ('nekusàn', 5),\n"," ('ziezazkidaketèn', 1),\n"," ('\"délicieux\",', 1),\n"," ('Planté', 1),\n"," ('soiréeak', 1),\n"," ('Crécy', 11),\n"," ('Crécyk', 1),\n"," ('zizkièn', 2),\n"," ('ziokeèn', 2),\n"," ('mystère?', 1),\n"," ('zinèn', 2),\n"," ('zeramatzàn', 4),\n"," ('nindukezùn', 1),\n"," ('Crécyren', 2),\n"," ('zegokièn', 4),\n"," ('\"beauté', 1),\n"," ('élégances\"', 1),\n"," ('réduit', 1),\n"," ('zizkiotèn', 7),\n"," ('bazihoàn', 1),\n"," ('zerraièn', 1),\n"," ('tournéean', 1),\n"," ('première,', 1),\n"," ('Grévy-renean-erantzun', 1),\n"," ('Grévyrekin?', 1),\n"," ('Grévy?', 1),\n"," ('Grévyrenera', 1),\n"," ('Grévyrekin.', 1),\n"," ('Rémi', 3),\n"," ('Pérouse', 6),\n"," ('\"coupé\"an', 1),\n"," ('Rémiren', 1),\n"," ('zirudiketèn', 1),\n"," ('Dorée\"tik', 1),\n"," ('zitzaizkièn', 5),\n"," ('Prévost-enera', 3),\n"," ('Prévostenera', 1),\n"," ('Prévosteneko', 1),\n"," ('zekarkiòn', 1),\n"," ('Prévost-enean;', 1),\n"," ('Rémik', 4),\n"," ('nizùn', 1),\n"," ('Rémik-,', 1),\n"," ('zizkigùn', 1),\n"," ('Dorée-raino', 1),\n"," ('Prévostenean', 2),\n"," ('Dorée-ra', 1),\n"," ('zerakarkeèn', 1),\n"," ('zekiokeèn', 2),\n"," ('\"negligé\"', 1),\n"," ('bazihoazèn', 1),\n"," ('zemaiòn', 1),\n"," ('zeramakeèn', 1),\n"," ('zekusàn', 1),\n"," ('Éden', 1),\n"," ('Théâtre-a,', 1),\n"," ('ziezazkiokeèn', 1),\n"," ('d´Orléanseko', 2),\n"," ('\"Thé', 1),\n"," ('Métra', 1),\n"," ('ziezaioketèn', 2),\n"," ('Bréchot,', 1),\n"," ('Théâtre-Français-ean,', 1),\n"," ('zukèen', 1),\n"," ('Théâtre-Français-eko', 1),\n"," ('Bréchot', 1),\n"," ('Trémoïlle-renean,', 1),\n"," ('zioketèn', 2),\n"," ('Trémoïlle', 1),\n"," ('Trémoïlletar', 1),\n"," ('Fénelon', 1),\n"," ('Fénelonengan,', 1),\n"," ('Trémouailletar', 1),\n"," ('Trémouilletar', 1),\n"," ('Trémouaille', 1),\n"," ('Trémouille', 1),\n"," ('zebilkiòn', 1),\n"," ('Trémoïllez', 1),\n"," ('Trémoïlle\"tarrak', 1),\n"," ('Trémoïlle\"tarrak,', 1),\n"," ('Trémoïlle\",', 1),\n"," ('zetorkiòn', 2),\n"," ('Pérouse-ra', 1),\n"," ('zitzakeèn', 7),\n"," ('lezakeèn', 1),\n"," ('zitekèen', 1),\n"," ('zirautèn', 1),\n"," ('zirakiòn', 1),\n"," ('zitzaizkiòn,', 1),\n"," ('zihoakièn', 1),\n"," ('ziratekeèn', 4),\n"," ('Opéra-Comique-ra', 1),\n"," ('Massé', 1),\n"," ('Opéra-Comiquera', 1),\n"," ('zeragiòn', 1),\n"," ('Compiègneko', 4),\n"," ('Compiègne', 1),\n"," ('Lapérouse.', 1),\n"," ('zioèn', 1),\n"," ('Incohérents\"', 1),\n"," ('zerabilèn,', 1),\n"," ('leramakeèn', 1),\n"," ('zerièn', 3),\n"," ('zihoazkiòn', 1),\n"," ('zirakièn', 3),\n"," ('zitzaizkiokeèn', 2),\n"," ('Mémé', 3),\n"," ('Grévin', 1),\n"," ('zetxekiòn', 1),\n"," ('Lorédan,', 1),\n"," ('Pérousse', 1),\n"," ('Lorédan', 2),\n"," ('Lorédanek', 2),\n"," ('genezakeèn', 3),\n"," ('Pérousse-n', 1),\n"," ('zuèn-eta,', 1),\n"," ('zitzaiòn-jendearekin', 1),\n"," ('zeramatzatèn', 2),\n"," ('Bréauté-ko', 1),\n"," ('Bréauté-ren', 1),\n"," ('Bréauté', 5),\n"," ('Saint-Candé-rena,', 1),\n"," ('Orphée-ko', 1),\n"," ('\"Elzár', 1),\n"," ('zirèn,', 1),\n"," ('Mérimée-rengandik', 1),\n"," ('Halévy-ren', 1),\n"," ('Iéna-tarrak.', 1),\n"," ('Iénako', 1),\n"," ('Méméren', 1),\n"," ('Pérouse...', 1),\n"," ('Pérouse-esan', 1),\n"," ('Dorée\"ren', 1),\n"," ('zerabilkiòn', 1),\n"," ('zerauntsàn', 1),\n"," ('Clèves', 1),\n"," ('René-ren', 1),\n"," ('Ampère', 2),\n"," ('hidàn', 1),\n"," ('Rémirengana', 1),\n"," ('zèn,', 1),\n"," ('zekizkièn', 2),\n"," ('Barrière-ren', 1),\n"," ('Bréauté,', 1),\n"," ('poète', 1),\n"," ('zeritzèn', 1),\n"," ('zuèn,', 2),\n"," ('niàn', 1),\n"," ('Prévost-enean', 1),\n"," ('Dorée-n', 1),\n"," ('Dorée-ri', 1),\n"," ('Dorée', 2),\n"," ('ziratekèen', 1),\n"," ('zuèn-baina', 1),\n"," ('zuèn-bolada', 1),\n"," ('\"Légion', 1),\n"," ('Champs-Elysées-etara', 1),\n"," ('Vitré,', 2),\n"," ('Quimperlé,', 2),\n"," ('nindoàn', 1),\n"," ('zidakeèn', 2),\n"," ('nitzakeèn', 1),\n"," ('Elysées-era', 1),\n"," ('Elysées-etako', 1),\n"," ('matinée', 2),\n"," ('gintuztèn', 1),\n"," ('nituèn,', 1),\n"," ('nengokeèn', 1),\n"," ('ninderamatèn', 2),\n"," ('niezaiokeèn', 2),\n"," ('Débats-andereari', 1),\n"," ('Théodose', 1),\n"," ('neukakeèn', 1),\n"," ('zizkioketèn', 1),\n"," ('bazeudèn', 1),\n"," ('nintzaketèn', 1),\n"," ('Crécy!', 1),\n"," ('Crécy?', 1),\n"," ('nekièn', 2),\n"," ('zetzàn', 2),\n"," ('zekuskitèn', 1),\n"," ('bí', 3),\n"," ('maíz', 1),\n"," ('Hélène', 36),\n"," ('Léon-Bollée', 1),\n"," ('Réam-go', 1),\n"," ('Dó', 2),\n"," ('Mallarmé-tar', 1),\n"," ('Fernández.', 2),\n"," ('Fernández-ek,', 1),\n"," ('Ramón', 3),\n"," ('Fernández', 1),\n"," ('Fernández,', 2),\n"," ('Fernández-ek', 1),\n"," ('Fernández-tarrak.', 1),\n"," ('Hélènek,', 3),\n"," ('Hélène,', 1),\n"," ('Rivière', 2),\n"," ('età', 2),\n"," ('ginatekeèn', 1),\n"," ('zatekeeèn', 2),\n"," ('béronen', 1),\n"," ('jaukikàtuak', 1),\n"," ('pétralek', 1),\n"," ('bazezagutèn', 1),\n"," ('nèure', 1),\n"," ('mintzatùohi', 1),\n"," ('zirakitèn', 1),\n"," ('zitzaizkigùn', 1),\n"," ('zitzaigukeèn', 1),\n"," ('gùztiak', 1),\n"," ('zigukeèn', 1),\n"," ('zegozkigùn', 1),\n"," ('ziguketèn', 1),\n"," ('Zitekeèn', 1),\n"," ('zizkigutèn', 1),\n"," ('zeritzekeèn', 2),\n"," ('èrregutzeari', 1),\n"," ('genukeèn', 1),\n"," ('zegitèn', 1),\n"," ('ninderamàn', 1),\n"," ('zitzaidakeèn', 1),\n"," ('ziezazkidakeèn', 1),\n"," ('neuzkàn', 2),\n"," ('ausartù', 1),\n"," ('zekarkietèn', 1),\n"," ('zuèla.', 1),\n"," ('erè,', 1),\n"," ('àrriskutsuagoa', 1),\n"," ('nahitaèz', 1),\n"," ('ezér,', 1),\n"," ('bazirèn', 1),\n"," ('genbiltzàn', 2),\n"," ('generamàn', 1),\n"," ('zeramatèn', 1),\n"," ('zebiltzakeèn', 1),\n"," ('bakoitzeanloàri', 1),\n"," ('zezaguèn', 1),\n"," ('neramatzàn', 1),\n"," ('arkitektoàren', 1),\n"," ('zegoéneko', 1),\n"," ('delibèraturik', 1),\n"," ('bazèn', 1),\n"," ('banezaguèn', 1),\n"," ('àparte', 1),\n"," ('neurè', 1),\n"," ('nékatuta', 1),\n"," ('Zitezkeèn', 1),\n"," ('gintzaizkièn', 1),\n"," ('éderretsita,', 1),\n"," ('sastagaià', 1),\n"," ('niokeèn', 1),\n"," ('eré', 1),\n"," ('àzaletik', 1),\n"," ('zizkidakeèn', 1),\n"," ('bazeuzkakeèn', 1),\n"," ('genitüèn', 1),\n"," ('nezaguèn', 2),\n"," ('zitezèn', 1),\n"," ('zekartzatèn', 1),\n"," ('èzertan', 1),\n"," ('zeritzatèn', 1),\n"," ('gàueko', 1),\n"," ('hospitaltzàt', 1),\n"," ('gintuèri', 1),\n"," ('jadànik', 1),\n"," ('zeritzotèn', 1),\n"," ('gindukàn', 1),\n"," ('zén,', 1),\n"," ('bazinèn', 1),\n"," ('zitzaiekeèn', 1),\n"," ('adorearéngatik,', 1),\n"," ('désio-gai.', 1),\n"," ('zekidàn', 1),\n"," ('bazitzaizkigùn', 1),\n"," ('èraztun', 1),\n"," ('malkoék', 1),\n"," ('é', 1),\n"," ('Pompéek,', 1),\n"," ('Hernán', 1),\n"," ('Cortési', 1),\n"," ('Cortés', 1),\n"," ('Estréeko', 2),\n"," ('Boutièreseko', 1),\n"," ('Boétie', 2),\n"," ('Più', 1),\n"," ('Éstienne', 1),\n"," ('Mont-doré,', 1),\n"," ('Brétignyko', 1),\n"," ('Plombières-ekoak;', 1),\n"," ('Linné-ren', 1),\n"," ('Réne,', 1),\n"," ('partagée\".', 1),\n"," ('prétendais', 1),\n"," ('lanbidea-métier-egitera', 1),\n"," ('Calderón-en', 1),\n"," ('Sénancour-en', 2),\n"," ('périssable.', 1),\n"," ('périssons', 2),\n"," ('résistant,', 2),\n"," ('néant', 2),\n"," ('réservé,', 2),\n"," ('vanità', 1),\n"," ('tí,', 1),\n"," ('fía,', 1),\n"," ('cubría.', 1),\n"," ('Malón', 1),\n"," ('Encarnación', 1),\n"," ('Velázquez-en', 1),\n"," ('Cortés-ek', 1),\n"," ('Filosofía', 1),\n"," ('Brunetièrek', 1),\n"," ('l´indiffèrence', 1),\n"," ('matière', 1),\n"," ('tú', 1),\n"," ('existiría', 1),\n"," ('también', 1),\n"," ('Ingenerò', 1),\n"," ('(Traité', 4),\n"," ('idées', 3),\n"," ('Jesús', 1),\n"," ('Guía', 1),\n"," ('grèves,', 1),\n"," ('(Traité...,', 1),\n"," ('(Guía,', 1),\n"," ('Núñez', 1),\n"," ('Dégradation', 1),\n"," ('Ardigò,', 1),\n"," ('Alvargonzález', 1),\n"," ('corazón', 1),\n"," ('aquí,', 1),\n"," ('périssable.-Il', 1),\n"," ('SÉNANCOUR:', 1),\n"," ('Fouillée', 1),\n"," ('Sénancour-ek,', 1)]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"z5XLjHT6LuHw","colab_type":"code","colab":{}},"source":["adizkiak = [hitza for hitza in hiztegia_list if re.search(r'[àèòù]n\\b', hitza[0])]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x86r_K_6MzbZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1579797583345,"user_tz":-60,"elapsed":534,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"62241b0f-f1de-4f7e-af96-07597cca104b"},"source":["len(adizkiak)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["251"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"iR1VdbWUMwNZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1579797587557,"user_tz":-60,"elapsed":1603,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"1d905aff-eae5-4b84-ac13-2e0193dd2277"},"source":["adizkiak"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('zèn', 341),\n"," ('zuèn', 456),\n"," ('zihoàn', 15),\n"," ('zitzaièn', 6),\n"," ('zetorrèn', 15),\n"," ('\"mignàn', 1),\n"," ('(\"Milàn', 1),\n"," ('Milàn!\"),', 1),\n"," ('Niccolòn', 1),\n"," ('Cohèn', 6),\n"," ('Cohèn,', 1),\n"," ('nuèn', 164),\n"," ('ninduèn', 24),\n"," ('genuèn', 22),\n"," ('zizkidatèn', 4),\n"," ('nintzèn', 65),\n"," ('nengoèn', 9),\n"," ('nerabilèn', 2),\n"," ('nentzàn', 1),\n"," ('zukeèn', 41),\n"," ('nituèn', 63),\n"," ('zirèn', 150),\n"," ('zebilèn', 5),\n"," ('zidàn', 54),\n"," ('neukàn', 20),\n"," ('ziharduèn', 8),\n"," ('bazuèn', 2),\n"," ('zituèn', 165),\n"," ('zitzaiòn', 50),\n"," ('zièn', 26),\n"," ('zutèn', 113),\n"," ('zekarkiotèn', 2),\n"," ('zegoèn', 82),\n"," ('zeukatèn', 9),\n"," ('ziòn', 100),\n"," ('nintzatekeèn', 1),\n"," ('zekiketèn', 1),\n"," ('zeramàn', 20),\n"," ('zeudekeèn', 4),\n"," ('zeritzòn', 5),\n"," ('genituèn', 21),\n"," ('zerabilèn', 6),\n"," ('zetozèn', 4),\n"," ('zekièn', 5),\n"," ('zitzaigùn', 3),\n"," ('geniòn', 2),\n"," ('zezakeèn', 40),\n"," ('ziezaiokeèn', 6),\n"," ('zituztèn', 35),\n"," ('genizkiòn', 4),\n"," ('zeukàn', 51),\n"," ('zirudièn', 21),\n"," ('nukeèn', 15),\n"," ('zekidakeèn', 1),\n"," ('zituzkeèn', 11),\n"," ('nezakeèn', 5),\n"," ('zidatèn', 18),\n"," ('niòn', 7),\n"," ('ziezaizkiokeèn', 1),\n"," ('erregeenganako-zeukàn', 1),\n"," ('zituzketèn', 4),\n"," ('zitezkeèn', 9),\n"," ('zitzaidàn', 29),\n"," ('zekartèn', 2),\n"," ('zetorkièn', 1),\n"," ('zeriòn', 6),\n"," ('zetorkidàn', 1),\n"," ('zitzaizkidàn', 11),\n"," ('zezaketèn', 9),\n"," ('zizkidàn', 12),\n"," ('zizkiòn', 34),\n"," ('zietèn', 6),\n"," ('zekarzkidàn', 2),\n"," ('zekarzkiòn', 1),\n"," ('zeritzàn', 8),\n"," ('zitekeèn', 21),\n"," ('nintzaiòn', 3),\n"," ('ziekeèn', 3),\n"," ('nindutèn', 8),\n"," ('zetxezkiòn', 3),\n"," ('geundèn', 6),\n"," ('ginèn', 10),\n"," ('zèn\"', 1),\n"," ('zenuèn', 2),\n"," ('zuèn\"', 1),\n"," ('ginderamatzàn', 2),\n"," ('zitzaizkiòn', 13),\n"," ('zirauèn', 4),\n"," ('zihoazèn', 3),\n"," ('zeniòn', 1),\n"," ('zeutzàn', 2),\n"," ('zebiltzàn', 5),\n"," ('zegièn', 2),\n"," ('zeukakeèn', 1),\n"," ('ziruditèn', 7),\n"," ('zigùn', 7),\n"," ('zeudèn', 28),\n"," ('nizkiòn', 4),\n"," ('zitzaiokeèn', 3),\n"," ('nintzaièn', 5),\n"," ('zirudikeèn', 3),\n"," ('nièn', 7),\n"," ('nizkiokeèn', 1),\n"," ('zegozkièn', 1),\n"," ('nindukeèn', 2),\n"," ('zihoakiòn', 3),\n"," ('ziotèn', 23),\n"," ('niharduèn', 4),\n"," ('zuketèn', 4),\n"," ('nerabiltzàn', 1),\n"," ('zekartzàn', 1),\n"," ('nizkièn', 3),\n"," ('zerabiltzàn', 3),\n"," ('zegokigùn', 1),\n"," ('gintuèn', 1),\n"," ('zerizkiòn', 2),\n"," ('zatekeèn', 12),\n"," ('zegokeèn', 6),\n"," ('zegozkiòn', 4),\n"," ('geneukàn', 3),\n"," ('zerabiltzakeèn', 1),\n"," ('neramàn', 2),\n"," ('zetxezkièn', 1),\n"," ('zeuzkàn', 11),\n"," ('zekarrèn', 1),\n"," ('zegokiòn', 6),\n"," ('ziezadaketèn', 2),\n"," ('nituzkeèn', 3),\n"," ('ninduketèn', 2),\n"," ('neritzòn', 1),\n"," ('zegokiokeèn', 2),\n"," ('zebilkeèn', 2),\n"," ('bazekièn', 2),\n"," ('ziezadakeèn', 1),\n"," ('nekusàn', 5),\n"," ('ziezazkidaketèn', 1),\n"," ('zizkièn', 2),\n"," ('ziokeèn', 2),\n"," ('zinèn', 2),\n"," ('zeramatzàn', 4),\n"," ('nindukezùn', 1),\n"," ('zegokièn', 4),\n"," ('zizkiotèn', 7),\n"," ('bazihoàn', 1),\n"," ('zerraièn', 1),\n"," ('zirudiketèn', 1),\n"," ('zitzaizkièn', 5),\n"," ('zekarkiòn', 1),\n"," ('nizùn', 1),\n"," ('zizkigùn', 1),\n"," ('zerakarkeèn', 1),\n"," ('zekiokeèn', 2),\n"," ('bazihoazèn', 1),\n"," ('zemaiòn', 1),\n"," ('zeramakeèn', 1),\n"," ('zekusàn', 1),\n"," ('ziezazkiokeèn', 1),\n"," ('ziezaioketèn', 2),\n"," ('zioketèn', 2),\n"," ('zebilkiòn', 1),\n"," ('zetorkiòn', 2),\n"," ('zitzakeèn', 7),\n"," ('lezakeèn', 1),\n"," ('zirautèn', 1),\n"," ('zirakiòn', 1),\n"," ('zitzaizkiòn,', 1),\n"," ('zihoakièn', 1),\n"," ('ziratekeèn', 4),\n"," ('zeragiòn', 1),\n"," ('zioèn', 1),\n"," ('zerabilèn,', 1),\n"," ('leramakeèn', 1),\n"," ('zerièn', 3),\n"," ('zihoazkiòn', 1),\n"," ('zirakièn', 3),\n"," ('zitzaizkiokeèn', 2),\n"," ('zetxekiòn', 1),\n"," ('genezakeèn', 3),\n"," ('zuèn-eta,', 1),\n"," ('zitzaiòn-jendearekin', 1),\n"," ('zeramatzatèn', 2),\n"," ('zirèn,', 1),\n"," ('zerabilkiòn', 1),\n"," ('zerauntsàn', 1),\n"," ('hidàn', 1),\n"," ('zèn,', 1),\n"," ('zekizkièn', 2),\n"," ('zeritzèn', 1),\n"," ('zuèn,', 2),\n"," ('niàn', 1),\n"," ('zuèn-baina', 1),\n"," ('zuèn-bolada', 1),\n"," ('nindoàn', 1),\n"," ('zidakeèn', 2),\n"," ('nitzakeèn', 1),\n"," ('gintuztèn', 1),\n"," ('nituèn,', 1),\n"," ('nengokeèn', 1),\n"," ('ninderamatèn', 2),\n"," ('niezaiokeèn', 2),\n"," ('neukakeèn', 1),\n"," ('zizkioketèn', 1),\n"," ('bazeudèn', 1),\n"," ('nintzaketèn', 1),\n"," ('nekièn', 2),\n"," ('zetzàn', 2),\n"," ('zekuskitèn', 1),\n"," ('ginatekeèn', 1),\n"," ('zatekeeèn', 2),\n"," ('bazezagutèn', 1),\n"," ('zirakitèn', 1),\n"," ('zitzaizkigùn', 1),\n"," ('zitzaigukeèn', 1),\n"," ('zigukeèn', 1),\n"," ('zegozkigùn', 1),\n"," ('ziguketèn', 1),\n"," ('Zitekeèn', 1),\n"," ('zizkigutèn', 1),\n"," ('zeritzekeèn', 2),\n"," ('genukeèn', 1),\n"," ('zegitèn', 1),\n"," ('ninderamàn', 1),\n"," ('zitzaidakeèn', 1),\n"," ('ziezazkidakeèn', 1),\n"," ('neuzkàn', 2),\n"," ('zekarkietèn', 1),\n"," ('bazirèn', 1),\n"," ('genbiltzàn', 2),\n"," ('generamàn', 1),\n"," ('zeramatèn', 1),\n"," ('zebiltzakeèn', 1),\n"," ('zezaguèn', 1),\n"," ('neramatzàn', 1),\n"," ('bazèn', 1),\n"," ('banezaguèn', 1),\n"," ('Zitezkeèn', 1),\n"," ('gintzaizkièn', 1),\n"," ('niokeèn', 1),\n"," ('zizkidakeèn', 1),\n"," ('bazeuzkakeèn', 1),\n"," ('genitüèn', 1),\n"," ('nezaguèn', 2),\n"," ('zitezèn', 1),\n"," ('zekartzatèn', 1),\n"," ('zeritzatèn', 1),\n"," ('zeritzotèn', 1),\n"," ('gindukàn', 1),\n"," ('bazinèn', 1),\n"," ('zitzaiekeèn', 1),\n"," ('zekidàn', 1),\n"," ('bazitzaizkigùn', 1)]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"iQYNtdlFVgX3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1579857353098,"user_tz":-60,"elapsed":955,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"df1c24da-ec2f-4792-e1b8-24f2b118c0f1"},"source":["print(re.sub(r'[àèòù]n\\b', lambda x: unidecode.unidecode(x.group()), 'eta Rubének galdetu zion zeukàn liburua non zegoèn.'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["eta Rubének galdetu zion zeukan liburua non zegoen.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FJPGJMsEPk11","colab_type":"code","colab":{}},"source":["with open('EhuHac/EhuHac-eu.txt') as f_orig, \\\n","     open('EhuHac/EhuHac-2-eu.txt', 'w') as f_berria:\n","    orig = f_orig.read()\n","    garbia = re.sub(r'[àèòù]n\\b', \n","                    lambda x: unidecode.unidecode(x.group()), \n","                    orig)\n","    f_berria.write(garbia)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PmlqMdk-4nx","colab_type":"text"},"source":["## Errepikatuak kendu"]},{"cell_type":"code","metadata":{"id":"gygw7QpQ3mCc","colab_type":"code","colab":{}},"source":["with open('EhuHac/EhuHac-eu.txt') as f_eu_orig, \\\n","     open('EhuHac/EhuHac-2-eu.txt', 'w') as f_eu_berria, \\\n","     open('EhuHac/EhuHac-es.txt') as f_es_orig, \\\n","     open('EhuHac/EhuHac-2-es.txt', 'w') as f_es_berria, \\\n","     open('EhuHac/EhuHac-en.txt') as f_en_orig, \\\n","     open('EhuHac/EhuHac-2-en.txt', 'w') as f_en_berria:\n","    aurrekoa_eu = ''\n","    aurrekoa_es = ''\n","    aurrekoa_en = ''\n","    for lerroa, línea, line in zip(f_eu_orig, f_es_orig, f_en_orig):\n","        if (lerroa != aurrekoa_eu \n","                or línea != aurrekoa_es \n","                or line != aurrekoa_en):\n","            f_eu_berria.write(lerroa)\n","            f_es_berria.write(línea)\n","            f_en_berria.write(line)\n","            aurrekoa_eu = lerroa\n","            aurrekoa_es = línea\n","            aurrekoa_en = line"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ui5oLIqWEFzJ","colab_type":"text"},"source":["# Errepikatuak begiratu"]},{"cell_type":"code","metadata":{"id":"QB74U0JxGJXA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1586976897609,"user_tz":-120,"elapsed":26132,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"3dba9f6a-f89b-464c-9ce4-f9042a04ee75"},"source":["with open('EhuHac/EhuHac-trainorig-es.txt') as fitx:\n","    train_es = fitx.read().split('\\n')\n","with open('EhuHac/EhuHac-trainorig-en.txt') as fitx:\n","    train_en = fitx.read().split('\\n')\n","with open('EhuHac/EhuHac-trainorig-eu.txt') as fitx:\n","    train_eu = fitx.read().split('\\n')\n","\n","with open('EhuHac/EhuHac-val-es.txt') as fitx:\n","    val_es = fitx.read().split('\\n')\n","with open('EhuHac/EhuHac-val-en.txt') as fitx:\n","    val_en = fitx.read().split('\\n')\n","with open('EhuHac/EhuHac-val-eu.txt') as fitx:\n","    val_eu = fitx.read().split('\\n')\n","\n","esaldiak_train = set()\n","print('Entrenamenduan:')\n","kont = 0\n","for es, en, eu in zip(train_es, train_en, train_eu):\n","    tupla = (es, en, eu)\n","    if tupla in esaldiak_train:\n","        print(tupla)\n","        kont += 1\n","    else:\n","        esaldiak_train.add(tupla)\n","print(kont)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-¿Sí?', '\"Yeah?\"', '-Bai?')\n","('', '', '-Kaixo!')\n","('', '', '-galdetu nion.')\n","('-¿Sí?', '\"Yeah?\"', '-Bai?')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¡Reno!', '\"Reno!\"', '-Reno!')\n","('Le dije:', 'I said:', 'Nik esan nion:')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí...', '\"Yes...', '-Bai...')\n","('-No, gracias.', '\"No, thanks.\"', '-Ez, eskerrik asko.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Estoy bien.', '\"I\\'m all right.', '-Ondo nago.')\n","('No.', 'No.\"', 'Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('Le dije que sí.', 'I said I was.', 'Baietz esan nion.')\n","('-No.', '\"No.', '-Ez.')\n","('-le pregunté.', '', '-galdetu nion.')\n","('¿Cómo dio conmigo?', 'How\\'d he find me?\"', 'Nola aurkitu ninduen?')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', 'Barre egin zuen.')\n","('Dije que sí con la cabeza.', 'I nodded.', 'Baietz esan nion buruaz.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('¿Por qué?', '\"Why?\"', 'Zer ba?')\n","('-Está bien.', '\"All right.', '-Konforme.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('', '', '-galdetu zidan.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Sí?', '\"Yes?\"', '-Bai?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('', '', '-galdetu zidan.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-Vaya, vaya.', '\"Well, well.\"', '-Oso ondo.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-No.', '\"No.', '-Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-No.', '\"No.\"', '-Ez.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-galdetu nion.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-¿Qué ha pasado?', '\"What happened?\"', '-Zer gertatu da?')\n","('-De acuerdo.', '\"Right.', '-Ondo.')\n","('-Sí.', '\"Uh-huh.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('', '', '-niri begiratu zidan.')\n","('-Sí.', '\"Uh-huh.', '-Bai.')\n","('Me eché a reír.', 'I laughed.', 'Barre egin nuen.')\n","('-Calla.', '\"Sh-h-h.', '-Iso.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('\"Cogido con las manos cubiertas de sangre.', '\"Taken with blood-stained hands.', '\"Eskuak odoletan zituen atxilotzean.')\n","('Peligrosísimo\".', 'Very dangerous.\"', 'Oso arriskutsua\".')\n","('-Buenas noches, señorita Lisa.', '\"Good night, Mademoiselle Lisa.\"', '-Gabon, Lisa andereñoa.')\n","('-Sí, doña Lisa.', '\"Yes, Madame Lisa.\"', '-Bai, Lisa andrea.')\n","('', '', 'A!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-¡Yo!', '\"I!', '-Ni!')\n","('¡Ah!', 'Ah!', 'A!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('', '', '-galdetu zuen-.')\n","('Hubo un nuevo silencio.', 'There was another pause.', 'Beste isilaldi bat izan zen.')\n","('', '', 'A!')\n","('', '', 'Mrs.')\n","('', '', 'Mrs.')\n","('-¿Sí?', '\"That so?\"', \"'Bai zera!'\")\n","('-Sí.', '\"Yes.\"', \"'Bai.'\")\n","('-No.', '\"No.\"', \"'Ez.'\")\n","('-No.', '\"No.\"', \"'Ez.'\")\n","('-No.', '\"No.\"', \"'Ez.'\")\n","('-Carraway.', '\"Carraway.\"', \"'Carraway.'\")\n","('-Sí.', '\"Yes.', \"'Bai.\")\n","('-¿Por qué?', '\"Why?\"', '-Zer dela eta?')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-¿Cuánto?', '\"How much?\"', '-Zenbat?')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('-No-dijo K.', '\"No,\" said K.', '-Ez-esan zuen K.k.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('', '', '-galdetu zuen.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('¡Mira!', 'Lo!', 'Hara!')\n","('Zaratustra respondió:', 'Zarathustra answered:', 'Zaratustrak erantzun zion:')\n","('La hora en que digáis:', 'The hour when ye say:', 'Hau esango duzuen ordua:')\n","('La hora en que digáis:', 'The hour when ye say:', 'Hau esango duzuen ordua:')\n","('La hora en que digáis:', 'The hour when ye say:', 'Hau esango duzuen ordua:')\n","('Mirad, yo os enseño el superhombre:', 'Lo, I teach you the Superman:', 'Begira, gaingizona aldarrikatzen dizuet:')\n","('Yo os digo:', 'I tell you:', 'Neuk diotsuet:')\n","('¡Ay!', 'Alas!', 'Ai ene!')\n","('¡Ay!', 'Alas!', 'Ai ene!')\n","('Zaratustra respondió:', 'Zarathustra answered:', 'Zaratustrak erantzun zion:')\n","('¿A quién es al que más odian?', 'Whom do they hate most?', 'Nor gorrotatzen dute gehien?')\n","('-Así comenzó el ocaso de Zaratustra.', \"Thus began Zarathustra's down-going.\", '-Honela hasi zen Zaratustraren beherabidea.')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¡Creedme, hermanos míos!', 'Believe me, my brethren!', 'Sinetsidazue, ene senideok!')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('El sí-mismo dice al yo:', 'The Self saith unto the ego:', 'Nor Berak Niari esaten dio:')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¿Qué es ese hombre?', 'What is this man?', 'Zer da gizon hau?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Mas por mi amor y mi esperanza te conjuro:', 'But by my love and hope I conjure thee:', 'Baina neure maitasun eta itxaropenarengatik zin egiten diat:')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Yo os conozco.', 'I know you.', 'Ezagutzen zaituztet.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Ved, pues, a esos superfluos!', 'Just see these superfluous ones!', 'Begiraiezue soberakin hauei!')\n","('¡Ved, pues, a esos superfluos!', 'Just see these superfluous ones!', 'Begiraiezue soberakin hauei!')\n","('¡Apartaos del mal olor!', 'Do go out of the way of the bad odour!', 'Ihes egizue usain txarra dagoen tokitik!')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Muchos países ha visto Zaratustra, y muchos pueblos:', 'Many lands saw Zarathustra, and many peoples:', 'Lurralde asko ikusi ditu Zaratustrak eta herri asko:')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('2', '2.', 'II')\n","('3', '3.', 'III')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Dios es una suposición:', 'God is a conjecture:', 'Jainkoa aieru bat da:')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Ay, hermanos míos!', 'Ah, my brethren!', 'Ai, ene senideok!')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¿Cómo?', 'What?', 'Nola?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Ay!', 'Alas!', 'Ai ene!')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¿Para qué?', 'Wherefore?', 'Zertarako?')\n","('¿Cómo?', 'How?', 'Nola?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('-', '-', '-')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Recorres tu camino de grandeza:', 'Thou goest the way to thy greatness:', 'Heure handitasunaren bidetik habil:')\n","('Estoy dispuesto.', 'I am ready.', 'Prest nago.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Oh tarde de mi vida!', 'O afternoon of my life!', 'Oi, nire bizitzaren arratsaldea!')\n","('-', '-', '-')\n","('¡Aléjate, hora bienaventurada!', 'Away with thee, thou blissful hour!', 'Utikan, ordu zorionekoa!')\n","('-', '-', '-')\n","('-', '-', '-')\n","('¡por eso ahora nos separamos!', 'so let us part!', 'horregatik banatzen gara!')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('3', '3.', 'III')\n","('¡Bien!', 'Well!', 'Tira!')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('Así cantó Zaratustra.', 'Thus sang Zarathustra.', 'Honela kantatu zuen Zaratustrak.')\n","('-', '-', '-')\n","('', '', '-')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('-', '-', '-')\n","('¡Adelante!', 'Well!', 'Aurrera!')\n","('-', '-', '-')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('3', '3.', 'III')\n","('4', '4.', 'IV')\n","('5', '5.', 'V')\n","('', '', '-')\n","('7', '7.', 'VII')\n","('8', '8.', 'VIII')\n","('9', '9.', 'IX')\n","('10', '10.', 'X')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('El mar está tempestuoso:', 'The sea stormeth:', 'Itsasoa orroaka ari da:')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('¡Arriba!', 'Up!', 'Jaiki!')\n","('¡Dichoso de mí!', 'Joy to me!', 'Bejondeidala niri!')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('--', '-', '--')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('-', '-', '-')\n","('2', '2.', 'II')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('3', '3.', 'III')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('4', '4.', 'IV')\n","('-', '-', '-')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('5', '5.', 'V')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('6', '6.', 'VI')\n","('-', '-', '-')\n","('Oh, ¿cómo no iba yo a anhelar la eternidad y el nupcial anillo de los anillos,-el anillo del retorno?', 'Oh, how could I not be ardent for Eternity, and for the marriage-ring of rings-the ring of the return?', 'Oi nola ez nuen ba nik betieraren irrika sentituko eta eraztunetan ezkon-eraztunarena-itzuleraren eraztunarena?')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('7', '7.', 'VII')\n","('-', '-', '-')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('Así me dijo el demonio una vez:', 'Thus spake the devil unto me, once on a time:', 'Honela mintzatu zitzaidan deabrua behinola:')\n","('\"También Dios tiene su infierno:', '\"Even God hath his hell:', '\"Jainkoak ere badu bere ifernua:')\n","('es su amor a los hombres.\"', 'it is his love for man.\"', 'gizonenganako maitasuna du hori\".')\n","('\"Dios ha muerto;', '\"God is dead:', '\"Hil da Jainkoa;')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('¡Bien!', 'Well!', 'Tira!')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('--', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Bien!', 'Well!', 'Tira!')\n","('¡Bien!', 'Well then!', 'Tira!')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('--', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡No!', 'Nay!', 'Ez!')\n","('--', '-', '-')\n","('', '', '-')\n","('¿Cómo?', 'What?', 'Nola?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Oh felicidad!', 'O happiness!', 'Oi zoriona!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('-', '-', '-')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('¡No!', 'Nay!', 'Ez!')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('¡Ante Dios!', 'Before God!', 'Jainkoaren aurrean!')\n","('¡Bien!', 'Well!', 'Tira!')\n","('3', '3.', 'III')\n","('4', '4.', 'IV')\n","('5', '5.', 'V')\n","('-', '-', '-')\n","('6', '6.', 'VI')\n","('¡No!', 'Nay!', 'Ez!')\n","('¡Tres veces no!', 'Three times Nay!', 'Hirugarrenez ez!')\n","('--', '-', '-')\n","('7', '7.', 'VII')\n","('-', '-', '-')\n","('8', '8.', 'VIII')\n","('9', '9.', 'IX')\n","('10', '10.', 'X')\n","('11', '11.', 'XI')\n","('12', '12.', 'XII')\n","('¡Vosotros creadores, vosotros hombres superiores!', 'Ye creating ones, ye higher men!', 'Zuek sortzaileok, gizon garaiagook!')\n","('13', '13.', 'XIII')\n","('14', '14.', 'XIV')\n","('15', '15.', 'XV')\n","('18', '18.', 'XVIII')\n","('19', '19.', 'XIX')\n","('20', '20.', 'XX')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('¡No!', 'Nay!', 'Ez!')\n","('¡No!', 'Nay!', 'Ez!')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('¡Bien!', 'Well!', 'Tira!')\n","('1', '1.', 'I')\n","('Sela.', 'Selah.', 'Sela.')\n","('Sela.', 'Selah.', 'Sela.')\n","('Sela.', 'Selah.', 'Sela.')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('El desierto crece:', 'THE DESERTS GROW:', 'Basamortua hazten ari da:')\n","('¡ay de aquel que dentro de sí cobija desiertos!', 'WOE HIM WHO DOTH THEM HIDE!', 'ai ene, basamortuak bere baitan gordetzen dituena!')\n","('1', '1.', 'I')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('2', '2.', 'II')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('-Y el asno rebuznó I-A.', '-The ass, however, here brayed YE-A.', '-Eta astoak honi erantzun egin zion arrantzaka: I-A')\n","('', '', '- Eta astoak honi erantzun egin zion arrantzaka:')\n","('', '', '- Eta astoak honi erantzun egin zion arrantzaka:')\n","('-Y el asno rebuznó I-A.', '-The ass, however, here brayed YE-A.', 'I-A.')\n","('', '', '- Eta astoak honi erantzun egin zion arrantzaka:')\n","('-Y el asno rebuznó I-A.', '-The ass, however, here brayed YE-A.', 'I-A.')\n","('', '', '- Eta astoak honi erantzun egin zion arrantzaka:')\n","('-Y el asno rebuznó I-A.', '-The ass, however, here brayed YE-A.', 'I-A.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('3', '3.', 'III')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('3', '3.', 'III')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('4', '4.', 'IV')\n","('', 'Ah!', 'Ai!')\n","('¡Ay!', 'Ah!', 'Ai!')\n","('5', '5.', 'V')\n","('¡Ay!', 'Ah!', 'Ai!')\n","('¡Ay!', 'Ah!', 'Ai!')\n","('6', '6.', 'VI')\n","('7', '7.', 'VII')\n","('8', '8.', 'VIII')\n","('El dolor dice:', 'Woe saith:', 'Samina mintzo da:')\n","('10', '10.', 'X')\n","('11', '11.', 'XI')\n","('12', '12.', 'XII')\n","('¡Bien!', 'Well!', 'Tira!')\n","('¡Adelante!', 'Cheer up!', 'Gora!')\n","('Así habló Zaratustra;', 'Thus spake Zarathustra;', 'Honela mintzatu zen Zaratustra;')\n","('-', '-', '-')\n","('¡Bien!', 'Well!', 'Tira!')\n","('1', '1.', '1')\n","('2', '2.', '2')\n","('3', '3.', '3')\n","('4', '4.', '4')\n","('5', '5.', '5')\n","('6', '6.', '6')\n","('7', '7.', '7')\n","('8', '8.', '8')\n","('11', '11', '11')\n","('-', '', '-')\n","('-¡Siga!', 'Further!', '-Aurrera!')\n","('-¡Siga!', 'Further!', '-Aurrera!')\n","('¡Aire viciado!', 'Bad air!', 'Aire gaizkoatua!')\n","('1', '1.', '1')\n","('2', '2.', '2')\n","('3', '3.', '3')\n","('4', '4.', '4')\n","('5', '5.', '5')\n","('6', '6.', '6')\n","('7', '7.', '7')\n","('8', '8.', '8')\n","('9', '9.', '9')\n","('10', '10.', '10')\n","('-', '-', '-')\n","('12', '12.', '12')\n","('13', '13.', '13')\n","('14', '14.', '14')\n","('15', '15.', '15')\n","('16', '16.', '16')\n","('17', '17.', '17')\n","('-', '', '-')\n","('¡Basta!', 'Enough!', 'Aski da!')\n","('1', '1.', '1')\n","('2', '2.', '2')\n","('¿Qué significan los ideales ascéticos?', 'What is the meaning of ascetic ideals?', 'Zer esan nahi dute ideal aszetikoek?')\n","('3', '3.', '3')\n","('4', '4.', '4')\n","('5', '5.', '5')\n","('6', '6.', '6')\n","('', '', '-')\n","('7', '7.', '7')\n","('8', '8.', '8')\n","('9', '9.', '9')\n","('10', '10.', '10')\n","('11', '11.', '11')\n","('¿Qué significa esto?', 'What does this mean?', 'Zer esan nahi du horrek?')\n","('12', '12.', '12')\n","('13', '13.', '13')\n","('14', '14.', '14')\n","('15', '15.', '15')\n","('16', '16.', '16')\n","('17', '17.', '17')\n","('18', '18.', '18')\n","('19', '19.', '19')\n","('20', '20.', '20')\n","('21', '21.', '21')\n","('22', '22.', '22')\n","('23', '23.', '23')\n","('24', '24.', '24')\n","('25', '25.', '25')\n","('¡No!', 'Nay!', 'Ez!')\n","('-¡Basta!', 'Enough!', '-Aski da!')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('No.', 'No.', 'Ez.')\n","('', '', '- Hara!')\n","('', '', '-galdetu zuen-.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('Sonrió.', 'He smiled.', 'Irribarre egin zuen.')\n","('El coronel se sobresaltó.', 'The colonel started.', 'Koronela asaldatu egin zen.')\n","('-¿Qué?', \"'What?'\", '-Zer?')\n","('-Nada-preguntó.', \"'Nothing?' she asked.\", '-Ezer ez-galdetu zuen.')\n","('Apretó los dientes.', 'He clenched his teeth.', 'Hortzak estutu zituen.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('-Es lógico -respondió-.', '', '- Garbi dago -erantzun zuen-.')\n","('Los muertos de hace poco están más cerca de nosotros y precisamente por eso los queremos más.', '\"WeU, of course, people who\\'ve just died are nearer to us, so we love them more,\" he said.', 'Hil berriak hurbilago dauzkagu eta horrexegatik ditugu maiteago.')\n","('-¿No?', '\"No?', '-Ez?')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('1', 'Chapter One', '1')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('2', 'Chapter Two', '2')\n","('3', 'Chapter Three', '3')\n","('4', 'Chapter Four', '4')\n","('-Pues...', '', '- Ba...')\n","('5', 'Chapter Five', '5')\n","('-pregunté.', '', '-galdetu nuen.')\n","('1', 'Chapter One', '1')\n","('2', 'Chapter Two', '2')\n","('3', 'Chapter Three', '3')\n","('Yo no comprendía.', \"I didn't understand.\", 'Ez nuen ulertzen.')\n","('4', 'Chapter Four', '4')\n","('5', 'Chapter Five', '5')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('6', 'Chapter Six', '6')\n","('1', 'Chapter One', '1')\n","('', '', '- Bai!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('2', 'Chapter Two', '2')\n","('-No...', '\"No...', '-Ez...')\n","('No.', 'No.\"', 'Ez.')\n","('3', 'Chapter Three', '3')\n","('4', 'Chapter Four', '4')\n","('¿Y Micòl?', 'And what about Micol?', 'Eta Micòl?')\n","('5', 'Chapter Five', '5')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('6', 'Chapter Six', '6')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('7', 'Chapter Seven', '7')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Asentí.', 'I nodded.', 'Baiezkoa egin nuen.')\n","('Pero ¿y ahora?', 'But now?', 'Baina, orain?')\n","('-¿Quién?', '', '- Nor?')\n","('¿Qué hacer?', 'What was to be done?', 'Zer egin?')\n","('Capítulo 1', 'CHAPTER I.', 'I. KAPITULUA')\n","('Capítulo 2', 'CHAPTER II.', 'II. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 4', 'CHAPTER IV.', 'IV. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 5', 'CHAPTER V.', 'V. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 6', 'CHAPTER VI.', 'VI. KAPITULUA')\n","('Capítulo 7', 'CHAPTER VII.', 'VII. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 8', 'CHAPTER VIII.', 'VIII. KAPITULUA')\n","('Capítulo 9', 'CHAPTER IX.', 'IX. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 10', 'CHAPTER X.', 'X. KAPITULUA')\n","('Capítulo 11', 'CHAPTER XI.', 'XI. KAPITULUA')\n","('Capítulo 12', 'CHAPTER XII.', 'XII. KAPITULUA')\n","('Capítulo 13', 'CHAPTER XIII.', 'XIII. KAPITULUA')\n","('Capítulo 14', 'CHAPTER XIV.', 'XIV. KAPITULUA')\n","('Capítulo 16', 'CHAPTER XVI.', 'XVI. KAPITULUA')\n","('Capítulo 17', 'CHAPTER XVII.', 'XVII. KAPITULUA')\n","('Capítulo 18', 'CHAPTER XVIII.', 'XVIII. KAPITULUA')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¡Ah!', '', '- A!')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('1', 'I', '1')\n","('2', 'II', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('', '', '- Hara!')\n","('-No.', '', '- Ez.')\n","('3', 'III', '3')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('CAPÍTULO III', 'III', 'Hirugarren atala')\n","('1', 'I', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', 'II', '2')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('1', 'I', '1')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('2', 'II', '2')\n","('TERCERA PARTE', '3', 'HIRUGARREN ZATIA')\n","('CAPÍTULO I', 'I', 'Lehenengo atala')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('2', '2', '2')\n","('CAPÍTULO II', 'II', 'Bigarren atala')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('3', '3', '3')\n","('-¿Qué haces?', '', '- Zertan ari zara?')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('CAPÍTULO III', 'III', 'Hirugarren atala')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Por supuesto.', \"'Of course.\", '-Bai, jakina.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('1', '1', '1')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","('-Lo siento.', \"'I'm sorry.\", '-Sentitzen dut.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¿Qué?', '', '- Zer?')\n","('1', '1', '1')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¿Davis?', \"'Davis?\", '-Davis?')\n","('', '', 'Mrs.')\n","('2', '2', '2')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('', '', '-galdetu zuen.')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('2', '2', '2')\n","('-Sí.', '', '-Bai.')\n","('CAPÍTULO I', 'I', 'Lehenengo atala')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('2', 'II', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Naturalmente.', \"'Of course.\", '-Jakina.')\n","('CAPÍTULO II', 'II', 'Bigarren atala')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-preguntó.', '', '-galdetu zuen.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('4', '4', '4')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Muy bien.', \"'All right.'\", '-Ondo.')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('5', '5', '5')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('CAPÍTULO I', 'I', 'Lehenengo atala')\n","('1', '1', '1')\n","('2', '2', '2')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('CAPITULO II', 'II', 'Bigarren atala')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Por supuesto.', 'Of course.', 'Jakina.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Por supuesto.', \"'Of course.\", '-Jakina.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('CAPÍTULO III', 'III', 'Hirugarren atala')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', '2', '2')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('3', '3', '3')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Por supuesto.', \"'Of course.'\", '-Bai, noski.')\n","('Castle pensó:', 'Castle thought:', 'Castlek pentsatu zuen:')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('4', '4', '4')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('5', '5', '5')\n","('Castle pensó:', 'Castle thought:', 'Castlek pentsatu zuen:')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Lo ignoro.', \"'I don't know.\", '-Ez dakit.')\n","('6', '6', '6')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('7', '7', '7')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No estoy seguro.', \"'I'm not sure.\", '-Ez nago ziur.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('CAPÍTULO I', 'I', 'Lehenengo atala')\n","('1', '1', '1')\n","('', '', 'Mrs.')\n","('', '', 'Mrs.')\n","('-¿Sam?', \"'Sam?'\", '-Sam?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('Pensó:', 'She thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('2', '2', '2')\n","('-¡Oh!', '', '- O!')\n","('3', '3', '3')\n","('-Por supuesto.', \"'Of course.'\", '-Jakina.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('CAPÍTULO II', 'II', 'Bigarren atala')\n","('1', '1', '1')\n","('-¿Por qué no?', \"'Why not?'\", '-Zergatik ez?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('2', '2', '2')\n","('3', '3', '3')\n","('-No.', \"'No.'\", '-Ez.')\n","('4', '4', '4')\n","('5', '5', '5')\n","('-Lo sé.', \"'I know.'\", '-Bazakiat.')\n","('-¿Por qué?', \"'Why?\", '-Zer dela eta?')\n","('1', '1', '1')\n","('-Sí, por favor.', \"'Yes, please.'\", '-Bai, mesedez.')\n","('Pensó:', 'She thought:', 'Pentsatu zuen:')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('', '', 'Castle.')\n","('', '', 'Castlek.')\n","('2', '2', '2')\n","('¿Cómo está Sam?', \"How's Sam?'\", 'Zer moduz Sam?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('', '', '\"Ah!')\n","('CAPÍTULO III', 'Chapter Three', '-III -')\n","('CAPÍTULO V', 'Chapter Five', '-V -')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('', '', 'Ah!')\n","('CAPÍTULO VI', 'Chapter Six', '-VI -')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('CAPÍTULO VII', 'Chapter Seven', '-VII -')\n","('CAPÍTULO VIII', 'Chapter Eight', '-VIII -')\n","('', '', '- Bai!')\n","('', '', '- Oh!')\n","('-No.', '', '- Ez.')\n","('CAPÍTULO IX', 'Chapter Nine', '-IX -')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('', '', 'Ah!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Estás seguro?', '\"Are you sure?\"', '-Ziur zaude?')\n","('', '', 'Ah!')\n","('', '', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('Emma se paró.', 'She stopped.', 'Emma gelditu egin zen.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('CAPÍTULO PRIMERO', 'Chapter One', '-I -')\n","('-¿Cómo?', '', '- Nola?')\n","('', '', '- Ah!')\n","('-Pues bien...', '', '- Horra ba!...')\n","('-¿Por qué no?', '', '- Zergatik ez?')\n","('CAPÍTULO II', 'Chapter Two', '-II -')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('CAPÍTULO III', 'Chapter Three', '-III -')\n","('CAPÍTULO IV', 'Chapter Four', '-IV -')\n","('', '', '- Ah!')\n","('CAPÍTULO V', 'Chapter Five', '-V -')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', '- Oh!')\n","('CAPÍTULO VI', 'Chapter Six', '-VI -')\n","('', '', '- Ah!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('CAPÍTULO VII', 'Chapter Seven', '-VII -')\n","('', '', '- Ah!')\n","('-¿Cómo?', '\"What?\"', '-Nola?')\n","('CAPÍTULO VIII', 'Chapter Eight', '-VIII -')\n","('', '', 'Oh!')\n","('-Pero...', '\"But-\"', '-Baina...')\n","('¿Es culpa mía?', 'Is it my fault?', 'Nire errua al da?')\n","('CAPÍTULO IX', 'Chapter Nine', '-IX -')\n","('', '', 'Ah!')\n","('', '', '- Oh!')\n","('CAPÍTULO X', 'Chapter Ten', '-X -')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-esan zuen.')\n","('-Sí.', '\"I am.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('', '', '- Ah!')\n","('Se echó a reír.', 'He laughed.', 'Barre egin zuen.')\n","('Me eché a reír.', 'I laughed.', 'Barre egin nuen.')\n","('¡Ay!', 'Alas!', 'Ene!')\n","('-¡Bien, bien, bien!', 'good! good!', '-Ederki, ederki, ederki!')\n","('¡ja, ja, ja!', 'ha! ha!', 'Ja, ja, ja!')\n","('¡Ja, ja, ja!', 'Ha! ha!', 'Ja, ja, ja!')\n","('-¡Ji, ji, ji!', '\"Hee! hee!', '-Ji, ji, ji!')\n","('¡Ah!', 'Ah!', 'Ene!')\n","('-No lo sé;', '\"I don\\'t know;', '\"Ez dakit;')\n","('', '', 'Hara!')\n","('-¡Ah!', '', '\"A!')\n","('La baronesa le miró un momento.', 'The Baroness looked at him a moment.', 'Baronesa begira geratu zitzaion pixka batean.')\n","('¿No es así?', 'Is it not so?', 'Ez da hala?')\n","('-Preferiría no hacerlo.', '\"I would prefer not to.\"', '-Aukeran nahiago ez.')\n","('Silencio.', 'No answer.', 'Erantzunik ez.')\n","('Silencio.', 'No answer.', 'Erantzunik ez.')\n","('-Preferiría no hacerlo.', '\"I would prefer not to.\"', '-Aukeran nahiago ez.')\n","('-Preferiría no hacerlo.', '\"I would prefer not to.\"', '-Aukeran nahiago ez.')\n","('No contestó.', 'He answered nothing.', 'Deus ez zuen erantzun.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('Silencio.', 'No answer.', 'Erantzunik ez.')\n","('-¡Bartleby!', '\"Bartleby!\"', '-Bartleby!')\n","('', '', 'Begira:')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('-No.', '\"No.', '-Ez.')\n","('¿Es verdad?', 'Is that true?\"', 'Egia al da?')\n","('', '', '-galdetu nion.')\n","('', 'Ah!', 'Ah!')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¡Ah, ah!', '\"Aha!', '-Ah! ah!')\n","('', '', '- Arraioa!')\n","('-¿Cómo?', '', '- Nola?')\n","('', 'Ah!', 'Ah!')\n","('', '', '- Oi!')\n","('', '', '- Eh!')\n","('', '', '- Ongi da!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Cómo?', '\"What?\"', '-Nola?')\n","('', '', '- Oi!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', 'Ah!')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('', '', '- Hara!')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('', '', 'Oi!')\n","('', '', '- Hara!')\n","('-¡Señor!', '', '- Jauna!')\n","('', '', 'Ah!')\n","('', '', '- Oi!')\n","('', '', '- Ah!')\n","('¡Cómo!', 'What!', 'Nolaz!')\n","('', '', 'Oi!')\n","('', '', 'Ah!')\n","('', '', 'Ah!')\n","('No.', 'No.', 'ez.')\n","('-Así lo espero.', '\"I hope so.', '-Hala espero dut.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', 'Oi!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('', '', '- Oi!')\n","('', '', '- Ah!')\n","('', 'Oh!', 'Ai!')\n","('', '', 'Ongi da!')\n","('', '', 'Oi!')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación II', 'REMARK II.', '2. oharra')\n","('Contradicción:', 'Antithesis.', 'Antitesia:')\n","('Contradicción:', 'Antithesis.', 'Antitesia:')\n","('Contradicción:', 'Antithesis.', 'Antitesia:')\n","('', '', '-Ezaba ezak bat!')\n","('-¡Alto!', '', '-Geldi!')\n","('-No.', '\"No.', '-Ez.')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('-¿Eh?', '\"Eh?', '-Eh?')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-esan zuen.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('-le dije.', '', '-esan nion.')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('', '', '-esan zuen.')\n","('-No.', '\"No.', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez zekiat.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez zekiat.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('Luego dijo:', '', 'Gero hauxe esan zidan:')\n","('-le dije.', '', '-esan nion.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('', '', '-esan nion-.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('No le contesté.', \"I didn't answer him.\", 'Ez nion erantzun.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('No.', 'No.', 'Ez.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('Lo siento.', \"I'm sorry.\", 'Sentitzen dut.')\n","('-¿Para qué?', '', '- Zertarako?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Yo?', '\"Me?', '-Nik?')\n","('No.', 'No.', 'Ez.')\n","('-¿Qué?', '\"What?\" she said.', '-Zer?')\n","('', '', '-hark.')\n","('De verdad.', 'No kidding.', 'Ez naiz txantxetan ari.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('', '', '-galdetu nion-.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-Evidentemente.', '\"Obviously.\"', '-Hala zirudik.')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('De verdad.', 'I really do.', 'Benetan.')\n","('¿Por qué lo preguntas?', 'Why do you ask?\"', 'Zergatik galdetzen didak?')\n","('-Por nada.', '\"No reason.', '-Ezergatik ez.')\n","('-Sí.', 'Listen.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('Ahora vete a la cama.', 'Go to bed now.', 'Orain joan zaitez ohera.')\n","('¿Dónde estás?', 'Where are you?', 'Non zaude?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('De verdad.', 'She really does.', 'Benetan.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '', '- Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('Yo me voy a acostar.', \"I'm going to bed.\", 'Ni ohera noa.')\n","('-No.', '\"No, I didn\\'t.\"', '-Ez, ez nekien.')\n","('-Está bien.', '\"All right.', '-Ondo da.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('De verdad.', 'I really did.', 'Benetan.')\n","('De verdad.', 'I really did.', 'Benetan.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('De verdad.', 'I really did.', 'Benetan.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Lo sé.', '\"I know.\"', '-Badakit.')\n","('No sé por qué.', \"I don't know why.\", 'Ez dakit zergatik.')\n","('D.B.', 'D.B.', 'D.B.')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('¿Adónde?', 'Where?', 'Nora?')\n","('¡Bienvenido, Stephen!', 'Welcome home, Stephen!', 'Ongietorri etxera, Stephen!')\n","('-Vuélvete a la cama.', '-Get back into bed.', '-Sar hadi atzera ohean.')\n","('No eran marrullerías.', 'He was not foxing.', 'Ez zen aitzakia.')\n","('Stephen contestó:', 'Stephen answered:', 'Stephenek erantzun:')\n","('Sí.', 'Yes...', 'Bai...')\n","('Sí.', 'Yes...', 'Bai...')\n","('¡Simón!', 'Simon!', 'Simon!')\n","('-preguntó míster Dédalus.', 'asked Mr Dedalus.', '-galdetu zuen Dedalus jaunak.')\n","('-¡Todos adentro!', '-All in!', '-Denok barrura!')\n","('-¡Todos adentro!', '-All in!', '-Denok barrura!')\n","('¡Todos adentro!', 'All in!', 'Denok barrura!')\n","('-Dédalus, señor.', '-Dedalus, sir.', '-Dedalus, jauna.')\n","('-¡La otra mano!', '-Other hand!', '-Beste eskua!')\n","('-¿Qué te ha dicho?', '-What did he say?', '-Zer esan dik?')\n","('-¡Hurra!', '-Hurroo!', '-Gora!')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-dijo Heron-.', 'said Heron.', '-esan zuen Heronek-.')\n","('-preguntó Stephen.', 'asked Stephen.', '-galdetu zuen Stephenek.')\n","('-No.', '-No.', '-Ez!')\n","('-No.', '-No.', '-Ez!')\n","('No.', 'No.', 'Ez!')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('Amén.', 'Amen.', 'Amen.')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('¿Cómo?', 'What?', 'Zer?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('Sí.', 'Yes.', 'Bai.')\n","('', '', 'O!')\n","('¿Cómo?', 'How?', 'Nola?')\n","('En el nombre del Padre y del Hijo y del Espíritu Santo.', 'In the name of the Father and of the Son and of the Holy Ghost.', 'Aitaren, Semearen eta Espiritu Santuaren izenean.')\n","('Amén.', 'Amen.', 'Amen.')\n","('No.', 'No.', 'Ez.')\n","('', '', 'O!')\n","('No.', 'No.', 'Ez.')\n","('No quisiste.', 'You would not.', 'Ez zenuen nahi izan.')\n","('', '', 'Ez.')\n","('¡Confesarse!', 'Confess!', 'Aitortu!')\n","('-¿Alguna cosa más, hijo mío?', '-Anything else, my child?', '-Beste ezer, seme?')\n","('-Sí, padre.', '-Yes, father.', '-Bai, aita.')\n","('-Corpus Domini nostri.', '-CORPUS DOMINI NOSTRI.', '-Corpus Domini nostri')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¡Au!', 'Ao!', 'Ai!')\n","('¡Bous Stephanoumenos!', 'Bous Stephanoumenos!', 'Bous Stephanoumenos!')\n","('-¡Stephanephoros!', '-Stephaneforos!', '-Stephaneforos!')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('¿Dónde?', 'Where?', 'Non?')\n","('-Sí, padre.', '-Yes, father.', '-Bai, aita.')\n","('', '', 'Jainko maitea!')\n","('-preguntó Stephen.', 'asked Stephen.', '-galdetu zuen Stephenek.')\n","('Paciencia.', 'Patience.', 'Pazientzia.')\n","('-¿Para qué es eso?', '-What is it for?', '-Zertarako duk?')\n","('-No.', '-No.', '-Ez.')\n","('', '', 'O!')\n","('Podía ser.', 'It might be.', 'Bazitekeen.')\n","('No me evoques encantos que se van.', 'Tell no more of enchanted days.', 'Ez zakizkit mintza soreztaren xarmaz')\n","('¿No estás cansada de ese ardiente afán?', 'Are you not weary of ardent ways?', 'Ez al zara neka hain bide suharraz?')\n","('¿No estás cansada de ese ardiente afán?', 'Are you not weary of ardent ways?', 'Ez al zara neka hain bide suharraz?')\n","('No me evoques encantos que se van.', 'Tell no more of enchanted days.', 'Ez zakizkit mintza soreztaren xarmaz')\n","('¿No estás cansada de ese ardiente afán?', 'Are you not weary of ardent ways?', 'Ez al zara neka hain bide suharraz?')\n","('¿Qué pájaros eran aquéllos?', 'What birds were they?', 'Zer txori ziren haiek?')\n","('Vámonos.', 'Come away.', 'Goazen.')\n","('-preguntó Cranly.', 'Cranly asked.', '-galdetu zuen Cranlyk.')\n","('-preguntó Cranly.', 'Cranly asked.', '-galdetu zuen Cranlyk.')\n","('-preguntó Cranly.', 'Cranly asked.', '-galdetu zuen Cranlyk.')\n","('No.', 'No.', 'Ez.')\n","('Amén.', 'Amen.', 'Amen.')\n","('Pero no.', 'But no.', 'Baina ez.')\n","('-¡Ven!', \"'Come!'\", '-Goazen!')\n","('¡No!', 'No!', 'Ez!')\n","('Ignatius Gallaher se rió.', 'Ignatius Gallaher laughed.', 'Ignatius Gallaherrek barre egin zuen.')\n","('-Bueno...', \"'Well...\", '-Beno...')\n","('-Sí, señor.', \"'Yes, sir.'\", '-Bai, jauna.')\n","('En ningún caso deberá el susodicho Bernard Bodley buscar...', 'In no case shall the said Bernard Bodley be...', 'Ezingo du, inolako moduz, aipaturiko Bernard Bodley berak...')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('', '', '-Eta?')\n","('', '', '-A!')\n","('', '', '-Bai zera!')\n","('-preguntó.', '', '-galdetu zuen.')\n","('', '', '-A!')\n","('¡Pok!', 'Pok!', 'Punp!')\n","('', '', '-A!')\n","('', '', '-A!')\n","('-¿Qué?', '', '-Zer?')\n","('', '', '-A!')\n","('-Damas y caballeros.', \"'Ladies and Gentlemen,\", '-Jaun-andreok...')\n","('-Damas y caballeros.', \"'Ladies and Gentlemen,\", '-Jaun-andreok...')\n","('-Sí, señor-dijo el cochero.', \"'Yes, sir,' said the cabman.\", '-Bai, jauna-esan zuen kotxe-gidariak.')\n","('', '', '-O!')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('-¿Dónde?', '', '-Non?')\n","('-¡Gretta!', \"'Gretta!'\", '-Gretta!')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¿Para qué?', \"'What for?'\", '-Zertarako?')\n","('-¿Qué?', '-What?', '-Zer?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Qué?', '-What?', '-Zer?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('Sí.', 'Yes.', 'Bai.')\n","('preguntó Stephen.', 'Stephen asked.', '-galdetu zuen Stephenek.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('preguntó Stephen.', 'Stephen asked.', '-galdetu zuen Stephenek.')\n","('-No, señor.', '-No, sir.', '-Ez, jauna.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('No.', 'No.', 'Ez.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('No.', 'No.', 'Ez.')\n","('¡Jesús!', 'Jesus!', 'Jesus!')\n","('¿No?', 'No?', 'Ez?')\n","('¡Tilintilín!', 'Dringdring!', 'Tilin-tilin.')\n","('Bueno, no pasa nada.', \"O, that's all right.\", 'Tira, ondo nago.')\n","('¿Quién?', 'Who?', 'Nor?')\n","('Yo...', 'I...', 'Ni...')\n","('No.', 'No.', 'Ez.')\n","('Già.', 'Già.', 'Già.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('¿No?', 'No?', 'Ez?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('preguntó.', 'he asked.', '-galdetu zuen.')\n","('No.', 'No.', 'Ez.')\n","('¡Atención!', 'Watch!', 'Erne!')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek.')\n","('No.', 'No.', 'Ez.')\n","('¡Pobre papá!', 'Poor papa!', 'Aita gaixoa!')\n","('Nadie.', 'No-one.', 'Inor ez.')\n","('Para sujetársela.', 'To keep it up.', 'Goian eusteko hari.')\n","('Olvidar.', 'Forget.', 'Ahaztu.')\n","('No:', 'No:', 'Ez:')\n","('Sí:', 'Yes:', 'Bai:')\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Caramba.', 'Hello.', 'To.')\n","('Espera.', 'Wait.', 'Hago.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek.')\n","('-Sí, señor, dijo el farmacéutico.', '-Yes, sir, the chemist said.', '-Bai, jauna-esan zuen botikariak-.')\n","('Todos esperaraban.', 'All waited.', 'Denak zain zeuden.')\n","('-No, dijo Mr. Bloom.', '-No, Mr Bloom said.', '-Ez-esan zuen Bloomek-.')\n","('Milly.', 'Milly.', 'Milly.')\n","('Mullingar.', 'Mullingar.', 'Mullingar.')\n","('Joven estudiante.', 'Young student.', 'Ikasle gaztea.')\n","('preguntó Mr. Power.', 'Mr Power asked.', '-galdetu zuen Powerrek.')\n","('Sí.', 'Yes.', 'Bai.')\n","('preguntó Mr. Power.', 'Mr Power asked.', '-galdetu zuen Powerrek.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek-.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('El corazón.', 'Heart.', 'Bihotzekoa.')\n","('Nadie lo reclama.', 'Nobody owns.', 'Nork eraman?')\n","('Por las piedras.', 'Over the stones.', 'Harlosetan.')\n","('-¿Por qué?', '-Why?', '-Zergatik?')\n","('Quince.', 'Fifteen.', 'Hamabost.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('No.', 'No.', 'Ez.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('¿Eh?', 'Eh?', 'E?')\n","('preguntó.', 'he asked.', '-galdetu zuen-.')\n","('¡Pobre Dignam!', 'Poor Dignam!', 'Dignam gaixoa!')\n","('Caramba.', 'Hello.', 'To.')\n","('No, no:', 'No, no:', 'Ez, ez:')\n","('No:', 'No:', 'Ez:')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Se pararon.', 'They stopped.', 'Gelditu egin ziren.')\n","('Gracias.', 'Thank you.', 'Mila esker.')\n","('Sllt.', 'Sllt.', 'Sllt.')\n","('Sllt.', 'Sllt.', 'Sllt.')\n","('-Espere.', '-Wait.', '-Zaude.')\n","('-¡Monks!', '-Monks!', '-Monks!')\n","('Intentarlo de todas formas.', 'Try it anyhow.', 'Saiatu behintzat.')\n","('Sí.', 'Yes.', 'Bai.')\n","('No.', 'No.', 'Ez.')\n","('Aquí.', 'Here.', 'Hemen.')\n","('No.', 'No.', 'Ez.')\n","('preguntó Mr. Bloom.', 'Mr Bloom asked.', '-galdetu zuen Bloomek.')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('-¿Cómo está usted?', '-How do you do?', '-Zer moduz?')\n","('preguntó Stephen.', 'Stephen asked.', '-galdetu zuen Stephenek.')\n","('Sí, sí.', 'Yes, yes.', 'Bai, bai.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('dijo Myles Crawford.', 'Myles Crawford said.', '-esan zuen Myles Crawfordek.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('Se lo diré.', \"I'll tell you.\", 'Esango dizut.')\n","('Bien.', 'Right.', 'Ederki.')\n","('Bien.', 'Right.', 'Ederki.')\n","('Sí...', 'Yes...', 'Bai...')\n","('Sí.', 'Yes.', 'Bai.')\n","('¡Bah!', 'Psha!', 'Beeh!')\n","('A. E.', 'A. E.', 'A. E.')\n","('preguntó el profesor.', 'the professor asked.', '-galdetu zuen irakasleak.')\n","('-Ya veo, dijo el profesor.', '-I see, the professor said.', '-Argi dago-esan zuen irakasleak.')\n","('No.', 'No.', 'ez.')\n","('Imprecaron al nazareno con recios insultos.', 'Iron nails ran in.', 'Iosi Naute Romanoek Iltzez.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('¿Eh?', 'Eh?', 'E?')\n","('No.', 'No.', 'ez.')\n","('No, no.', 'No, no.', 'Ez, ez.')\n","('¿Hermana?', 'Sister?', 'Arreba?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-No, dijo Mr. Bloom.', '-No, Mr Bloom said.', '-Ez-esan zuen Bloomek-.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('preguntó Mr. Bloom.', 'Mr Bloom asked.', '-galdetu zuen Bloomek.')\n","('Cruel.', 'Cruel.', 'Krudela.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('Té.', 'Tea.', 'Tea.')\n","('No lo veo.', \"Can't see it.\", 'Ez diat ikusten.')\n","('Sí:', 'Yes:', 'Bai:')\n","('Espera.', 'Wait.', 'Hago.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Trago.', 'Gulp.', 'Dzanga.')\n","('Casher.', 'Kosher.', 'Kosher.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('-No.', '-No.', '-Ez.')\n","('Las dos.', 'Two.', 'Ordu biak.')\n","('Vino.', 'Wine.', 'Ardoa.')\n","('-Sí, dijo.', '-Yes, he said.', '-Bai-esan zuen-.')\n","('Instinto.', 'Instinct.', 'Sena.')\n","('Nadie.', 'No-one.', 'Inor ez.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('dijo Napias Flynn.', 'Nosey Flynn said.', '-esan zuen Flynn Sudurluzek-.')\n","('preguntó Paddy Leonard.', 'Paddy Leonard asked.', '-galdetu zuen Paddy Leonardek.')\n","('dijo.', 'he said.', '-esan zuen.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Ballsbndge.', 'Ballsbridge.', 'Ballsbridge.')\n","('A. E.', 'A. E.', 'A. E.')\n","('Mordedura de la conciencia.', 'Agenbite of inwit.', 'Agenbite of inwit.')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('No.', 'No.', 'ez.')\n","('Nadie me ha regalado nada.', 'I paid my way.', 'Neure kabuz ordaindu dut.')\n","('Espera.', 'Wait.', 'Hago.')\n","('Jueves.', 'Thursday.', 'Osteguna.')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('¡Telegrama!', 'Telegram!', 'Telegrama!')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('-¿Qué?', '-What?', '-Zer?')\n","('Conoce a tu viejo.', 'He knows your old fellow.', 'Ezagutzen dik hire zaharra.')\n","('No.', 'No.', 'Ez.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BEST', 'BEST:', 'BEST')\n","('(risas)', '(Laughter)', '(Algara)')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Avefría.', 'Lapwing.', 'Hegabera.')\n","('-¿Por qué?', '-Why?', '-Zergatik?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Día.', 'Day.', 'Eguna.')\n","('Sí.', 'Yes.', 'Bai.')\n","('preguntó.', 'he asked.', '-galdetu zuen.')\n","('preguntó Boody.', 'Boody asked.', '-galdetu zuen Boodyk.')\n","('dijo.', 'he said.', '-esan zuen.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('dijo Almidano Artifoni.', 'Almidano Artifoni said.', '-esan zuen Almidano Artifonik.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('', 'Yes:', 'Bai:')\n","('No, señor.', 'No, sir.', 'Ez, jauna.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('preguntó Ned Lambert.', 'Ned Lambert asked.', '-galdetu zuen Ned Lambertek-.')\n","('¿Qué?', 'What?', 'Zer?')\n","('seis.', 'six.', 'sei.')\n","('-¿Ven ustedes?', '-See?', '-Ikusten?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('cuatro.', 'four.', 'lau.')\n","('preguntó.', 'he asked.', '-galdetu zuen.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Escucha:', 'Listen:', 'Entzun:')\n","('No:', 'No:', 'Ez:')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¡Talán!', '-Barang!', '-Talan!')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('Sí.', 'Yes.', 'Bai.')\n","('No.', 'No.', 'Ez.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Amén.', 'Amen.', 'Amen.')\n","('dijo Stephen.', 'Stephen said.', '-esan zuen Stephenek.')\n","('Mordedura.', 'Agenbite.', 'Agenbite.')\n","('Mordedura de la conciencia.', 'Agenbite of inwit.', 'Agenbite of inwit.')\n","('¿Qué tal van las cosas?', 'How are things?', 'Zer moduz?')\n","('Rataplán.', 'Baraabum.', 'Ra-ta-plan.')\n","('Revelación.', 'Avowal.', 'Agerpena.')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Aún no.', 'Not yet.', 'Oraindik ez.')\n","('Adelante.', 'On.', 'Aurrera.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Lascas.', 'Chips.', 'Printzak.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Viejo Bloom.', 'Old Bloom.', 'Bloom zaharra.')\n","('-No.', '-No.', '-Ez.')\n","('preguntó Mr. Dedalus.', 'Mr Dedalus asked.', '-galdetu zuen Dedalus jaunak.')\n","('¿Quién?', 'Who?', 'Nor?')\n","('preguntó.', 'he asked.', '-galdetu zuen-.')\n","('-¿Es cierto?', '-Is that a fact?', '-Benetan?')\n","('Para Raoul.', 'For Raoul.', 'Raoulentzat.')\n","('De nuevo.', 'Again.', 'Berriro.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('-¡Ay!', '-O!', '-O!')\n","('¡Ay!', 'O!', 'O!')\n","('¡Ay!', 'O!', 'O!')\n","('El reloj tabaleaba.', 'Clock clacked.', 'Erlojuaren klaskada.')\n","('A las cuatro.', 'At four.', 'Lauretan.')\n","('No hay nadie.', \"There's no-one.\", 'Ez dago inor.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('¿Eh?', 'What?', 'Ezta?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('Adiós.', 'Farewell.', 'Agur.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí:', 'Yes:', 'Bai:')\n","('¿A mí?', 'Me?', 'Ni?')\n","('¿Qué tal?', 'How do you?', 'Zer moduz?')\n","('¿Y qué?', 'There?', 'Hor?')\n","('¿Qué?', 'What?', 'Zer?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('No:', 'No:', 'Ez:')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Monta.', 'Tup.', 'Zazt.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Ven.', 'Come.', 'Zatoz.')\n","('Ven.', 'Come.', 'Etorri.')\n","('Cloche.', 'Cloche.', 'Cloche.')\n","('¡Dingdón!', 'Heigho!', 'Haika!')\n","('Para sujetársela.', 'To keep it up.', 'Goian eusteko.')\n","('Mujer.', 'Woman.', 'Emakumea.')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek-.')\n","('¡Pat!', 'Pat!', 'Pat!')\n","('Je je.', 'Hee hee.', 'Ji ji.')\n","('Je je je je.', 'Hee hee hee hee.', 'Ji ji ji ji.')\n","('Cantando.', 'Singing.', 'Kantuz.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Lluvia.', 'Rain.', 'Euria.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('¿Cuánto?', 'How much?', 'Zenbat?')\n","('Je je je je.', 'Hee hee hee hee.', 'Ji ji ji ji.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Todos se fueron.', 'All gone.', 'Denak joanak.')\n","('Rudy.', 'Rudy.', 'Rudy.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('¿Qué?', 'What?', 'Zer?')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Pobre Mrs.', 'Poor Mrs Purefoy.', 'Purefoy andre gaixoa.')\n","('Castilla.', 'Castile.', 'Gaztela.')\n","('Amén.', 'Amen.', 'Amen.')\n","('No.', 'No.', 'Ez.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Espera.', 'Wait.', 'Itxaron.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Toc.', 'Tap.', 'Tak.')\n","('¿Eh?', 'What?', 'Zer?')\n","('Toc.', 'Tap.', 'Tak.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Goulding, Collis, Ward.', 'Goulding, Collis, Ward.', 'Goulding, Collis, Ward.')\n","('Pon.', 'Pom.', 'Pom.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Cloche.', 'Cloche.', 'Cloche.')\n","('Sonnez la.', 'Sonnez la.', 'Sonnez la.')\n","('Poropón.', 'Pompedy.', 'Ponpoxoa.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Je je je je.', 'Hee hee hee hee.', 'Ji ji ji ji.')\n","('Sí.', 'Yes.', 'Bai.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('le digo yo.', 'says I.', '-nik.')\n","('¡Ah!', 'Ah!', 'Ai!')\n","('le digo yo.', 'says I.', '-nik.')\n","('-¿Quién?', '-Who?', '-Nork?')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('-¿Qué es eso?', \"-What's that?\", '-Zer da hori?')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('-Sí, dice Alf.', '-Yes, says Alf.', '-Bai-Alfek-.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Bob Doran.', 'says Bob Doran.', '-Bob Doranek.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('¿Qué?', 'What?', 'Zer?')\n","('dice Alf.', 'says Alf.', '-Alfek-.')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('le digo yo.', 'says I.', '-nik.')\n","('-...', '-...', '-...')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('¡Fenómeno!', 'Phenomenon!', 'Fenomenoa!')\n","('le digo yo.', 'says I.', '-nik.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('Mr. Acuatropatas:', 'Mr Allfours:', 'Allfours jauna:')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('el Rvdo.', 'the rev.', 'P. J.')\n","('-¿Quién?', '-Who?', '-Nork?')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('-¿Quién?', '-Who?', '-Nork?')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('J. J.', 'J. J.', 'J. J.')\n","('dice Joe.', 'says Joe.', '-dio Joek-.')\n","('dice Alf.', 'says Alf.', '-dio Alfek-.')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('¿Qué?', 'What?', 'Zer?')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Terry.', 'says Terry.', '-dio Terryk.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak-.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice John Wyse.', 'says John Wyse.', '-dio John Wysek.')\n","('dice Bloom.', 'says Bloom.', '-dio Bloomek-.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('', '', '-Eta?')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak-.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice John Wyse.', 'says John Wyse.', '-dio John Wysek.')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('-¿Por qué no?', '-Why not?', '-Zergatik ez?')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak-.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('No.', 'No.', 'Ez.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('No, no:', 'No, no:', 'Ez, ez:')\n","('¡Ah!', 'Ah!', 'Ai!')\n","('No.', 'No.', 'Ez.')\n","('¡Oh!', 'O!', 'Ooo!')\n","('Ah, sí.', 'Ah, yes.', 'A, bai.')\n","('Molly.', 'Molly.', 'Molly.')\n","('Tableau!', 'Tableau!', 'Tableau!')\n","('No.', 'No.', 'Ez.')\n","('¿Y por qué no?', 'Why not?', 'Zergatik ez?')\n","('¿Qué?', 'What?', 'Zer?')\n","('', '', 'O!')\n","('¿Qué?', 'What?', 'Zer?')\n","('Mullingar.', 'Mullingar.', 'Mullingar.')\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Joven estudiante.', 'Young student.', 'Ikasle gaztea.')\n","('Dignam.', 'Dignam.', 'Dignam.')\n","('Tic.', 'Tip.', 'Ttak.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Sí.', 'Yes.', 'Bai.')\n","('No.', 'No.', 'Ez.')\n","('Ummm.', 'Hm.', 'Hm.')\n","('No.', 'No.', 'Ez.')\n","('Ummm.', 'Hm.', 'Hm.')\n","('Ummm.', 'Hm.', 'Hm.')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('Mira.', 'See.', 'Begira.')\n","('No.', 'No.', 'Ez.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('No.', 'No.', 'Ez.')\n","('Ba.', 'Ba.', 'Saguz.')\n","('Ba.', 'Ba.', 'Saguz.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('Ba.', 'Ba.', 'Saguz.')\n","('Queridísimo papi.', 'Dearest Papli.', 'Aitatxo maitea.')\n","('No.', 'No.', 'Ez.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('No.', 'No.', 'Ez.')\n","('Mejor.', 'Better.', 'Hobe.')\n","('¡Oh!', 'O!', 'O!')\n","('¿Qué?', 'What?', 'Zer?')\n","('Gracias.', 'Thanks.', 'Eskerrik asko.')\n","('De aquí.', 'Here.', 'Hemen.')\n","('Cuco', 'Cuckoo', 'Kuku')\n","('Cuco', 'Cuckoo', 'Kuku')\n","('¡Ah!', 'Ah!', 'Ai!')\n","('¿Eh?', 'Eh?', 'E?')\n","('Buenas.', 'Night.', 'Gabon.')\n","('¡Plaap!', 'Pflaap!', 'Plaast!')\n","('LOS NIÑOS', 'THE CHILDREN:', 'HAURRAK')\n","('EL IDIOTA', 'THE IDIOT:', 'IDIOTA')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('¡Ah!', 'Ah!', 'A!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Qué es eso?', 'What is that?', 'Zer da hori?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Abajo sobre las manos.', 'On the hands down.', 'Eskuen gainean makurtuta.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¡Ay!', 'Ow!', 'Ai!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡Ah!', 'Ah!', 'A!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí.', 'Yes.', 'Bai.')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('Quince.', 'Fifteen.', 'Hamabost.')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('GERTY', 'GERTY:', 'GERTY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Cómo está usted?', 'How do you do?', 'Zer moduz?')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RICHIE', 'RICHIE:', 'RICHIE')\n","('RICHIE', 'RICHIE:', 'RICHIE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí.', 'Yes.', 'Bai.')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS OCIOSOS', 'THE LOITERERS:', 'ZER-SUMAKOAK')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('Vamos.', 'Come.', 'Zatoz.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARTHA', 'MARTHA:', 'MARTHA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BEAUFOY', 'BEAUFOY:', 'BEAUFOY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BEAUFOY', 'BEAUFOY:', 'BEAUFOY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BEAUFOY', 'BEAUFOY:', 'BEAUFOY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","(\"J. J. O'MOLLOY\", \"J. J. O'MOLLOY:\", \"J. J. O'MOLLOY\")\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('MRS. BELLINGHAM', 'MRS BELLINGHAM:', 'BELLINGHAM ANDREA')\n","('MRS. BELLINGHAM', 'MRS BELLINGHAM:', 'BELLINGHAM ANDREA')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('A mí también.', 'Me too.', 'Niri ere bai.')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('MRS. BELLINGHAM', 'MRS BELLINGHAM:', 'BELLINGHAM ANDREA')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Kismet.', 'Kismet.', 'Kismet.')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Gígaja.', 'Jigjag.', 'Txik-txak.')\n","('EL INNOMINADO', 'THE NAMELESS ONE:', 'IZENGABEA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('EL UJIER', 'THE CRIER:', 'UXERRA')\n","('¡Escandaloso!', 'Scandalous!', 'Eskandalagarria!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('Amén.', 'Amen.', 'Amen.')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","(\"JOHN O'CONNELL\", \"JOHN O'CONNELL:\", \"JOHN O'CONNELL\")\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡Dios salve a Leopold Primero!', 'God save Leopold the First!', 'Gora Leopold Lehena!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡No!', 'No!', 'Ez!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('colgado.', 'up.', 'ep.')\n","('colgado.', 'up.', 'ep.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('PADDY LEONARD', 'PADDY LEONARD:', 'PADDY LEONARD')\n","('Gracias.', 'Thank you.', 'Eskerrik asko.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","(\"J. J. O'MOLLOY\", \"J. J. O'MOLLOY:\", \"J. J. O'MOLLOY\")\n","('¡No!', 'Nay!', 'Ez!')\n","('NAPIAS FLYNN', 'NOSEY FLYNN:', 'FLYNN SUDURLUZE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BEN DOLLARD', 'BEN DOLLARD:', 'BEN DOLLARD')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('NAPIAS FLYNN', 'NOSEY FLYNN:', 'FLYNN SUDURLUZE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('PADDY LEONARD', 'PADDY LEONARD:', 'PADDY LEONARD')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA SIBILA CON VELO', 'THE VEILED SIBYL:', 'SIBILA ESTALZAPIDUNA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL PAISANO', 'THE CITIZEN:', 'HERRITARRA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Ser o no ser.', 'To be or not to be.', 'Izan ala ez izan.')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('', '', 'Zergatik?')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¡Ba!', 'Bah!', 'Beh!')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA GORRA', 'THE CAP:', 'BISERA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA GORRA', 'THE CAP:', 'BISERA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¿Qué?', 'What?', 'Zer?')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('No.', 'No.', 'Ez.')\n","('EL GRAMÓFONO', 'THE GRAMOPHONE:', 'GRAMOFONOA')\n","('ELÍAS', 'ELIJAH:', 'ELIAS')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BEST', 'BEST:', 'BEST')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAD', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAD', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAD', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Espera.', 'Wait.', 'Itxaron.')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('¿Dónde estamos?', 'Where are we?', 'Non gaude?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Sí.', 'Yes.', 'Bai.')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('¿Eh?', 'Eh?', 'E?')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('Nada hay nuevo bajo el sol.', 'Nothing new under the sun.', 'Ezer berririk ez eguzkipean.')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('KITTY', 'KITTY:', 'KITTY')\n","('PHILIP EBRIO', 'PHILIP DRUNK:', 'PHILIP MOZKOR')\n","('PHILIP SOBRIO', 'PHILIP SOBER:', 'PHILIP URZALE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('¡Jek!', 'Hek!', 'Hek!')\n","('BEN DOLLARD', 'BEN DOLLARD:', 'BEN DOLLARD')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BEN DOLLARD', 'BEN DOLLARD:', 'BEN DOLLARD')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('Adiós.', 'Farewell.', 'Agur.')\n","('Hy Franks.', 'Dr Hy Franks.', 'Hy Franks doktorea.')\n","('HENRY', 'HENRY:', 'HENRY')\n","('Ya todo está perdido.', 'All is lost now.', 'Dena galdua da orain.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí.', 'Yes.', 'Bai.')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Mejor oferta de Dub.', 'Best value in Dub.', 'Dublingo baliotsuena.')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA PEZUÑA', 'THE HOOF:', 'APATXA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('ZOE', 'ZOE:', 'ZOE')\n","('Sí.', 'Yes.', 'Bai.')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('Yo también.', 'I will.', 'Nik ere bai.')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('A mí.', 'Me.', 'Niri.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('La ciencia.', 'Science.', 'Zientzia.')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('¿Dónde?', 'Where?', 'Non?')\n","('¿A qué hora?', 'What time?', 'Zer ordutan?')\n","('¡Dos!', 'Two!', 'Bi!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('¡Arriba!', 'Up!', 'Jaiki!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BELLO', 'BELLO:', 'BELLO')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Yo....', 'I...', 'Ni...')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BELLO', 'BELLO:', 'BELLO')\n","('Demasiado tarde.', 'Too late.', 'Beranduegi.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('VOCES', 'VOICES:', 'AHOTSAK')\n","('Ah, sí.', 'Ah, yes.', 'A, bai.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Mnemo?', 'Mnemo?', 'Mnemo?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ECO', 'THE ECHO:', 'OIHARTZUNA')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('EL SALTO DE AGUA', 'THE WATERFALL:', 'UR-JAUZIA')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL SALTO DE AGUA', 'THE WATERFALL:', 'UR-JAUZIA')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('Amén.', 'Amen.', 'Amen.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡Nebrakada!', 'Nebrakada!', 'Nebrakada!')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BELLA', 'BELLA:', 'BELLA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('KITTY', 'KITTY:', 'KITTY')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Casada.', 'Married.', 'Ezkondua.')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Hoy.', 'Today.', 'Gaur.')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¿Dinero?', 'Money?', 'Dirua?')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('¿Qué?', 'What?', 'Zer?')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('MARION', 'MARION:', 'MARION')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('¿Qué?', 'What?', 'Zer?')\n","('MARION', 'MARION:', 'MARION')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Gracias, señor.', 'Thank you, sir.', 'Eskerrik asko, jauna.')\n","('KITTY', 'KITTY:', 'KITTY')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('SHAKESPEARE', 'SHAKESPEARE:', 'SHAKESPEARE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('LAS PUTAS', 'THE WHORES:', 'PUTAK')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('LAS PUTAS', 'THE WHORES:', 'PUTAK')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¡Diez a uno menos uno!', 'Ten to one bar one!', 'Hamar bati beste edozeinentzat!')\n","('¡Diez a uno menos uno!', 'Ten to one bar one!', 'Hamar bati beste edozeinentzat!')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('LAS HORAS', 'HOURS:', 'ORDUAK')\n","('LOS MAESTRANTES', 'CAVALIERS:', 'ZALDIZKOAK')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('¡Dingdón!', 'Heigho!', 'Haika!')\n","('ZOE', 'ZOE:', 'ZOE')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('ZOE', 'ZOE:', 'ZOE')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('KITTY', 'KITTY:', 'KITTY')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('¡Bravo!', 'Bravo!', 'Biba!')\n","('¡Encore!', 'Encore!', 'Beste bat!')\n","('SIMON', 'SIMON:', 'SIMON')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('No.', 'No.', 'Ez.')\n","('BUCK MULLIGAN', 'BUCK MULLIGAN:', 'BUCK MULLIGAN')\n","('Epi oinopa ponton.', 'Epi oinopa ponton.', 'Epi oinopa ponton.')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¡No!', 'No!', 'Ez!')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('EL CHORRO DE GAS', 'THE GASJET:', 'GAS-TXORROTA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BELLA', 'BELLA:', 'BELLA')\n","('LAS PUTAS', 'THE WHORES:', 'PUTAK')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('Diez chelines.', 'Ten shillings.', 'Hamar txelin.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Diez chelines?', 'Ten shillings?', 'Hamar txelin?')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('¿Qué?', 'What?', 'Zer?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('VOCES', 'VOICES:', 'AHOTSAK')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BIDDY EXPURGACIONES', 'BIDDY THE CLAP:', 'BIDDY GONOKOKO')\n","('KATE COÑONA', 'CUNTY KATE:', 'KATE POTORRO')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('EDUARDO SÉPTIMO', 'EDWARD THE SEVENTH:', 'EDUARDO ZAZPIGARRENA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BIDDY EXPURGACIONES', 'BIDDY THE CLAP:', 'BIDDY GONOKOKO')\n","('LA VIRAGO', 'THE VIRAGO:', 'VIRAGOA')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('EL PAISANO', 'THE CITIZEN:', 'HERRITARRA')\n","('EL ZAGAL REBELDE', 'THE CROPPY BOY:', 'MATXINO GAZTEA')\n","('RUMBOLD', 'RUMBOLD:', 'RUMBOLD')\n","('EDUARDO SÉPTIMO', 'EDWARD THE SEVENTH:', 'EDUARDO ZAZPIGARRENA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('UN BRAVUCÓN', 'A ROUGH:', 'HARROPUTZ BAT')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('KATE COÑONA', 'CUNTY KATE:', 'KATE POTORRO')\n","('BIDDY EXPURGACIONES', 'BIDDY THE CLAP:', 'BIDDY GONOKOKO')\n","('KATE COÑONA', 'CUNTY KATE:', 'KATE POTORRO')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('VOCES', 'VOICES:', 'AHOTSAK')\n","('¡Policía!', 'Police!', 'Polizia!')\n","(\"EL PADRE MALACHI O'FLYNN\", \"FATHER MALACHI O'FLYNN:\", \"AITA MALACHI O'FLYNN\")\n","('EL REVERENDO MR. HAINES LOVE', 'THE REVEREND MR HAINES LOVE:', 'HAINES LOVE JAUN AGURGARRIA')\n","('(Desde las alturas la voz de Adonai clama)', '(From on high the voice of Adonai calls.)', '(Adonairen ahotsa entzuten da zeru-goietan)')\n","('ADONAI', 'ADONAI:', 'ADONAI')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('EL COMANDANTE TWEEDY', 'MAJOR TWEEDY:', 'TWEEDY MAIORRA')\n","('¡Aire!', 'Air!', 'Airea!')\n","('¿Quién?', 'Who?', 'Nor?')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('EL PERDIGUERO', 'THE RETRIEVER:', 'EHIZA-TXAKURRA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('¿Quién es usted?', 'Who are you?', 'Nor zara zu?')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('Le conozco.', 'I know him.', 'Ezagutzen dut.')\n","('Copa de oro.', 'Gold cup.', 'Urrezko kopa.')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('¿Qué?', 'What?', 'Zer?')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('LOS GUARDIAS', 'THE WATCH:', 'HERRIZAINAK')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('EL CABALLO', 'THE HORSE:', 'ZALDIA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Buenas noches.', 'Good night.', 'Gabon.')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Buenas.', 'Night.', 'Gabon.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Lástima.', 'Pity.', 'Pena.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Por qué?', 'Why?', 'Zer, bada?')\n","('¿Qué hay en un nombre?', \"What's in a name?\", 'Zer dago, bada, izen batean?')\n","('-¡Pun!', '-Pom!', '-Pum!')\n","('De allí vengo yo.', \"That's where I hails from.\", 'Han dut nik jaioterria.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('Vamos.', 'Come.', 'Zatoz.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Incompleto.', 'Incomplete.', 'Osatu gabea.')\n","('Se sienta.', 'She sits.', 'Esertzen da.')\n","('Crepúsculo.', 'Twilight.', 'Ilunabarra.')\n","('Piensa.', 'She thinks.', 'Pentsatzen du.')\n","('Crepúsculo.', 'Twilight.', 'Ilunabarra.')\n","('¿Qué?', 'What?', 'Zer?')\n","('No.', 'No.', 'Ez.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Por Stephen:', 'By Stephen:', 'Stephenek:')\n","('Liliata rutilantium.', 'Liliata rutilantium.', 'Liliata rutilantium.')\n","('Por Bloom:', 'By Bloom:', 'Bloomek:')\n","('¿Como por ejemplo?', 'As?', 'Adibidez?')\n","('¿Cómo?', 'How?', 'Nola?')\n","('¿Cómo?', 'How?', 'Nola?')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Qué es eso?', \"'What's that?'\", '-Zer da hori?')\n","('-¡Oooh!', \"'Oo!'\", '-Oooo!')\n","('-¡Oooh!', '', '-Oooo!')\n","('-¡Oooh!', \"'Oo!'\", '-Oooo!')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('', '', 'Zergatik?')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', '', '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('No hubo respuesta.', 'No answer.', 'Erantzunik ez.')\n","('-¿Por qué no?', \"'Why not?'\", '-Zergatik ez?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Lo que espera mi madre.', \"'What my mother hopes.\", '-Nire amak espero duena.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¡Oh!', '\"Oh!', '\"O!')\n","('-¡Oh!', '\"Oh!', '\"O!')\n","('-¡Oh, sí!', '\"Oh!', '\"O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('-¡Oh, sí!', '\"Oh!', '\"O!')\n","('Adiós.', 'Good-bye.', 'Agur.')\n","('¡Oh!', 'Oh!', 'O!')\n","('-No.', \"'No.'\", '-Ez.')\n","('¡Hop, hop, hop!', \"Rataplan, rataplan, rataplan.'\", 'hop, hop, hop!')\n","('', '', '- Ikusten?')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('-¡Lavativa y aspirina!', \"'Enema and aspirin!\", '-Aiuta eta aspirina!')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('-No lo sé.', \"'I don't know.'\", '-Ez dakit.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('V', 'V', 'V')\n","('', '', '- Ongi:')\n","('VI', 'VI', 'VI')\n","('¿Lo entiende?', 'Do you understand?', 'Ulertzen?')\n","('Jungwirt\".', 'Jungwirt.\"', 'Jungwirt\".')\n","('¿Lo entiende?', \"Do you understand?'\", 'Ulertzen?')\n","('Dice:', 'He says:', 'Esaten du:')\n","('El tren se detuvo.', 'The train stopped.', 'Trena gelditu egin zen.')\n","('...', '...', '...')\n","('¿Y por qué?', 'And why?', 'Eta zergatik?')\n","('Sonó el teléfono.', 'The telephone rang.', 'Telefonoak jo zuen.')\n","('-De Praga.', \"'From Prague.'\", '-Pragakoa.')\n","('-No.', \"'No.'\", '-Ez.')\n","('...', '...', '...')\n","('Ahora.', 'Now.', 'Orain.')\n","('', '', '-esan nion-.')\n","('-Pero...', '\"But-\"', '-Baina...')\n","('...', '...', '...')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-¿Por qué?', '', '- Zergatik?')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Pero...', '\"But-\"', '-Baina...')\n","('...', '...', '...')\n","('...', '...', '...')\n","('-¿Qué?', '', '- Zer?')\n","('-¡No!', '\"No!', '-Ez!')\n","('-dije-.', '\"What?\" I said.', '-esan nion-.')\n","('', '', '- Eta?')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('A las duras y a las maduras:', 'THROUGH THICK AND THIN:', 'KOSTA AHALA KOSTA:')\n","('La auténtica historia de la lucha de un hombre contra fuerzas superiores y mujeres de baja estofa...', \"THE TRUE STORY OF A MAN'S FIGHT AGAINST HIGH ODDS AND LOW WOMEN...\", 'GIZON BATEN BORROKA, GOI-INDARREN ETA EMATXARREN KONTRA...')\n","('', '', 'Nik...')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('Abrí la puerta.', 'I opened the door.', 'Atea ireki nuen.')\n","('Negué con la cabeza.', 'I shook my head.', 'Buruari eragin nion.')\n","('', '', 'Esan nion:')\n","('-Muy bien-dije-.', '\"All right,\" I said.', '-Ederki-esan nion-.')\n","('', '', '-esan nion.')\n","('-Ya lo sé.', '\"I know.', '-Badakit.')\n","('', '', 'Nik...')\n","('...', '...', '...')\n","('-¿Quién es?', '', '-Nor da?')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('No.', 'No.', 'Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-Bai.')\n","('-¿Cómo te llamas?', '\"What is your name?\"', '-Nola duzu izena?')\n","('', '', '-Ixo!')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('-¿Qué es esto?', '', '-Zer da hau?')\n","('-preguntó.', '', '-galdetu zuen.')\n","('-Si, señora.', '\"Yes, madame.\"', '-Bai, andrea.')\n","('-Si, señora.', '\"Yes, madame.\"', '-Bai, andrea.')\n","('-Si, señora.', '\"Yes, madame.\"', '-Bai, andrea.')\n","('-¿Qué es esto?', '', '-Zer da hau?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Eso es.', \"That's it.\", 'Hori da.')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('', '', 'Arranopola!')\n","('-¿Y?', '\"And?\"', '-Eta?')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('', '', 'Arraioa!')\n","('-¿Quién?', '\"Who?\"', '-Nork?')\n","('-preguntó-.', '', '-galdetu zuen-.')\n","('-¿Y bien?', '\"Well?\"', '-Eta?')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-le preguntó.', '', '-galdetu zion.')\n","('-Gracias, señor.', '\"Thank you, sir.', '-Eskerrik asko, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-Si, mi señora.', '\"Yes, my lady.\"', '-Bai, andrea.')\n","('-Si.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Cómo empezó el fuego?', '', '-Nola hasi zen sua?')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('', '', '-galdetu zion.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('¡No!', 'No!', 'Ez!')\n","('-¿Cuánto?', '\"How much?\"', '-Zenbat?')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('', '', '-oihu egin zuen-.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-No.', '\"No.', '-Ez.')\n","('', '', 'Ai!')\n","('-No.', '\"No.', '-Ez.')\n","('No.', 'No.', 'Ez.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Cómo?', '', '-Nola?')\n","('-No-contestó-.', '\"No,\" he said.', '-Ez-esan zuen-.')\n","('¡Vamos!', '\"Come!\"', 'Goazen!')\n","('Capítulo primero', 'CHAPTER I.', '1. KAPITULUA')\n","('Capítulo II', 'CHAPTER II.', '2. KAPITULUA')\n","('Capítulo III', 'CHAPTER III.', '3. KAPITULUA')\n","('Capítulo IV', 'CHAPTER IV.', '4. KAPITULUA')\n","('Capítulo V', 'CHAPTER V.', '5. KAPITULUA')\n","('Capítulo VII', 'CHAPTER VII.', '7. KAPITULUA')\n","('Capítulo VIII', 'CHAPTER VIII.', '8. KAPITULUA')\n","('Capítulo II', 'CHAPTER II.', '2. KAPITULUA')\n","('Capítulo III', 'CHAPTER III.', '3. KAPITULUA')\n","('Capítulo V', 'CHAPTER V.', '5. KAPITULUA')\n","('Capítulo primero', 'CHAPTER I.', '1. KAPITULUA')\n","('Capítulo II', 'CHAPTER II.', '2. KAPITULUA')\n","('Capítulo III', 'CHAPTER III.', '3. KAPITULUA')\n","('Capítulo IV', 'CHAPTER IV.', '4. KAPITULUA')\n","('Capítulo V', 'CHAPTER V.', '5. KAPITULUA')\n","('Capítulo VI', 'CHAPTER VI.', '6. KAPITULUA')\n","('Capítulo VII', 'CHAPTER VII.', '7. KAPITULUA')\n","('Capítulo VIII', 'CHAPTER VIII.', '8. KAPITULUA')\n","('Capítulo IX', 'CHAPTER IX.', '9. KAPITULUA')\n","('Capítulo XI', 'CHAPTER XI.', '11. KAPITULUA')\n","('I', 'I', 'I')\n","('¡Ah!', 'Ah!', 'A!')\n","('Good-bye.', 'Good-bye.', 'Good-bye.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('', '', 'Bai;')\n","('No.', 'No.', 'Ez.')\n","('II', 'II', 'II')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('¿Cómo?', 'What?', 'Zer?')\n","('', '', 'Zer!')\n","('¿Qué?', 'What?', 'Zer?')\n","('III', 'III', 'III')\n","('', '', 'Nik...')\n","('', '', 'Ai!')\n","('No sé.', \"I don't know.\", 'Ez dakit.')\n","('El destino.', 'Destiny.', 'Patua.')\n","('¡No!', 'No!', 'Ez!')\n","('', '', 'Bai;')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('¿Eh?', 'Eh?', 'E?')\n","('¡El horror!\"', \"The horror!'\", 'Horrorea!\".')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-Sí, señor.', '\"Yes, sire.\"', '-Bai, jauna.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No.', 'No.', 'Ez.')\n","('-Enemigos.', '\"Enemies.\"', '-Kontrarioak ez, etsaiak.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', '-A!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-galdetu zuen.')\n","('-¡Silencio!', '', '-Ixo!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡No!', '', '-Ez!')\n","('¿Pero cómo?', 'But how?', 'Baina nola?')\n","('De Kolyvan, gobierno de Omsk, Siberia, 6 de agosto.', '\"From Kolyvan, Government of Omsk, Siberia, 6th August.', 'Kolivan, Omsk probintzia, Siberia, abuztuak 6.')\n","('-¿Por qué no?', '', '-Eta zergatik ez?')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('', '', '-esan zuen.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¡No!', '', '-Ez!')\n","('', '', '-esan zuen.')\n","('-¡No!', '', '-Ez!')\n","('-gritó-.', '', '-oihu egin zuen-.')\n","('', '', 'Nadia!')\n","('', '', '-galdetu zuen.')\n","('', '', '-galdetu zuen.')\n","('-A pie.', '\"On foot.\"', '-Oinez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí...', '\"Yes...', '-Bai...')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No...', '\"No...', '-Ez...')\n","('-Todavía no.', '\"Not yet.\"', '-Oraindik ez.')\n","('-¿Qué es esto?', '', '-Zer da hau?')\n","('-¿Yo?', '', '-Ni?')\n","('', '', 'Bai!')\n","('¡No!', 'No!', 'Ez!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Entró un hombre.', 'A man entered.', 'Gizon bat sartu zen.')\n","('-preguntó.', '', '-galdetu zion.')\n","('-Miguel Strogoff.', '\"Michael Strogoff.\"', '-Mikel Strogoff.')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duk?')\n","('', '', '-galdetu zion.')\n","('-Sí, Alteza.', '\"Yes, your Highness.\"', '-Bai, jauna.')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('¿No?', 'No?', 'Ez?')\n","('Pausa.', 'A pause.', 'Isilunea.')\n","('-Sí.', '\"Yes;', '\"Bai.')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('V', 'V', 'V')\n","('-Sí...', '', '- Bai...')\n","('Sí.', 'Yes.', 'Bai.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('VI', 'VI', 'VI')\n","('VII', 'VII', 'VII')\n","('VIII', 'VIII', 'VIII')\n","('IX', 'IX', 'IX')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('', '', 'Berdin dio.')\n","('-No pasa nada Vasia.', '\"Never mind, Vasya.', '-Lasai, Vasia.')\n","('-¡Qué impaciente!', '\"How eager you are!', '-Hori presa zurea!')\n","('-No.', '\"No.', '-Ez.')\n","('Se oyen pasos en algún sitio.', 'Somewhere people were walking.', 'Non edo non, pauso-hotsak entzuten dira.')\n","('-¿Qué es esto?', '\"What is this?', '-Zer da hau?')\n","('-¿Quién es usted?', '\"Who are you?\"', '-Nor zara?')\n","('', '', '-Bai!')\n","('Abajo, abajo, abajo.', 'Down, down, down.', 'Behera, behera, behera.')\n","('', '', 'O!')\n","('Veamos:', 'Let me see:', 'Ikus dezagun:')\n","('', '', 'Nola!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('', '', 'Ixo!')\n","('¡Ven!', \"Come on!'\", 'Goazen!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('¡Que sí, que no, que sí, que no, la danza sí!', \"Will you, won't you, will you, won't you, will you join the dance?\", 'Nahi duzu, ez duzu nahi, nahi duzu, ez duzu nahi, nahi duzu dantzan parte hartu?')\n","('¡Sooopa qué hermooosa!', 'Beau-ootiful Soo-oop!', 'Zoooopa goooozoooa!')\n","('', '', 'Badakizu?')\n","('-¡Oh!', '', '-O!')\n","('-¿Qué es esto?', '', '-Zer da hau?')\n","('¡Hola!', 'Ahoy!', 'E!')\n","('', '', '-esan zuen-.')\n","('Cosa fácil es:', 'That is easy:', 'Hori erreza da:')\n","('\"¿Y qué más?\"', '\"So what?\"', '-Eta?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('', '', '-A!')\n","('', '', 'Hara!')\n","('Nadie.', 'Nobody.', 'Inork ez.')\n","('', '', 'A!')\n","('¡Ah, no!', 'Certainly not!', 'Bai zera!')\n","('', '', 'A!')\n","('', '', '-Hara!')\n","('', '', '-Hara!')\n","('Nada.', 'Nothing.', 'Deus ez.')\n","('¿A quién?', 'To whom?', 'Nori?')\n","('No.', 'No.', 'Ez.')\n","('', '', 'Bai zera!')\n","('¿Eh?', 'Am I right?', 'Ez al da egia?')\n","('', '', '\"')\n","('No sabía qué hacer.', \"I didn't know what to do.\", 'Ez nekien zer egin.')\n","('', '', '-A!')\n","('', '', 'Hara!')\n","('Siempre lo mismo.', 'Always the same.', 'Beti gauza bera.')\n","('ou...', 'ou...', 'ou...')\n","('¡Ah!', 'Ah!', 'A!')\n","('', '', '-A!')\n","('¡Ah!', '', 'A!')\n","('', '', '-A!')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('SEGUNDA PARTE', 'II', 'BIGARREN ZATIA')\n","('', '', 'Baina, nolanahi ere den, bidezkoa da ez dezazula zure atsedena nirearen karietara sakrifika, eta bitartekoak eskaini nahi dizkizut zure maiteñoari gutun hori niri zuzendua dela, eta ez zuri, froga diezaiozun.')\n","('I', 'I', 'I')\n","('¿Pero cómo?', 'But how?', 'Baina nola?')\n","('No sé.', 'I cannot tell.', 'Ez dakit.')\n","('II', 'II', 'II')\n","('', '', '-Hara!')\n","('', '', 'O!')\n","('', '', '\"Horra!')\n","('-No.', '\"No.', '-Ez.')\n","('-¡Ah!', '\"Oh!', '\"O!')\n","('', '', '-Ez?')\n","('', '', 'Mme.')\n","('Quince años y medio.', 'Fifteen and a half.', \"Hamabost urte t'erdi.\")\n","('Marie-Claude Carpenter.', 'Marie-Claude Carpenter.', 'Marie Claude Carpenter.')\n","('Betty Fernández.', 'Betty Fernandez.', 'Betty Fernández.')\n","('Quince años y medio.', 'Fifteen and a half.', \"Hamabost urte t'erdi.\")\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Antínoo había muerto.', 'Antinous was dead.', 'Antinoo hila zen.')\n","('Antínoo había muerto.', 'Antinous was dead.', 'Antinoo hila zen.')\n","('Antínoo había muerto.', 'Antinous was dead.', 'Antinoo hila zen.')\n","('', '', 'Badakizu:')\n","('Tenía razón.', 'He was right.', 'Arrazoi zuen.')\n","('La puerta se abrió.', 'The door opened.', 'Ireki zen atea.')\n","('', '', 'Badakizu?')\n","('', '', '- Bai!')\n","('', '', '- Bai!')\n","('-Sí.', '\"Yes.\"', '-Bai!')\n","('', '', '-galdetu zuen.')\n","('', '', '- Bai!')\n","('-¿Qué?', '', '- Zer?')\n","('-¡Oh, no!', '\"Oh, no!', '-O, ez!')\n","('', '', '- Bai!')\n","('', '', '-galdetu zuen amak.')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('', '', '- Bai!')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¿Por qué?', '\"Why?', '-Zer ba?')\n","('', '', '- Bai noski!')\n","('-¡Camaradas!', '\"Comrades!', '-Lagunkideok!')\n","('', '', 'Entzun!')\n","('I', 'CHAPTER I', 'I')\n","('-Cristo ha resucitado de entre los muertos...', '\"Christ has arisen from the dead.\"', 'Kristo hilen artetik biztu zen...')\n","('-¿Cuándo?', '\"When?', '-Noiz?')\n","('II', 'CHAPTER II', 'II')\n","('III', 'CHAPTER III', 'III')\n","('IV', 'CHAPTER IV', 'IV')\n","('V', 'CHAPTER V', 'V')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('¡Sí!', '', 'Bai!')\n","('-Sí.', '\"Yes.\"', '-Bai!')\n","('VI', 'CHAPTER VI', 'VI')\n","('VII', 'CHAPTER VII', 'VII')\n","('VIII', 'CHAPTER VIII', 'VIII')\n","('IX', 'CHAPTER IX', 'IX')\n","('-¿Qué quiere?', '\"What do you want?\"', '-Zer nahi duzu?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('X', 'CHAPTER X', 'X')\n","('XI', 'CHAPTER XI', 'XI')\n","('XII', 'CHAPTER XII', 'XII')\n","('-¡Camaradas!', '\"Comrades!', '-Lagunkideok!')\n","('XIII', 'CHAPTER XIII', 'XIII')\n","('XIV', 'CHAPTER XIV', 'XIV')\n","('', '', 'Benetan!')\n","('XV', 'CHAPTER XV', 'XV')\n","('XVI', 'CHAPTER XVI', 'XVI')\n","('', '', '- Bai!')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('', '', '- Egia da!')\n","('XVIII', 'CHAPTER XVIII', 'XVIII')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('XIX', 'CHAPTER XIX', 'XIX')\n","('XX', 'CHAPTER XX', 'XX')\n","('-¿Quién?', '\"Who?', '-Nork?')\n","('-Vlassov.', '\"Vlasov.\"', '-Vlasov.')\n","('XXII', 'CHAPTER XXII', 'XXII')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Sí?', '\"Yes?', '-Bai?')\n","('', '', '- O!')\n","('XXIII', 'CHAPTER XXIII', 'XXIII')\n","('XXVI', 'CHAPTER XXVI', 'XXVI')\n","('-Gracias.', '\"Thank you.\"', '-Eskerrik asko.')\n","('XXVIII', 'CHAPTER XXVIII', 'XXVIII')\n","('', '', '- Ez da egia!')\n","('XXIX', 'CHAPTER XXIX', 'XXIX')\n","('Por ejemplo:', 'For example:', 'Adibidez:')\n","('', '1877', '')\n","('', '1877', '')\n","('¿Enfermedad?', 'A disease?', 'Gaixotasuna?')\n","('¡No!', 'No!', 'Ez!')\n","('¿Para qué?', 'Wherefore?', 'Zertarako?')\n","('No.', 'No.', 'Ez.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('¿Y qué?', 'And what then?', 'Eta zer?')\n","('¿Y qué?', 'And what then?', 'Eta zer?')\n","('', '', '-esan zuen.')\n","('', '', 'Hara!')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '', '- Zergatik?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No;', '\"No;', '-Ez;')\n","('-¿Por qué?', '\"Why not?\"', '-Zergatik?')\n","('-¿Para qué?', '', '- Zertarako?')\n","('No.', 'No.', 'Ez.')\n","('-¡Pechorin!', '\"Pechorin!', '-Petxorin!')\n","('Adiós.', 'Good-bye.\"', 'Agur.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', 'Arraioa!')\n","('', '', '- Ondo!')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('11', '11', '11')\n","('-¿Y qué?', '\"So what?', '-Eta zer?')\n","('12', '12', '12')\n","('13', '13', '13')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¿Sí?', '\"Yes?', '-Bai?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¿Por qué no?', '', '-Zergatik ez?')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('-No.', '\"No.\"', '-Ez.')\n","('11', '11', '11')\n","('12', '12', '12')\n","('No saben nada.', \"You don't know anything.\", 'Ez dakizue ezer.')\n","('¡Todavía sigo estando viva!', \"For the time being I'm still alive!\", 'Oraindik segitzen diat bizitzen!')\n","('Si ustedes supiesen.', 'If you only knew.', 'Jakingo bazenute.')\n","('No saben nada.', \"You don't know anything.\", 'Ez dakizue ezer.')\n","('No saben nada.', 'You don\\'t know anything.\"', 'Ez dakizue ezer ere.')\n","('Sí.', 'Yes.', 'Bai.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('-No.', '\"No.', '-Ez.')\n","('11', '11', '11')\n","('12', '12', '12')\n","('13', '13', '13')\n","('14', '14', '14')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('11', '11', '11')\n","('12', '12', '12')\n","('1', '1', '1')\n","('2', '2', '2')\n","('Pero...', 'But...\"', 'Baina...')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('-¿De verdad?', '\"Really?\"', '-Benetan?')\n","('7', '7', '7')\n","('8', '8', '8')\n","('¡El pecado no existe!', 'There is no sin!\"', 'Bekaturik ez zegok!')\n","('9', '9', '9')\n","('10', '10', '10')\n","('CAPITULO VII:', '', '')\n","('CAPITULO III:', '', '')\n","('CAPITULO XIII:', '', '')\n","('CAPITULO III:', '', '')\n","('CAPITULO VII:', '', '')\n","('', '', 'Are gehiago:')\n","('', '', 'Are gehiago:')\n","('CAPITULO IV:', '', '')\n","('CAPITULO XIV:', '', '')\n","('CAPITULO II:', '', '')\n","('CAPITULO VII:', '', '')\n","('CAPITULO III:', '', '')\n","('CAPITULO XV:', '', '')\n","('CAPITULO XIII:', '', '')\n","('CAPITULO XVIII:', '', '')\n","('CAPITULO XIX:', '', '')\n","('CAPITULO II:', '', '')\n","('CAPITULO III:', '', '')\n","('CAPITULO XI:', '', '')\n","('CAPITULO VIII:', '', '')\n","('CAPITULO XIX:', '', '')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('CONTINUACION DE LA MISMA MATERIA', '17. The same Subject continued', 'XVII. Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', '5. The same Subject continued', 'V. Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', '10. The same Subject continued', 'X. Gai beraren jarraipena')\n","('CAPITULO IV:', '', 'IV. Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', '11. The same Subject continued', 'XI. Gai beraren jarraipena')\n","('CAPITULO XII:', '', '')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('De Erzurum, 20 de la luna de Gemadi, 2,1711', 'Erzeron, the 20th of the moon of the 2d Gemmadi, 1711', 'Erzeron-dik, 1711ko Gemmadi 2.aren ilargiaren 20an.')\n","('Usbek a su amigo Rustan, a Isfahán', 'Usbek to his Friend Rustan, at Ispahan', 'USBEK-ek ISPAHAN-go bere adiskide RUSTAN-i')\n","('', '', 'E!')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Adiós.', 'Farewel.', 'Agur.')\n","('De París, 20 de la luna de Rhegeb, 1713', 'Paris, the 20th of the moon Rhegeb, 1713', 'Parisen, 1713ko Rhegeb-en ilargiaren 20an.')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('', '', '- E!')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Adiós.', 'Farewel.', 'Adio.')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('', '', 'Hara!')\n","('Usbek a Iben, a Esmirna', 'Usbek to Ibben, at Smyrna', 'USBEK-ek SMYRNE-n dagoen IBBEN-i')\n","('', '', 'Areago oraindik:')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('', '', 'A!')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Adiós.', 'Farewel.', 'Adio.')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben, at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('', '', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek a Mirza, a Isfahán', 'Usbek to Mirza, at Ispahan', 'USBEK-ek ISPAHAN-en dagoen MIRZA-ri')\n","('', '', 'RICA-k ***-i')\n","('', '', 'RICA-k ***-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek a Iben, a Esmirna', 'Usbek to Ibben, at Smyrna', 'USBEK-ek SMYRNE-n dagoen IBBEN-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Rica a Redi, a Venecia', 'Rica to Rhedi, at Venice', 'RICA-k VENEZIAn dagoen RHEDI-ri')\n","('Usbek a Iben, a Esmirna', 'Usbek to Ibben, at Smyrna', 'USBEK-ek SMYRNE-n dagoen IBBEN-i')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('No:', 'No:', 'Ez.')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Usbek a...', 'Usbek to * * *', 'USBEK-ek ***-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('De París, 1 de la luna de Chalval, 1718', 'Paris, the 1st of the moon Chalval, 1718', 'Parisen, 1718ko Chalval-en ilargiaren 1ean.')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben, at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Usbek a...', 'Usbek to * * *', 'USBEK-ek ***-i')\n","('De París, 4 de la luna de Chaban, 1719', 'Paris, the 4th of the moon Chahban, 1719', 'Parisen, 1719ko Chahban-en ilargiaren 4ean.')\n","('Usbek a Nesir, a Isfahán', 'Usbek to Nessir, at Ispahan', 'USBEK-ek ISPAHAN-en dagoen NESSIR-i')\n","('Adiós.', 'Farewel.', 'Adio.')\n","('Del serrallo de Isfahán, 2 de la luna de Maharran, 1720', 'From the seraglio at Ispahan, the 2d of the moon Maharran, 1720', 'Ispahan-go anderenetik, 1720ko Maharram-en ilargiaren 2an.')\n","('Solim a Usbek, a París', 'Solin to Usbek, at Paris', 'SOLIM-ek PARISen dagoen USBEK-i')\n","('Del serrallo de Isfahán, 8 de la luna de Rebiab, 1,1720', 'From the seraglio at Ispahan, the 8th of the moon of the first Rebiab, 1720', 'Ispahan-go anderenetik, 1720ko Rebiab 1.aren ilargiaren 8an.')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('', '', '- Oh!')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '- Oh!')\n","('¡Simples palabras!', 'Mere words!', 'Hitz hutsak!')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik, bada?')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('', '', '-')\n","('', '', '- Oh!')\n","('', 'Ah!', 'Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('No;', 'No;', 'Ez;')\n","('Lord Henry se encogió de hombros.', 'Lord Henry shrugged his shoulders.', 'Lord Henryk soina goratu zuen.')\n","('Lord Henry se echó a reír.', 'Lord Henry laughed.', 'Lord Henryk barre egin zuen.')\n","('', '', '- Oh!')\n","('', '', '- Ah!')\n","('Lord Henry se encogió de hombros.', 'Lord Henry shrugged his shoulders.', 'Lord Henryk soina goratu zuen.')\n","('No;', 'No;', 'Ez.')\n","('¿Qué significaba aquello?', 'What did it mean?', 'Zer esan nahi zuen horrek?')\n","('No;', 'No;', 'Ez;')\n","('No;', 'No;', 'Ez;')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No;', 'No;', 'Ez;')\n","('No;', 'No;', 'Ez;')\n","('Dorian negó con un movimiento de cabeza.', 'Dorian shook his head.', 'Dorianek burua mugitu zuen.')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('', '', '- Oh!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¡Pobre Basil!', 'Poor Basil!', 'Basil gizajoa!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('¡No!', 'No!', 'Ez!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('Lord Henry se encogió de hombros.', 'Lord Henry shrugged his shoulders.', 'Lord Henryk soina goratu zuen.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Dorian se encogió de hombros.', 'Dorian shrugged his shoulders.', 'Dorianek soina goratu zuen.')\n","('¿Dinero?', 'Money?', 'Dirua?')\n","('-¡Dios mío!', '\"My God!', '-Jainko nirea!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('', '\"Oh!', '- Oh!')\n","('', '', '- Ah!')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('¡Dios del cielo!', 'Good heavens!', 'Jainko maitea!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('No.', 'No.', 'Ez.')\n","('', '', '- Oh!')\n","('Lord Henry se echó a reír.', 'Lord Henry laughed.', 'Lord Henryk barre egin zuen.')\n","('Eso es todo.', 'That is all.', 'Hori da dena.')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('Eso es todo.', 'That is all.', 'Hori da dena.')\n","('Se echó a reír.', 'He laughed.', 'Barre egin zuen.')\n","('No.', 'No.', 'Ez.')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('2', '2', '2')\n","('3', '3', '3')\n","('-No, señor.', \"'No, sir.\", '-Ez, jauna.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('4', '4', '4')\n","('5', '5', '5')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('6', '6', '6')\n","('7', '7', '7')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('8', '8', '8')\n","('9', '9', '9')\n","('-¿Qué quieres decir?', '', '-Zer esan nahi duzu?')\n","('-¡Hola!', '', '-Kaixo!')\n","('-Sí.', '', '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('10', '10', '10')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('11', '11', '11')\n","('-No.', \"'No.'\", '-Ez.')\n","('Estaba solo.', 'He was alone.', 'Bakarrik zegoen.')\n","('12', '12', '12')\n","('13', '13', '13')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('14', '14', '14')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¡Oh, claro!', '', '-A, bai!')\n","('15', '15', '15')\n","('-¡No!', '', '-Ez!')\n","('-...', \"'...\", '-...')\n","('16', '16', '16')\n","('17', '17', '17')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¡Oh!', '', '-O!')\n","('-¡Me salvé!', '', '-Igeri egin nuen!')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('-Pronto?', \"'Pronto?'\", '-Pronto?')\n","('¿Dónde estás?', \"Where are you?'\", 'Non zaude?')\n","('-¿Dónde?', \"'Where?'\", '-Non?')\n","('19', '19', '19')\n","('20', '20', '20')\n","('Atentamente,', 'Sincerely,', 'Adeitasunez,')\n","('Atentamente,', 'Sincerely,', 'Adeitasunez,')\n","('21', '21', '21')\n","('22', '22', '22')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-En efecto.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('Gracias.', 'Thank you.', 'Eskerrik asko.')\n","('23', '23', '23')\n","('Marge', 'Marge', 'Marge')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¡Marge!', \"'Marge!\", '-Marge!')\n","('', '', '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('24', '24', '24')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('25', '25', '25')\n","('-No.', \"'No.'\", '-Ez.')\n","('Abrió los ojos.', 'He opened his eyes.', 'Begiak zabaldu zituen.')\n","('-¿Cuándo?', \"'When?'\", '-Noiz?')\n","('-No.', \"'No.'\", '-Ez.')\n","('- preguntó.', '', '-galdetu zion.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-¿Cuándo?', \"'When?'\", '-Noiz?')\n","('-No.', \"'No.\", '-Ez.')\n","('Venecia', 'Venice', 'Venezia')\n","('-¿Qué?', '', '-Zer?')\n","('1', '1', '1')\n","('-¡No!', \"'No!\", '-Ez!')\n","('2', '2', '2')\n","('¡Ja, ja!', 'Ha!', 'Ja, ja!')\n","('-¡No!', \"'No!\", '-Ez!')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Un hombre.', 'A man.', 'Gizon batek.')\n","('3', '3', '3')\n","('Pero...', '', 'Baina...')\n","('4', '4', '4')\n","('-No.', \"'No.\", '-Ez.')\n","('-...', \"'...\", '-...')\n","('-No.', \"'No.\", '-Ez.')\n","('5', '5', '5')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('6', '6', '6')\n","('No.', 'No.', 'Ez.')\n","('7', '7', '7')\n","('-No.', \"'No.\", '-Ez.')\n","('-...', \"'...\", '-...')\n","('-...', \"'...\", '-...')\n","('Pero no.', 'But no.', 'Baina ez.')\n","('Se humedeció los labios.', 'He wet his lips.', 'Ezpainak busti zituen.')\n","('-En el plazo de una semana.', \"'Within a week.\", '-Astebete barru.')\n","('-¿De veras?', '', '-Benetan?')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('8', '8', '8')\n","('-¡Hola, Jonathan!', \"'Hello, Jonathan!\", '-Kaixo, Jonathan!')\n","('-...', \"'...\", '-...')\n","('Eso es todo.', \"That's all.'\", 'Hori da dena.')\n","('No.', \"No.'\", 'Ez.')\n","('Adiós.', \"Bye-bye.'\", 'Agur.')\n","('9', '9', '9')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('10', '10', '10')\n","('-No.', \"'No.\", '-Ez.')\n","('11', '11', '11')\n","('', '', 'Zergatik ez?')\n","('-No.', \"'No.'\", '-Ez.')\n","('12', '12', '12')\n","('-No.', '', '-Ez.')\n","('-No.', '', '-Ez.')\n","('Respuesta:', 'Answer:', 'Erantzuna:')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('13', '13', '13')\n","('-¡No!', '', '-Ez!')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('14', '14', '14')\n","('-¿Y bien?', '', '-Eta?')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Lo sé.', 'I know that.', 'Badakit.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('Por eso.', \"That's why.\", 'Horrexegatik.')\n","('15', '15', '15')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('16', '16', '16')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Jonathan meneó la cabeza.', 'Jonathan shook his head.', 'Jonathanek buruari eragin zion.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('17', '17', '17')\n","('¿Dónde estás?', 'Where are you?', 'Non zaude?')\n","('-¡Hola, Tome!', \"'Hello, Tome!\", '-Kaixo, Tom!')\n","('Sí.', 'Yes.', 'Bai.')\n","('18', '18', '18')\n","('-No.', \"'No.\", '-Ez.')\n","('Jonathan guardó silencio.', 'Jonathan was silent.', 'Jonathan isilik zegoen.')\n","('-Sí-dijo Tom-.', \"'Yes,' Tom said.\", '-Bai-esan zuen Tomek-.')\n","('19', '19', '19')\n","('-¿Qué ocurre?', '', '-Zer gertatzen da?')\n","('Jonathan sonrió.', 'Jonathan smiled.', 'Jonathanek irribarre egin zuen.')\n","('Sonó el timbre.', 'The doorbell rang.', 'Txirrinak jo zuen.')\n","('-¿Quién es?', '', '-Nor da?')\n","('-Lippo.', \"'Lippo.\", '-Lippo.')\n","('-Pronto.', \"'Pronto.\", '-Pronto.')\n","('Tom meneó la cabeza.', 'Tom shook his head.', 'Tomek buruari eragin zion.')\n","('20', '20', '20')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('21', '21', '21')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¿Tom?', \"'Tom?'\", '-Tom?')\n","('-¿Sí?', \"'Yes?'\", '-Bai?')\n","('Tom asintió con la cabeza.', 'Tom nodded.', 'Tomek baiezkoa egin zuen buruaz.')\n","('-No lo sé.', '', '-Ez dakit.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('¿No está de acuerdo?', \"Don't you agree?\", 'Ez al zaude ados?')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('22', '22', '22')\n","('-¿Ah, sí?', \"'Oh, yes?'\", '-Ah, bai?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('Yo...', '', 'Nik...')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('-No.', \"'No.\", '-Ez.')\n","('23', '23', '23')\n","('-¿Quién es?', '', '-Nor da?')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Pero...', '', '-Baina...')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('24', '24', '24')\n","('Estuvo de acuerdo.', 'He agreed.', 'Bat etorri zen.')\n","('Asintió.', 'He assented.', 'Ados egon zen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Estuvo de acuerdo.', 'He agreed.', 'Ados zegoen.')\n","('', '', '-esan zuen-.')\n","('', '', '- Zer?')\n","('Eut. ¿Cómo no?', 'EUTHYPHRO: Certainly.', '-Nola ez, bada?')\n","('Eut. Sí.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('Eut. Es verdad.', 'EUTHYPHRO: True.', '-Egia diozu.')\n","('Eut. Sí.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('Eut. Sí.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('Eut. Ciertamente.', 'EUTHYPHRO: Very true.', '-Erabat, bai.')\n","('Eut. Sí.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('Eut. Ciertamente.', 'EUTHYPHRO: Exactly.', '-Erabat, bai.')\n","('-Sí-dijo.', 'Yes, he said.', '-Bai-esan zuen.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-¿Cómo dices?', 'What do you mean?', '-Nola diozu?')\n","('-Así es.', 'Very true.', '-Hori da.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Necesariamente.', 'Certainly.', '-Nahitaez.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'True.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-¿Cómo dices?', 'What do you mean?', '-Nola diozu?')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'True.', '-Bai.')\n","('FED. Sí.', 'PHAEDRUS: Yes.', '-Bai.')\n","('FED. Así es.', 'PHAEDRUS: That is true.', '-Horrela da.')\n","('FED. \"De mis asuntos tienes noticia, y has oído también, cómo considero la conveniencia de que esto suceda.', \"PHAEDRUS: 'You know how matters stand with me, and how, as I conceive, they might be arranged for our common interest;\", '-\"Ezagutzen duzu nire egoera, eta hori gertatzea komeni zaigula uste dudala ere entzun duzu.')\n","('FED. Sí.', 'PHAEDRUS: Yes.', '-Bai.')\n","('FED. Sí.', 'PHAEDRUS: Yes.', '-Bai.')\n","('FED. Sí.', 'PHAEDRUS: Yes.', '-Bai.')\n","('FED. Sí.', 'PHAEDRUS: Yes.', '-Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: True.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: True.', 'Po. Bai.')\n","('POL. Forzosamente.', 'POLUS: Certainly.', 'Po. Derrigor.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Ciertamente.', 'POLUS: I should.', 'Po. Nik bai.')\n","('POL. ¿Cómo no?', 'POLUS: Of course.', 'Po. Nola ez, bada?')\n","('POL. Sí.', 'POLUS: True.', 'Po. Bai.')\n","('POL. Forzosamente.', 'POLUS: Certainly.', 'Po. Derrigor.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Horixe.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('', '', 'Ala ez?')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: True.', 'Po. Bai.')\n","('POL. Así parece.', 'POLUS: True.', 'Po. Hala dirudi.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Nik bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sin duda.', 'CALLICLES: Certainly.', 'Ka. Erabat.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. ¿Cómo no?', 'CALLICLES: To be sure.', 'Ka. Nola ez, bada?')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. ¿Cómo no?', 'CALLICLES: Certainly.', 'Ka. Nola ez, bada?')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. ¿Cómo no?', 'CALLICLES: To be sure.', 'Ka. Nola ez, bada?')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Halaxe da.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sin duda.', 'CALLICLES: To be sure.', 'Ka. Erabat.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sin duda.', 'CALLICLES: Certainly.', 'Ka. Erabat.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Así parece.', 'CALLICLES: True.', 'Ka. Hala dirudi.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', '', 'Ka. Bai.')\n","('CAL. Ciertamente.', 'CALLICLES: Quite true.', 'Ka. Erabat.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: True.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Certainly.', '-Bai, noski.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Certainly.', '-Erabat, bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Eso es.', 'HERMOGENES: True.', '-Hori da.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Certainly.', '-Bai, noski.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Yes.', '-Bai, noski.')\n","('HERM. Dices verdad.', 'HERMOGENES: That is true.', '-Egia diozu.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sólo tienes que hablar.', 'HERMOGENES: Let me hear.', '-Esan besterik ez duzu.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('', '', '- Bai.')\n","('HERM. Así es.', 'HERMOGENES: That is true.', '-Hori da.')\n","('HERM. Desde luego.', 'HERMOGENES: Yes.', '-Bai, noski.')\n","('HERM. Sí.', 'HERMOGENES: True.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: True.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Claro.', 'MENO: I should.', '-Bai, noski.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('SÓC. ¿Y entonces?', '', '- Eta zer?')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('MEN. Así parece.', 'MENO: True.', '-Hala dirudi.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('MEN. Es verdad.', 'MENO: True.', '-Egia diozu.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: True.', '-Bai.')\n","('MEN. Por supuesto.', 'MENO: Certainly.', '-Guztiz, bai.')\n","('MEN. Sí.', 'MENO: True.', '-Bai.')\n","('MEN. Por supuesto.', 'MENO: True.', '-Bai, noski.')\n","('ÁN. Sí.', 'ANYTUS: Yes.', '-Bai.')\n","('MEN. Por supuesto.', 'MENO: Certainly.', '-Bai, noski.')\n","('SÓC. ¿Cómo dices?', 'SOCRATES: What do you mean?', '-Nola diozu?')\n","('MEN. Así es.', 'MENO: True.', '-Hori da.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Por supuesto.', 'MENO: Certainly.', '-Erabat, bai.')\n","('MEN. Por supuesto.', 'MENO: Certainly.', '-Guztiz, bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Por supuesto.', 'MENO: Certainly.', '-Erabat, bai.')\n","('', '', '\"')\n","('¡Bien!', 'Ah!', 'Ongi da!')\n","('', '', 'Entzun.')\n","('', '', '...')\n","('', '', 'Bai.')\n","('¡Ah!', 'Ah!', 'A!')\n","('', '', 'E!')\n","('\"¡Ah!', '\"Ah!', '-A!')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('', '', 'O!')\n","('', '', '-Bai zera!')\n","('-¿De veras?', '', '-Benetan?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('', '', '-Jainkoarren!')\n","('', '', 'Ikus dezagun.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¡Ah!', '', '-Ah!')\n","('-No.', '\"No.', '-Ez.')\n","('', '', 'Alde hemendik!')\n","('-Lo siento.', '\"I\\'m sorry.', '-Sentitzen dut.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('', '', '-esan zuen-.')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('', '', '-esan nion-.')\n","('-No;', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', '-esan zuen-.')\n","('No me moví.', \"I didn't move.\", 'Ez nintzen mugitu.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('-No.', '\"No.\"', '-Ez.')\n","('Sus ojos se agrandaron.', 'Her eyes rounded.', 'Begiak handi-handi jarri zitzaizkion.')\n","('Eso es todo.', 'That\\'s all.\"', 'Hori duk dena.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('Brody se encogió de hombros.', 'Brody shrugged.', 'Brodyk sorbaldak uzkurtu zituen.')\n","('-¡Váyase al diablo!', '\"Go-- yourself.\"', '-Hoa pikutara!')\n","('-¡Váyase al diablo!', '\"Go-- yourself.\"', '-Hoa pikutara!')\n","('', 'I said:', 'Nik esan nion:')\n","('-¿Por qué?', '', '-Zergatik?')\n","('-¿Y bien?', '\"Well?\"', '-Eta?')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('-Desde luego.', '\"Sure.\"', '-Noski.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('-Muy bien, señor.', '\"Very good, sir.', '-Oso ondo, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('', 'I said:', 'Nik esan nion:')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-Bo!')\n","('-No;', '\"No.', '-Ez.')\n","('-Claro.', '\"Sure.', '-Bai, noski.')\n","('-Claro.', '\"Sure.', '-Jakina.')\n","('Sonrió.', 'She smiled.', 'Irribarre egin zuen.')\n","('', '', '-esan zidan.')\n","('-Es usted encantador.', '\"You\\'re cute.\"', '-Ederra zara.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('', '', '-esan nion.')\n","('-¿Sí?', '', '-Bai?')\n","('-¿Dónde está Agnes?', '\"Where\\'s Agnes?\"', '-Non dago Agnes?')\n","('No me moví.', \"I didn't move.\", 'Ez nintzen mugitu.')\n","('-¿Sí?', '\"Yeah?\"', '-Bai?')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', '-galdetu nion.')\n","('', 'I said:', 'Nik esan nion:')\n","('-¿Qué desea?', '\"What you want?\"', '-Zer nahi duzu?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', 'Irribarre egin zuen.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('', '', '-Goazen!')\n","('-No.', '\"No.\"', '-Ez!')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('', 'I said:', 'Nik esan nion:')\n","('-No.', '\"No.', '-Ez.')\n","('Sonrió.', 'He smiled.', 'Irribarre egin zuen.')\n","('-Sí.', '\"Uh-huh.', '-Bai.')\n","('-dije.', '', '-esan nion.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-Lo siento.', '\"I\\'m sorry.', '-Sentitzen dut.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('Asentí.', 'I nodded.', 'Baietz egin nion buruaz.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('Me reí.', 'I laughed.', 'Barre egin nuen.')\n","('-Sí.', \"'Yeah.\", '\"Bai.')\n","('-No.', \"'No.\", '\"Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('Sonreí.', 'I smiled.', 'Irribarre egin nuen.')\n","('-¿Por qué no?', \"'Why not?\", '\"Zergatik ez?')\n","('', '', 'Esan nion:')\n","('-No.', \"'No.\", '\"Ez.')\n","('-Sí.', \"'Yeah.\", '\"Bai.')\n","('', 'I said:', 'Esan nuen:')\n","('Se lo dije.', 'I told him.', 'Esan nion.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('', '', '-')\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Sacudió la cabeza.', 'He shook his head.', 'Buruari eragin zion.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('Nadie se movió.', 'Nobody moved.', 'Inor ez zen mugitu.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('', '', '-Ez.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('No dije nada.', \"I didn't say anything.\", 'Ez nuen ezer esan.')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Por qué?', '', '-Zergatik?')\n","('-Muy bien-dije-.', '\"Okay,\" I said.', '-Ederki-esan nion-.')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('¿Sí o no?', 'Yes or no?', 'Bai ala ez?')\n","('Lo miré fijamente.', 'I stared at him.', 'Begietara begiratu nion.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Sí?', '', '-Bai?')\n","('-¿Por qué?', '\"Why?\"', '-Zer ba?')\n","('-Tal vez.', '\"Maybe.', '-Agian.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('Está trabajando.', 'He\\'s working.\"', 'Lanean ari da.')\n","('Ella sonrió.', 'She smiled.', 'Irribarre egin zuen.')\n","('-¿Cómo se llama?', '\"What\\'s your name?\"', '-Nola duzu izena?')\n","('', '', 'Zer gertatzen da?')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('¿Qué hora es?', 'What time is it?\"', 'Zer ordu da?')\n","('-Si.', '\"Yes.\"', '-Bai.')\n","('No.', 'No.', 'Ez.')\n","('¿No?', 'No?', 'Ez?')\n","('No.', 'No.', 'Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-No, gracias.', '\"No, thanks.\"', '-Ez, eskerrik asko.')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('Nadie dijo nada.', 'Nobody said anything.', 'Inork ez zuen ezer esan.')\n","('-¿Yo?', '\"Me?', '-Ni?')\n","('-No.', '\"Nope.\"', '-Ez.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Lo ignoro.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('Sacudió la cabeza.', 'He shook his head.', 'Buruari eragin zion.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('Error.', 'Mistake.', 'Gaizki egina.')\n","('', '', 'Badakizu?')\n","('La puerta se cerró.', 'The door closed.', 'Atea itxi zen.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('', '', 'Ez.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('La puerta se cerró.', 'The door closed.', 'Atea itxi zen.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Entonces dijo:', 'Then he said:', 'Gero esan zuen:')\n","('-No.', '\"No.\"', '-Ez.')\n","('Tal vez.', 'Maybe.', 'Agian.')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('Suicidio.', 'Suicide.', 'Suizidioa.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('No.', 'No.', 'Ez.')\n","('-¿Y con eso?', '\"So?\"', '-Eta?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿No?', '\"No?', '-Ez?')\n","('', '', 'Ai!')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-¿Por qué?', '', '-Zergatik?')\n","('-¡Oh!', '\"Oh.\"', '-Ah!')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('Silencio.', 'Silence.', 'Isiltasuna.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('Yo no contesté.', \"I didn't answer him.\", 'Ez nion erantzun.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-¿Yo?', '\"Me?', '-Nik?')\n","('Se lo dije.', 'I told him.', 'Esan nion.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Muy bien.', '\"Okay.', '-Ederki.')\n","('-¿Por qué?', '', '-Zergatik?')\n","('-No.', '\"No.', '-Ez.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-¿Yo?', '\"Me?', '-Nik?')\n","('Nada más.', 'Nothing else.', 'Besterik ez.')\n","('¿Para qué?', 'What for?', 'Zertarako?')\n","('¿Algo más?', 'Anything else?\"', 'Besterik?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-Gracias.', '\"Thank you.\"', '-Eskerrik asko.')\n","('', '', '-esan zuen.')\n","('Después dijo:', 'Then he said:', 'Gero esan zuen:')\n","('-No.', '\"No.', '-Ez.')\n","('Me puse de pie.', 'I stood up.', 'Zutitu nintzen.')\n","('-Ya sé.', '\"I know.', '-Badakit.')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-Por supuesto.', '\"Of course.', '-Noski.')\n","('¿Para qué?', 'What for?', 'Zertarako?')\n","('Era cierto.', 'It was true.', 'Egia zen.')\n","('', '', 'Ikus dezagun:')\n","('Era cierto.', 'It was true.', 'Egia zen.')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('-Lo sé.', '\"I know.', '\"Badakit.')\n","('-Sí.', '\"Yes.', '\"Bai.')\n","('-No.', '\"No.\"', '\"Ez\".')\n","('-Sí.', '\"Yes.\"', '\"Bai\".')\n","('-No.', '\"No.', '\"Ez.')\n","('-No.', '\"No.\"', '\"Ez\".')\n","('-No lo sé.', '\"I don\\'t know.', '\"Ez dakit.')\n","('-No.', '\"No.\"', '\"Ez\".')\n","('-No.', '\"No.', '\"Ez.')\n","('-Sí.', '\"Yes.', '\"Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Reiting?', \"'Reiting?'\", '-Reiting?')\n","('-¿Qué?', \"'What?'\", '-Zer?')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('Silencio.', 'Silence.', 'Isiltasuna.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('¿Por qué?', \"Why?'\", 'Zer dela eta?')\n","('Törless no respondió.', \"Törless didn't reply.\", 'Törlessek ez zuen erantzunik eman.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-¡Alá!', \"'Allah!\", '-Alaren izenean!')\n","('-Muy bien.', \"'Very good.\", '-Oso ondo.')\n","('-No lo sé.', \"'I do not know.\", '-Ez dakit.')\n","('-¿Y...?', \"'And?'\", '-Eta?')\n","('¡Mira!', 'Look!', 'Begira!')\n","('- ¡No!', '', '- Ez!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('- ¿Qué es eso?', '', '- Zer da hori?')\n","('No.', 'No.', 'Ez.')\n","('-No lo sé.', \"'I do not know.\", '-Ez dakit.')\n","('-¡Ah!', \"'Aha!\", '-A!')\n","('No.', 'No.', 'Ez.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¡Dios sabe!', \"'God knows.\", '-Jainkoak daki.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('-Muy bien.', \"'Very good.\", '-Oso ondo.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¡No!', \"'No!\", '-Ez!')\n","('-Muy bien.', \"'Very good.\", '-Oso ondo.')\n","('-¡Mira!', \"'Look!\", '-Ikusi!')\n","('-¡Mira!', \"'Look!\", '-Ikusi!')\n","('-¡Mira!', \"'Look!\", '-Ikusi!')\n","('', '', '- A!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('¡No!', 'No!', 'Ez!')\n","('-Eso es verdad.', \"'That is true.\", '-Hori egia da.')\n","('-Muy bien.', \"'Good.\", '-Ondo.')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('Pero...', '', 'Baina...')\n","('-Es verdad.', \"'It is true.\", '-Egia da.')\n","('¡Mira!', \"'Look!\", 'Begira!')\n","('-¡Sí!', \"'Yes!\", '-Bai!')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('- ¡Mira!', '', '- Begira!')\n","('-No.', \"'No.\", '-Ez.')\n","('- ¡Ay!', '', '- Ai!')\n","('-¡Oh!', \"'Oho!\", '-Hara!')\n","('-Es verdad.', \"'True.\", '-Egia da.')\n","('No.', 'No.', 'Ez.')\n","('-¡No!', \"'No!\", '\"Ez!')\n","('Yo...', '', 'Ni...')\n","('', '', 'bai.')\n","('¡Justa es la Rueda!', 'Just is the Wheel!', 'Zuzena da Gurpila!')\n","('¡Justa es la Rueda!', 'Just is the Wheel!', 'Zuzena da Gurpila!')\n","('¿Y por qué?', \"And why?'\", 'Eta zergatik?')\n","('-¡No!', \"'No!\", '-Ez!')\n","('¡Mira!', \"'Look!\", 'Ikusi!')\n","('Kim sacudió la cabeza.', 'Kim shook his head.', 'Kimek buruari eragin zion.')\n","('-¡Vamos!', \"'Hai!\", '-Hai!')\n","('¿Qué?', 'What?', 'Zer?')\n","('-Bien dicho.', \"'Well said.\", '-Ondo esana.')\n","('-¡Ah!', \"'Aha!\", '-Hara!')\n","('-¡óyeme!', \"'Hear me!\", '-Entzun!')\n","('¡Justa es la Rueda!', 'Just is the Wheel!', 'Zuzena da Gurpila!')\n","('Tu Cordelia.', 'Your Cordelia', 'Zure Cordelia')\n","('Johannes:', 'Johannes,', 'Johannes,')\n","('¡Maldito azar!', 'Cursed chance!', 'Zorte madarikatua!')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('Nada.', 'Nothing.', 'Deus ez.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('¿Cómo podría olvidarte?', 'As if I could forget you!', 'Ahaztu ahal izango bazintut bezala!')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio I:', 'Note I.', 'I. Eskolioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Explicación:', 'Explanation.', 'Azalpena')\n","('Explicación:', 'Explanation.', 'Azalpena')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', '', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio I:', 'Note I.', 'I. Eskolioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('DEFINICIONES', 'DEFINITIONS', 'Definizioak')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'xi.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio I:', 'Note I.', 'I. Eskolioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Que era lo primero.', 'This was our first point.', 'Hau baitzen lehen puntua.')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario III:', 'Corollary III.', 'III. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'note);', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Demostración:', 'Proof.', 'Prop.')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', '', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('DEFINICIONES', 'DEFINITIONS.', 'Definizioak')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('PROPOSICIÓN IX', 'Proof.', 'IX. Proposizioa')\n","('Demostración:', 'xvii.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', '-This Prop.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('PROPOSICIÓN xxxvi', 'Proof.', 'XXXVI. Proposizioa')\n","('Escolio I:', 'Note I.', 'I. Eskolioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'i.).', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('De otra manera:', 'Another Proof.', 'Bestela')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('', '', 'Eskolioa')\n","('AXIOMAS', 'AXIOMS.', 'Axiomak')\n","('PROPOSICIÓN i', 'PROPOSITIONS.', 'I. Proposizioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('PROPOSICIÓN xxxiv', 'Proof.', 'XXXIV. Proposizioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'arab.).')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('El doctor B.', 'Dr.', 'B.')\n","('', '', 'Hara!')\n","('', '', 'Hara bada!')\n","('', '', '-Ederki!')\n","('-¡Cómo es eso, cómo es eso!', '\"What\\'s that!', '-Hau da hau! Hau da hau!')\n","('', '', 'Tira ba!')\n","('-¡Qué!', '\"What!', '-Zer!')\n","('', '', 'A!')\n","('', '', 'Ai ene!')\n","('', '', '-Hara!')\n","('', '', '-A!')\n","('-Todavía no.', '\"Not yet.', '-Oraindik ez.')\n","('', '', 'Horra!')\n","('', '', '\"Tira!')\n","('', '', 'bertsetean:')\n","('Mil quinientos dólares.', 'Fifteen hundred dollars.\"', 'Mila eta bostehun dolar.')\n","('No sé.', \"I don't know.\", 'Ez dakit.')\n","('-¡No!', '', '-Ez!')\n","('Tengo frío.', \"I'm cold.\", 'Hotzak nago.')\n","('No.', 'No.', 'Ez.')\n","('', '', 'Mila deabru!')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('¿Por qué?', '', 'Zergatik?')\n","('Y Nancy.', 'And Nancy.', 'Eta Nancy.')\n","('No sabía qué hacer.', \"I didn't know what to do.\", 'Ez nekien zer egin.')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('', '', 'Bai.')\n","('Silencio.', 'Silence.', 'Isilunea.')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('Altura:', 'Height:', 'Altura:')\n","('Delito:', 'Crime:', 'Delitua:')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('¡Jesús!', 'Jesus!', 'Jesus!')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Lluvia.', 'Rain.', 'Euria.')\n","('', '', 'Eta?')\n","('Yo sí.', 'I have.', 'Nik bai.')\n","('-¿Cuándo?', '', '-Noiz?')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Tres?', 'Three?', 'Hiru?')\n","('-Nunca.', '\"Never.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('', '', 'Entzun.')\n","('-No.', '\"No.', '-Ez.')\n","('El final.', 'The end.', 'Bukaera.')\n","('Una caja de colchón.', 'A mattress box.', 'Koltxoi kaxa bat.')\n","('¡No!', 'No!', 'Ez!')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('¡No!', 'No!', 'Ez.')\n","('No sé.', \"I don't know.\", 'Ez dakit.')\n","('¡Ja!', '', 'Ja!')\n","('¿Cómo estás?', '\"How are you?', 'Zer moduz?')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('V', 'V', 'V')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('VI', 'VI', 'VI')\n","('-No.', '\"No.\"', '-Ez.')\n","('VII', 'VII', 'VII')\n","('VIII', 'VIII', 'VIII')\n","('-¡Ah!', '\"Ah!\"', '-Ah!')\n","('IX', 'IX', 'IX')\n","('-¿Quién es?', '', '- Nor da?')\n","('¿Y usted?', '', 'Eta zu?')\n","('X', 'X', 'X')\n","('XI', 'XI', 'XI')\n","('XII', 'XII', 'XII')\n","('-¿Eh?', '\"Eh?', '-Eh?')\n","('¿Qué?', 'What?', 'Zer?')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¿Y bien?', '', '- Eta?')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('Bazárov arrugó el ceño.', 'Bazarov frowned.', 'Bekokia zimurtu zuen Bazarovek.')\n","('Bazárov se levantó.', 'Bazarov stood up.', 'Zutik jarri zen Bazarov.')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('-No.', '', '- Ez.')\n","('-¡Ah!', '', '- Ah!')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('Bazárov no respondió.', 'Bazarov made no reply.', 'Bazarovek ez zuen ezer erantzun.')\n","('-Sí...', '\"Yes...', '-Bai...')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai.')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('', '', '- Bai;')\n","('-Sí...', '\"Yes...', '-Bai...')\n","('', '', '- Bai!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-No...', '\"No...', '-Ez...')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-No...', '\"No...', '-Ez...')\n","('¿Usted?', 'You?\"', 'Zuk?')\n","('', '', 'Ikusten?')\n","('-No le comprendo.', '\"I don\\'t understand you.\"', '-Ez dizut ulertzen.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡Hum!', '\"Hmmm!', '-Jum!')\n","('-¿Y eso por qué?', '\"Why so?\"', '-Zergatik?')\n","('-¿De veras?', '\"Really?', '-Benetan?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-Sí.', '', '- Bai.')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Y?', '\"Well?\"', '-Eta?')\n","('-¡Evgueni!', '', '- Jevgeni!')\n","('-¡Ah!', '', '- Ah!')\n","('', 'Such were the words of the Corinthians.', '')\n","('', 'Summer was now over.', '')\n","('', 'Summer was now over.', '')\n","('', 'Summer was now over.', '')\n","('', '', '-A!')\n","('', '', '-O!')\n","('-No.', '\"No.', '-Ez.')\n","('-¿De verdad?', '\"Really?\"', '-Benetan?')\n","('-¡Eh!', '', '-E!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-le preguntó.', '', '-galdetu zion.')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-No;', '', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('', '', 'Bai.')\n","('', '', 'O!')\n","('', '', '-Ez.')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('', '', '-Bai.')\n","('-¡Silencio!', '\"Silence!', '-Ixo!')\n","('', '', 'Gizajoa!')\n","('¡Ay!', 'Alas!', 'Hara!')\n","('-¡Oh!', '', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '', '-O!')\n","('', '', 'O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('', '', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('¡Jamás!', 'Never!', 'Inoiz ez!')\n","('¡Ay!', 'Ah!', 'A!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-No lo sé.', '', '-Ez dakit.')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('-¡Asilo!', '\"Sanctuary!', '-Asiloa!')\n","('¡Febo!', 'Phoebus!', 'Febo!')\n","('¡Febo!', 'Phoebus!', 'Febo!')\n","('-¡Oh, sí!', '\"Oh!', '-O!')\n","('', '', 'E!')\n","('', '', '-Entzun!')\n","('-¡Socorro!', '\"Help!', '-Lagundu!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-¿De verdad?', '', '-Benetan?')\n","('-¡Febo!', '\"Phoebus!', '-Febo!')\n","('', '', '-Arraioa!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('', '', '-galdetu zion Thunesko erregeak.')\n","('', '', 'E!')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('-¡Señor!', '\"Sire!', '-Jauna!')\n","('-¡Señor!', '\"Sire!', '-Jauna!')\n","('', '', 'Hara!')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('¡Oh!', '\"Oh!', 'O!')\n","('-Bien, ¿y qué?', '\"Well?\"', '-Eta?')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('', '', 'Hel niri!')\n","('¡Ay!', 'Alas!', 'A!')\n","('¡Oh!', 'Oh!', 'O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Mi hija!', '\"My daughter!', '-Nire alaba!')\n","('', '', 'Ikus dezagun.')\n","('', '', 'A!')\n","('', '', '-Tira!')\n","('', '', 'Ez dakit.')\n","('-¡Febo!', '\"Phoebus!', '-Febo!')\n","('-A la joven.', '\"The young one.\"', '-Gaztea.')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-¡No!', '\"No!', '-Ez!')\n","('', '', 'VI')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('Capítulo VI', 'CHAPTER VI', '')\n","('', '', 'VII')\n","('Capítulo VII', 'CHAPTER VII', '')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('Capítulo VI', 'CHAPTER VI', '')\n","('', '', 'VII')\n","('Capítulo VII', 'CHAPTER VII', '')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('', '', 'IX')\n","('Capítulo IX', 'CHAPTER IX', '')\n","('', '', 'X')\n","('Capítulo X', 'CHAPTER X', '')\n","('', '', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('Capítulo VI', 'CHAPTER VI', '')\n","('', '', 'VIII')\n","('Capítulo VIII', 'CHAPTER VIII', '')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VII')\n","('Capítulo VII', 'CHAPTER VII', '')\n","('', '', 'VIII')\n","('Capítulo VIII', 'CHAPTER VIII', '')\n","('Capítulo IX', 'CHAPTER IX', 'IX')\n","('', '', 'X')\n","('Capítulo X', 'CHAPTER X', '')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('Capítulo VI', 'CHAPTER VI', '')\n","('', '', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('Capítulo VI', 'CHAPTER VI', '')\n","('', '', 'VII')\n","('Capítulo VII', 'CHAPTER VII', '')\n","('', '', 'VIII')\n","('Capítulo VIII', 'CHAPTER VIII', '')\n","('', 'CHAPTER I', 'I')\n","('Capítulo I', '', '')\n","('', '', 'II')\n","('Capítulo II', 'CHAPTER II', '')\n","('', '', 'III')\n","('Capítulo III', 'CHAPTER III', '')\n","('', '', 'IV')\n","('Capítulo IV', 'CHAPTER IV', '')\n","('', '', 'V')\n","('Capítulo V', 'CHAPTER V', '')\n","('', '', 'VI')\n","('Capítulo VI', 'CHAPTER VI', '')\n","('', '', 'VII')\n","('Capítulo VII', 'CHAPTER VII', '')\n","('', '', 'VIII')\n","('Capítulo VIII', 'CHAPTER VIII', '')\n","('', '', 'IX')\n","('Capítulo IX', 'CHAPTER IX', '')\n","('', '', 'X')\n","('Capítulo X', 'CHAPTER X', '')\n","('', '', 'XI')\n","('Capítulo XI', 'CHAPTER XI', '')\n","('', '', 'XII')\n","('Capítulo XII', 'CHAPTER XII', '')\n","('', '', 'XIV')\n","('Capítulo XIV', 'CHAPTER XIV', '')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('-¿Quién es?', '', '-Nor da?')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-le preguntó.', '', '-galdetu zion.')\n","('-Sí, señorita.', '\"Yes, miss.\"', '-Bai, andereño.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-¡Ah!', '', '-Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('', '', '-galdetu nion.')\n","('¡No!', 'No!', 'Ez!')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('-le pregunté-.', '', '-galdetu nion-.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-No.', '\"No.\"', '-Ez.')\n","('Buenos días.', 'Good morning.\"', 'Egun on.')\n","('-¡Ah!', '', '-Ah!')\n","('Muy bien.', 'Very well.', 'Oso ongi.')\n","('', '', 'Eta, o!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('I', 'CHAPTER I', '1')\n","('¡No!', 'No!', 'Ez!')\n","('II', 'CHAPTER II', '2')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik ez?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('III', 'CHAPTER III', '3')\n","('', '', 'Ai!')\n","('Muy bien.', 'Very well.', 'Oso ongi.')\n","('IV', 'CHAPTER IV', '4')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('V', 'CHAPTER V', '5')\n","('-¿Y bien?', '', '-Eta?')\n","('-Sí.', '\"Yes?\"', '-Eta?')\n","('', '', 'Ez!')\n","('-preguntó-.', '', '-galdetu zion-.')\n","('VI', 'CHAPTER VI', '6')\n","('VII', 'CHAPTER VII', '7')\n","('-No.', '\"No.', '-Ez.')\n","('VIII', 'CHAPTER VIII', '8')\n","('¡Ah!', 'Ah!', 'Ene!')\n","('I', 'CHAPTER I', '1')\n","('II', 'CHAPTER II', '2')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('¿Qué significaba esto?', 'What did it mean?', 'Zer esan nahi zuen horrek?')\n","('III', 'CHAPTER III', '3')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('I', 'CHAPTER I', '1')\n","('II', 'CHAPTER II', '2')\n","('-le pregunté.', '', '-galdetu nion nik.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('III', 'CHAPTER III', '3')\n","('-Sí.', '', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('IV', 'CHAPTER IV', '4')\n","('No.', 'No.', 'Ez.')\n","('V', 'CHAPTER V', '5')\n","('No.', 'No.', 'Ez.')\n","('VI', 'CHAPTER VI', '6')\n","('Muy bien.', 'Very well.', 'Ederki.')\n","('-¿Cuándo?', '\"When?', '-Noiz?')\n","('VII', 'CHAPTER VII', '7')\n","('-me dijo-.', '', '-esan zidan-.')\n","('-me dijo-.', '', '-esan zidan-.')\n","('-¡Oh!', '', '-O!')\n","('-No.', '\"No.', '-Ez.')\n","('-le pregunté.', '', '-galdetu nion.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Solo.', '\"Alone.\"', '-Bakarrik.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('VIII', 'CHAPTER VIII', '8')\n","('-Muy bien.', '\"Very good.', '-Ederki.')\n","('-No.', '\"No.\"', '-Ez.')\n","('IX', 'CHAPTER IX', '9')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¡Alto ahí!', '', '-Egon!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('X', 'CHAPTER X', '10')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik?')\n","('-Muy bien.', '\"Very well.', '-Ederki.')\n","('¿No?', 'No?', 'Ez?')\n","('¡No!', 'No!', 'Ez!')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('-No.', '\"No.\"', '-Ez.')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('V', 'V', 'V')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('La portilla estaba fría.', 'The gate was cold.', 'Langa hotza zegoen.')\n","('\"Sí, señora\". dijo T.P.', '\"Yessum.\" T.P.', '\"Bai, etxeko\\'ndre\", esan zuen T.P.-k.')\n","('T.P.', 'T.P.', 'T.P.')\n","('\"Sí, señor\".', '\"Yes, sir.\"', '\"Bai, nagusi\", esan zuen Dilseyk.')\n","('\"Era Madre\". dijo Quentin.', '\"That was Mother.\" Quentin said.', '\"Ama zen\", esan zuen Quentinek.')\n","('T.P.', 'T.P.', 'T.P.')\n","('T.P.', 'T.P.', 'T.P.')\n","('Vamos\".', 'Come on.', 'Goazen\".')\n","('No era Padre.', \"It wasn't Father.\", 'Ez zen Aita.')\n","('Dan aulló.', 'Dan howled.', 'Dan uluka ari zen.')\n","('Vamos.', 'Come on.', 'Goazen.')\n","('Dan aulló.', 'Dan howled.', 'Dan uluka ari zen.')\n","('T.P.', 'T.P.', 'T.P.')\n","('Jason lloraba.', 'Jason cried.', 'Jasonek negar egin zuen.')\n","('T.P.', 'T.P.', 'T.P.')\n","('T.P.', 'T.P.', 'T.P.')\n","('\"Yo sé lo que me digo\". dijo Frony.', '\"I knows what I knows.\" Frony said.', '\"Nik zertxobait badakit\", esan zuen Fronyk.')\n","('T.P.', 'T.P.', 'T.P.')\n","('\"Benjy\". dijo T.P.', '\"Benjy.\" T.P.', '\"Benjy\", esan zuen T.P.-k behetik.')\n","('Caddy olía como los árboles.', 'Caddy smelled like trees.', 'Caddyk zuhaitz usaina zeukan.')\n","('Eh.', 'Here.', 'Aizu.')\n","('\"Por favor.', '\"Please.', '\"Mesedez.')\n","('\"Caddy\".', '\"Caddy.\"', '\"Caddy\", esan zuen Charliek.')\n","('Caddy olía como los árboles.', 'Caddy smelled like trees.', 'Caddyk zuhaitz usaina zeukan.')\n","('\"Cállese\". dijo Luster.', '\"Hush.\" Luster said.', '\"Ixo\", esan zuen Lusterrek.')\n","('Se pararon.', 'They stopped.', 'Gelditu egin ziren.')\n","('Vamos\".', 'Come on.\"', 'Goazen\".')\n","('Vamos\".', 'Come on.\"', 'Goazen\".')\n","('Eh.', 'Here.', 'Tori.')\n","('Me dio la flor.', 'He gave me the flower.', 'Lorea eman zidan.')\n","('Me callé.', 'I hushed.', 'Isildu egin nintzen.')\n","('\"Cállese\". dijo Luster.', '\"Hush.\" Luster said.', '\"Ixo\", esan zuen Lusterrek.')\n","('Empecé a llorar.', 'I began to cry.', 'Ni negarrez hasi nintzen.')\n","('Me callé.', 'I hushed.', 'Isildu egin nintzen.')\n","('Y por qué, dijo Dilsey.', 'How come it is, Dilsey said.', 'Nolatan, esan zuen Dilseyk.')\n","('Madre dijo,', 'Mother said,', 'Amak esan zuen,')\n","('Benjy.', 'Benjy.', 'Benjy.')\n","('dijo Padre.', 'Father said.', '\"Ixo\", esan zuen Aitak.')\n","('\"Candace\".', '\"Candace.\"', '\"Candace\", esan zuen Amak.')\n","('\"Candace\".', '\"Candace.\"', '\"Candace\", esan zuen Amak.')\n","('Calla\".', 'Hush.\"', 'Ixo\".')\n","('No, no.', 'No, no.', 'Ez, ez.')\n","('\"Calla, Benjy\".', '\"Hush, Benjy.\"', '\"Ixo, Benjy\", esan zuen Caddyk.')\n","('dijo Padre.', 'Father said.', '\"Ixo\", esan zuen Aitak.')\n","('Oíamos el tejado.', 'We could hear the roof.', 'Teilatua aditzen genuen.')\n","('Oíamos el tejado.', 'We could hear the roof.', 'Teilatua aditzen genuen.')\n","('Oíamos el fuego y el tejado.', 'We could hear the fire and the roof.', 'Sua eta teilatua aditzen genituen.')\n","('Oíamos el fuego y el tejado.', 'We could hear the fire and the roof.', 'Sua eta teilatua aditzen genituen.')\n","('\"Candace\".', '\"Candace.\"', '\"Candace\", esan zuen Amak.')\n","('\"Calla, Caroline\". dijo Padre.', '\"Hush, Caroline.\" Father said.', '\"Ixo, Caroline\", esan zuen Aitak.')\n","('Yo empecé a llorar.', 'I began to cry.', 'Ni negarrez hasi nintzen.')\n","('Su boca era roja.', 'Her mouth was red.', 'Bere ahoa gorri-gorri zegoen.')\n","('Ella olía como los árboles.', 'She smelled like trees.', 'Zuhaitz usaina zeukan.')\n","('Jason se calló.', 'Jason hushed.', 'Jason isildu egin zen.')\n","('dijo Dilsey.', 'Dilsey said.', '\"Ixo\", esan zuen Dilseyk.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('\"No, señor.', '\"No, sir.', '\"Ez, jauna.')\n","('Benjy.', 'Benjy.', 'Benjy.')\n","('Voy a escaparme.', \"I'm going to run away.\", 'Alde egin egingo dut.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Tres días.', 'Three days.', 'Hiru egun.')\n","('Eres algo extraño, no.', \"You're funny, aren't you.\", 'Xelebrea zara, e.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('\"No.', '\"No.', '\"Ez.')\n","('\"Sí.', '\"Yes.', '\"Bai.')\n","('Está bien.', 'All right.', 'Ondo da.')\n","('No:', 'No:', 'Ez:')\n","('Mejor.', 'Better.', 'Hobeto.')\n","('\"Sí.', '\"Yes.', '\"Bai.')\n","('\"Vamos a nadar al molino\", dijo el tercero.', '\"Let\\'s go to the mill and go swimming,\" the third said.', '\"Goazen errotara igeri egitera\", esan zuen hirugarrenak.')\n","('No:', 'No:', 'Ez:')\n","('¿Perdón?', 'Sir?', 'Jauna?')\n","('\"No, señora.', '\"No, ma\\'am.', '\"Ez, etxekoandre.')\n","('Salimos.', 'We went out.', 'Atera egin ginen.')\n","('\"Adiós\", dije.', '\"Goodbye,\" I said.', '\"Agur\", esan nuen.')\n","('\"¿Es usted de la universidad?\".', '\"You from the college?\"', '\"Estudiantea al zara?\"')\n","('\"Vamos, amiguita\".', '\"Come on, sister.\"', '\"Goazen, arrebatxo\".')\n","('Gracias.', 'Thanks.', 'Eskerrik asko.')\n","('¿Ahí?', 'There?', 'Han?')\n","('\"¿Qué yo he robado a su hermana?\" dije.', '\" Steal his sister?\" I said.', '\"Nik bere arreba lapurtu?\" esan nuen.')\n","('Me levanté.', 'I got up.', 'Zutitu egin nintzen.')\n","('Seguimos andando.', 'We went on.', 'Aurrera segi genuen.')\n","('Se la dije.', 'I told him.', 'Esan egin nion.')\n","('\"Hum\", dijo el Juez.', '\"H\\'m,\" the squire said.', '\"Mmm\", esan zuen epaileak.')\n","('\"Hum\", dijo el Juez.', '\"H\\'m,\" the squire said.', '\"Mmm\", esan zuen epaileak.')\n","('\"Hum\", dijo el Juez.', '\"H\\'m,\" the squire said.', '\"Mmm\", esan zuen epaileak.')\n","('Sí\".', 'Yes.\"', 'Bai\".')\n","('El tranvía se detuvo.', 'The car stopped.', 'Tranbia gelditu egin zen.')\n","('Shreve tiene una botella en su baúl.', 'Shreve has a bottle in his trunk.', 'Shrevek botila bat dauka bere baulean.')\n","('\"De acuerdo.', '\"All right.', '\"Ondo da.')\n","('No contesté.', \"I didn't answer.\", 'Ez nuen erantzun.')\n","('Entré.', 'I went in.', 'Sartu egin nintzen.')\n","('\"Eh, Jason\", dice.', '\"You, Jason,\" she says.', '\"Aizu, Jason\", dio.')\n","('\"No he querido ofenderle\", digo.', '\"No offense,\" I says.', '\"Ez gaizki hartu\", diot nik.')\n","('Miró a la tumba.', 'She looked at the grave.', 'Hilobira begiratu zuen.')\n","('No dije nada.', \"I didn't say anything.\", 'Ez nuen ezer esan.')\n","('\"Está bien.', '\"All right.', '\"Ondo da.')\n","('\"No.', '\"No.', '\"Ez.')\n","('Por favor, Jason.', 'Please, Jason.', 'Mesedez, Jason.')\n","('\"No\", dice.', '\"No,\" she says.', '\"Ez\", dio berak.')\n","('Se levantó.', 'She got up.', 'Zutitu egin zen.')\n","('Me levanté.', 'I got up.', 'Altxa egin nintzen.')\n","('\"Es verdad\", dice.', '\"Dat\\'s de troof,\" he says.', '\"Ho\\'i \\'re egia da\", dio berak.')\n","('Regresé a la tienda.', 'I went back to the store.', 'Dendara itzuli nintzen.')\n","('\"No\", dice.', '\"No,\" she says.', '\"Ez\", dio berak.')\n","('Luego continué.', 'Then I went on.', 'Gero aurrera segi nuen.')\n","('Volví a la tienda.', 'I went back to the store.', 'Dendara itzuli nintzen.')\n","('Earl dice,', 'Earl says,', 'Earlek esaten du,')\n","('\"Nada\", digo.', '\"Nothing,\" I says.', '\"Ezer ez\", diot nik.')\n","('Salí.', 'I went on out.', 'Atera egin nintzen.')\n","('\"Sí\", digo.', '\"Yes,\" I says.', '\"Bai\", diot nik.')\n","('\"No los tengo\", dice.', '\"I aint got dat much,\" he says.', '\"Ez daukat horrenbeste\", dio berak.')\n","('\"Vaya\", digo.', '\"All right,\" I says.', '\"Beno ba\", diot nik.')\n","('\"No\", dice.', '\"No,\" she says.', '\"Ez\", dio berak.')\n","('\"No.', '\"No.', '\"Ez.')\n","('Me miró.', 'She looked at me.', 'Begiratu egin zidan.')\n","('\"Jason\", dice.', '\"Jason,\" she says.', '\"Jason\", dio berak.')\n","('\"Bueno\", digo.', '\"All right,\" I says.', '\"Ondo da\", diot nik.')\n","('\"No.', '\"No.', '\"Ez.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Quentin.', '\"Quentin.', '\"Quentin.')\n","('No hubo respuesta.', 'There was no answer.', 'Ez zen erantzunik izan.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Ay, abuela\".', '\"Aw, mammy.\"', '\"Ai, mammy\".')\n","('¡Jesús!', 'Jesus!', 'Jesus!')\n","('La señora Compson no dijo nada.', 'Mrs Compson said nothing.', 'Mrs Compsonek ez zuen ezer esan.')\n","('Dilsey salió.', 'Dilsey went out.', 'Dilsey atera egin zen.')\n","('\"Sí.', '\"Yes.', '\"Bai.')\n","('\"No.', '\"No.', '\"Ez.')\n","('\"No\", dijo Jason.', '\"No,\" Jason said.', '\"Ez\", esan zuen Jasonek.')\n","('\"Sí\", dijo Jason.', '\"Yes,\" Jason said.', '\"Bai\", esan zuen Jasonek.')\n","('Salieron.', 'They went out.', 'Atera egin ziren.')\n","('Cállese\".', 'Hush.\"', 'Ixo\".')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Arre, Queenie\".', '\"Hum up, Queenie.\"', '\"Arre, Queenie\".')\n","('-¡Piggy!', '\"Piggy!', '-Txerri!')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¡Piggy!', '\"Piggy!\"', '-Txerri!')\n","('-¡Bárbaro!', '\"Wacco.\"', '-Egundokoa.')\n","('-¡Fantástico!', '\"Wizard.\"', '-Izugarria.')\n","('¡Mira!', 'Look!\"', 'Begira!')\n","('-¡Empuja!', '\"Heave!\"', '-Eeeup!')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Pero...', '\"But-\"', '-Baina...')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('Todos los días.', 'Every day.', 'Egunero.')\n","('Eso es todo.', 'That\\'s all.\"', 'Besterik ez.')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Ralph frunció el ceño.', 'Ralph frowned.', 'Ralphek betoskoa zimurtu:')\n","('-No.', '\"No.', '-Ez.')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ralph!', 'Ralph!\"', 'Ralph!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Vuelve!', '\"Come back!', '-Itzuli!')\n","('¡Vuelve!', 'Come back!\"', 'Itzuli!')\n","('-Y otra cosa.', '\"And another thing.', '-Eta beste gauza bat.')\n","('No.', 'No.', 'Ez.')\n","('-¿Cómo te llamas?', '\"What\\'s your name?\"', '-Nola duk izena?')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-¿Eh?', '\"Huh?\"', '-Zer?')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Piggy!', 'Piggy!\"', 'Txerri!')\n","('-Y otra cosa.', '\"And another thing.', '-Eta beste gauza bat.')\n","('Suspiró.', 'He sighed.', 'Hasperen egin zuen.')\n","('-¡Jack!', '\"Jack!', '-Jack!')\n","('-Humo.', '\"Smoke.\"', '-Kea.')\n","('-Mira.', '\"Look.\"', '-Begira.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Hubo un silencio.', 'There was silence.', 'Isiltasuna.')\n","('', '', 'Beldurra?')\n","('¿De verdad?', 'Really?\"', 'Benetan?')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez diakiat.')\n","('-¿Y mis cazadores, qué?', '\"What about my hunters?\"', '-Eta nire ehiztariak zer?')\n","('-¡Jack!', '\"Jack!\"', '-Jack!')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez diakiat.')\n","('-Y otra cosa.', '\"And another thing.', '-Eta beste gauza bat.')\n","('-Aquí.', '\"Here.\"', '-Hemen.')\n","('¿Entiendes?', 'Understand?', 'Ulertzen?')\n","('-¿Han comido todos bastante?', '\"Has everybody eaten as much as they want?\"', '-Jan al duzue denok nahi beste?')\n","('Habló Jack:', 'Jack spoke.', 'Jack mintzatu zen:')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('-¡Mata a la fiera!', '\" Kill the beast!', '-Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('-¡Mata a la fiera!', '\" Kill the beast!', '-Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('-¡Mata a la fiera!', '\" Kill the beast!', '-Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('-Piggy.', '\"Piggy.\"', '-Txerri.')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-Piggy.', '\"Piggy.\"', '-Txerri.')\n","('-¿Eh?', '\"Uh?\"', '-Bai?')\n","('-Piggy.', '\"Piggy.\"', '-Txerri.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Roger.', '\"Roger.\"', '-Roger.')\n","('-¿Por qué?', '\"What for?\"', '-Zer dela eta?')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-¡No!', '\"No!', '-Ez!')\n","('-¿Sí?', '\"Yes?\"', '-Bai?')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ralph!', 'Ralph!\"', 'Ralph!')\n","('-¿Qué pasa?', '\"What is it?\"', '-Zer gertatzen da?')\n","('-¡Sam!', '\"Sam!', '-Sam!')\n","('¡Sam!', 'Sam!\"', 'Sam!')\n","('-¿Qué quieres decir?', '\"What d\\'you mean?\"', '-Zer esan nahi duk?')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ralph!', 'Ralph!\"', 'Ralph!')\n","('-¡Piggy!', '\"Piggy!', '-Txerri!')\n","('-Está bien.', '\"All right.', '-Ondo da.')\n","('Ralph gritó:', 'Ralph shouted.', 'Ralphek oihu:')\n","('-Humo.', '\"Smoke.\"', '-Kea.')\n","('-¡Alto!', '\"Halt!', '-Alto!')\n","('¿Quién va?', 'Who goes there?\"', 'Nor dabil?')\n","('Silencio.', 'Silence.', 'Isiltasuna.')\n","('-Voy a reunir la asamblea.', '\"I\\'m calling an assembly.\"', '-Batzarrerako deia.')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Jack!', '\"Jack!\"', '-Jack!')\n","('-No.', '\"No.', '-Ez.')\n","('-¡Mata a la fiera!', '\" Kill the beast!', 'Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('-Samyeric...', '\"Samneric-\"', '-Samderik...')\n","('-¿Quién?', '\"Who?', '-Nork?')\n","('-No lo sé.', '\"I dunno.', '-Ez diakiat.')\n","('-¡Empujen!', '\"Heave!', '-Bultza!')\n","('¡Empujen!', 'Heave!', 'Bultza!')\n","('¡Empujen!', 'Heave!\"', 'Bultza!')\n","('-¡Empujen!', '\"Heave!', '-Bultza!')\n","('¡Empujen!', 'Heave!', 'Bultza!')\n","('¡Empujen!', 'Heave!\"', 'Bultza!')\n","('-¿Ves?', '\"See?', '-Ikusten?')\n","('-¡Humo!', '\"Smoke!\"', '-Kea!')\n","('-Piensa.', '\"Think.\"', '-Pentsa ezak.')\n","('¿Y qué?', 'So what?', 'Eta zer?')\n","('No grites.', \"Don't scream.\", 'Ez egin garrasirik.')\n","('-Hola.', '\"Hullo.\"', '-Kaixo.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('', '', '...')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Capítulo II', 'CHAPTER TWO', 'II. KAPITULUA')\n","('Capítulo V', 'CHAPTER FIVE', 'V. KAPITULUA')\n","6052\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"btccw_7-JXtA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1586976897610,"user_tz":-120,"elapsed":25139,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"830a826e-fbd6-432f-8c12-f46df4675b2e"},"source":["esaldiak_val = set()\n","print('Balidazioan:')\n","kont = 0\n","for es, en, eu in zip(val_es, val_en, val_eu):\n","    tupla = (es, en, eu)\n","    if tupla in esaldiak_val:\n","        print(tupla)\n","        kont += 1\n","    else:\n","        esaldiak_val.add(tupla)\n","print(kont)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Balidazioan:\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DDNzaeI0KKpD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1586976897611,"user_tz":-120,"elapsed":24414,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9b0e8357-a718-4210-8c39-10d51152681c"},"source":["print('Balidaziokoak entrenamenduan:')\n","kont = 0\n","for es, en, eu in zip(val_es, val_en, val_eu):\n","    tupla = (es, en, eu)\n","    if tupla in esaldiak_train:\n","        print(tupla)\n","        kont += 1\n","print(kont)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Balidaziokoak entrenamenduan:\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ah!', 'Ah!', 'A!')\n","('¿Eh?', 'Eh?', 'E?')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VVHp7asyLN3i","colab_type":"code","colab":{}},"source":["with open('EhuHac/EhuHac-trainhobea-es.txt') as fitx:\n","    hobea_es = fitx.read().split('\\n')\n","with open('EhuHac/EhuHac-trainhobea-en.txt') as fitx:\n","    hobea_en = fitx.read().split('\\n')\n","with open('EhuHac/EhuHac-trainhobea-eu.txt') as fitx:\n","    hobea_eu = fitx.read().split('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcVuzGn-LYve","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1586976913601,"user_tz":-120,"elapsed":39309,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d3a046b6-7cc7-4047-b301-c24237a2c3de"},"source":["esaldiak_hobea = set()\n","print('Entrenamendu \"hobetuan\":')\n","kont = 0\n","for es, en, eu in zip(hobea_es, hobea_en, hobea_eu):\n","    tupla = (es, en, eu)\n","    if tupla in esaldiak_hobea:\n","        print(tupla)\n","        kont += 1\n","    else:\n","        esaldiak_hobea.add(tupla)\n","print(kont)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n","('Capítulo XI', '11', 'xi')\n","('Capítulo XII', '12', 'xii')\n","('Capítulo II', '2', 'ii')\n","('Capítulo IV', '4', 'iv')\n","('Capítulo V', '5', 'v')\n","('Capítulo VI', '6', 'vi')\n","('Capítulo VII', '7', 'vii')\n","('Capítulo IX', '9', 'ix')\n","('Capítulo primero', '1', 'i')\n","('Capítulo II', '2', 'ii')\n","('Capítulo III', '3', 'iii')\n","('Capítulo V', '5', 'v')\n","('Capítulo VI', '6', 'vi')\n","('Capítulo VIII', '8', 'viii')\n","('Capítulo IX', '9', 'ix')\n","('Capítulo III', '3', 'iii')\n","('Capítulo VI', '6', 'vi')\n","('Capítulo IX', '9', 'ix')\n","('Capítulo X', '10', 'x')\n","('Capítulo XI', '11', 'xi')\n","('Capítulo IV', '4', 'iv')\n","('Capítulo V', '5', 'v')\n","('Capítulo VIII', '8', 'viii')\n","('Capítulo IX', '9', 'ix')\n","('Capítulo X', '10', 'x')\n","('Capítulo XI', '11', 'xi')\n","('Capítulo XII', '12', 'xii')\n","('Capítulo primero', '1', 'i')\n","('Capítulo III', '3', 'iii')\n","('Capítulo V', '5', 'v')\n","('Capítulo VI', '6', 'vi')\n","('Capítulo VIII', '8', 'viii')\n","('Capítulo X', '10', 'x')\n","('Capítulo XI', '11', 'xi')\n","('Capítulo XII', '12', 'xii')\n","('Capítulo XIII', '13', 'xiii')\n","('Capítulo XIV', '14', 'xiv')\n","('Capítulo IV', '4', 'iv')\n","('Capítulo VI', '6', 'vi')\n","('Capítulo VII', '7', 'vii')\n","('Capítulo IX', '9', 'ix')\n","('Capítulo X', '10', 'x')\n","('Capítulo XI', '11', 'xi')\n","('Capítulo XII', '12', 'xii')\n","('Capítulo III', '3', 'iii')\n","('Capítulo IV', '4', 'iv')\n","('Capítulo VII', '7', 'vii')\n","('Capítulo IX', '9', 'ix')\n","('Y vio Dios que era bueno.', 'And God saw that [it was] good.', 'Eta Jainkoak ona zela ikusi zuen.')\n","('Habló Jehová a Moisés y le dijo:', 'And the LORD spoke to Moses, saying,', 'Honela mintzatu zitzaion Jauna Moisesi:')\n","('Habló Jehová a Moisés y le dijo:', 'Then the LORD spoke to Moses, saying,', 'Honela mintzatu zitzaion Jauna Moisesi:')\n","('Habló Jehová a Moisés y le dijo:', 'And the LORD spoke to Moses, saying:', 'Honela mintzatu zitzaion Jauna Moisesi:')\n","('Jehová habló a Moisés y le dijo:', 'And the LORD spoke to Moses, saying,', 'Honela mintzatu zitzaion Jauna Moisesi:')\n","('Habló Jehová a Moisés y le dijo:', 'And the LORD spoke to Moses, saying:', 'Honela mintzatu zitzaion Jauna Moisesi:')\n","('Habló Jehová a Moisés y le dijo:', 'And the LORD spoke to Moses, saying,', 'Honela mintzatu zitzaion Jauna Moisesi:')\n","('El nombre de su madre era Hamutal, hija de Jeremías, de Libna.', \"His mother's name [was] Hamutal the daughter of Jeremiah of Libnah.\", 'Haren amak Hamutal zuen izena eta Libnako Jeremiasen alaba zen.')\n","('Adoram, Uzal, Dicla,', 'Hadoram, Uzal, Diklah,', 'Hadoram, Uzal, Dikla,')\n","('Hijo de Jonatán fue Merib-baal, y Merib-baal engendró a Micaía.', 'The son of Jonathan [was] Merib-Baal, and Merib-Baal begot Micah.', 'Jonatanen semea Meribaal izan zen, eta Meribaalek Mika sortu zuen.')\n","('Noga, Nefeg, Jafía,', 'Nogah, Nepheg, Japhia,', 'Nogah, Nefeg, Jafias,')\n","('¡Alaben la misericordia de Jehová y sus maravillas para con los hijos de los hombres!,', 'Oh, that [men] would give thanks to the LORD [for] His goodness, And [for] His wonderful works to the children of men!', 'Gorets bezate Jauna bere maitasunagatik, gizakien alde egiten dituen gauza harrigarriengatik.')\n","('Alabad a Jehová, porque él es bueno, porque para siempre es su misericordia.', 'Oh, give thanks to the LORD, for [He is] good! For His mercy [endures] forever.', 'Goretsazue Jauna, ona baita, haren maitasuna betikoa baita.')\n","('¡Aleluya!', 'Praise the LORD!', 'Aleluia! Gora Jauna!')\n","('¡Aleluya!', 'Praise the LORD!', 'Aleluia! Gora Jauna!')\n","('¡Aleluya!', 'Praise the LORD!', 'Aleluia! Gora Jauna!')\n","('Las palabras del chismoso son como bocados suaves que penetran hasta las entrañas.', 'The words of a talebearer [are] like tasty trifles, And they go down into the inmost body.', 'Iraintzailearen hitzak jaki goxoak bezalako: barren-barreneraino iristen dira.')\n","('¿Quién me emplazará?', 'Who will arraign Me?', 'Nork egingo niri erronka?')\n","('¿Quién será el pastor que pueda resistirme?', 'And who [is] that shepherd Who will withstand Me?\"', 'Zein erregek emango niri aurpegi?')\n","('Velad y orad para que no entréis en tentación; el espíritu a la verdad está dispuesto, pero la carne es débil.', '\"Watch and pray, lest you enter into temptation. The spirit indeed [is] willing, but the flesh [is] weak.\"', 'Zaudete erne eta egizue otoitz, tentaldian ez erortzeko: gogoz gartsu izan arren, ahula baita gizakia\".')\n","('Y lo besó.', 'and kissed Him.', 'Eta musu eman zion.')\n","('porque todo aquel que pide, recibe; y el que busca, halla; y al que llama, se le abrirá.', '\"For everyone who asks receives, and he who seeks finds, and to him who knocks it will be opened.', 'Zeren eskatzen duenak hartu egiten baitu, bilatzen duenak aurkitu, eta atea jotzen duenari zabaldu egiten baitzaio.')\n","('Jesús le dijo: -- ¿Por qué me llamas bueno?', 'So Jesus said to him, \"Why do you call Me good?', 'Jesusek erantzun zion: -Zergatik esaten didazu ona?')\n","('¡De ninguna manera!', 'Certainly not!', 'Ez horixe!')\n","('¡De ninguna manera!', 'Certainly not!', 'Inola ere ez!')\n","('Amén.', 'Amen.', 'Amen.')\n","('Amén.', 'Amen.', 'Amen.')\n","('Amén.', 'Amen.', 'Amen.')\n","('Gracia y paz a vosotros, de Dios nuestro Padre y del Señor Jesucristo.', 'Grace to you and peace from God our Father and the Lord Jesus Christ.', 'Jainko gure Aitak eta Jesu Kristo Jaunak eman biezazkizuete grazia eta bakea.')\n","('Amén.', 'Amen.', 'Amen.')\n","('Gracia y paz a vosotros, de Dios nuestro Padre y del Señor Jesucristo.', 'Grace to you and peace from God our Father and the Lord Jesus Christ.', 'Jainko gure Aitak eta Jesu Kristo Jaunak eman biezazkizuete grazia eta bakea.')\n","('Amén.', 'Amen.', 'Amen.')\n","('Amén.', 'Amen.', 'Amen.')\n","('El que tiene oído, oiga lo que el Espíritu dice a las iglesias.', '\"He who has an ear, let him hear what the Spirit says to the churches.', 'Ulertzeko gauza denak uler beza Espirituak eliz elkarteei esaten diena.')\n","('El que tiene oído, oiga lo que el Espíritu dice a las iglesias\\' \".', '\"He who has an ear, let him hear what the Spirit says to the churches.\" \\'', 'Ulertzeko gauza denak uler beza Espirituak eliz elkarteei esaten diena.')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('MARCHBANKS: Sí.', 'MARCHBANKS. Yes.', 'MARCHBANKS: Bai.')\n","('Adiós.', 'Good-bye.', 'Agur.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('-Sí.', '\"Yep.', '-Bai.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Me encogí de hombros.', 'I shrugged.', 'Besagainak goititu nituen.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-preguntó Chick.', 'asked Chick.', '-galdetu zuen Chickek.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-dijo Colin-.', 'said Colin.', '-esan zuen Colinek-.')\n","('-preguntó Chick.', 'asked Chick.', '-galdetu zuen Chickek.')\n","('-dijo Chloé.', \"' said Chloe.\", '-esan zuen Chloek.')\n","('-preguntó Chick.', 'asked Chick.', '-galdetu zuen Chickek.')\n","('-dijo Chick.', \"' said Chick.\", '-esan zuen Chickek.')\n","('-dijo Colin.', \"' said Colin.\", '-esan zuen Colinek.')\n","('-dijo Colin-.', 'said Colin.', '-esan zuen Colinek-.')\n","('-dijo Chloé.', 'said Chloe.', '-galdetu zuen Chloek.')\n","('-dijo Colin-.', 'said Colin.', '-esan zuen Colinek-.')\n","('-dijo Colin.', \"' said Colin.\", '-esan zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-dijo Chloé.', 'said Chloe.', '-esan zuen Chloek.')\n","('-Sí-dijo Colin-.', \"'Yes,' said Colin.\", '-Bai-esan zuen Colinek-.')\n","('-dijo Chick-.', 'said Chick.', '-esan zuen Chickek-.')\n","('-dijo Chick-.', 'said Chick.', '-esan zuen Chickek-.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-Sí-dijo Colin-.', \"'Yes,' said Colin.\", '-Bai-esan zuen Colinek-.')\n","('-preguntó Nicolás.', 'asked Nicolas.', '-galdetu zuen Nicolasek.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('-preguntó Nicolás.', 'asked Nicolas.', '-galdetu zuen Nicolasek.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-¡Oiga!', \"'Hello!\", '-Adizu!')\n","('-preguntó Chick.', 'asked Chick.', '-galdetu zuen Chickek.')\n","('-dijo Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-Sí-dijo Chick-.', \"'Yes,' said Chick.\", '-Bai-esan zuen Chickek-.')\n","('-preguntó Chick.', 'asked Chick.', '-galdetu zuen Chickek.')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('-dijo Colin-.', 'said Colin.', '-esan zuen Colinek-.')\n","('-Sí-dijo Colin-.', \"'Yes,' said Colin.\", '-Bai-erantzun zuen Colinek-.')\n","('-preguntó Nicolás.', 'asked Nicolas.', '-galdetu zuen Nicolasek.')\n","('-preguntó Nicolás-.', 'said Nicolas.', '-galdetu zuen Nicolasek-.')\n","('-¡Oh!', \"'Oh!\", '-O!')\n","('-dijo Nicolás-.', \"' said Nicolas.\", '-esan zuen Nicolasek-.')\n","('-dijo Alise-.', \"' said Lisa.\", '-esan zuen Alisek-.')\n","('-dijo Alise-.', \"' said Lisa.\", '-esan zuen Alisek-.')\n","('-preguntó Alise.', 'asked Lisa.', '-galdetu zuen Alisek.')\n","('-preguntó Alise.', 'asked Lisa.', '-galdetu zuen Alisek.')\n","('-dijo Chick.', 'said Chick.', '-galdetu zuen Chickek.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-preguntó Chick.', 'asked Chick.', '-galdetu zuen Chickek.')\n","('-¡Oh!', \"'Oh!\", '-O!')\n","('-¿Por qué?', \"'Why?'\", '- Zergatik?')\n","('-¿Por qué?', \"'Why not?'\", '-Zergatik?')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-dijo.', \"' he said.\", '-esan zuen.')\n","('-dijo Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-Sí-dijo Colin-.', \"'Yes,' said Colin.\", '-Bai-esan zuen Colinek-.')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('-Sí-dijo Colin-.', \"'Yes,' said Colin.\", '-Bai-esan zuen Colinek-.')\n","('-preguntó Colin.', 'asked Colin.', '-galdetu zuen Colinek.')\n","('-dijo Nicolás-.', 'said Nicolas.', '-esan zuen Nicolasek-.')\n","('-dijo Chloé.', 'said Chloe.', '-esan zuen Chloek.')\n","('-No-dijo Chloé-.', \"'No,' said Chloe.\", '-Ez-esan zuen Chloek-.')\n","('-preguntó Isis.', 'asked Isis.', '-galdetu zuen Isisek.')\n","('-preguntó Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('-preguntó Colin.', 'said Colin.', '-esan zuen Colinek.')\n","('-dijo Alise-.', 'said Lisa.', '-esan zuen Alisek-.')\n","('-¡Douglas!', \"'Douglas!\", '-Douglas!')\n","('-¡Presente!', \"'Present!\", '-Hemen!')\n","('-dijo Colin.', 'said Colin.', '-galdetu zuen Colinek.')\n","('Resumen', 'SUMMARY', 'Laburpena')\n","('Resumen del capítulo', 'SUMMARY OF CHAPTER', 'Kapituluaren laburpena')\n","('Resumen', 'SUMMARY', 'Laburbilduma')\n","('Resumen', 'SUMMARY', 'Laburbilduma')\n","('No.', 'No.', 'Ez.')\n","('-preguntó el señor Gradgrind.', 'asked Mr. Gradgrind.', 'galdetu zuen Mr. Gradgrindek.')\n","('-¡Naturalmente que sí!', \"'Of course there is.'\", '\"Horixe dagoela.\"')\n","('-¡Naturalmente que sí!', \"'Of course there is.'\", '\"Horixe dagoela.\"')\n","('-¡Naturalmente que sí!', \"'Of course there is.'\", '\"Horixe dagoela.\"')\n","('-Sí, padre.', \"'Yes, father.'\", '\"Bai, aita.\"')\n","('-Sí, padre.', \"'Yes, father.'\", '\"Bai, aita.\"')\n","('-Gracias.', \"'Thank you.\", '\"Eskerrik asko.')\n","('No.', 'No.', 'Ez.')\n","('-Sí.', \"'Yes.'\", '\"Bai.\"')\n","('-¡No!', \"'No!'\", '\"Ez!\"')\n","('¿No te inspira todo esto repulsión?', \"Does not that repel you?'\", 'Horrek ez zaitu higuintzen?\"')\n","('-¡No!', \"'No!'\", '\"Ez!\"')\n","('¡Buenas noches!', \"Good night!'\", 'Gau on!\"')\n","('\"¡Ding, dong!', '\"Ding, dong!\"', '-Din, don!')\n","('\", preguntó Scrooge.', 'asked Scrooge.', '-galdetu zuen Scroogek.')\n","('Sí.', 'Yes.', 'Bai.')\n","('\", dijo Scrooge.', 'said Scrooge.', '-galdetu zuen Scroogek.')\n","('Y el ermitaño reía.', 'And the hermit laughed.', 'Eta ermitauak barre egiten zuen.')\n","('Ulenspiegel respondió:', 'Ulenspiegel replied:', 'Ulenspiegelek:')\n","('Ulenspiegel respondió:', 'Ulenspiegel replied:', 'Ulenspiegelen erantzuna:')\n","('Claes respondió:', 'Claes replied:', 'Claesek honela erantzun zuen:')\n","('-Nele es mala.', '\"Nele is bad.', '-Nele gaiztoa da.')\n","('Ulenspiegel respondió:', 'Ulenspiegel answered:', 'Ulenspiegelek:')\n","('¡Gloria a la Fuerza!', 'Glory to Force!\"', 'Loria Indarrari!')\n","('Escucha, comprende y mira. ¿Te place nuestra respuesta?', '\"Wait, hear and see! Say, wretch, art thou not glad?', 'Egon, entzun eta ikus, Esan, ez duzu ulertzen?')\n","('Halla los Siete.', 'Find the Seven.\"', 'Zazpiak aurki.')\n","('I', 'I', '1')\n","('II', 'II', '2')\n","('III', 'III', '3')\n","('IV', 'IV', '4')\n","('V', 'V', '5')\n","('VI', 'VI', '6')\n","('VII', 'VII', '7')\n","('VIII', 'VIII', '8')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('IX', 'IX', '9')\n","('X', 'X', '10')\n","('XI', 'XI', '11')\n","('XII', 'XII', '12')\n","('XV', 'XV', '15')\n","('XVI', 'XVI', '16')\n","('XVII', 'XVII', '17')\n","('XVIII', 'XVIII', '18')\n","('XIX', 'XIX', '19')\n","('XX', 'XX', '20')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-Amén.', '\"Amen.\"', '-Amen.')\n","('-Amén.', '\"Amen.\"', '-Amen.')\n","('-¿Cuánto?', '\"How much?\"', '-Zenbat?')\n","('-Amén-dijo Jackson.', '\"Amen,\" Jackson said.', '-Amen-Jacksonek.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('-¿Para qué?', '\"What for?', '-Zertarako?')\n","('-Jackson.', '\"Jackson.\"', '-Jackson.')\n","('-Sí, señor.', '\"Yes sir.', '-Bai, jauna.')\n","('-No, señor.', '\"No sir.', '-Ez, jauna.')\n","('-Nadie.', '\"Nobody.\"', '-Ezta inor ere.')\n","('-Sí, señor.', '\"Yes sir.', '-Bai, jauna.')\n","('-¿Para qué?', '\"What for?', '-Zertarako?')\n","('-Sí, señor.', '\"Yes sir.', '-Bai, jauna.')\n","('-No, señor.', '\"No sir.', '-Ez, jauna.')\n","('-Sí, señor.', '\"Yes sir.', '-Bai, jauna.')\n","('-Sí, señor.', '\"Yes sir.', '-Bai, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No, señor.', '\"No sir.', '-Ez, jauna.')\n","('-Sí, señor.', '\"Yes sir.\"', '-Bai, jauna.')\n","('-Sí, señor.', '\"Yes sir.', '-Bai, jauna.')\n","('París, 4 de agosto de 17...', 'Paris, Aug. 4, 17-.', 'Parisen, 17**ko abuztuaren 4an.')\n","('CECILIA VOLANGES A SOFÍA CARNAY', 'CECILIA VOLANGES to SOPHIA CARNAY.', 'CÉCILE VOLANGESEK SOPHIE CARNAYRI')\n","('CECILIA VOLANGES A SOFÍA CARNAY', 'CECILIA VOLANGES to SOPHIA CARNAY.', 'CÉCILE VOLANGESEK SOPHIE CARNAYRI')\n","('CECILIA VOLANGES A SOFÍA CARNAY', 'CECILIA VOLANGES to SOPHIA CARNAY.', 'CÉCILE VOLANGESEK SOPHIE CARNAYRI')\n","('En..., a 20 de agosto de 17...', 'Aug. 20, 17-.', '...tik, 17**ko abuztuaren 20an.')\n","('Adiós, mi bella amiga.', 'Adieu, my lovely friend!', 'Adio, adiskide ederra.')\n","('En..., a 20 de agosto de 17...', 'Aug. 20, 17-.', '...tik, 17**ko abuztuaren 20an.')\n","('En..., a 20 de agosto de 17...', 'Aug. 20, 17-.', '...tik, 17**ko abuztuaren 20an.')\n","('CECILIA VOLANGES A SOFÍA CARNAY', 'CECILIA VOLANGES to SOPHIA CARNAY.', 'CÉCILE VOLANGESEK SOPHIE CARNAYRI')\n","('En..., a 24 de agosto de 17...', 'Aug. 24, 17-.', '...tik, 17**ko abuztuaren 24an.')\n","('LA SEÑORA DE VOLANGES A LA PRESIDENTA DE TOURVEL', 'MADAME DE VOLANGES to the Presidente DE TOURVEL.', 'VOLANGES ANDREAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('En..., a 24 de agosto de 17...', 'Aug. 24, 17-.', '...tik, 17**ko abuztuaren 24an.')\n","('En..., a 24 de agosto de 17...', 'Aug. 24, 17-.', '...tik, 17**ko abuztuaren 24an.')\n","('Adiós, mi bella amiga.', 'Adieu, my lovely friend!', 'Adio, adiskide ederra.')\n","('EL VIZCONDE DE VALMONT A LA PRESIDENTA DETOURVEL', 'VISCOUNT VALMONT to the Presidente DE TOURVEL.', 'VALMONTEKO BIZKONDEAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE VOLANGES', 'The Presidente DE TOURVEL to MADAME DE VOLANGES.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VOLANGES ANDREARI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to VISCOUNT VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('CECILIA VOLANGES A SOFÍA CARNAY', 'CECILIA VOLANGES to SOPHIA CARNAY.', 'CÉCILE VOLANGESEK SOPHIE CARNAYRI')\n","('LA PRESIDENTA DE TOURVEL AL VIZCONDE DE VALMONT', 'The Presidente DE TOURVEL to VISCOUNT VALMONT.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VALMONTEKO BIZKONDEARI')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE VOLANGES', 'The Presidente DE TOURVEL to MADAME DE VOLANGES.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VOLANGES ANDREARI')\n","('EL CABALLERO DANCENY A CECILIA VOLANGES', 'The CHEVALIER DANCENY to CECILIA VOLANGES.', 'DANCENY ZALDUNAK CÉCILE VOLANGESI')\n","('En..., a 29 de agosto de 17...', 'Aug. 29, 17-.', '...tik, 17**ko abuztuaren 29an.')\n","('Adiós, mi bella amiga.', 'Adieu, my lovely friend!', 'Adio, adiskide ederra.')\n","('CECILIA VOLANGES AL CABALLERO DANCENY', 'CECILIA VOLANGES to the CHEVALIER DANCENY.', 'CÉCILE VOLANGESEK DANCENY ZALDUNARI')\n","('LA PRESIDENTA DE TOURVEL AL VIZCONDE DE VALMONT', 'The Presidente DE TOURVEL to the VISCOUNT DE VALMONT.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VALMONTEKO BIZKONDEARI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to VISCOUNT VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to the VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('En..., a 4 de septiembre de 17...', 'Sept. 4, 17-.', '...tik, 17**ko irailaren 24an.')\n","('LA PRESIDENTA DE TOURVEL AL VIZCONDE DE VALMONT', 'The Presidente DE TOURVEL to the VISCOUNT DE VALMONT.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VALMONTEKO BIZKONDEARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('En..., a 5 de septiembre de 17...', 'Sept. 5, 17-.', '...tik, 17**ko irailaren 5ean.')\n","('EL VIZCONDE DE VALMONT A LA PRESIDENTA DE TOURVEL', 'VISCOUNT DE VALMONT to the Presidente DE TOURVEL.', 'VALMONTEKO BIZKONDEAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('No.', 'No.', 'Ez.')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('En..., a 8 de septiembre de 17...', 'Sept. 8, 17-.', '...tik, 17**ko irailaren 8an.')\n","('CECILIA VOLANGES A SOFÍA CARNAY', 'CECILIA VOLANGES to SOPHIA CARNAY.', 'CÉCILE VOLANGESEK SOPHIE CARNAYRI')\n","('En..., a 7 de septiembre de 17...', 'Sept. 7, 17-.', '...tik, 17**ko irailaren 7an.')\n","('Adiós, vizconde mío;', 'Adieu, Viscount!', 'Adio, bizkonde;')\n","('EL CABALLERO DANCENY A CECILIA VOLANGES', 'CHEVALIER DANCENY to CECILIA VOLANGES.', 'DANCENY ZALDUNAK CÉCILE VOLANGESI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'The VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA PRESIDENTA DE TOURVEL AL VIZCONDE DE VALMONT', 'The Presidente DE TOURVEL to the VISCOUNT DE VALMONT.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VALMONTEKO BIZKONDEARI')\n","('CECILIA VOLANGES AL CABALLERO DANCENY', 'CECILIA VOLANGES to the CHEVALIER DANCENY.', 'CÉCILE VOLANGESEK DANCENY ZALDUNARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('Adiós.', 'Sept.', 'Adio.')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('EL CABALLERO DANCENY A CECILIA VOLANGES', 'CHEVALIER DANCENY to CECILIA VOLANGES.', 'DANCENY ZALDUNAK CÉCILE VOLANGESI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'MARCHIONESS DE MERTEUIL to VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE DE VALMONT A LA PRESIDENTA DE TOURVEL', 'VISCOUNT DE VALMONT to the Presidente DE TOURVEL.', 'VALMONTEKO BIZKONDEAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'The VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('EL CABALLERO DANCENY A CECILIA VOLANGES', 'CHEVALIER DANCENY to CECILIA VOLANGES.', 'DANCENY ZALDUNAK CÉCILE VOLANGESI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to the VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('CECILIA VOLANGES AL CABALLERO DANCENY', 'CECILIA VOLANGES to the CHEVALIER DANCENY.', 'CÉCILE VOLANGESEK DANCENY ZALDUNARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE DE VALMONT A CECILIA VOLANGES', 'VISCOUNT DE VALMONT to CECILIA VOLANGES.', 'VALMONTEKO BIZKONDEAK CÉCILE VOLANGESI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'MARCHIONESS DE MERTEUIL to VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE DE VALMONT A LA PRESIDENTA DE TOURVEL', 'VISCOUNT DE VALMONT to the Presidente DE TOURVEL.', 'VALMONTEKO BIZKONDEAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL CABALLERO DANCENY AL VIZCONDE DE VALMONT', 'CHEVALIER DANCENY to the VISCOUNT DE VALMONT.', 'DANCENY ZALDUNAK VALMONTEKO BIZKONDEARI')\n","('¡Oh!', 'Oh!', 'O!')\n","('CECILIA VOLANGES AL CABALLERO DANCENY', 'CECILIA VOLANGES to the CHEVALIER DANCENY.', 'CÉCILE VOLANGESEK DANCENY ZALDUNARI')\n","('CECILIA VOLANGES AL VIZCONDE DE VALMONT', 'CECILIA VOLANGES to the VISCOUNT DE VALMONT.', 'CÉCILE VOLANGESEK VALMONTEKO BIZKONDEARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('CECILIA VOLANGES A LA MARQUESA DE MERTEUIL', 'CECILIA VOLANGES to the MARCHIONESS DE MERTEUIL.', 'CÉCILE VOLANGESEK MERTEUILEKO MARKESARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'The VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('París, 4 de octubre de 17...', 'Paris, Oct. 4, 17-.', 'Parisen, 17**ko urriaren 4an.')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('CECILIA VOLANGES A LA MARQUESA DE MERTEUIL', 'CECILIA VOLANGES to the MARCHIONESS DE MERTEUIL.', 'CÉCILE VOLANGESEK MERTEUILEKO MARKESARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA SEÑORA DE ROSEMONDE A LA PRESIDENTA DE TOURVEL', 'MADAME DE ROSEMONDE to the Presidente DE TOURVEL.', 'ROSEMONDE ANDREAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'The VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('CECILIA VOLANGES AL CABALLERO DANCENY', 'CECILIA VOLANGES to the CHEVALIER DANCENY.', 'CÉCILE VOLANGESEK DANCENY ZALDUNARI')\n","('LA SEÑORA DE ROSEMONDE A LA PRESIDENTA DE TOURVEL', 'MADAME DE ROSEMONDE to the Presidente DE TOURVEL.', 'ROSEMONDE ANDREAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('Castillo de..., 22 de octubre de 17...', 'Castle of--, Oct. 22, 17-.', '...ko gaztelutik, 17**ko urriaren 22an.')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE ROSEMONDE', 'The Presidente DE TOURVEL to MADAME DE ROSEMONDE.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK ROSEMONDE ANDREARI')\n","('LA SEÑORA DE ROSEMONDE A LA PRESIDENTA DE TOURVEL', 'MADAME DE ROSEMONDE to the Presidente DE TOURVEL.', 'ROSEMONDE ANDREAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to the VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE ROSEMONDE', 'The Presidente DE TOURVEL to MADAME DE ROSEMONDE.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK ROSEMONDE ANDREARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'The VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'MARCHIONESS DE MERTEUIL to the VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE ROSEMONDE', 'The Presidente DE TOURVEL to MADAME DE ROSEMONDE.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK ROSEMONDE ANDREARI')\n","('LA PRESIDENTA DE TOURVEL AL VIZCONDE DE VALMONT', 'The Presidente DE TOURVEL to the VISCOUNT DE VALMONT.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK VALMONTEKO BIZKONDEARI')\n","('EL VIZCONDE DE VALMONT A LA PRESIDENTA DE TOURVEL', 'VISCOUNT DE VALMONT to the Presidente DE TOURVEL.', 'VALMONTEKO BIZKONDEAK TOURVEL LEHENDAKARIAREN EMAZTEARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE ROSEMONDE', 'The Presidente DE TOURVEL to MADAME DE ROSEMONDE.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK ROSEMONDE ANDREARI')\n","('No es culpa mía.', 'it is not my fault.', 'Ez dun nire errua.\"')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA PRESIDENTA DE TOURVEL A LA SEÑORA DE ROSEMONDE', 'The Presidente DE TOURVEL to MADAME DE ROSEMONDE.', 'TOURVEL LEHENDAKARIAREN EMAZTEAK ROSEMONDE ANDREARI')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to the VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('Castillo de..., 29 de noviembre de 17...', 'Castle of--, Nov. 29, 17-.', '...ko gaztelutik, 17**ko azaroaren 29an.')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('EL CABALLERO DANCENY A LA MARQUESA DE MERTEUIL', 'CHEVALIER DANCENY to the MARCHIONESS DE MERTEUIL.', 'DANCENY ZALDUNAK MERTEUILEKO MARKESARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('EL VIZCONDE DE VALMONT A LA MARQUESA DE MERTEUIL', 'The VISCOUNT DE VALMONT to the MARCHIONESS DE MERTEUIL.', 'VALMONTEKO BIZKONDEAK MERTEUILEKO MARKESARI')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('CECILIA VOLANGES AL CABALLERO DANCENY', 'CECILIA VOLANGES to the CHEVALIER DANCENY.', 'CÉCILE VOLANGESEK DANCENY ZALDUNARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('LA MARQUESA DE MERTEUIL AL VIZCONDE DE VALMONT', 'The MARCHIONESS DE MERTEUIL to the VISCOUNT DE VALMONT.', 'MERTEUILEKO MARKESAK VALMONTEKO BIZKONDEARI')\n","('París, 6 de diciembre de 17...', 'Paris, Dec. 6, 17-.', 'Parisen, 17**ko abenduaren 6an.')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('EL CABALLERO DANCENY AL VIZCONDE DE VALMONT', 'CHEVALIER DANCENY to the VISCOUNT DE VALMONT.', 'DANCENY ZALDUNAK VALMONTEKO BIZKONDEARI')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('EL SEÑOR BERTRAND A LA SEÑORA DE ROSEMONDE', 'M. BERTRAND to MADAME DE ROSEMONDE.', 'BERTRAND JAUNAK ROSEMONDE ANDREARI')\n","('Señora:', 'Madam,', 'ANDREA,')\n","('París, 10 de diciembre de 17...', 'Paris, Dec. 10, 17-.', 'Parisen, 17**ko abenduaren 10ean.')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('Señora:', 'Madam,', 'ANDREA,')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('Adiós, mi querida y digna amiga.', 'Adieu, my dear and worthy friend!', 'Adio, adiskide maite eta duina.')\n","('EL CABALLERO DANCENY A LA SEÑORA DE ROSEMONDE', 'The CHEVALIER DANCENY to MADAME DE ROSEMONDE.', 'DANCENY ZALDUNAK ROSEMONDE ANDREARI')\n","('LA SEÑORA DE VOLANGES A LA SEÑORA DE ROSEMONDE', 'MADAME DE VOLANGES to MADAME DE ROSEMONDE.', 'VOLANGES ANDREAK ROSEMONDE ANDREARI')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('Sí...', 'Yes....', 'Bai...')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-¿Por qué?', '\"Why?\"', '-Zer ba?')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-Ahora, no.', '\"Not now.\"', '-Orain ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-¿Cómo?', '\"How?\"', '-Nola?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Sí?', '\"Yes?\"', '-Bai?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-¿En dónde?', '\"Where?\"', '-Non?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-Todavía no.', '\"Not yet.', '-Oraindik ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('Spade sacudió la cabeza.', 'Spade shook his head.', 'Spadek buruari eragin zion.')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-No.', '\"No.', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Sonó el teléfono.', 'The telephone-bell rang.', 'Telefonoak jo zuen.')\n","('Izquierdo, derecho, izquierdo, derecho.', 'Left, right, left, right.', 'Ezkerra, eskuina, ezkerra, eskuina.')\n","('Uno, dos, tres, cuatro.', 'One, two, three, four.', 'Bat, bi, hiru, lau.')\n","('Eso es.', \"That's the stuff.\", 'Hori da.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zer ba?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-Está bien.', '\"All right.', '-Ederki.')\n","('De veras.', 'I really do.', 'Benetan.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿No?', 'Right?\"', 'Asmatu dut?')\n","('Spade se echó a reír.', 'Spade laughed.', 'Spadek barre egin zuen.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-pregunté.', 'I asked.', '-galdetu nuen.')\n","('-No.', '\"No.', '-Ez.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-Quizá.', '\"Maybe.', '-Baliteke.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Todavía no.', '\"Not now.\"', '-Orain ez.')\n","('-De acuerdo.', '\"All right.', '-Ederki.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Esperé.', 'I waited.', 'Zain geratu nintzen.')\n","('-¿No?', '\"No?\"', '-Ez?')\n","('-No, gracias.', '\"No, thanks.\"', '-Ez, eskerrik asko.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('¿Se da cuenta?', 'See?', 'Ikusten?')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Cuánto?', '\"How much?\"', '-Zenbat?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('Inútil.', 'That got me nothing.', 'Alferrik.')\n","('-Aún no.', '\"Not yet.\"', '-Oraindik ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¿No?', '\"No?\"', '-Ez?')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Sí?', '\"Yeah?\"', '-Bai?')\n","('-¿Sí?', '\"Yeah?\"', '-Bai?')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-pregunté.', 'I asked.', '-galdetu nuen.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¡Reno!', '\"Reno!\"', '-Reno!')\n","('-pregunté-.', 'I asked.', '-galdetu nion-.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Quién es?', '\"Who is he?\"', '-Nor da?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí...', '\"Yes...', '-Bai...')\n","('-No, gracias.', '\"No, thanks.\"', '-Ez, eskerrik asko.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-pregunté.', 'I asked.', '-galdetu nuen.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Estoy bien.', '\"I\\'m all right.', '-Ondo nago.')\n","('No.', 'No.\"', 'Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.', '-Ez.')\n","('Le dije que sí.', 'I said I was.', 'Baietz esan nion.')\n","('-No.', '\"No.', '-Ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('¿Cómo dio conmigo?', 'How\\'d he find me?\"', 'Nola aurkitu ninduen?')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.', '-Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('Dije que sí con la cabeza.', 'I nodded.', 'Baietz esan nion buruaz.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-preguntó.', 'he asked.', '-galdetu zidan.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('¿Por qué?', '\"Why?\"', 'Zer ba?')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-Está bien.', '\"All right.', '-Konforme.')\n","('-pregunté-.', 'I asked.', '-galdetu nuen-.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.', '-Ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.', '-Ez.')\n","('-pregunté.', 'I asked.', '-galdetu nuen.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Creo que no.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Sí?', '\"Yes?\"', '-Bai?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-Vaya, vaya.', '\"Well, well.\"', '-Oso ondo.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-No.', '\"No.', '-Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-No.', '\"No.\"', '-Ez.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Qué ha pasado?', '\"What happened?\"', '-Zer gertatu da?')\n","('-De acuerdo.', '\"Right.', '-Ondo.')\n","('-Sí.', '\"Uh-huh.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-Sí.', '\"Uh-huh.', '-Bai.')\n","('Me eché a reír.', 'I laughed.', 'Barre egin nuen.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('Parte 1', 'PART I.', 'I PARTEA')\n","('Parte 2', 'PART II.', 'II PARTEA')\n","('\"Cogido con las manos cubiertas de sangre.', '\"Taken with blood-stained hands.', '\"Eskuak odoletan zituen atxilotzean.')\n","('Peligrosísimo\".', 'Very dangerous.\"', 'Oso arriskutsua\".')\n","('-Buenas noches, señorita Lisa.', '\"Good night, Mademoiselle Lisa.\"', '-Gabon, Lisa andereñoa.')\n","('-Sí, doña Lisa.', '\"Yes, Madame Lisa.\"', '-Bai, Lisa andrea.')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('Hubo un nuevo silencio.', 'There was another pause.', 'Beste isilaldi bat izan zen.')\n","('Se lo dije.', 'I told him.', 'Esan nion.')\n","('-Muy bien.', '\"All right.\"', \"'Ederki.'\")\n","('-¿Sí?', '\"That so?\"', \"'Bai zera!'\")\n","('-No.', '\"No.\"', \"'Ez.'\")\n","('-¿Qué?', '\"What?\"', \"'Zer?'\")\n","('-No.', '\"No.\"', \"'Ez.'\")\n","('-No.', '\"No.\"', \"'Ez.'\")\n","('-Carraway.', '\"Carraway.\"', \"'Carraway.'\")\n","('-Sí.', '\"Yes.', \"'Bai.\")\n","('-¿Por qué?', '\"Why?\"', '-Zer dela eta?')\n","('-¿Cuánto?', '\"How much?\"', '-Zenbat?')\n","('-¡Cómo!', '\"What?', '-Zer?')\n","('K.', 'K.', 'K.')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('K.', 'K.', 'K.')\n","('-No-dijo K.', '\"No,\" said K.', '-Ez-esan zuen K.k.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('K.', 'K.', 'K.')\n","('¡Mira!', 'Lo!', 'Hara!')\n","('Zaratustra respondió:', 'Zarathustra answered:', 'Zaratustrak erantzun zion:')\n","('La hora en que digáis:', 'The hour when ye say:', 'Hau esango duzuen ordua:')\n","('La hora en que digáis:', 'The hour when ye say:', 'Hau esango duzuen ordua:')\n","('Mirad, yo os enseño el superhombre:', 'Lo, I teach you the Superman:', 'Begira, gaingizona aldarrikatzen dizuet:')\n","('Yo os digo:', 'I tell you:', 'Neuk diotsuet:')\n","('¡Ay!', 'Alas!', 'Ai ene!')\n","('¡Ay!', 'Alas!', 'Ai ene!')\n","('Zaratustra respondió:', 'Zarathustra answered:', 'Zaratustrak erantzun zion:')\n","('¿A quién es al que más odian?', 'Whom do they hate most?', 'Nor gorrotatzen dute gehien?')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¿O acaso es:', 'Or is it this:', 'Edo ez ote da:')\n","('¡Creedme, hermanos míos!', 'Believe me, my brethren!', 'Sinetsidazue, ene senideok!')\n","('El sí-mismo dice al yo:', 'The Self saith unto the ego:', 'Nor Berak Niari esaten dio:')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¿Qué es ese hombre?', 'What is this man?', 'Zer da gizon hau?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Mas por mi amor y mi esperanza te conjuro:', 'But by my love and hope I conjure thee:', 'Baina neure maitasun eta itxaropenarengatik zin egiten diat:')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Yo os conozco.', 'I know you.', 'Ezagutzen zaituztet.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Ved, pues, a esos superfluos!', 'Just see these superfluous ones!', 'Begiraiezue soberakin hauei!')\n","('¡Ved, pues, a esos superfluos!', 'Just see these superfluous ones!', 'Begiraiezue soberakin hauei!')\n","('¡Apartaos del mal olor!', 'Do go out of the way of the bad odour!', 'Ihes egizue usain txarra dagoen tokitik!')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Muchos países ha visto Zaratustra, y muchos pueblos:', 'Many lands saw Zarathustra, and many peoples:', 'Lurralde asko ikusi ditu Zaratustrak eta herri asko:')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('allí está el origen de vuestra virtud.', 'there is the origin of your virtue.', 'hantxe dago zuen bertutearen sorburua.')\n","('2', '2.', 'II')\n","('3', '3.', 'III')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Dios es una suposición:', 'God is a conjecture:', 'Jainkoa aieru bat da:')\n","('-', '-', '-')\n","('-', '-', '\"-')\n","('¡Ay, hermanos míos!', 'Ah, my brethren!', 'Ai, ene senideok!')\n","('-', '-', '-')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¿Cómo?', 'What?', 'Nola?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Ay!', 'Alas!', 'Ai ene!')\n","('-Así habló Zaratustra.', '-Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('Es de noche:', \"'Tis night:\", 'Gaua da:')\n","('-', '-', '-')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¿Para qué?', 'Wherefore?', 'Zertarako?')\n","('¿Cómo?', 'How?', 'Nola?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('-', '-', '-')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('-', '-', '-')\n","('Y yo respondí:', 'And I answered:', 'Eta nik erantzun nuen:')\n","('Entonces algo me habló de nuevo sin voz:', 'Then was there again spoken unto me without voice:', 'Orduan berriz ere hotsik gabe mintzatu zitzaidan:')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Recorres tu camino de grandeza:', 'Thou goest the way to thy greatness:', 'Heure handitasunaren bidetik habil:')\n","('Estoy dispuesto.', 'I am ready.', 'Prest nago.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('¡Muerde!', 'Bite!', 'Hozka egin!')\n","('¡Oh tarde de mi vida!', 'O afternoon of my life!', 'Oi, nire bizitzaren arratsaldea!')\n","('-', '-', '-')\n","('-', '-', '-')\n","('¡por eso ahora nos separamos!', 'so let us part!', 'horregatik banatzen gara!')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('3', '3.', 'III')\n","('¡Bien!', 'Well!', 'Tira!')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('-', '-', '-')\n","('¡Adelante!', 'Well!', 'Aurrera!')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('3', '3.', 'III')\n","('--', '-', '--')\n","('4', '4.', 'IV')\n","('5', '5.', 'V')\n","('8', '8.', 'VIII')\n","('9', '9.', 'IX')\n","('10', '10.', 'X')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('El mar está tempestuoso:', 'The sea stormeth:', 'Itsasoa orroaka ari da:')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('¡Arriba!', 'Up!', 'Jaiki!')\n","('¡Dichoso de mí!', 'Joy to me!', 'Bejondeidala niri!')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('-', '-', '-')\n","('2', '2.', 'II')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('3', '3.', 'III')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('4', '4.', 'IV')\n","('-', '-', '-')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('5', '5.', 'V')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('6', '6.', 'VI')\n","('-', '-', '-')\n","('Oh, ¿cómo no iba yo a anhelar la eternidad y el nupcial anillo de los anillos,-el anillo del retorno?', 'Oh, how could I not be ardent for Eternity, and for the marriage-ring of rings-the ring of the return?', 'Oi nola ez nuen ba nik betieraren irrika sentituko eta eraztunetan ezkon-eraztunarena-itzuleraren eraztunarena?')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('7', '7.', 'VII')\n","('-', '-', '-')\n","('Nunca encontré todavía la mujer de quien quisiera tener hijos, a no ser esta mujer a quien yo amo:', 'Never yet have I found the woman by whom I should like to have children, unless it be this woman whom I love:', 'Ez nuen inoiz aurkitu, berarengandik nik haurrak izateko moduko emakumerik, maite dudan emakume hau izan ezik:')\n","('¡pues yo te amo, oh eternidad!', 'for I love thee, O Eternity!', 'zeren maite baitzaitut, oi betiera!')\n","('¡Pues yo te amo, oh eternidad!', 'FOR I LOVE THEE, O ETERNITY!', 'Zeren maite baitzaitut nik, oi betiera!')\n","('Así me dijo el demonio una vez:', 'Thus spake the devil unto me, once on a time:', 'Honela mintzatu zitzaidan deabrua behinola:')\n","('\"También Dios tiene su infierno:', '\"Even God hath his hell:', '\"Jainkoak ere badu bere ifernua:')\n","('es su amor a los hombres.\"', 'it is his love for man.\"', 'gizonenganako maitasuna du hori\".')\n","('\"Dios ha muerto;', '\"God is dead:', '\"Hil da Jainkoa;')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('-', '-', '-')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Bien!', 'Well!', 'Tira!')\n","('¡Bien!', 'Well then!', 'Tira!')\n","('1', '1.', 'I')\n","('-', '-', '-')\n","('--', '-', '-')\n","('-', '-', '-')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Quédate!', 'Stay!', 'Hago!')\n","('¡No!', 'Nay!', 'Ez!')\n","('-', '-', '-')\n","('¿Cómo?', 'What?', 'Nola?')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('¡Oh felicidad!', 'O happiness!', 'Oi zoriona!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('-', '-', '-')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('-', '-', '-')\n","('¡No!', 'Nay!', 'Ez!')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('¡Ante Dios!', 'Before God!', 'Jainkoaren aurrean!')\n","('¡Bien!', 'Well!', 'Tira!')\n","('3', '3.', 'III')\n","('4', '4.', 'IV')\n","('5', '5.', 'V')\n","('-', '-', '-')\n","('6', '6.', 'VI')\n","('¡No!', 'Nay!', 'Ez!')\n","('¡Tres veces no!', 'Three times Nay!', 'Hirugarrenez ez!')\n","('--', '-', '-')\n","('7', '7.', 'VII')\n","('-', '-', '-')\n","('8', '8.', 'VIII')\n","('10', '10.', 'X')\n","('11', '11.', 'XI')\n","('12', '12.', 'XII')\n","('¡Vosotros creadores, vosotros hombres superiores!', 'Ye creating ones, ye higher men!', 'Zuek sortzaileok, gizon garaiagook!')\n","('13', '13.', 'XIII')\n","('14', '14.', 'XIV')\n","('15', '15.', 'XV')\n","('18', '18.', 'XVIII')\n","('19', '19.', 'XIX')\n","('20', '20.', 'XX')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('-', '-', '-')\n","('¡No!', 'Nay!', 'Ez!')\n","('-', '-', '-')\n","('-', '-', '-')\n","('Así habló el concienzudo;', 'Thus spake the conscientious one;', 'Honela mintzatu zen kontzientzitsua;')\n","('¡Bien!', 'Well!', 'Tira!')\n","('1', '1.', 'I')\n","('¡Quiera Dios mejorarla!', 'May the Lord improve it!', 'Jainkoak on beza!')\n","('Sela.', 'Selah.', 'Sela.')\n","('El desierto crece:', 'THE DESERTS GROW:', 'Basamortua hazten ari da:')\n","('1', '1.', 'I')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('2', '2.', 'II')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('1', '1.', 'I')\n","('2', '2.', 'II')\n","('3', '3.', 'III')\n","('Así habló Zaratustra.', 'Thus spake Zarathustra.', 'Honela mintzatu zen Zaratustra.')\n","('2', '2.', 'II')\n","('3', '3.', 'III')\n","('¡Silencio!', 'Hush!', 'Ixo!')\n","('4', '4.', 'IV')\n","('¡Ay!', 'Ah!', 'Ai!')\n","('5', '5.', 'V')\n","('¡Ay!', 'Ah!', 'Ai!')\n","('¡Ay!', 'Ah!', 'Ai!')\n","('6', '6.', 'VI')\n","('7', '7.', 'VII')\n","('8', '8.', 'VIII')\n","('El dolor dice:', 'Woe saith:', 'Samina mintzo da:')\n","('10', '10.', 'X')\n","('11', '11.', 'XI')\n","('12', '12.', 'XII')\n","('¡Bien!', 'Well!', 'Tira!')\n","('¡Adelante!', 'Cheer up!', 'Gora!')\n","('¡Oh hombre!', 'O man!', 'Oi gizona!')\n","('Así habló Zaratustra;', 'Thus spake Zarathustra;', 'Honela mintzatu zen Zaratustra;')\n","('-', '-', '-')\n","('¡Bien!', 'Well!', 'Tira!')\n","('--', '-', '-')\n","('1', '1.', '1')\n","('2', '2.', '2')\n","('3', '3.', '3')\n","('4', '4.', '4')\n","('5', '5.', '5')\n","('6', '6.', '6')\n","('7', '7.', '7')\n","('8', '8.', '8')\n","('11', '11', '11')\n","('-¡Siga!', 'Further!', '-Aurrera!')\n","('¡Aire viciado!', 'Bad air!', 'Aire gaizkoatua!')\n","('¡Basta!', 'Enough!', 'Aski da!')\n","('1', '1.', '1')\n","('2', '2.', '2')\n","('3', '3.', '3')\n","('4', '4.', '4')\n","('5', '5.', '5')\n","('6', '6.', '6')\n","('7', '7.', '7')\n","('8', '8.', '8')\n","('9', '9.', '9')\n","('10', '10.', '10')\n","('-', '-', '-')\n","('12', '12.', '12')\n","('13', '13.', '13')\n","('14', '14.', '14')\n","('15', '15.', '15')\n","('17', '17.', '17')\n","('¡Basta!', 'Enough!', 'Aski da!')\n","('1', '1.', '1')\n","('2', '2.', '2')\n","('¿Qué significan los ideales ascéticos?', 'What is the meaning of ascetic ideals?', 'Zer esan nahi dute ideal aszetikoek?')\n","('3', '3.', '3')\n","('4', '4.', '4')\n","('5', '5.', '5')\n","('6', '6.', '6')\n","('7', '7.', '7')\n","('8', '8.', '8')\n","('9', '9.', '9')\n","('10', '10.', '10')\n","('11', '11.', '11')\n","('¿Qué significa esto?', 'What does this mean?', 'Zer esan nahi du horrek?')\n","('12', '12.', '12')\n","('13', '13.', '13')\n","('14', '14.', '14')\n","('15', '15.', '15')\n","('16', '16.', '16')\n","('17', '17.', '17')\n","('18', '18.', '18')\n","('19', '19.', '19')\n","('20', '20.', '20')\n","('21', '21.', '21')\n","('22', '22.', '22')\n","('23', '23.', '23')\n","('24', '24.', '24')\n","('25', '25.', '25')\n","('¡No!', 'Nay!', 'Ez!')\n","('-¡Basta!', 'Enough!', '-Aski da!')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('No.', 'No.', 'Ez.')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-¿Y bien?', '\"Well?\"', '-Eta?')\n","('-¿A quién?', '\"Whom?\"', '-Nor?')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('a.', 'a.', 'a.')\n","('b.', 'b.', 'b.')\n","('c.', 'c.', 'c.')\n","('El coronel se sobresaltó.', 'The colonel started.', 'Koronela asaldatu egin zen.')\n","('-¿Qué?', \"'What?'\", '-Zer?')\n","('Apretó los dientes.', 'He clenched his teeth.', 'Hortzak estutu zituen.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('-¿No?', '\"No?', '-Ez?')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('3', 'Chapter Three', '3')\n","('5', 'Chapter Five', '5')\n","('-pregunté.', 'I asked.', '-galdetu nuen.')\n","('-pregunté-.', 'I asked.', '-galdetu nuen-.')\n","('2', 'Chapter Two', '2')\n","('3', 'Chapter Three', '3')\n","('Yo no comprendía.', \"I didn't understand.\", 'Ez nuen ulertzen.')\n","('4', 'Chapter Four', '4')\n","('5', 'Chapter Five', '5')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('6', 'Chapter Six', '6')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('2', 'Chapter Two', '2')\n","('-No...', '\"No...', '-Ez...')\n","('No.', 'No.\"', 'Ez.')\n","('-pregunté-.', 'I asked.', '-galdetu nuen-.')\n","('4', 'Chapter Four', '4')\n","('¿Y Micòl?', 'And what about Micol?', 'Eta Micòl?')\n","('5', 'Chapter Five', '5')\n","('-No.', '\"No.\"', '-Ez.')\n","('6', 'Chapter Six', '6')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('7', 'Chapter Seven', '7')\n","('-No.', '\"No.', '-Ez.')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('Pero ¿y ahora?', 'But now?', 'Baina, orain?')\n","('¿Qué hacer?', 'What was to be done?', 'Zer egin?')\n","('Capítulo 1', 'CHAPTER I.', 'I. KAPITULUA')\n","('Capítulo 2', 'CHAPTER II.', 'II. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 5', 'CHAPTER V.', 'V. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 6', 'CHAPTER VI.', 'VI. KAPITULUA')\n","('Capítulo 7', 'CHAPTER VII.', 'VII. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 9', 'CHAPTER IX.', 'IX. KAPITULUA')\n","('Del diario de Otilia', \"FROM OTTILIE'S DIARY.\", 'Ottiliaren Egunkaritik')\n","('Capítulo 10', 'CHAPTER X.', 'X. KAPITULUA')\n","('Capítulo 11', 'CHAPTER XI.', 'XI. KAPITULUA')\n","('Capítulo 12', 'CHAPTER XII.', 'XII. KAPITULUA')\n","('Capítulo 13', 'CHAPTER XIII.', 'XIII. KAPITULUA')\n","('Capítulo 14', 'CHAPTER XIV.', 'XIV. KAPITULUA')\n","('Capítulo 16', 'CHAPTER XVI.', 'XVI. KAPITULUA')\n","('Capítulo 17', 'CHAPTER XVII.', 'XVII. KAPITULUA')\n","('Capítulo 18', 'CHAPTER XVIII.', 'XVIII. KAPITULUA')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('1', 'I', '1')\n","('2', 'II', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('3', 'III', '3')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('CAPÍTULO III', 'III', 'Hirugarren atala')\n","('1', 'I', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', 'II', '2')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-preguntó Castle.', 'Castle asked.', '-galdegin zuen Castlek.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('2', 'II', '2')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('2', '2', '2')\n","('CAPÍTULO II', 'II', 'Bigarren atala')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('CAPÍTULO III', 'III', 'Hirugarren atala')\n","('1', '1', '1')\n","('-inquirió Castle.', 'Castle asked.', '-galdetu zuen Castlek.')\n","('-Por supuesto.', \"'Of course.\", '-Bai, jakina.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-No.', \"'No.\", '-Ez.')\n","('1', '1', '1')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","('-Lo siento.', \"'I'm sorry.\", '-Sentitzen dut.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('2', '2', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¿Davis?', \"'Davis?\", '-Davis?')\n","('2', '2', '2')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('2', '2', '2')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('2', 'II', '2')\n","('-No.', \"'No.\", '-Ez.')\n","('-Naturalmente.', \"'Of course.\", '-Jakina.')\n","('CAPÍTULO II', 'II', 'Bigarren atala')\n","('1', '1', '1')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Muy bien.', \"'All right.'\", '-Ondo.')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('5', '5', '5')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('CAPITULO II', 'II', 'Bigarren atala')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Por supuesto.', 'Of course.', 'Jakina.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Por supuesto.', \"'Of course.\", '-Jakina.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('CAPÍTULO III', 'III', 'Hirugarren atala')\n","('1', '1', '1')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('2', '2', '2')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('3', '3', '3')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Por supuesto.', \"'Of course.'\", '-Bai, noski.')\n","('Castle pensó:', 'Castle thought:', 'Castlek pentsatu zuen:')\n","('-No, no.', \"'No, no.\", '-Ez, ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('4', '4', '4')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('5', '5', '5')\n","('Castle pensó:', 'Castle thought:', 'Castlek pentsatu zuen:')\n","('-Lo ignoro.', \"'I don't know.\", '-Ez dakit.')\n","('6', '6', '6')\n","('Pensó:', 'He thought:', 'Pentsatu zuen:')\n","('7', '7', '7')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No estoy seguro.', \"'I'm not sure.\", '-Ez nago ziur.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('1', '1', '1')\n","('-¿Sam?', \"'Sam?'\", '-Sam?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('Pensó:', 'She thought:', 'Pentsatu zuen:')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('2', '2', '2')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('3', '3', '3')\n","('-Por supuesto.', \"'Of course.'\", '-Jakina.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('CAPÍTULO II', 'II', 'Bigarren atala')\n","('1', '1', '1')\n","('-¿Por qué no?', \"'Why not?'\", '-Zergatik ez?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('2', '2', '2')\n","('3', '3', '3')\n","('-No.', \"'No.'\", '-Ez.')\n","('4', '4', '4')\n","('5', '5', '5')\n","('-Lo sé.', \"'I know.'\", '-Bazakiat.')\n","('-¿Por qué?', \"'Why?\", '-Zer dela eta?')\n","('1', '1', '1')\n","('-Sí, por favor.', \"'Yes, please.'\", '-Bai, mesedez.')\n","('-No.', \"'No.\", '-Ez.')\n","('2', '2', '2')\n","('¿Cómo está Sam?', \"How's Sam?'\", 'Zer moduz Sam?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('CAPÍTULO III', 'Chapter Three', '-III -')\n","('CAPÍTULO V', 'Chapter Five', '-V -')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('CAPÍTULO VI', 'Chapter Six', '-VI -')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('CAPÍTULO VII', 'Chapter Seven', '-VII -')\n","('CAPÍTULO IX', 'Chapter Nine', '-IX -')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Estás seguro?', '\"Are you sure?\"', '-Ziur zaude?')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('Emma se paró.', 'She stopped.', 'Emma gelditu egin zen.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('CAPÍTULO II', 'Chapter Two', '-II -')\n","('-¡Ah!', '\"Ah!\"', '-Ah!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('CAPÍTULO III', 'Chapter Three', '-III -')\n","('CAPÍTULO IV', 'Chapter Four', '-IV -')\n","('CAPÍTULO V', 'Chapter Five', '-V -')\n","('CAPÍTULO VI', 'Chapter Six', '-VI -')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('CAPÍTULO VII', 'Chapter Seven', '-VII -')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-dijo Emma.', 'said Emma.', 'esan zuen Emmak.')\n","('CAPÍTULO VIII', 'Chapter Eight', '-VIII -')\n","('¿Es culpa mía?', 'Is it my fault?', 'Nire errua al da?')\n","('-exclamó.', 'she cried.', 'oihukatu zuen.')\n","('CAPÍTULO IX', 'Chapter Nine', '-IX -')\n","('CAPÍTULO X', 'Chapter Ten', '-X -')\n","('-No.', '\"No.\"', '-Ez.')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-dijo Adye.', 'said Adye.', '-galdetu zion Adyek.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('-¡Ah!', '\"Ah!\"', '-A!')\n","('-¿Y bien?', '\"Well?\"', '-Eta?')\n","('Se echó a reír.', 'He laughed.', 'Barre egin zuen.')\n","('Me eché a reír.', 'I laughed.', 'Barre egin nuen.')\n","('¡Ay!', 'Alas!', 'Ene!')\n","('-¡Bien, bien, bien!', 'good! good!', '-Ederki, ederki, ederki!')\n","('-pregunté.', 'I asked.', '-galdegin nuen.')\n","('¡ja, ja, ja!', 'ha! ha!', 'Ja, ja, ja!')\n","('-¡Ji, ji, ji!', '\"Hee! hee!', '-Ji, ji, ji!')\n","('¡Ah!', 'Ah!', 'Ene!')\n","('-preguntó el joven.', 'asked the young man.', 'galdetu zion mutilak.')\n","('-No lo sé;', '\"I don\\'t know;', '\"Ez dakit;')\n","('-preguntó Gertrude.', 'asked Gertrude.', 'galdetu zion Gertrudek.')\n","('-preguntó Felix-.', 'Felix asked.', 'galdetu zion Felixek.')\n","('-le preguntó.', 'she asked.', 'galdetu zion.')\n","('La baronesa le miró un momento.', 'The Baroness looked at him a moment.', 'Baronesa begira geratu zitzaion pixka batean.')\n","('¿No es así?', 'Is it not so?', 'Ez da hala?')\n","('-Preferiría no hacerlo.', '\"I would prefer not to.\"', '-Aukeran nahiago ez.')\n","('Silencio.', 'No answer.', 'Erantzunik ez.')\n","('-Preferiría no hacerlo.', '\"I would prefer not to.\"', '-Aukeran nahiago ez.')\n","('-Preferiría no hacerlo.', '\"I would prefer not to.\"', '-Aukeran nahiago ez.')\n","('No contestó.', 'He answered nothing.', 'Deus ez zuen erantzun.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('Silencio.', 'No answer.', 'Erantzunik ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.', '-Ez.')\n","('¿Es verdad?', 'Is that true?\"', 'Egia al da?')\n","('LXI.', '61.', '61.')\n","('LXXIII.', '73.', '73.')\n","('II.', '2.', '2.')\n","('VI.', '6.', '6.')\n","('XXVI.', '26.', '26.')\n","('XXVII.', '27.', '27.')\n","('XXXI.', '31.', '31.')\n","('XXXVIII.', '38.', '38.')\n","('LV.', '55.', '55.')\n","('LXVIII.', '68.', '68.')\n","('LXXIII.', '73.', '73.')\n","('LXXXVII.', '87.', '87.')\n","('XCI.', '91.', '91.')\n","('CIX.', '109.', '109.')\n","('CXVII.', '117.', '117.')\n","('CXIX.', '119.', '119.')\n","('CXXI.', '121.', '121.')\n","('CXXV.', '125.', '125.')\n","('CXXXVI.', '136.', '136.')\n","('CXLI.', '141.', '141.')\n","('CLXXIV.', '174.', '174.')\n","('X.', '10.', '10.')\n","('XVII.', '17.', '17.')\n","('XXIII.', '23.', '23.')\n","('XXXVII.', '37.', '37.')\n","('XXXVIII.', '38.', '38.')\n","('XLIII.', '43.', '43.')\n","('XLV.', '45.', '45.')\n","('XLVIII.', '48.', '48.')\n","('LVIII.', '58.', '58.')\n","('LXX.', '70.', '70.')\n","('LXXIII.', '73.', '73.')\n","('LXXXVI.', '86.', '86.')\n","('XC.', '90.', '90.')\n","('XCIX.', '99.', '99.')\n","('CVIII.', '108.', '108.')\n","('CXL.', '140.', '140.')\n","('CXLV.', '145.', '145.')\n","('CLII.', '152.', '152.')\n","('XVI.', '16.', '16.')\n","('XVII.', '17.', '17.')\n","('XXVI.', '26.', '26.')\n","('XXXVI.', '36.', '36.')\n","('XLV.', '45.', '45.')\n","('LVII.', '57.', '57.')\n","('LXVII.', '67.', '67.')\n","('LXXI.', '71.', '71.')\n","('LXXIV.', '74.', '74.')\n","('LXXX.', '80.', '80.')\n","('LXXXI.', '81.', '81.')\n","('LXXXIII.', '83.', '83.')\n","('XC.', '90.', '90.')\n","('XCIV.', '94.', '94.')\n","('CVII.', '107.', '107.')\n","('CVIII.', '108.', '108.')\n","('CXII.', '112.', '112.')\n","('CXXI.', '121.', '121.')\n","('CXXXIX.', '139.', '139.')\n","('CXL.', '140.', '140.')\n","('CXLI.', '141.', '141.')\n","('CXLII.', '142.', '142.')\n","('CXLV.', '145.', '145.')\n","('CLII.', '152.', '152.')\n","('CLXVI.', '166.', '166.')\n","('CXC.', '190.', '190.')\n","('III.', '3.', '3.')\n","('IV.', '4.', '4.')\n","('VIII.', '8.', '8.')\n","('XI.', '11.', '11.')\n","('XIII.', '13.', '13.')\n","('XVIII.', '18.', '18.')\n","('XXIII.', '23.', '23.')\n","('XXVI.', '26.', '26.')\n","('XXXV.', '35.', '35.')\n","('XXXVI.', '36.', '36.')\n","('XXXIX.', '39.', '39.')\n","('XLIII.', '43.', '43.')\n","('XLV.', '45.', '45.')\n","('XLVIII.', '48.', '48.')\n","('LIX.', '59.', '59.')\n","('LXXI.', '71.', '71.')\n","('LXXVII.', '77.', '77.')\n","('LXXX.', '80.', '80.')\n","('LXXXIII.', '83.', '83.')\n","('LXXXVII.', '87.', '87.')\n","('XCI.', '91.', '91.')\n","('XCII.', '92.', '92.')\n","('CII.', '102.', '102.')\n","('CVIII.', '108.', '108.')\n","('CXXIV.', '124.', '124.')\n","('CXXVI.', '126.', '126.')\n","('III.', '3.', '3.')\n","('IV.', '4.', '4.')\n","('VI.', '6.', '6.')\n","('XV.', '15.', '15.')\n","('XXII.', '22.', '22.')\n","('XXIV.', '24.', '24.')\n","('XXXVII.', '37.', '37.')\n","('XL.', '40.', '40.')\n","('LII.', '52.', '52.')\n","('LXVII.', '67.', '67.')\n","('LXX.', '70.', '70.')\n","('LXXI.', '71.', '71.')\n","('LXXIV.', '74.', '74.')\n","('LXXXI.', '81.', '81.')\n","('LXXXIX.', '89.', '89.')\n","('XC.', '90.', '90.')\n","('CVIII.', '108.', '108.')\n","('CX.', '110.', '110.')\n","('CXVIII.', '118.', '118.')\n","('CXXIV.', '124.', '124.')\n","('CXXVII.', '127.', '127.')\n","('CXXXII.', '132.', '132.')\n","('CXXXVIII.', '138.', '138.')\n","('CXXXIX.', '139.', '139.')\n","('II.', '2.', '2.')\n","('VII.', '7.', '7.')\n","('XVII.', '17.', '17.')\n","('XXVIII.', '28.', '28.')\n","('XXXVII.', '37.', '37.')\n","('XXXVIII.', '38.', '38.')\n","('XLII.', '42.', '42.')\n","('XLIV.', '44.', '44.')\n","('XLVI.', '46.', '46.')\n","('XLVII.', '47.', '47.')\n","('XLIX.', '49.', '49.')\n","('LIII.', '53.', '53.')\n","('LVIII.', '58.', '58.')\n","('LXI.', '61.', '61.')\n","('LXV.', '65.', '65.')\n","('LXX.', '70.', '70.')\n","('LXXII.', '72.', '72.')\n","('LXXV.', '75.', '75.')\n","('LXXVII.', '77.', '77.')\n","('LXXXI.', '81.', '81.')\n","('LXXXVIII.', '88.', '88.')\n","('XC.', '90.', '90.')\n","('XCVII.', '97.', '97.')\n","('XCIX.', '99.', '99.')\n","('CVII.', '107.', '107.')\n","('CVIII.', '108.', '108.')\n","('CXXIV.', '124.', '124.')\n","('CXXVIII.', '128.', '128.')\n","('CXXXI.', '131.', '131.')\n","('CLV.', '155.', '155.')\n","('CLVIII.', '158.', '158.')\n","('CLXXXII.', '182.', '182.')\n","('CLXXXVI.', '186.', '186.')\n","('CCI.', '201.', '201.')\n","('VIII.', '8.', '8.')\n","('XII.', '12.', '12.')\n","('XVI.', '16.', '16.')\n","('XVIII.', '18.', '18.')\n","('XXVI.', '26.', '26.')\n","('XXVII.', '27.', '27.')\n","('XXXI.', '31.', '31.')\n","('XXXVI.', '36.', '36.')\n","('XLIX.', '49.', '49.')\n","('LVI.', '56.', '56.')\n","('LVIII.', '58.', '58.')\n","('LX.', '60.', '60.')\n","('LXVII.', '67.', '67.')\n","('LXXV.', '75.', '75.')\n","('LXXXIX.', '89.', '89.')\n","('XCIV.', '94.', '94.')\n","('CII.', '102.', '102.')\n","('CVI.', '106.', '106.')\n","('CVII.', '107.', '107.')\n","('CXVIII.', '118.', '118.')\n","('CXX.', '120.', '120.')\n","('CXXVIII.', '128.', '128.')\n","('CXXX.', '130.', '130.')\n","('CXXXII.', '132.', '132.')\n","('CXXXVIII.', '138.', '138.')\n","('CXXXIX.', '139.', '139.')\n","('III.', '3.', '3.')\n","('VI.', '6.', '6.')\n","('VIII.', '8.', '8.')\n","('XIV.', '14.', '14.')\n","('XV.', '15.', '15.')\n","('XXVII.', '27.', '27.')\n","('XXXVI.', '36.', '36.')\n","('XL.', '40.', '40.')\n","('XLII.', '42.', '42.')\n","('XLIII.', '43.', '43.')\n","('XLV.', '45.', '45.')\n","('XLVIII.', '48.', '48.')\n","('LIX.', '59.', '59.')\n","('LXXI.', '71.', '71.')\n","('LXXVII.', '77.', '77.')\n","('LXXXVI.', '86.', '86.')\n","('XCIX.', '99.', '99.')\n","('CI.', '101.', '101.')\n","('CIV.', '104.', '104.')\n","('CVI.', '106.', '106.')\n","('CXI.', '111.', '111.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¡Ah, ah!', '\"Aha!', '-Ah! ah!')\n","('-¡Ah, ah!', '\"Aha!', '-Ah! ah!')\n","('-¿Cómo?', '\"What?\"', '-Nola?')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('-Así lo espero.', '\"I hope so.', '-Hala espero dut.')\n","('-le preguntó.', 'she asked.', 'galdetu zion.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación', 'REMARK.', 'Oharra')\n","('Observación II', 'REMARK II.', '2. oharra')\n","('Contradicción:', 'Antithesis.', 'Antitesia:')\n","('Contradicción:', 'Antithesis.', 'Antitesia:')\n","('Contradicción:', 'Antithesis.', 'Antitesia:')\n","('-¿Cómo?', '\"What?\"', '-Zer?')\n","('-No.', '\"No.', '-Ez.')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('-preguntó Michelino.', 'Michelino asked.', '-galdetu zuen Michelinok.')\n","('Invierno', 'WINTER', 'NEGUA')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('-¿Eh?', '\"Eh?', '-Eh?')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('Verano', 'SUMMER', 'UDA')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('Primavera', 'SPRING', 'UDABERRIA')\n","('Verano', 'SUMMER', 'UDA')\n","('18.', '18.', '18.')\n","('Otoño', 'AUTUMN', 'UDAZKENA')\n","('Invierno', 'WINTER', 'NEGUA')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?', '-Zergatik?')\n","('-le dije.', 'I said.', '-esan nion.')\n","('-No.', '\"Nope.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-dijo.', 'he said.', '-esan zuen.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez zekiat.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez zekiat.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-le dije.', 'I said.', '-esan nion.')\n","('No le contesté.', \"I didn't answer him.\", 'Ez nion erantzun.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('No.', 'No.', 'Ez.')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('-me dijo-.', 'he said.', '-esan zuen-.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Sí, ¿eh?', '\"Yeah?', '-Bai?')\n","('-¿Para qué?', '\"What for?\"', '- Zertarako?')\n","('-¿Yo?', '\"Me?', '-Nik?')\n","('-¿Qué?', '\"What?\" she said.', '-Zer? -hark.')\n","('De verdad.', 'No kidding.', 'Ez naiz txantxetan ari.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-Evidentemente.', '\"Obviously.\"', '-Hala zirudik.')\n","('De verdad.', 'I really do.', 'Benetan.')\n","('¿Por qué lo preguntas?', 'Why do you ask?\"', 'Zergatik galdetzen didak?')\n","('-Sí.', 'Listen.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('Ahora vete a la cama.', 'Go to bed now.', 'Orain joan zaitez ohera.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-le dije.', 'I asked him.', '-galdetu nion.')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('En serio.', \"I'm not kidding.\", 'Ez naiz txantxetan ari.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('De verdad.', 'She really does.', 'Benetan.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('Yo me voy a acostar.', \"I'm going to bed.\", 'Ni ohera noa.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('De verdad.', 'I really did.', 'Benetan.')\n","('De verdad.', 'I really did.', 'Benetan.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('De verdad.', 'I really did.', 'Benetan.')\n","('-le dije.', 'I said.', '-esan nion.')\n","('-le pregunté-.', 'I asked her.', '-galdetu nion-.')\n","('-me preguntó.', 'she asked me.', '-galdetu zidan.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Lo sé.', '\"I know.\"', '-Badakit.')\n","('No sé por qué.', \"I don't know why.\", 'Ez dakit zergatik.')\n","('D.B.', 'D.B.', 'D.B.')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('¿Adónde?', 'Where?', 'Nora?')\n","('¡Bienvenido, Stephen!', 'Welcome home, Stephen!', 'Ongietorri etxera, Stephen!')\n","('-Vuélvete a la cama.', '-Get back into bed.', '-Sar hadi atzera ohean.')\n","('No eran marrullerías.', 'He was not foxing.', 'Ez zen aitzakia.')\n","('Stephen contestó:', 'Stephen answered:', 'Stephenek erantzun:')\n","('Sí.', 'Yes...', 'Bai...')\n","('Sí.', 'Yes...', 'Bai...')\n","('Amén.', 'Amen.', 'Amen.')\n","('¡Simón!', 'Simon!', 'Simon!')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('-preguntó míster Dédalus.', 'asked Mr Dedalus.', '-galdetu zuen Dedalus jaunak.')\n","('-¡Todos adentro!', '-All in!', '-Denok barrura!')\n","('-¡Todos adentro!', '-All in!', '-Denok barrura!')\n","('¡Todos adentro!', 'All in!', 'Denok barrura!')\n","('-Dédalus, señor.', '-Dedalus, sir.', '-Dedalus, jauna.')\n","('-¡La otra mano!', '-Other hand!', '-Beste eskua!')\n","('-¿Qué te ha dicho?', '-What did he say?', '-Zer esan dik?')\n","('-¡Hurra!', '-Hurroo!', '-Gora!')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-dijo Heron-.', 'said Heron.', '-esan zuen Heronek-.')\n","('-preguntó Stephen.', 'asked Stephen.', '-galdetu zuen Stephenek.')\n","('-No.', '-No.', '-Ez!')\n","('-No.', '-No.', '-Ez!')\n","('No.', 'No.', 'Ez!')\n","('-Sí.', '-Yes.', '-Bai.')\n","('Amén.', 'Amen.', 'Amen.')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('En el nombre del Padre y del Hijo y del Espíritu Santo.', 'In the name of the Father and of the Son and of the Holy Ghost.', 'Aitaren, Semearen eta Espiritu Santuaren izenean.')\n","('Amén.', 'Amen.', 'Amen.')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('¿Cómo?', 'What?', 'Zer?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('Sí.', 'Yes.', 'Bai.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('En el nombre del Padre y del Hijo y del Espíritu Santo.', 'In the name of the Father and of the Son and of the Holy Ghost.', 'Aitaren, Semearen eta Espiritu Santuaren izenean.')\n","('Amén.', 'Amen.', 'Amen.')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('No quisiste.', 'You would not.', 'Ez zenuen nahi izan.')\n","('¡Confesarse!', 'Confess!', 'Aitortu!')\n","('Era verdad.', 'It was true.', 'Egia zen.')\n","('-¿Alguna cosa más, hijo mío?', '-Anything else, my child?', '-Beste ezer, seme?')\n","('-Sí, padre.', '-Yes, father.', '-Bai, aita.')\n","('-Corpus Domini nostri.', '-CORPUS DOMINI NOSTRI.', '-Corpus Domini nostri')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¡Au!', 'Ao!', 'Ai!')\n","('¡Bous Stephanoumenos!', 'Bous Stephanoumenos!', 'Bous Stephanoumenos!')\n","('-¡Stephanephoros!', '-Stephaneforos!', '-Stephaneforos!')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('-Sí, padre.', '-Yes, father.', '-Bai, aita.')\n","('-preguntó Stephen.', 'asked Stephen.', '-galdetu zuen Stephenek.')\n","('Paciencia.', 'Patience.', 'Pazientzia.')\n","('-¿Para qué es eso?', '-What is it for?', '-Zertarako duk?')\n","('-No.', '-No.', '-Ez.')\n","('Podía ser.', 'It might be.', 'Bazitekeen.')\n","('¿Qué pájaros eran aquéllos?', 'What birds were they?', 'Zer txori ziren haiek?')\n","('Vámonos.', 'Come away.', 'Goazen.')\n","('-preguntó Cranly.', 'Cranly asked.', '-galdetu zuen Cranlyk.')\n","('-preguntó Cranly.', 'Cranly asked.', '-galdetu zuen Cranlyk.')\n","('-preguntó Cranly.', 'Cranly asked.', '-galdetu zuen Cranlyk.')\n","('No.', 'No.', 'Ez.')\n","('Amén.', 'Amen.', 'Amen.')\n","('Pero no.', 'But no.', 'Baina ez.')\n","('-dije.', 'I said.', '-esan nuen.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-¡Ven!', \"'Come!'\", '-Goazen!')\n","('¡No!', 'No!', 'Ez!')\n","('-dijo.', 'he said.', '-esan zuen.')\n","('-¡Hey, Corley!', \"'Hallo, Corley!'\", '-Eup! Corley!')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('Ignatius Gallaher se rió.', 'Ignatius Gallaher laughed.', 'Ignatius Gallaherrek barre egin zuen.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('-Bueno...', \"'Well...\", '-Beno...')\n","('-Sí, señor.', \"'Yes, sir.'\", '-Bai, jauna.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-dijo el viejo.', 'said the old man.', '-esan zuen gizon zaharrak.')\n","('-le preguntó.', 'he asked.', '-galdetu zion.')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('¡Pok!', 'Pok!', 'Punp!')\n","('-preguntó Miss Ivors.', 'asked Miss Ivors.', '-galdetu zion Ivors andereñoak.')\n","('-Damas y caballeros.', \"'Ladies and Gentlemen,\", '-Jaun-andreok...')\n","('-Sí, señor-dijo el cochero.', \"'Yes, sir,' said the cabman.\", '-Bai, jauna-esan zuen kotxe-gidariak.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('-¡Gretta!', \"'Gretta!'\", '-Gretta!')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('-¿Para qué?', \"'What for?'\", '-Zertarako?')\n","('-¿Qué?', '-What?', '-Zer?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Qué?', '-What?', '-Zer?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('Sí.', 'Yes.', 'Bai.')\n","('preguntó Stephen.', 'Stephen asked.', '-galdetu zuen Stephenek.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('preguntó Stephen.', 'Stephen asked.', '-galdetu zuen Stephenek.')\n","('-No, señor.', '-No, sir.', '-Ez, jauna.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('No.', 'No.', 'Ez.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('No.', 'No.', 'Ez.')\n","('¡Jesús!', 'Jesus!', 'Jesus!')\n","('¿No?', 'No?', 'Ez?')\n","('¡Tilintilín!', 'Dringdring!', 'Tilin-tilin.')\n","('Bueno, no pasa nada.', \"O, that's all right.\", 'Tira, ondo nago.')\n","('¿Quién?', 'Who?', 'Nor?')\n","('Yo...', 'I...', 'Ni...')\n","('No.', 'No.', 'Ez.')\n","('Già.', 'Già.', 'Già.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('¿No?', 'No?', 'Ez?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('preguntó.', 'he asked.', '-galdetu zuen.')\n","('No.', 'No.', 'Ez.')\n","('¡Atención!', 'Watch!', 'Erne!')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek.')\n","('No.', 'No.', 'Ez.')\n","('¡Pobre papá!', 'Poor papa!', 'Aita gaixoa!')\n","('Para sujetársela.', 'To keep it up.', 'Goian eusteko hari.')\n","('Olvidar.', 'Forget.', 'Ahaztu.')\n","('Sí:', 'Yes:', 'Bai:')\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Caramba.', 'Hello.', 'To.')\n","('Espera.', 'Wait.', 'Hago.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek.')\n","('-Sí, señor, dijo el farmacéutico.', '-Yes, sir, the chemist said.', '-Bai, jauna-esan zuen botikariak-.')\n","('Todos esperaraban.', 'All waited.', 'Denak zain zeuden.')\n","('-No, dijo Mr. Bloom.', '-No, Mr Bloom said.', '-Ez-esan zuen Bloomek-.')\n","('Milly.', 'Milly.', 'Milly.')\n","('Mullingar.', 'Mullingar.', 'Mullingar.')\n","('Joven estudiante.', 'Young student.', 'Ikasle gaztea.')\n","('preguntó Mr. Power.', 'Mr Power asked.', '-galdetu zuen Powerrek.')\n","('Sí.', 'Yes.', 'Bai.')\n","('preguntó Mr. Power.', 'Mr Power asked.', '-galdetu zuen Powerrek.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek-.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('El corazón.', 'Heart.', 'Bihotzekoa.')\n","('Traquetean los huesos.', 'Rattle his bones.', 'Hezur-hotsa.')\n","('Nadie lo reclama.', 'Nobody owns.', 'Nork eraman?')\n","('Por las piedras.', 'Over the stones.', 'Harlosetan.')\n","('-¿Por qué?', '-Why?', '-Zergatik?')\n","('Quince.', 'Fifteen.', 'Hamabost.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('No.', 'No.', 'Ez.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('¿Eh?', 'Eh?', 'E?')\n","('preguntó.', 'he asked.', '-galdetu zuen-.')\n","('¡Pobre Dignam!', 'Poor Dignam!', 'Dignam gaixoa!')\n","('Caramba.', 'Hello.', 'To.')\n","('No, no:', 'No, no:', 'Ez, ez:')\n","('No:', 'No:', 'Ez:')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Se pararon.', 'They stopped.', 'Gelditu egin ziren.')\n","('Gracias.', 'Thank you.', 'Mila esker.')\n","('Sllt.', 'Sllt.', 'Sllt.')\n","('Sllt.', 'Sllt.', 'Sllt.')\n","('-Espere.', '-Wait.', '-Zaude.')\n","('-¡Monks!', '-Monks!', '-Monks!')\n","('Intentarlo de todas formas.', 'Try it anyhow.', 'Saiatu behintzat.')\n","('Sí.', 'Yes.', 'Bai.')\n","('No.', 'No.', 'Ez.')\n","('Aquí.', 'Here.', 'Hemen.')\n","('No.', 'No.', 'Ez.')\n","('preguntó Mr. Bloom.', 'Mr Bloom asked.', '-galdetu zuen Bloomek.')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('-¿Cómo está usted?', '-How do you do?', '-Zer moduz?')\n","('preguntó Stephen.', 'Stephen asked.', '-galdetu zuen Stephenek.')\n","('Sí, sí.', 'Yes, yes.', 'Bai, bai.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('dijo Myles Crawford.', 'Myles Crawford said.', '-esan zuen Myles Crawfordek.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('Se lo diré.', \"I'll tell you.\", 'Esango dizut.')\n","('Bien.', 'Right.', 'Ederki.')\n","('Bien.', 'Right.', 'Ederki.')\n","('Sí...', 'Yes...', 'Bai...')\n","('Sí.', 'Yes.', 'Bai.')\n","('¡Bah!', 'Psha!', 'Beeh!')\n","('A. E.', 'A. E.', 'A. E.')\n","('preguntó el profesor.', 'the professor asked.', '-galdetu zuen irakasleak.')\n","('-Ya veo, dijo el profesor.', '-I see, the professor said.', '-Argi dago-esan zuen irakasleak.')\n","('No.', 'No.', 'ez.')\n","('Imprecaron al nazareno con recios insultos.', 'Iron nails ran in.', 'Iosi Naute Romanoek Iltzez.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('¿Eh?', 'Eh?', 'E?')\n","('No.', 'No.', 'ez.')\n","('No, no.', 'No, no.', 'Ez, ez.')\n","('¿Hermana?', 'Sister?', 'Arreba?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-No, dijo Mr. Bloom.', '-No, Mr Bloom said.', '-Ez-esan zuen Bloomek-.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('preguntó Mr. Bloom.', 'Mr Bloom asked.', '-galdetu zuen Bloomek.')\n","('Cruel.', 'Cruel.', 'Krudela.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('Té.', 'Tea.', 'Tea.')\n","('No lo veo.', \"Can't see it.\", 'Ez diat ikusten.')\n","('Sí:', 'Yes:', 'Bai:')\n","('Espera.', 'Wait.', 'Hago.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Casher.', 'Kosher.', 'Kosher.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('Vino.', 'Wine.', 'Ardoa.')\n","('-Sí, dijo.', '-Yes, he said.', '-Bai-esan zuen-.')\n","('Instinto.', 'Instinct.', 'Sena.')\n","('Nadie.', 'No-one.', 'Inor ez.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('dijo Napias Flynn.', 'Nosey Flynn said.', '-esan zuen Flynn Sudurluzek-.')\n","('preguntó Paddy Leonard.', 'Paddy Leonard asked.', '-galdetu zuen Paddy Leonardek.')\n","('dijo.', 'he said.', '-esan zuen.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('A. E.', 'A. E.', 'A. E.')\n","('Mordedura de la conciencia.', 'Agenbite of inwit.', 'Agenbite of inwit.')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('No.', 'No.', 'ez.')\n","('Espera.', 'Wait.', 'Hago.')\n","('Jueves.', 'Thursday.', 'Osteguna.')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('-Sí.', '-Yes.', '-Bai.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('¡Telegrama!', 'Telegram!', 'Telegrama!')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('-¿Qué?', '-What?', '-Zer?')\n","('Conoce a tu viejo.', 'He knows your old fellow.', 'Ezagutzen dik hire zaharra.')\n","('No.', 'No.', 'Ez.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BEST', 'BEST:', 'BEST')\n","('(risas)', '(Laughter)', '(Algara)')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Avefría.', 'Lapwing.', 'Hegabera.')\n","('-¿Por qué?', '-Why?', '-Zergatik?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Día.', 'Day.', 'Eguna.')\n","('Sí.', 'Yes.', 'Bai.')\n","('preguntó.', 'he asked.', '-galdetu zuen.')\n","('preguntó Boody.', 'Boody asked.', '-galdetu zuen Boodyk.')\n","('preguntó.', 'she asked.', '-galdetu zuen.')\n","('dijo.', 'he said.', '-esan zuen.')\n","('-Sí, señor.', '-Yes, sir.', '-Bai, jauna.')\n","('dijo Almidano Artifoni.', 'Almidano Artifoni said.', '-esan zuen Almidano Artifonik.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('No, señor.', 'No, sir.', 'Ez, jauna.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('preguntó Ned Lambert.', 'Ned Lambert asked.', '-galdetu zuen Ned Lambertek-.')\n","('¿Qué?', 'What?', 'Zer?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('seis.', 'six.', 'sei.')\n","('-¿Ven ustedes?', '-See?', '-Ikusten?')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('preguntó.', 'he asked.', '-galdetu zuen.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Escucha:', 'Listen:', 'Entzun:')\n","('No:', 'No:', 'Ez:')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¡Talán!', '-Barang!', '-Talan!')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('Sí.', 'Yes.', 'Bai.')\n","('No.', 'No.', 'Ez.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Amén.', 'Amen.', 'Amen.')\n","('dijo Stephen.', 'Stephen said.', '-esan zuen Stephenek.')\n","('Mordedura.', 'Agenbite.', 'Agenbite.')\n","('Mordedura de la conciencia.', 'Agenbite of inwit.', 'Agenbite of inwit.')\n","('¿Qué tal van las cosas?', 'How are things?', 'Zer moduz?')\n","('Rataplán.', 'Baraabum.', 'Ra-ta-plan.')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Aún no.', 'Not yet.', 'Oraindik ez.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Viejo Bloom.', 'Old Bloom.', 'Bloom zaharra.')\n","('-No.', '-No.', '-Ez.')\n","('preguntó Mr. Dedalus.', 'Mr Dedalus asked.', '-galdetu zuen Dedalus jaunak.')\n","('¿Quién?', 'Who?', 'Nor?')\n","('preguntó.', 'he asked.', '-galdetu zuen-.')\n","('-¿Es cierto?', '-Is that a fact?', '-Benetan?')\n","('Para Raoul.', 'For Raoul.', 'Raoulentzat.')\n","('De nuevo.', 'Again.', 'Berriro.')\n","('-¡Ay!', '-O!', '-O!')\n","('¡Ay!', 'O!', 'O!')\n","('¡Ay!', 'O!', 'O!')\n","('El reloj tabaleaba.', 'Clock clacked.', 'Erlojuaren klaskada.')\n","('dijo.', 'he said.', '-esan zuen-.')\n","('¿Eh?', 'What?', 'Ezta?')\n","('-Sí.', '-Yes.', '-Bai.')\n","('Adiós.', 'Farewell.', 'Agur.')\n","('Sí.', 'Yes.', 'Bai.')\n","('Sí:', 'Yes:', 'Bai:')\n","('¿A mí?', 'Me?', 'Ni?')\n","('¿Qué tal?', 'How do you?', 'Zer moduz?')\n","('¿Y qué?', 'There?', 'Hor?')\n","('¿Qué?', 'What?', 'Zer?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('No:', 'No:', 'Ez:')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Monta.', 'Tup.', 'Zazt.')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Ven.', 'Come.', 'Zatoz.')\n","('Ven.', 'Come.', 'Etorri.')\n","('Cloche.', 'Cloche.', 'Cloche.')\n","('¡Dingdón!', 'Heigho!', 'Haika!')\n","('Para sujetársela.', 'To keep it up.', 'Goian eusteko.')\n","('Mujer.', 'Woman.', 'Emakumea.')\n","('-Sí, dijo Mr. Bloom.', '-Yes, Mr Bloom said.', '-Bai-esan zuen Bloomek-.')\n","('¡Pat!', 'Pat!', 'Pat!')\n","('Cantando.', 'Singing.', 'Kantuz.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Lluvia.', 'Rain.', 'Euria.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('¿Cuánto?', 'How much?', 'Zenbat?')\n","('Je je je je.', 'Hee hee hee hee.', 'Ji ji ji ji.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Todos se fueron.', 'All gone.', 'Denak joanak.')\n","('Rudy.', 'Rudy.', 'Rudy.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Toc.', 'Tap.', 'Ttak.')\n","('¿Qué?', 'What?', 'Zer?')\n","('Toc.', 'Tap.', 'Ttak.')\n","('Castilla.', 'Castile.', 'Gaztela.')\n","('Amén.', 'Amen.', 'Amen.')\n","('No.', 'No.', 'Ez.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Espera.', 'Wait.', 'Itxaron.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Toc.', 'Tap.', 'Tak.')\n","('¿Eh?', 'What?', 'Zer?')\n","('Toc.', 'Tap.', 'Tak.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Goulding, Collis, Ward.', 'Goulding, Collis, Ward.', 'Goulding, Collis, Ward.')\n","('Pon.', 'Pom.', 'Pom.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Cloche.', 'Cloche.', 'Cloche.')\n","('Sonnez la.', 'Sonnez la.', 'Sonnez la.')\n","('Long John.', 'Long John.', 'John Luzea.')\n","('Pon.', 'Pom.', 'Pom.')\n","('Toc.', 'Tap.', 'Tak.')\n","('Sí.', 'Yes.', 'Bai.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('le digo yo.', 'says I.', '-nik.')\n","('¡Ah!', 'Ah!', 'Ai!')\n","('le digo yo.', 'says I.', '-nik.')\n","('-¿Quién?', '-Who?', '-Nork?')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('-¿Qué es eso?', \"-What's that?\", '-Zer da hori?')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('-Sí, dice Alf.', '-Yes, says Alf.', '-Bai-Alfek-.')\n","('¿Por qué?', 'Why?', 'Zer ba?')\n","('dice Joe.', 'says Joe.', '-Joek.')\n","('dice Bob Doran.', 'says Bob Doran.', '-Bob Doranek.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('¿Qué?', 'What?', 'Zer?')\n","('dice Alf.', 'says Alf.', '-Alfek-.')\n","('-...', '-...', '-...')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('¡Fenómeno!', 'Phenomenon!', 'Fenomenoa!')\n","('le digo yo.', 'says I.', '-nik.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('Mr. Acuatropatas:', 'Mr Allfours:', 'Allfours jauna:')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('-¿Quién?', '-Who?', '-Nork?')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('-¿Quién?', '-Who?', '-Nork?')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('J. J.', 'J. J.', 'J. J.')\n","('-Sí, dice J. J.', '-Yes, says J. J.', '-Bai-dio J. J.k-.')\n","('dice Joe.', 'says Joe.', '-dio Joek-.')\n","('dice Alf.', 'says Alf.', '-dio Alfek-.')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('¿Qué?', 'What?', 'Zer?')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Terry.', 'says Terry.', '-dio Terryk.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak-.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice John Wyse.', 'says John Wyse.', '-dio John Wysek.')\n","('dice Bloom.', 'says Bloom.', '-dio Bloomek-.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak-.')\n","('dice Joe.', 'says Joe.', '-dio Joek.')\n","('dice John Wyse.', 'says John Wyse.', '-dio John Wysek.')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('dice Alf.', 'says Alf.', '-dio Alfek.')\n","('-¿Por qué no?', '-Why not?', '-Zergatik ez?')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak-.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('dice el paisano.', 'says the citizen.', '-dio Herritarrak.')\n","('No.', 'No.', 'Ez.')\n","('-¿Qué?', '-What?', '-Zer?')\n","('No, no:', 'No, no:', 'Ez, ez:')\n","('¡Ah!', 'Ah!', 'Ai!')\n","('No.', 'No.', 'Ez.')\n","('¡Oh!', 'O!', 'Ooo!')\n","('Ah, sí.', 'Ah, yes.', 'A, bai.')\n","('Molly.', 'Molly.', 'Molly.')\n","('Tableau!', 'Tableau!', 'Tableau!')\n","('No.', 'No.', 'Ez.')\n","('¿Y por qué no?', 'Why not?', 'Zergatik ez?')\n","('¿Qué?', 'What?', 'Zer?')\n","('¿Qué?', 'What?', 'Zer?')\n","('Mullingar.', 'Mullingar.', 'Mullingar.')\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Joven estudiante.', 'Young student.', 'Ikasle gaztea.')\n","('Dignam.', 'Dignam.', 'Dignam.')\n","('Tic.', 'Tip.', 'Ttak.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('Sí.', 'Yes.', 'Bai.')\n","('No.', 'No.', 'Ez.')\n","('Ummm.', 'Hm.', 'Hm.')\n","('No.', 'No.', 'Ez.')\n","('Ummm.', 'Hm.', 'Hm.')\n","('Ummm.', 'Hm.', 'Hm.')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('No.', 'No.', 'Ez.')\n","('Ba.', 'Ba.', 'Saguz.')\n","('Ba.', 'Ba.', 'Saguz.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('Ba.', 'Ba.', 'Saguz.')\n","('Queridísimo papi.', 'Dearest Papli.', 'Aitatxo maitea.')\n","('No.', 'No.', 'Ez.')\n","('No.', 'No.', 'Ez.')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('No.', 'No.', 'Ez.')\n","('Mejor.', 'Better.', 'Hobe.')\n","('¡Oh!', 'O!', 'O!')\n","('¿Qué?', 'What?', 'Zer?')\n","('Gracias.', 'Thanks.', 'Eskerrik asko.')\n","('De aquí.', 'Here.', 'Hemen.')\n","('Cuco', 'Cuckoo', 'Kuku')\n","('Cuco', 'Cuckoo', 'Kuku')\n","('¡Ah!', 'Ah!', 'Ai!')\n","('¿Eh?', 'Eh?', 'E?')\n","('Buenas.', 'Night.', 'Gabon.')\n","('¡Plaap!', 'Pflaap!', 'Plaast!')\n","('LOS NIÑOS', 'THE CHILDREN:', 'HAURRAK')\n","('EL IDIOTA', 'THE IDIOT:', 'IDIOTA')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('¡Ah!', 'Ah!', 'A!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Qué es eso?', 'What is that?', 'Zer da hori?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Abajo sobre las manos.', 'On the hands down.', 'Eskuen gainean makurtuta.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¡Ay!', 'Ow!', 'Ai!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RUDOLPH', 'RUDOLPH:', 'RUDOLPH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡Ah!', 'Ah!', 'A!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí.', 'Yes.', 'Bai.')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARION', 'MARION:', 'MARION')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('Quince.', 'Fifteen.', 'Hamabost.')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('GERTY', 'GERTY:', 'GERTY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Cómo está usted?', 'How do you do?', 'Zer moduz?')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('RICHIE', 'RICHIE:', 'RICHIE')\n","('RICHIE', 'RICHIE:', 'RICHIE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí.', 'Yes.', 'Bai.')\n","('MRS. BREEN', 'MRS BREEN:', 'BREEN ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS OCIOSOS', 'THE LOITERERS:', 'ZER-SUMAKOAK')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Vamos.', 'Come.', 'Zatoz.')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Bloom.', 'Bloom.', 'Bloom.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARTHA', 'MARTHA:', 'MARTHA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BEAUFOY', 'BEAUFOY:', 'BEAUFOY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BEAUFOY', 'BEAUFOY:', 'BEAUFOY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MARY DRISCOLL', 'MARY DRISCOLL:', 'MARY DRISCOLL')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","(\"J. J. O'MOLLOY\", \"J. J. O'MOLLOY:\", \"J. J. O'MOLLOY\")\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('MRS. BELLINGHAM', 'MRS BELLINGHAM:', 'BELLINGHAM ANDREA')\n","('MRS. BELLINGHAM', 'MRS BELLINGHAM:', 'BELLINGHAM ANDREA')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('A mí también.', 'Me too.', 'Niri ere bai.')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('MRS. YELVERTON BARRY', 'MRS YELVERTON BARRY:', 'YELVERTON BARRY ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('MRS. BELLINGHAM', 'MRS BELLINGHAM:', 'BELLINGHAM ANDREA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Kismet.', 'Kismet.', 'Kismet.')\n","('LA HONORABLE MRS. MERVYN TALBOYS', 'THE HONOURABLE MRS MERVYN TALBOYS:', 'MERVYN TALBOYS ANDRE PRESTUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL INNOMINADO', 'THE NAMELESS ONE:', 'IZENGABEA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('EL UJIER', 'THE CRIER:', 'UXERRA')\n","('¡Escandaloso!', 'Scandalous!', 'Eskandalagarria!')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('Amén.', 'Amen.', 'Amen.')\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","(\"JOHN O'CONNELL\", \"JOHN O'CONNELL:\", \"JOHN O'CONNELL\")\n","('PADDY DIGNAM', 'PADDY DIGNAM:', 'PADDY DIGNAM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡Dios salve a Leopold Primero!', 'God save Leopold the First!', 'Gora Leopold Lehena!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡No!', 'No!', 'Ez!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('colgado.', 'up.', 'ep.')\n","('colgado.', 'up.', 'ep.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('PADDY LEONARD', 'PADDY LEONARD:', 'PADDY LEONARD')\n","('Gracias.', 'Thank you.', 'Eskerrik asko.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","(\"J. J. O'MOLLOY\", \"J. J. O'MOLLOY:\", \"J. J. O'MOLLOY\")\n","('¡No!', 'Nay!', 'Ez!')\n","('NAPIAS FLYNN', 'NOSEY FLYNN:', 'FLYNN SUDURLUZE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('NAPIAS FLYNN', 'NOSEY FLYNN:', 'FLYNN SUDURLUZE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('PADDY LEONARD', 'PADDY LEONARD:', 'PADDY LEONARD')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('LA SIBILA CON VELO', 'THE VEILED SIBYL:', 'SIBILA ESTALZAPIDUNA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL PAISANO', 'THE CITIZEN:', 'HERRITARRA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Ser o no ser.', 'To be or not to be.', 'Izan ala ez izan.')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¡Ba!', 'Bah!', 'Beh!')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA GORRA', 'THE CAP:', 'BISERA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA GORRA', 'THE CAP:', 'BISERA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¿Qué?', 'What?', 'Zer?')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('No.', 'No.', 'Ez.')\n","('EL GRAMÓFONO', 'THE GRAMOPHONE:', 'GRAMOFONOA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BEST', 'BEST:', 'BEST')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAD', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('VIRAD', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAD', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Espera.', 'Wait.', 'Itxaron.')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('¿Dónde estamos?', 'Where are we?', 'Non gaude?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Sí.', 'Yes.', 'Bai.')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('¿Eh?', 'Eh?', 'E?')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('Nada hay nuevo bajo el sol.', 'Nothing new under the sun.', 'Ezer berririk ez eguzkipean.')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('KITTY', 'KITTY:', 'KITTY')\n","('PHILIP EBRIO', 'PHILIP DRUNK:', 'PHILIP MOZKOR')\n","('PHILIP SOBRIO', 'PHILIP SOBER:', 'PHILIP URZALE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('¡Jek!', 'Hek!', 'Hek!')\n","('BEN DOLLARD', 'BEN DOLLARD:', 'BEN DOLLARD')\n","('BEN DOLLARD', 'BEN DOLLARD:', 'BEN DOLLARD')\n","('VIRAG', 'VIRAG:', 'VIRAG')\n","('Adiós.', 'Farewell.', 'Agur.')\n","('K 11.', 'K. II.', 'K. 11.')\n","('Hy Franks.', 'Dr Hy Franks.', 'Hy Franks doktorea.')\n","('HENRY', 'HENRY:', 'HENRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí.', 'Yes.', 'Bai.')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Mejor oferta de Dub.', 'Best value in Dub.', 'Dublingo baliotsuena.')\n","('EL ABANICO', 'THE FAN:', 'HAIZEMAILEA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('ZOE', 'ZOE:', 'ZOE')\n","('Sí.', 'Yes.', 'Bai.')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('Yo también.', 'I will.', 'Nik ere bai.')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('A mí.', 'Me.', 'Niri.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('La ciencia.', 'Science.', 'Zientzia.')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('¿Dónde?', 'Where?', 'Non?')\n","('¿A qué hora?', 'What time?', 'Zer ordutan?')\n","('¡Dos!', 'Two!', 'Bi!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('¡Arriba!', 'Up!', 'Jaiki!')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BELLO', 'BELLO:', 'BELLO')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Yo....', 'I...', 'Ni...')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('UNA VOZ', 'A VOICE:', 'AHOTS BAT')\n","('BELLO', 'BELLO:', 'BELLO')\n","('Demasiado tarde.', 'Too late.', 'Beranduegi.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLO', 'BELLO:', 'BELLO')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('VOCES', 'VOICES:', 'AHOTSAK')\n","('Ah, sí.', 'Ah, yes.', 'A, bai.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Mnemo?', 'Mnemo?', 'Mnemo?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('EL SALTO DE AGUA', 'THE WATERFALL:', 'UR-JAUZIA')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL SALTO DE AGUA', 'THE WATERFALL:', 'UR-JAUZIA')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LOS TEJOS', 'THE YEWS:', 'HAGINAK')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('Amén.', 'Amen.', 'Amen.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¡Nebrakada!', 'Nebrakada!', 'Nebrakada!')\n","('LA NINFA', 'THE NYMPH:', 'NINFA')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BELLA', 'BELLA:', 'BELLA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('KITTY', 'KITTY:', 'KITTY')\n","('Espera.', 'Wait.', 'Itxoin.')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Casada.', 'Married.', 'Ezkondua.')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Hoy.', 'Today.', 'Gaur.')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¿Dinero?', 'Money?', 'Dirua?')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('¿Qué?', 'What?', 'Zer?')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('LENEHAN', 'LENEHAN:', 'LENEHAN')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('MARION', 'MARION:', 'MARION')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('¿Qué?', 'What?', 'Zer?')\n","('MARION', 'MARION:', 'MARION')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BOYLAN', 'BOYLAN:', 'BOYLAN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Gracias, señor.', 'Thank you, sir.', 'Eskerrik asko, jauna.')\n","('KITTY', 'KITTY:', 'KITTY')\n","('KITTY', 'KITTY:', 'KITTY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BELLA', 'BELLA:', 'BELLA')\n","('LAS PUTAS', 'THE WHORES:', 'PUTAK')\n","('ZOE', 'ZOE:', 'ZOE')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('ZOE', 'ZOE:', 'ZOE')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('LAS HORAS', 'HOURS:', 'ORDUAK')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('¡Dingdón!', 'Heigho!', 'Haika!')\n","('ZOE', 'ZOE:', 'ZOE')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('ZOE', 'ZOE:', 'ZOE')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('MAGINNI', 'MAGINNI:', 'MAGINNI')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('KITTY', 'KITTY:', 'KITTY')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA PIANOLA', 'THE PIANOLA:', 'PIANOLA')\n","('¡Encore!', 'Encore!', 'Beste bat!')\n","('SIMON', 'SIMON:', 'SIMON')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('No.', 'No.', 'Ez.')\n","('BUCK MULLIGAN', 'BUCK MULLIGAN:', 'BUCK MULLIGAN')\n","('Epi oinopa ponton.', 'Epi oinopa ponton.', 'Epi oinopa ponton.')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¡No!', 'No!', 'Ez!')\n","('LA MADRE', 'THE MOTHER:', 'AMA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('EL CHORRO DE GAS', 'THE GASJET:', 'GAS-TXORROTA')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BELLA', 'BELLA:', 'BELLA')\n","('LAS PUTAS', 'THE WHORES:', 'PUTAK')\n","('ZOE', 'ZOE:', 'ZOE')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('Diez chelines.', 'Ten shillings.', 'Hamar txelin.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Diez chelines?', 'Ten shillings?', 'Hamar txelin?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('FLORRY', 'FLORRY:', 'FLORRY')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BELLA', 'BELLA:', 'BELLA')\n","('ZOE', 'ZOE:', 'ZOE')\n","('¿Qué?', 'What?', 'Zer?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('VOCES', 'VOICES:', 'AHOTSAK')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BIDDY EXPURGACIONES', 'BIDDY THE CLAP:', 'BIDDY GONOKOKO')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('EDUARDO SÉPTIMO', 'EDWARD THE SEVENTH:', 'EDUARDO ZAZPIGARRENA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BIDDY EXPURGACIONES', 'BIDDY THE CLAP:', 'BIDDY GONOKOKO')\n","('LA ALCAHUETA', 'THE BAWD:', 'MADREA')\n","('EL PAISANO', 'THE CITIZEN:', 'HERRITARRA')\n","('EL ZAGAL REBELDE', 'THE CROPPY BOY:', 'MATXINO GAZTEA')\n","('RUMBOLD', 'RUMBOLD:', 'RUMBOLD')\n","('EDUARDO SÉPTIMO', 'EDWARD THE SEVENTH:', 'EDUARDO ZAZPIGARRENA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('UN BRAVUCÓN', 'A ROUGH:', 'HARROPUTZ BAT')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('EL PEÓN', 'THE NAVVY:', 'OBRAKO PEOIA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('KATE COÑONA', 'CUNTY KATE:', 'KATE POTORRO')\n","('BIDDY EXPURGACIONES', 'BIDDY THE CLAP:', 'BIDDY GONOKOKO')\n","('KATE COÑONA', 'CUNTY KATE:', 'KATE POTORRO')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('VOCES', 'VOICES:', 'AHOTSAK')\n","('¡Policía!', 'Police!', 'Polizia!')\n","(\"EL PADRE MALACHI O'FLYNN\", \"FATHER MALACHI O'FLYNN:\", \"AITA MALACHI O'FLYNN\")\n","('EL REVERENDO MR. HAINES LOVE', 'THE REVEREND MR HAINES LOVE:', 'HAINES LOVE JAUN AGURGARRIA')\n","('(Desde las alturas la voz de Adonai clama)', '(From on high the voice of Adonai calls.)', '(Adonairen ahotsa entzuten da zeru-goietan)')\n","('ADONAI', 'ADONAI:', 'ADONAI')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('LYNCH', 'LYNCH:', 'LYNCH')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('¡Aire!', 'Air!', 'Airea!')\n","('¿Quién?', 'Who?', 'Nor?')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('CISSY CAFFREY', 'CISSY CAFFREY:', 'CISSY CAFFREY')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('¿Quién es usted?', 'Who are you?', 'Nor zara zu?')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('SOLDADO COMPTON', 'PRIVATE COMPTON:', 'COMPTON SOLDADUA')\n","('SOLDADO CARR', 'PRIVATE CARR:', 'CARR SOLDADUA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('Le conozco.', 'I know him.', 'Ezagutzen dut.')\n","('Copa de oro.', 'Gold cup.', 'Urrezko kopa.')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('¿Qué?', 'What?', 'Zer?')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA PRIMERO', 'FIRST WATCH:', 'LEHEN HERRIZAINA')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('GUARDIA SEGUNDO', 'SECOND WATCH:', 'BIGARREN HERRIZAINA')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('LOS GUARDIAS', 'THE WATCH:', 'HERRIZAINAK')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Buenas noches.', 'Good night.', 'Gabon.')\n","('KELLEHER COPETÓN', 'CORNY KELLEHER:', 'CORNY KELLEHER')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Buenas.', 'Night.', 'Gabon.')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('Lástima.', 'Pity.', 'Pena.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('BLOOM', 'BLOOM:', 'BLOOM')\n","('¿Por qué?', 'Why?', 'Zer, bada?')\n","('¿Qué hay en un nombre?', \"What's in a name?\", 'Zer dago, bada, izen batean?')\n","('-¡Pun!', '-Pom!', '-Pum!')\n","('De allí vengo yo.', \"That's where I hails from.\", 'Han dut nik jaioterria.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Quién?', '-Who?', '-Nor?')\n","('Vamos.', 'Come.', 'Zatoz.')\n","('Sí.', 'Yes.', 'Bai.')\n","('¿Qué es el hogar sin Fiambre en Pote Ciruelo?', \"What is home without Plumtree's Potted Meat?\", \"Zer da etxea Plumtree's Haragi ontziraturik gabe?\")\n","('Incompleto.', 'Incomplete.', 'Osatu gabea.')\n","('Se sienta.', 'She sits.', 'Esertzen da.')\n","('Crepúsculo.', 'Twilight.', 'Ilunabarra.')\n","('Piensa.', 'She thinks.', 'Pentsatzen du.')\n","('Crepúsculo.', 'Twilight.', 'Ilunabarra.')\n","('¿Qué?', 'What?', 'Zer?')\n","('No.', 'No.', 'Ez.')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('Por Stephen:', 'By Stephen:', 'Stephenek:')\n","('Liliata rutilantium.', 'Liliata rutilantium.', 'Liliata rutilantium.')\n","('¿Como por ejemplo?', 'As?', 'Adibidez?')\n","('¿Cómo?', 'How?', 'Nola?')\n","('¿Cómo?', 'How?', 'Nola?')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Qué es eso?', \"'What's that?'\", '-Zer da hori?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Qué es eso?', \"'What's that?'\", '-Zer da hori?')\n","('-¡Oooh!', \"'Oo!'\", '-Oooo!')\n","('-¡Oooh!', \"'Oo!'\", '-Oooo!')\n","('-¡Oooh!', \"'Oo!'\", '-Oooo!')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¡No!', \"'No!'\", '-Ez!')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¡No!', \"'No!'\", '-Ez!')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('No hubo respuesta.', 'No answer.', 'Erantzunik ez.')\n","('-¡No!', \"'No!'\", '-Ez!')\n","('-¿Por qué no?', \"'Why not?'\", '-Zergatik ez?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Lo que espera mi madre.', \"'What my mother hopes.\", '-Nire amak espero duena.')\n","('-¿Qué ha sido eso?', \"'What was that?'\", '-Zer zen hori?')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¡Oh!', '\"Oh!', '\"O!')\n","('-¡Oh!', '\"Oh!', '\"O!')\n","('-¡Oh, sí!', '\"Oh!', '\"O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('-¡Oh, sí!', '\"Oh!', '\"O!')\n","('Adiós.', 'Good-bye.', 'Agur.')\n","('¡Oh!', 'Oh!', 'O!')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('-¡Lavativa y aspirina!', \"'Enema and aspirin!\", '-Aiuta eta aspirina!')\n","('-¡Aquí!', \"'Present!'\", '-Hemen!')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('-No lo sé.', \"'I don't know.'\", '-Ez dakit.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('V', 'V', 'V')\n","('VI', 'VI', 'VI')\n","('¿Lo entiende?', 'Do you understand?', 'Ulertzen?')\n","('Eso es.', 'Yes.', 'Bai.')\n","('Jungwirt\".', 'Jungwirt.\"', 'Jungwirt\".')\n","('¿Lo entiende?', \"Do you understand?'\", 'Ulertzen?')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('Dice:', 'He says:', 'Esaten du:')\n","('El tren se detuvo.', 'The train stopped.', 'Trena gelditu egin zen.')\n","('¿Y por qué?', 'And why?', 'Eta zergatik?')\n","('Sonó el teléfono.', 'The telephone rang.', 'Telefonoak jo zuen.')\n","('-De Praga.', \"'From Prague.'\", '-Pragakoa.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('...', '...', '...')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('Ahora.', 'Now.', 'Orain.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-dije.', 'I said.', '-esan nion.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-dije.', 'I said.', '-esan nion.')\n","('...', '...', '...')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-dije.', 'I said.', '-esan nion.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-Pero...', '\"But-\"', '-Baina...')\n","('...', '...', '...')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('...', '...', '...')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('¿Por qué?', '\"Why?\"', 'Zergatik?')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('Me llamó.', 'She called to me.', 'Deitu egin zidan.')\n","('La auténtica historia de la lucha de un hombre contra fuerzas superiores y mujeres de baja estofa...', \"THE TRUE STORY OF A MAN'S FIGHT AGAINST HIGH ODDS AND LOW WOMEN...\", 'GIZON BATEN BORROKA, GOI-INDARREN ETA EMATXARREN KONTRA...')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('Abrí la puerta.', 'I opened the door.', 'Atea ireki nuen.')\n","('-Muy bien-dije-.', '\"All right,\" I said.', '-Ederki-esan nion-.')\n","('-dije-.', 'I said.', '-esan nion-.')\n","('-Ya lo sé.', '\"I know.', '-Badakit.')\n","('Mona.', 'Mona.', 'Mona.')\n","('...', '...', '...')\n","('6.', '6.', '6.')\n","('18.', '18.', '18.')\n","('26.', '26.', '26.')\n","('3.', '3.', '3.')\n","('6.', '6.', '6.')\n","('3.', '3.', '3.')\n","('17.', '17.', '17.')\n","('18.', '18.', '18.')\n","('2.', '2.', '2.')\n","('4.', '4.', '4.')\n","('18.', '18.', '18.')\n","('25.', '25.', '25.')\n","('7.', '7.', '7.')\n","('12.', '12.', '12.')\n","('11.', '11.', '11.')\n","('2.', '2.', '2.')\n","('28.', '28.', '28.')\n","('3.', '3.', '3.')\n","('5.', '5.', '5.')\n","('11.', '11.', '11.')\n","('2.', '2.', '2.')\n","('5.', '5.', '5.')\n","('7.', '7.', '7.')\n","('2.', '2.', '2.')\n","('10.', '10.', '10.')\n","('14.', '14.', '14.')\n","('25.', '25.', '25.')\n","('3.', '3.', '3.')\n","('13.', '13.', '13.')\n","('20.', '20.', '20.')\n","('22.', '22.', '22.')\n","('28.', '28.', '28.')\n","('13.', '13.', '13.')\n","('17.', '17.', '17.')\n","('25.', '25.', '25.')\n","('3.', '3.', '3.')\n","('10.', '10.', '10.')\n","('8.', '8.', '8.')\n","('13.', '13.', '13.')\n","('6.', '6.', '6.')\n","('4.', '4.', '4.')\n","('14.', '14.', '14.')\n","('18.', '18.', '18.')\n","('20.', '20.', '20.')\n","('2.', '2.', '2.')\n","('4.', '4.', '4.')\n","('22.', '22.', '22.')\n","('28.', '28.', '28.')\n","('2.', '2.', '2.')\n","('2.', '2.', '2.')\n","('2.', '2.', '2.')\n","('14.', '14.', '14.')\n","('7.', '7.', '7.')\n","('10.', '10.', '10.')\n","('17.', '17.', '17.')\n","('7.', '7.', '7.')\n","('8.', '8.', '8.')\n","('15.', '15.', '15.')\n","('2.', '2.', '2.')\n","('10.', '10.', '10.')\n","('9.', '9.', '9.')\n","('12.', '12.', '12.')\n","('6.', '6.', '6.')\n","('7.', '7.', '7.')\n","('3.', '3.', '3.')\n","('10.', '10.', '10.')\n","('6.', '6.', '6.')\n","('7.', '7.', '7.')\n","('8.', '8.', '8.')\n","('12.', '12.', '12.')\n","('10.', '10.', '10.')\n","('6.', '6.', '6.')\n","('13.', '13.', '13.')\n","('14.', '14.', '14.')\n","('4.', '4.', '4.')\n","('8.', '8.', '8.')\n","('2.', '2.', '2.')\n","('6.', '6.', '6.')\n","('10.', '10.', '10.')\n","('3.', '3.', '3.')\n","('3.', '3.', '3.')\n","('11.', '11.', '11.')\n","('12.', '12.', '12.')\n","('17.', '17.', '17.')\n","('18.', '18.', '18.')\n","('20.', '20.', '20.')\n","('37.', '37.', '37.')\n","('53.', '53.', '53.')\n","('8.', '8.', '8.')\n","('-¿Quién es?', '\"Who is he?\"', '-Nor da?')\n","('-¿Quién es?', '\"Who is he?\"', '-Nor da?')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-les preguntó-.', 'he asked.', '-galdetu zien-.')\n","('-preguntó Balin.', 'Balin asked.', '-galdetu zuen Balinek.')\n","('No.', 'No.', 'Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Cómo te llamas?', '\"What is your name?\"', '-Nola duzu izena?')\n","('-¿Cómo te llamas?', '\"What is your name?\"', '-Nola duzu izena?')\n","('Lo ignoro.', \"I don't know.\", 'Ez dakit.')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('-¿Qué es esto?', '\"What is this?\"', '-Zer da hau?')\n","('-preguntó-.', 'he asked.', '-galdetu zuen-.')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('-Si, señora.', '\"Yes, madame.\"', '-Bai, andrea.')\n","('-Si, señora.', '\"Yes, madame.\"', '-Bai, andrea.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('-preguntó-.', 'he asked.', '-galdetu zuen-.')\n","('-¿Y?', '\"And?\"', '-Eta?')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¿Y bien?', '\"Well?\"', '-Eta?')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-le preguntó.', 'he asked.', '-galdetu zion.')\n","('-Gracias, señor.', '\"Thank you, sir.', '-Eskerrik asko, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-Si, mi señora.', '\"Yes, my lady.\"', '-Bai, andrea.')\n","('-Si.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-dijo.', 'he said.', '-esan zuen.')\n","('-¿Yo?', '\"I?', '-Nik?')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('-dijo.', 'he said.', '-esan zuen.')\n","('-gritó-.', 'he cried.', '-oihu egin zuen-.')\n","('-¿Adónde vamos?', '\"Where are we going?\"', '-Nora goaz?')\n","('-inquirió.', 'he asked.', '-galdetu zuen.')\n","('¡No!', 'No!', 'Ez!')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('-¿Adonde vas?', '\"Where goest thou?\"', '-Nora zoaz?')\n","('-¿Cuánto?', '\"How much?\"', '-Zenbat?')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('-No.', '\"No.', '-Ez.')\n","('-preguntó Danny.', 'Danny asked.', '-galdetu zuen Dannyk.')\n","('-exclamó-.', 'she cried.', '-oihu egin zuen-.')\n","('-No.', '\"No.', '-Ez.')\n","('No.', 'No.', 'Ez.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No-contestó-.', '\"No,\" he said.', '-Ez-esan zuen-.')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('Capítulo primero', 'CHAPTER I.', '1. KAPITULUA')\n","('Capítulo II', 'CHAPTER II.', '2. KAPITULUA')\n","('Capítulo III', 'CHAPTER III.', '3. KAPITULUA')\n","('Capítulo IV', 'CHAPTER IV.', '4. KAPITULUA')\n","('Capítulo VII', 'CHAPTER VII.', '7. KAPITULUA')\n","('Capítulo VIII', 'CHAPTER VIII.', '8. KAPITULUA')\n","('Capítulo II', 'CHAPTER II.', '2. KAPITULUA')\n","('Capítulo III', 'CHAPTER III.', '3. KAPITULUA')\n","('Capítulo V', 'CHAPTER V.', '5. KAPITULUA')\n","('Capítulo primero', 'CHAPTER I.', '1. KAPITULUA')\n","('Capítulo II', 'CHAPTER II.', '2. KAPITULUA')\n","('Capítulo III', 'CHAPTER III.', '3. KAPITULUA')\n","('Capítulo IV', 'CHAPTER IV.', '4. KAPITULUA')\n","('Capítulo V', 'CHAPTER V.', '5. KAPITULUA')\n","('Capítulo VII', 'CHAPTER VII.', '7. KAPITULUA')\n","('Capítulo IX', 'CHAPTER IX.', '9. KAPITULUA')\n","('Capítulo XI', 'CHAPTER XI.', '11. KAPITULUA')\n","('I', 'I', 'I')\n","('¡Ah!', 'Ah!', 'A!')\n","('Good-bye.', 'Good-bye.', 'Good-bye.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('No.', 'No.', 'Ez.')\n","('II', 'II', 'II')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('-exclamó-.', 'he cried.', '-oihu egin zuen-.')\n","('¿Cómo?', 'What?', 'Zer?')\n","('¿Qué?', 'What?', 'Zer?')\n","('No sé.', \"I don't know.\", 'Ez dakit.')\n","('¡Qué voz! ¡Qué voz!', 'A voice! a voice!', 'Hura zen ahotsa, hura!')\n","('El destino.', 'Destiny.', 'Patua.')\n","('¡No!', 'No!', 'Ez!')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('¿Eh?', 'Eh?', 'E?')\n","('¡El horror!\"', \"The horror!'\", 'Horrorea!\".')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No.', 'No.', 'Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Pero cómo?', 'But how?', 'Baina nola?')\n","('De Kolyvan, gobierno de Omsk, Siberia, 6 de agosto.', '\"From Kolyvan, Government of Omsk, Siberia, 6th August.', 'Kolivan, Omsk probintzia, Siberia, abuztuak 6.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí...', '\"Yes...', '-Bai...')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No...', '\"No...', '-Ez...')\n","('-Todavía no.', '\"Not yet.\"', '-Oraindik ez.')\n","('-preguntó Miguel Strogoff.', 'asked Michael.', '-galdetu zion Mikel Strogoffek.')\n","('-preguntó Miguel Strogoff.', 'asked Michael.', '-galdetu zion Mikel Strogoffek.')\n","('¡No!', 'No!', 'Ez!')\n","('Entró un hombre.', 'A man entered.', 'Gizon bat sartu zen.')\n","('-Miguel Strogoff.', '\"Michael Strogoff.\"', '-Mikel Strogoff.')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duk?')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('¿No?', 'No?', 'Ez?')\n","('Pausa.', 'A pause.', 'Isilunea.')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('V', 'V', 'V')\n","('Sí.', 'Yes.', 'Bai.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('VI', 'VI', 'VI')\n","('VII', 'VII', 'VII')\n","('VIII', 'VIII', 'VIII')\n","('IX', 'IX', 'IX')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('-No pasa nada Vasia.', '\"Never mind, Vasya.', '-Lasai, Vasia.')\n","('-¿Para qué?', '\"What for?\"', '-Zertarako?')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Quién es usted?', '\"Who are you?\"', '-Nor zara?')\n","('Abajo, abajo, abajo.', 'Down, down, down.', 'Behera, behera, behera.')\n","('Veamos:', 'Let me see:', 'Ikus dezagun:')\n","('-preguntó la Oruga.', 'said the Caterpillar.', '-esan zuen Beldarrak.')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-dijo Alicia.', 'said Alice.', '-esan zuen Alicek.')\n","('-dijo Alicia.', 'said Alice.', '-esan zuen Alicek.')\n","('¡Ven!', \"Come on!'\", 'Goazen!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('¡Que sí, que no, que sí, que no, la danza sí!', \"Will you, won't you, will you, won't you, will you join the dance?\", 'Nahi duzu, ez duzu nahi, nahi duzu, ez duzu nahi, nahi duzu dantzan parte hartu?')\n","('-dijo Alicia.', 'said Alice.', '-esan zuen Alicek.')\n","('¡Sooopa qué beeella! ¡Sooopa qué hermooosa!', 'Beau-ootiful Soo-oop!', 'Zoooopa goooozoooa!')\n","('-dijo la Liebre de Marzo.', 'said the March Hare.', '-esan zuen Martxoko Erbiak.')\n","('12.', 'CHAPTER XII.', 'XII.')\n","('-dijo Alicia.', 'said Alice.', '-esan zuen Alicek.')\n","('2.', 'CHAPTER II.', 'II.')\n","('-exclamó-.', 'she cried.', '-oihu egin zuen-.')\n","('3.', 'CHAPTER III.', 'III.')\n","('7.', 'CHAPTER VII.', 'VII.')\n","('9.', 'CHAPTER IX.', 'IX.')\n","('Cosa fácil es:', 'That is easy:', 'Hori erreza da:')\n","('12.', 'CHAPTER XII.', 'XII.')\n","('\"¿Y qué más?\"', '\"So what?\"', '-Eta?')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Nada.', 'Nothing.', 'Ezer ez.')\n","('Nadie.', 'Nobody.', 'Inork ez.')\n","('¡Ah, no!', 'Certainly not!', 'Bai zera!')\n","('Nada.', 'Nothing.', 'Deus ez.')\n","('¿A quién?', 'To whom?', 'Nori?')\n","('No.', 'No.', 'Ez.')\n","('No sabía qué hacer.', \"I didn't know what to do.\", 'Ez nekien zer egin.')\n","('Siempre lo mismo.', 'Always the same.', 'Beti gauza bera.')\n","('ou...', 'ou...', 'ou...')\n","('¡Ah!', 'Ah!', 'A!')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('I', 'I', 'I')\n","('¿Pero cómo?', 'But how?', 'Baina nola?')\n","('No sé.', 'I cannot tell.', 'Ez dakit.')\n","('II', 'II', 'II')\n","('-No.', '\"No.', '-Ez.')\n","('-¡Ah!', '\"Oh!', '\"O!')\n","('Quince años y medio.', 'Fifteen and a half.', \"Hamabost urte t'erdi.\")\n","('Marie-Claude Carpenter.', 'Marie-Claude Carpenter.', 'Marie Claude Carpenter.')\n","('Betty Fernández.', 'Betty Fernandez.', 'Betty Fernández.')\n","('Quince años y medio.', 'Fifteen and a half.', \"Hamabost urte t'erdi.\")\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Antínoo había muerto.', 'Antinous was dead.', 'Antinoo hila zen.')\n","('Antínoo había muerto.', 'Antinous was dead.', 'Antinoo hila zen.')\n","('Antínoo había muerto.', 'Antinous was dead.', 'Antinoo hila zen.')\n","('Tenía razón.', 'He was right.', 'Arrazoi zuen.')\n","('La puerta se abrió.', 'The door opened.', 'Ireki zen atea.')\n","('-¡Camaradas!', '\"Comrades!\"', '-Lagunkideok!')\n","('-¡Oh, no!', '\"Oh, no!', '-O, ez!')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?', '-Zer ba?')\n","('-¡Camaradas!', '\"Comrades!', '-Lagunkideok!')\n","('I', 'CHAPTER I', 'I')\n","('-Cristo ha resucitado de entre los muertos...', '\"Christ has arisen from the dead.\"', 'Kristo hilen artetik biztu zen...')\n","('-¿Cuándo?', '\"When?', '-Noiz?')\n","('III', 'CHAPTER III', 'III')\n","('IV', 'CHAPTER IV', 'IV')\n","('VII', 'CHAPTER VII', 'VII')\n","('VIII', 'CHAPTER VIII', 'VIII')\n","('IX', 'CHAPTER IX', 'IX')\n","('-¿Qué quiere?', '\"What do you want?\"', '-Zer nahi duzu?')\n","('¿Sí?', 'Yes?', 'Bai?')\n","('X', 'CHAPTER X', 'X')\n","('XI', 'CHAPTER XI', 'XI')\n","('XII', 'CHAPTER XII', 'XII')\n","('-¡Camaradas!', '\"Comrades!', '-Lagunkideok!')\n","('XIII', 'CHAPTER XIII', 'XIII')\n","('XV', 'CHAPTER XV', 'XV')\n","('XVI', 'CHAPTER XVI', 'XVI')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('XVIII', 'CHAPTER XVIII', 'XVIII')\n","('-No.', '\"No.\"', '-Ez.')\n","('XIX', 'CHAPTER XIX', 'XIX')\n","('XX', 'CHAPTER XX', 'XX')\n","('-¿Yo?', '\"I?\"', '-Ni?')\n","('-¿Quién?', '\"Who?', '-Nork?')\n","('-Vlassov.', '\"Vlasov.\"', '-Vlasov.')\n","('XXII', 'CHAPTER XXII', 'XXII')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Sí?', '\"Yes?', '-Bai?')\n","('XXIII', 'CHAPTER XXIII', 'XXIII')\n","('XXVI', 'CHAPTER XXVI', 'XXVI')\n","('-Gracias.', '\"Thank you.\"', '-Eskerrik asko.')\n","('XXVIII', 'CHAPTER XXVIII', 'XXVIII')\n","('Por ejemplo:', 'For example:', 'Adibidez:')\n","('¿Enfermedad?', 'A disease?', 'Gaixotasuna?')\n","('¡No!', 'No!', 'Ez!')\n","('¿Para qué?', 'Wherefore?', 'Zertarako?')\n","('No.', 'No.', 'Ez.')\n","('¿Cómo?', 'How?', 'Nola?')\n","('¿Y qué?', 'And what then?', 'Eta zer?')\n","('¿Y qué?', 'And what then?', 'Eta zer?')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No;', '\"No;', '-Ez;')\n","('No.', 'No.', 'Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('Adiós.', 'Good-bye.', 'Agur.')\n","('-dijo.', 'she said.', '-esan zuen.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-¿Y qué?', '\"So what?', '-Eta zer?')\n","('13', '13', '13')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¿Sí?', '\"Yes?', '-Bai?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('-No.', '\"No.\"', '-Ez.')\n","('11', '11', '11')\n","('12', '12', '12')\n","('-le preguntó.', 'she asked.', '-galdetu zion.')\n","('No saben nada.', \"You don't know anything.\", 'Ez dakizue ezer.')\n","('¡Todavía sigo estando viva!', \"For the time being I'm still alive!\", 'Oraindik segitzen diat bizitzen!')\n","('Si ustedes supiesen.', 'If you only knew.', 'Jakingo bazenute.')\n","('No saben nada.', \"You don't know anything.\", 'Ez dakizue ezer.')\n","('No saben nada.', 'You don\\'t know anything.\"', 'Ez dakizue ezer ere.')\n","('Sí.', 'Yes.', 'Bai.')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('5', '5', '5')\n","('6', '6', '6')\n","('8', '8', '8')\n","('10', '10', '10')\n","('-No.', '\"No.', '-Ez.')\n","('11', '11', '11')\n","('12', '12', '12')\n","('13', '13', '13')\n","('14', '14', '14')\n","('1', '1', '1')\n","('2', '2', '2')\n","('3', '3', '3')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('9', '9', '9')\n","('10', '10', '10')\n","('11', '11', '11')\n","('12', '12', '12')\n","('1', '1', '1')\n","('2', '2', '2')\n","('Pero...', 'But...\"', 'Baina...')\n","('4', '4', '4')\n","('5', '5', '5')\n","('6', '6', '6')\n","('7', '7', '7')\n","('8', '8', '8')\n","('¡El pecado no existe!', 'There is no sin!\"', 'Bekaturik ez zegok!')\n","('9', '9', '9')\n","('10', '10', '10')\n","('1º.', '1.', '1.')\n","('3º.', '3.', '3.')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('3º.', '3.', '3.')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'V. Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'X. Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DEL MISMO ASUNTO', 'The same Subject continued', 'Gai beraren jarraipena')\n","('2º.', '2.', '2.')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('2º.', '2.', '2.')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('CONTINUACION DE LA MISMA MATERIA', 'The same Subject continued', 'Gai beraren jarraipena')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('De Erzurum, 20 de la luna de Gemadi, 2,1711', 'Erzeron, the 20th of the moon of the 2d Gemmadi, 1711', 'Erzeron-dik, 1711ko Gemmadi 2.aren ilargiaren 20an.')\n","('Usbek a su amigo Rustan, a Isfahán', 'Usbek to his Friend Rustan, at Ispahan', 'USBEK-ek ISPAHAN-go bere adiskide RUSTAN-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Adiós.', 'Farewel.', 'Agur.')\n","('De París, 20 de la luna de Rhegeb, 1713', 'Paris, the 20th of the moon Rhegeb, 1713', 'Parisen, 1713ko Rhegeb-en ilargiaren 20an.')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Adiós.', 'Farewel.', 'Adio.')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Adiós.', 'Farewel.', 'Adio.')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben, at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek a Iben, a Esmirna', 'Usbek to Ibben, at Smyrna', 'USBEK-ek SMYRNE-n dagoen IBBEN-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Rica a Redi, a Venecia', 'Rica to Rhedi, at Venice', 'RICA-k VENEZIAn dagoen RHEDI-ri')\n","('Usbek a Iben, a Esmirna', 'Usbek to Ibben, at Smyrna', 'USBEK-ek SMYRNE-n dagoen IBBEN-i')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('No:', 'No:', 'Ez.')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Usbek a...', 'Usbek to * * *', 'USBEK-ek ***-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek al mismo', 'Usbek to the Same', 'USBEK-ek BERAri')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('De París, 1 de la luna de Chalval, 1718', 'Paris, the 1st of the moon Chalval, 1718', 'Parisen, 1718ko Chalval-en ilargiaren 1ean.')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben, at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Usbek a Redi, a Venecia', 'Usbek to Rhedi, at Venice', 'USBEK-ek VENEZIAn dagoen RHEDI-ri')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica a...', 'Rica to * * *', 'RICA-k ***-i')\n","('Rica al mismo', 'Rica to the Same', 'RICA-k BERAri')\n","('Rica a Iben, a Esmirna', 'Rica to Ibben at Smyrna', 'RICA-k SMYRNE-n dagoen IBBEN-i')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Rica a Usbek, a...', 'Rica to Usbek, at * * *', 'RICA-k ***-n dagoen USBEK-i')\n","('Usbek a...', 'Usbek to * * *', 'USBEK-ek ***-i')\n","('De París, 4 de la luna de Chaban, 1719', 'Paris, the 4th of the moon Chahban, 1719', 'Parisen, 1719ko Chahban-en ilargiaren 4ean.')\n","('Usbek a Nesir, a Isfahán', 'Usbek to Nessir, at Ispahan', 'USBEK-ek ISPAHAN-en dagoen NESSIR-i')\n","('Adiós.', 'Farewel.', 'Adio.')\n","('Del serrallo de Isfahán, 2 de la luna de Maharran, 1720', 'From the seraglio at Ispahan, the 2d of the moon Maharran, 1720', 'Ispahan-go anderenetik, 1720ko Maharram-en ilargiaren 2an.')\n","('Del serrallo de Isfahán, 8 de la luna de Rebiab, 1,1720', 'From the seraglio at Ispahan, the 8th of the moon of the first Rebiab, 1720', 'Ispahan-go anderenetik, 1720ko Rebiab 1.aren ilargiaren 8an.')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('¡Simples palabras!', 'Mere words!', 'Hitz hutsak!')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik, bada?')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('No;', 'No;', 'Ez;')\n","('Lord Henry se encogió de hombros.', 'Lord Henry shrugged his shoulders.', 'Lord Henryk soina goratu zuen.')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('Lord Henry se echó a reír.', 'Lord Henry laughed.', 'Lord Henryk barre egin zuen.')\n","('Lord Henry se encogió de hombros.', 'Lord Henry shrugged his shoulders.', 'Lord Henryk soina goratu zuen.')\n","('No;', 'No;', 'Ez.')\n","('¿Qué significaba aquello?', 'What did it mean?', 'Zer esan nahi zuen horrek?')\n","('No;', 'No;', 'Ez;')\n","('No;', 'No;', 'Ez;')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No;', 'No;', 'Ez;')\n","('No;', 'No;', 'Ez;')\n","('Dorian negó con un movimiento de cabeza.', 'Dorian shook his head.', 'Dorianek burua mugitu zuen.')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¡Pobre Basil!', 'Poor Basil!', 'Basil gizajoa!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('¡No!', 'No!', 'Ez!')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('Lord Henry se encogió de hombros.', 'Lord Henry shrugged his shoulders.', 'Lord Henryk soina goratu zuen.')\n","('Dorian se encogió de hombros.', 'Dorian shrugged his shoulders.', 'Dorianek soina goratu zuen.')\n","('¿Dinero?', 'Money?', 'Dirua?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-¿Quién?', '\"Who?\"', '-Nor?')\n","('¡Dios del cielo!', 'Good heavens!', 'Jainko maitea!')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('No.', 'No.', 'Ez.')\n","('Lord Henry se echó a reír.', 'Lord Henry laughed.', 'Lord Henryk barre egin zuen.')\n","('Eso es todo.', 'That is all.', 'Hori da dena.')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('Eso es todo.', 'That is all.', 'Hori da dena.')\n","('Se echó a reír.', 'He laughed.', 'Barre egin zuen.')\n","('No.', 'No.', 'Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('2', '2', '2')\n","('Gracias.', 'Thank you.', 'Eskerrik asko.')\n","('-No, señor.', \"'No, sir.\", '-Ez, jauna.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('4', '4', '4')\n","('5', '5', '5')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('6', '6', '6')\n","('7', '7', '7')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('8', '8', '8')\n","('9', '9', '9')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('10', '10', '10')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zer dela eta?')\n","('11', '11', '11')\n","('- preguntó.', 'he asked.', '-galdetu zion.')\n","('-¿Qué?', \"'What?'\", '-Zer?')\n","('-No.', \"'No.'\", '-Ez.')\n","('Tom asintió con la cabeza.', 'Tom nodded.', 'Tomek baiezkoa egin zuen.')\n","('Estaba solo.', 'He was alone.', 'Bakarrik zegoen.')\n","('12', '12', '12')\n","('-gritó Tom.', 'Tom shouted.', '-egin zuen garrasi Tomek.')\n","('13', '13', '13')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('14', '14', '14')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('15', '15', '15')\n","('-...', \"'...\", '-...')\n","('16', '16', '16')\n","('17', '17', '17')\n","('-preguntó Tom.', 'Tom asked.', '-galdetu zuen Tomek.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Dónde estás?', \"Where are you?'\", 'Non zaude?')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('-Pronto?', \"'Pronto?'\", '-Pronto?')\n","('¿Dónde estás?', \"Where are you?'\", 'Non zaude?')\n","('-¿Dónde?', \"'Where?'\", '-Non?')\n","('19', '19', '19')\n","('20', '20', '20')\n","('Atentamente,', 'Sincerely,', 'Adeitasunez,')\n","('Atentamente,', 'Sincerely,', 'Adeitasunez,')\n","('21', '21', '21')\n","('22', '22', '22')\n","('-preguntó.', 'he asked.', '-galdetu zuen.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-En efecto.', \"'Yes.'\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('Gracias.', 'Thank you.', 'Eskerrik asko.')\n","('23', '23', '23')\n","('Marge', 'Marge', 'Marge')\n","('-No.', \"'No.'\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¡Marge!', \"'Marge!\", '-Marge!')\n","('-No.', \"'No.\", '-Ez.')\n","('-exclamó Marge-.', 'Marge said.', '-esan zuen Margek-.')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('24', '24', '24')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('25', '25', '25')\n","('-No.', \"'No.'\", '-Ez.')\n","('-preguntó Tom-.', 'Tom asked.', '-galdetu zion Tomek-.')\n","('Abrió los ojos.', 'He opened his eyes.', 'Begiak zabaldu zituen.')\n","('-¿Cuándo?', \"'When?'\", '-Noiz?')\n","('- preguntó.', 'he asked.', '-galdetu zion.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-¿Cuándo?', \"'When?'\", '-Noiz?')\n","('-preguntó McCarron.', 'McCarron asked.', '-galdetu zuen McCarronek.')\n","('-No.', \"'No.\", '-Ez.')\n","('Venecia', 'Venice', 'Venezia')\n","('-¿Qué?', \"'What?'\", '-Zer?')\n","('1', '1', '1')\n","('-¡No!', \"'No!\", '-Ez!')\n","('2', '2', '2')\n","('-¡No!', \"'No!\", '-Ez!')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Un hombre.', 'A man.', 'Gizon batek.')\n","('3', '3', '3')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('4', '4', '4')\n","('-No.', \"'No.\", '-Ez.')\n","('-...', \"'...\", '-...')\n","('-No.', \"'No.\", '-Ez.')\n","('5', '5', '5')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('6', '6', '6')\n","('No.', 'No.', 'Ez.')\n","('7', '7', '7')\n","('-No.', \"'No.\", '-Ez.')\n","('-Gracias.', \"'Thank you.'\", '-Eskerrik asko.')\n","('-...', \"'...\", '-...')\n","('-...', \"'...\", '-...')\n","('Pero no.', 'But no.', 'Baina ez.')\n","('Se humedeció los labios.', 'He wet his lips.', 'Ezpainak busti zituen.')\n","('-¿Cuándo?', \"'When?'\", '-Noiz?')\n","('-En el plazo de una semana.', \"'Within a week.\", '-Astebete barru.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('8', '8', '8')\n","('-¡Hola, Jonathan!', \"'Hello, Jonathan!\", '-Kaixo, Jonathan!')\n","('-...', \"'...\", '-...')\n","('Eso es todo.', \"That's all.'\", 'Hori da dena.')\n","('No.', \"No.'\", 'Ez.')\n","('Adiós.', \"Bye-bye.'\", 'Agur.')\n","('9', '9', '9')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('10', '10', '10')\n","('-No.', \"'No.\", '-Ez.')\n","('11', '11', '11')\n","('12', '12', '12')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('13', '13', '13')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","('-No.', \"'No.\", '-Ez.')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('14', '14', '14')\n","('-dijo Simone-.', 'Simone said.', '-esan zuen Simonek-.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('¿Por qué?', \"Why?'\", 'Zer ba?')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Lo sé.', 'I know that.', 'Badakit.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('Por eso.', \"That's why.\", 'Horrexegatik.')\n","('15', '15', '15')\n","('Tom asintió con la cabeza.', 'Tom nodded.', 'Tomek baiezkoa egin zuen buruaz.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('16', '16', '16')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('Jonathan meneó la cabeza.', 'Jonathan shook his head.', 'Jonathanek buruari eragin zion.')\n","('-preguntó Tom.', 'Tom asked.', '-galdetu zuen Tomek.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('17', '17', '17')\n","('¿Dónde estás?', 'Where are you?', 'Non zaude?')\n","('-¡Hola, Tome!', \"'Hello, Tome!\", '-Kaixo, Tom!')\n","('Sí.', 'Yes.', 'Bai.')\n","('18', '18', '18')\n","('-No.', \"'No.\", '-Ez.')\n","('Jonathan guardó silencio.', 'Jonathan was silent.', 'Jonathan isilik zegoen.')\n","('19', '19', '19')\n","('Jonathan sonrió.', 'Jonathan smiled.', 'Jonathanek irribarre egin zuen.')\n","('Sonó el timbre.', 'The doorbell rang.', 'Txirrinak jo zuen.')\n","('-Lippo.', \"'Lippo.\", '-Lippo.')\n","('-Pronto.', \"'Pronto.\", '-Pronto.')\n","('-Nada.', \"'Nothing.\", '-Ezer ez.')\n","('-preguntó Tom-.', 'Tom asked.', '-galdetu zion Tomek-.')\n","('Tom meneó la cabeza.', 'Tom shook his head.', 'Tomek buruari eragin zion.')\n","('20', '20', '20')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('21', '21', '21')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¿Tom?', \"'Tom?'\", '-Tom?')\n","('-¿Sí?', \"'Yes?'\", '-Bai?')\n","('-preguntó Jonathan.', 'Jonathan asked.', '-galdetu zion Jonathanek.')\n","('Tom asintió con la cabeza.', 'Tom nodded.', 'Tomek baiezkoa egin zuen buruaz.')\n","('-No lo sé.', \"'I don't know.\", '-Ez dakit.')\n","('¿No está de acuerdo?', \"Don't you agree?\", 'Ez al zaude ados?')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('22', '22', '22')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('-¿Diga?', \"'Hello?'\", '-Bai?')\n","('Tom sonrió.', 'Tom smiled.', 'Tomek irribarre egin zuen.')\n","('-No.', \"'No.\", '-Ez.')\n","('23', '23', '23')\n","('-No.', \"'No.'\", '-Ez.')\n","('-preguntó Simone.', 'Simone asked.', '-galdetu zion Simonek.')\n","('-preguntó Georges.', 'Georges asked.', '-galdetu zuen Georgesek.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-preguntó Tom.', 'Tom asked.', '-galdetu zion Tomek.')\n","('24', '24', '24')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Aceptó.', 'He assented.', 'Onartu egin zuen.')\n","('Estuvo de acuerdo.', 'He agreed.', 'Ados zegoen.')\n","('Eut. ¿Cómo no? Sóc.', 'EUTHYPHRO: Certainly.', '-Nola ez, bada?')\n","('Eut. Sí.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('Sí. Sóc.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('Eut. Sí.', 'EUTHYPHRO: Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-De ningún modo.', 'Certainly not.', '-Inola ere ez.')\n","('-Sí.', 'True.', '-Bai.')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-¿Cómo dices?', 'What do you mean?', '-Nola diozu?')\n","('-Sí.', 'Yes.', '-Bai.')\n","('-Sí.', 'True.', '-Bai.')\n","('FED. Así es.', 'PHAEDRUS: That is true.', '-Horrela da.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: True.', 'Go. Bai.')\n","('GOR. Sí.', 'GORGIAS: Yes.', 'Go. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('SÓC.', 'POLUS: Certainly.', 'So.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: True.', 'Po. Bai.')\n","('POL. Sí.', 'POLUS: Yes.', 'Po. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sin duda.', 'CALLICLES: Certainly.', 'Ka. Erabat.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Sí.', 'CALLICLES: Yes.', 'Ka. Bai.')\n","('CAL. Ciertamente.', 'CALLICLES: Quite true.', 'Ka. Erabat.')\n","('Sí.', 'HERMOGENES: True.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí. SÓC.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Yes.', '-Bai, noski.')\n","('HERM. Dices verdad.', 'HERMOGENES: That is true.', '-Egia diozu.')\n","('Sólo tienes que hablar.', 'HERMOGENES: Let me hear.', '-Esan besterik ez duzu.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('HERM. Desde luego.', 'HERMOGENES: Very true.', '-Erabat, bai.')\n","('Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('HERM. Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('Sí.', 'HERMOGENES: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí. SÓC.', 'CRATYLUS: Yes.', '-Bai.')\n","('CRÁT. Sí.', 'CRATYLUS: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SÓC.', 'BOY: Certainly.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('SERVIDOR. Sí.', 'BOY: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí. SÓC.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: True.', '-Bai.')\n","('SÓC. ¿Cómo dices?', 'SOCRATES: What do you mean?', '-Nola diozu?')\n","('MEN. Así es.', 'MENO: True.', '-Hori da.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('MEN. Sí.', 'MENO: Yes.', '-Bai.')\n","('Sí. SÓC.', 'MENO: Yes.', '-Bai.')\n","('MEN. Por supuesto.', 'MENO: Certainly.', '-Erabat, bai.')\n","('¡Bien!', 'Ah!', 'Ongi da!')\n","('¡Ah!', 'Ah!', 'A!')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('-¡Ah!', '\"Ah!\"', '-A!')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-Lo siento.', '\"I\\'m sorry.', '-Sentitzen dut.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No;', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('No me moví.', \"I didn't move.\", 'Ez nintzen mugitu.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('-No.', '\"No.\"', '-Ez.')\n","('Sus ojos se agrandaron.', 'Her eyes rounded.', 'Begiak handi-handi jarri zitzaizkion.')\n","('Eso es todo.', 'That\\'s all.\"', 'Hori duk dena.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('Brody se encogió de hombros.', 'Brody shrugged.', 'Brodyk sorbaldak uzkurtu zituen.')\n","('-¡Váyase al diablo!', '\"Go-- yourself.\"', '-Hoa pikutara!')\n","('-¡Váyase al diablo!', '\"Go-- yourself.\"', '-Hoa pikutara!')\n","('-¿Y bien?', '\"Well?\"', '-Eta?')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('Sí, señor.', 'Yes, sir.', 'Bai, jauna.')\n","('-Desde luego.', '\"Sure.\"', '-Noski.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('-Muy bien, señor.', '\"Very good, sir.', '-Oso ondo, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No;', '\"No.', '-Ez.')\n","('-Claro.', '\"Sure.', '-Jakina.')\n","('Sonrió.', 'She smiled.', 'Irribarre egin zuen.')\n","('-Es usted encantador.', '\"You\\'re cute.\"', '-Ederra zara.')\n","('-le pregunté.', 'I asked her.', '-galdetu nion.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-¿Dónde está Agnes?', '\"Where\\'s Agnes?\"', '-Non dago Agnes?')\n","('No me moví.', \"I didn't move.\", 'Ez nintzen mugitu.')\n","('-¿Sí?', '\"Yeah?\"', '-Bai?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-¿Qué desea?', '\"What you want?\"', '-Zer nahi duzu?')\n","('-¿Qué hora es?', '\"What time is it?\"', '-Zer ordu da?')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('Sonrió.', 'He smiled.', 'Irribarre egin zuen.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-Lo siento.', '\"I\\'m sorry.', '-Sentitzen dut.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('Asentí.', 'I nodded.', 'Baietz egin nion buruaz.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-No me entiendes.', \"'You don't get me.\", '\"Ez duzu ulertzen.')\n","('Me reí.', 'I laughed.', 'Barre egin nuen.')\n","('-No.', \"'No.\", '\"Ez.')\n","('-No.', \"'No.\", '\"Ez.')\n","('No lo sé.', \"I don't know.\", 'Ez dakit.')\n","('Sonreí.', 'I smiled.', 'Irribarre egin nuen.')\n","('-¿Por qué no?', \"'Why not?\", '\"Zergatik ez?')\n","('-No.', \"'No.\", '\"Ez.')\n","('-Sí.', \"'Yeah.\", '\"Bai.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('Se lo dije.', 'I told him.', 'Esan nion.')\n","('Gracias.', 'Thanks.\"', 'Eskerrik asko.')\n","('¿Quién sabe?', 'Who knows?', 'Nork daki?')\n","('Sacudió la cabeza.', 'He shook his head.', 'Buruari eragin zion.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-le pregunté.', 'I asked him.', '-galdetu nion.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('-pregunté-.', 'I asked.', '-galdetu nuen-.')\n","('No le contesté.', \"I didn't answer him.\", 'Ez nion erantzun.')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('Nadie se movió.', 'Nobody moved.', 'Inor ez zen mugitu.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¿Sí?', '\"Yeah?', '-Bai?')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('Me agradeció y colgó.', 'He thanked me and hung up.', 'Eskerrak eman eta moztu zuen.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-le pregunté-.', 'I asked her.', '-galdetu nion-.')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('-le pregunté-.', 'I asked him.', '-galdetu nion-.')\n","('Lo miré fijamente.', 'I stared at him.', 'Begietara begiratu nion.')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('Tres intentos, tres fracasos.', 'Three shots, three misses.', 'Hiru tiro, hiru kale.')\n","('-Sí.', '\"Yeah.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Sí?', '\"Yes?\"', '-Bai?')\n","('-¿Por qué?', '\"Why?\"', '-Zer ba?')\n","('-Tal vez.', '\"Maybe.', '-Agian.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('Está trabajando.', 'He\\'s working.\"', 'Lanean ari da.')\n","('Ella sonrió.', 'She smiled.', 'Irribarre egin zuen.')\n","('-¿Cómo se llama?', '\"What\\'s your name?\"', '-Nola duzu izena?')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('¿Qué hora es?', 'What time is it?\"', 'Zer ordu da?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Si.', '\"Yes.\"', '-Bai.')\n","('No.', 'No.', 'Ez.')\n","('¿No?', 'No?', 'Ez?')\n","('No.', 'No.', 'Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Gracias.', '\"Thanks.\"', '-Eskerrik asko.')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('Nadie dijo nada.', 'Nobody said anything.', 'Inork ez zuen ezer esan.')\n","('-¿Yo?', '\"Me?', '-Ni?')\n","('-No.', '\"Nope.\"', '-Ez.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Lo ignoro.', '\"I don\\'t know.', '-Ez dakit.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('Sacudió la cabeza.', 'He shook his head.', 'Buruari eragin zion.')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('Error.', 'Mistake.', 'Gaizki egina.')\n","('La puerta se cerró.', 'The door closed.', 'Atea itxi zen.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('La puerta se cerró.', 'The door closed.', 'Atea itxi zen.')\n","('-No sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Tal vez.', 'Maybe.', 'Agian.')\n","('-Comprendo.', '\"I see.', '-Ulertzen dut.')\n","('Suicidio.', 'Suicide.', 'Suizidioa.')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('No.', 'No.', 'Ez.')\n","('-¿Y con eso?', '\"So?\"', '-Eta?')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-¿No?', '\"No?', '-Ez?')\n","('-Sí.', '\"Yeah.', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¡Oh!', '\"Oh.\"', '-Ah!')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('Silencio.', 'Silence.', 'Isiltasuna.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('Yo no contesté.', \"I didn't answer him.\", 'Ez nion erantzun.')\n","('¿Por qué?', 'Why?\"', 'Zer ba?')\n","('-¿Yo?', '\"Me?', '-Nik?')\n","('Se lo dije.', 'I told him.', 'Esan nion.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Muy bien.', '\"Okay.', '-Ederki.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-No.', '\"No.', '-Ez.')\n","('-Nada.', '\"Nothing.', '-Ezer ez.')\n","('-¿Yo?', '\"Me?', '-Nik?')\n","('Nada más.', 'Nothing else.', 'Besterik ez.')\n","('¿Para qué?', 'What for?', 'Zertarako?')\n","('¿Dónde?', 'Where?\"', 'Non?')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-No lo creo.', '\"I don\\'t think so.', '-Ez dut uste.')\n","('-¿Por qué?', '\"Why?\"', '-Zertarako?')\n","('-Gracias.', '\"Thank you.\"', '-Eskerrik asko.')\n","('Después dijo:', 'Then he said:', 'Gero esan zuen:')\n","('-No.', '\"No.', '-Ez.')\n","('Me puse de pie.', 'I stood up.', 'Zutitu nintzen.')\n","('-Ya sé.', '\"I know.', '-Badakit.')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez dakit.')\n","('-Por supuesto.', '\"Of course.', '-Noski.')\n","('¿Para qué?', 'What for?', 'Zertarako?')\n","('Era cierto.', 'It was true.', 'Egia zen.')\n","('Era cierto.', 'It was true.', 'Egia zen.')\n","('-Lo sé.', '\"I know.', '\"Badakit.')\n","('-Sí.', '\"Yes.', '\"Bai.')\n","('-No.', '\"No.', '\"Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '\"Ez dakit.')\n","('No.', 'No.', 'Ez.')\n","('-No.', '\"No.', '\"Ez.')\n","('-Sí.', '\"Yes.', '\"Bai.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Reiting?', \"'Reiting?'\", '-Reiting?')\n","('-¿Qué?', \"'What?'\", '-Zer?')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('Silencio.', 'Silence.', 'Isiltasuna.')\n","('-Sí.', \"'Yes.'\", '-Bai.')\n","('¿Por qué?', \"Why?'\", 'Zer dela eta?')\n","('Törless no respondió.', \"Törless didn't reply.\", 'Törlessek ez zuen erantzunik eman.')\n","('-No.', \"'No.'\", '-Ez.')\n","('-¿Por qué?', \"'Why?'\", '-Zergatik?')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-¡Alá!', \"'Allah!\", '-Alaren izenean!')\n","('-Muy bien.', \"'Very good.\", '-Oso ondo.')\n","('-No lo sé.', \"'I do not know.\", '-Ez dakit.')\n","('-¿Y...?', \"'And?'\", '-Eta?')\n","('¡Mira!', 'Look!', 'Begira!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('No.', 'No.', 'Ez.')\n","('-No lo sé.', \"'I do not know.\", '-Ez dakit.')\n","('-¡Ah!', \"'Aha!\", '-A!')\n","('No.', 'No.', 'Ez.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-Sí.', \"'Yes.\", '-Bai.')\n","('-¡Dios sabe!', \"'God knows.\", '-Jainkoak daki.')\n","('-¿Por qué?', \"'Why?\", '-Zergatik?')\n","('-Muy bien.', \"'Very good.\", '-Oso ondo.')\n","('-¡No!', \"'No!\", '-Ez!')\n","('-Muy bien.', \"'Very good.\", '-Oso ondo.')\n","('-¡Mira!', \"'Look!\", '-Ikusi!')\n","('-¡Mira!', \"'Look!\", '-Ikusi!')\n","('-¡Mira!', \"'Look!\", '-Ikusi!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('¡No!', 'No!', 'Ez!')\n","('-Eso es verdad.', \"'That is true.\", '-Hori egia da.')\n","('-Muy bien.', \"'Good.\", '-Ondo.')\n","('-¡Ah!', \"'Ah!\", '-A!')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-No.', \"'No.\", '-Ez.')\n","('-Es verdad.', \"'It is true.\", '-Egia da.')\n","('-¡Sí!', \"'Yes!\", '-Bai!')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('-No.', \"'No.\", '-Ez.')\n","('-¡Oh!', \"'Oho!\", '-Hara!')\n","('No.', 'No.', 'Ez.')\n","('-¡No!', \"'No!\", '\"Ez!')\n","('¡Justa es la Rueda!', 'Just is the Wheel!', 'Zuzena da Gurpila!')\n","('¡Justa es la Rueda!', 'Just is the Wheel!', 'Zuzena da Gurpila!')\n","('¿Y por qué?', \"And why?'\", 'Eta zergatik?')\n","('-¡No!', \"'No!\", '-Ez!')\n","('¡Mira!', \"'Look!\", 'Ikusi!')\n","('-¡Vamos!', \"'Hai!\", '-Hai!')\n","('¿Qué?', 'What?', 'Zer?')\n","('-Bien dicho.', \"'Well said.\", '-Ondo esana.')\n","('-¡Ah!', \"'Aha!\", '-Hara!')\n","('-¡óyeme!', \"'Hear me!\", '-Entzun!')\n","('¡Justa es la Rueda!', 'Just is the Wheel!', 'Zuzena da Gurpila!')\n","('Tu Cordelia.', 'Your Cordelia', 'Zure Cordelia')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('Nada.', 'Nothing.', 'Deus ez.')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('¿Cómo podría olvidarte?', 'As if I could forget you!', 'Ahaztu ahal izango bazintut bezala!')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('Mi Cordelia:', 'My Cordelia,', 'Ene Cordelia,')\n","('Tu Johannes.', 'Your Johannes', 'Zure Johannes.')\n","('III.', 'III.', 'III.')\n","('IV.', 'IV.', 'IV.')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Explicación:', 'Explanation.', 'Azalpena')\n","('Explicación:', 'Explanation.', 'Azalpena')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio I:', 'Note I.', 'I. Eskolioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('DEFINICIONES', 'DEFINITIONS', 'Definizioak')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio I:', 'Note I.', 'I. Eskolioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Que era lo primero.', 'This was our first point.', 'Hau baitzen lehen puntua.')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario III:', 'Corollary III.', 'III. Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('DEFINICIONES', 'DEFINITIONS.', 'Definizioak')\n","('II.', 'II.', 'II.')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', '-This Prop.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Escolio II:', 'Note II.', 'II. Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario I:', 'Corollary I.', 'I. Korolarioa')\n","('Corolario II:', 'Corollary II.', 'II. Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('De otra manera:', 'Another Proof.', 'Bestela')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('AXIOMAS', 'AXIOMS.', 'Axiomak')\n","('II.', 'II.', 'II.')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Corolario:', 'Corollary.', 'Korolarioa')\n","('Demostración:', 'Proof.', 'Demonstrazioa')\n","('Escolio:', 'Note.', 'Eskolioa')\n","('-¿Y?', '\"Well?\"', '-Eta?')\n","('-pregunté.', 'I asked.', '-galdetu nion.')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Por qué no?', '\"Why not?', '-Zergatik ez?')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-¿Quién es usted?', '\"Who are you?\"', '-Nor zara zu?')\n","('-Todavía no.', '\"Not yet.', '-Oraindik ez.')\n","('-¡Qué dice!', '\"What!\"', '-Zer!')\n","('24.', 'XXIV.', '24.')\n","('34.', 'XXXIV.', '34.')\n","('37.', 'XXXVII.', '37.')\n","('18.', 'XVIII.', '18.')\n","('20.', 'XX.', '20.')\n","('27.', 'XXVII.', '27.')\n","('30.', 'XXX.', '30.')\n","('34.', 'XXXIV.', '34.')\n","('47.', 'XLVII.', '47.')\n","('51.', 'LI.', '51.')\n","('10.', 'X.', '10.')\n","('34.', 'XXXIV.', '34.')\n","('47.', 'XLVII.', '47.')\n","('62.', 'LXII.', '62.')\n","('15.', 'XV.', '15.')\n","('34.', 'XXXIV.', '34.')\n","('45.', 'XLV.', '45.')\n","('46.', 'XLVI.', '46.')\n","('7.', 'VII.', '7.')\n","('25.', 'XXV.', '25.')\n","('34.', 'XXXIV.', '34.')\n","('37.', 'XXXVII.', '37.')\n","('1.', 'I.', '1.')\n","('26.', 'XXVI.', '26.')\n","('39.', 'XXXIX.', '39.')\n","('67.', 'LXVII.', '67.')\n","('68.', 'LXVIII.', '68.')\n","('14.', 'XIV.', '14.')\n","('26.', 'XXVI.', '26.')\n","('28.', 'XXVIII.', '28.')\n","('46.', 'XLVI.', '46.')\n","('58.', 'LVIII.', '58.')\n","('16.', 'XVI.', '16.')\n","('51.', 'LI.', '51.')\n","('60.', 'LX.', '60.')\n","('14.', 'XIV.', '14.')\n","('15.', 'XV.', '15.')\n","('44.', 'XLIV.', '44.')\n","('49.', 'XLIX.', '49.')\n","('55.', 'LV.', '55.')\n","('59.', 'LIX.', '59.')\n","('35.', 'XXXV.', '35.')\n","('LIBRO SEGUNDO', 'BOOK II', 'BIGARREN LIBURUA')\n","('7.', '7.', '7.')\n","('7.', '7.', '7.')\n","('1.', '1.', '1.')\n","('Mil quinientos dólares.', 'Fifteen hundred dollars.\"', 'Mila eta bostehun dolar.')\n","('No sé.', \"I don't know.\", 'Ez dakit.')\n","('Tengo frío.', \"I'm cold.\", 'Hotzak nago.')\n","('No.', 'No.', 'Ez.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('Y Nancy.', 'And Nancy.', 'Eta Nancy.')\n","('No sabía qué hacer.', \"I didn't know what to do.\", 'Ez nekien zer egin.')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('Silencio.', 'Silence.', 'Isilunea.')\n","('¿Por qué no?', 'Why not?', 'Zergatik ez?')\n","('Altura:', 'Height:', 'Altura:')\n","('Delito:', 'Crime:', 'Delitua:')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('¡Jesús!', 'Jesus!', 'Jesus!')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No lo sé.', '\"I don\\'t know.', '-Ez dakit.')\n","('Ya lo sé.', 'O.K.', 'Bai.')\n","('Yo sí.', 'I have.', 'Nik bai.')\n","('¿Por qué?', 'Why?\"', 'Zergatik?')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Tres?', 'Three?', 'Hiru?')\n","('-Nunca.', '\"Never.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('El final.', 'The end.', 'Bukaera.')\n","('Una caja de colchón.', 'A mattress box.', 'Koltxoi kaxa bat.')\n","('No me contestó.', \"He didn't answer me.\", 'Ez zidan erantzun.')\n","('¡No!', 'No!', 'Ez!')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.\"', '-Ez.')\n","('¡No!', 'No!', 'Ez.')\n","('No sé.', \"I don't know.\", 'Ez dakit.')\n","('¿Cómo estás?', '\"How are you?', 'Zer moduz?')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('V', 'V', 'V')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('VI', 'VI', 'VI')\n","('-No.', '\"No.\"', '-Ez.')\n","('VII', 'VII', 'VII')\n","('VIII', 'VIII', 'VIII')\n","('-¡Ah!', '\"Ah!\"', '-Ah!')\n","('IX', 'IX', 'IX')\n","('X', 'X', 'X')\n","('XI', 'XI', 'XI')\n","('XII', 'XII', 'XII')\n","('-¿Eh?', '\"Eh?', '-Eh?')\n","('¿Qué?', 'What?', 'Zer?')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-preguntó Bazárov.', 'asked Bazarov.', '-galdetu zuen Bazarovek.')\n","('-¿Y bien?', '\"Well?\"', '- Eta?')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('Bazárov arrugó el ceño.', 'Bazarov frowned.', 'Bekokia zimurtu zuen Bazarovek.')\n","('Bazárov se levantó.', 'Bazarov stood up.', 'Zutik jarri zen Bazarov.')\n","('-¿Cómo?', '\"What?', '-Zer?')\n","('-¡Ah!', '\"Ah!\"', '- Ah!')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('Bazárov no respondió.', 'Bazarov made no reply.', 'Bazarovek ez zuen ezer erantzun.')\n","('-preguntó Arkadi.', 'asked Arkady.', '-galdetu zuen Arkadik.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai.')\n","('¡Amén!', 'Amen!', 'Amen!')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-preguntó Bazárov.', 'Bazarov asked.', '-galdetu zuen Bazarovek.')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No...', '\"No...', '-Ez...')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-¡Ah!', '\"Ah!', '-Ah!')\n","('-preguntó Pável Petróvich.', 'asked Pavel Petrovich.', '-galdetu zuen Pavel Petrovitxek.')\n","('-preguntó.', 'he asked.', '-galdetu zion.')\n","('¿Usted?', 'You?\"', 'Zuk?')\n","('-No le comprendo.', '\"I don\\'t understand you.\"', '-Ez dizut ulertzen.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿De veras?', '\"Really?', '-Benetan?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Cómo?', '\"What?', '-Nola?')\n","('-¿Y?', '\"Well?\"', '-Eta?')\n","('-¡Evgueni!', '\"Evgeny!\"', '- Jevgeni!')\n","('-¡Ah!', '\"Ah!\"', '-A!')\n","('-¡Miguel Giborne!', '\"Michel Giborne!\"', '-Migel Giborne!')\n","('-No.', '\"No.', '-Ez.')\n","('-¿De verdad?', '\"Really?\"', '-Benetan?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('¿Y por qué?', 'And why?', 'Eta zergatik?')\n","('-¿Vuestro nombre?', '\"Your name?\"', '-Zure izena?')\n","('-¿Cómo?', '\"What!', '-Zer?')\n","('-¡Silencio!', '\"Silence!', '-Ixo!')\n","('¡Ay!', 'Alas!', 'Hara!')\n","('-¿De verdad?', '\"Truly?\"', '-Benetan?')\n","('-¡Oh!', '\"Oh!', '-O!...')\n","('-¡Oh!', '\"Oh!\"', '-O!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!\"', '-O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('Escucha.', 'Listen.', 'Entzun.')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('-¡Cómo!', '\"What!\"', '-Nola!')\n","('-¡Oh!', '\"Oh!\"', '-O!')\n","('-¡Febo!', '\"Phoebus!\"', '-Febo!')\n","('-¡Oh!', '\"Oh!\"', '-O!')\n","('¡Febo!', 'Phoebus!', 'Febo!')\n","('¡Febo!', 'Phoebus!', 'Febo!')\n","('-¡Oh, sí!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!\"', '-O!')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-¡Febo!', '\"Phoebus!', '-Febo!')\n","('-¿Y por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('II.', 'CHAPTER II.', 'II.')\n","('III.', 'CHAPTER III.', 'III.')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('-¡Señor!', '\"Sire!', '-Jauna!')\n","('¡Ay!', 'Alas!', 'Ai!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('¡Oh!', '\"Oh!', 'O!')\n","('-Bien, ¿y qué?', '\"Well?\"', '-Eta?')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('-preguntó ella.', 'she asked.', '-galdetu zuen neskak.')\n","('¡Oh!', 'Oh!', 'O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('¡Oh!', 'Oh!', 'O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Mi hija!', '\"My daughter!', '-Nire alaba!')\n","('-¡Febo!', '\"Phoebus!', '-Febo!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-A la joven.', '\"The young one.\"', '-Gaztea.')\n","('-¡Ah!', '\"Ah!', '-A!')\n","('Capítulo I', 'CHAPTER I', 'I')\n","('Capítulo I', 'CHAPTER I', 'I')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo IV', 'CHAPTER IV', 'IV')\n","('Capítulo V', 'CHAPTER V', 'V')\n","('Capítulo I', 'CHAPTER I', 'I')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo VII', 'CHAPTER VII', 'VII')\n","('Capítulo IX', 'CHAPTER IX', 'IX')\n","('Capítulo I', 'CHAPTER I', 'I')\n","('Capítulo II', 'CHAPTER II', 'II')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo IV', 'CHAPTER IV', 'IV')\n","('Capítulo V', 'CHAPTER V', 'V')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo V', 'CHAPTER V', 'V')\n","('Capítulo VIII', 'CHAPTER VIII', 'VIII')\n","('Capítulo I', 'CHAPTER I', 'I')\n","('Capítulo V', 'CHAPTER V', 'V')\n","('Capítulo VII', 'CHAPTER VII', 'VII')\n","('Capítulo X', 'CHAPTER X', 'X')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo II', 'CHAPTER II', 'II')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo VI', 'CHAPTER VI', 'VI')\n","('Capítulo VIII', 'CHAPTER VIII', 'VIII')\n","('Capítulo I', 'CHAPTER I', 'I')\n","('Capítulo III', 'CHAPTER III', 'III')\n","('Capítulo IV', 'CHAPTER IV', 'IV')\n","('Capítulo VI', 'CHAPTER VI', 'VI')\n","('Capítulo VII', 'CHAPTER VII', 'VII')\n","('Capítulo X', 'CHAPTER X', 'X')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('-No, señor.', '\"No, sir.', '-Ez, jauna.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí, señor.', '\"Yes, sir.', '-Bai, jauna.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-le preguntó.', 'she asked.', '-galdetu zion.')\n","('-le pregunté.', 'I asked her.', '-galdetu nion.')\n","('-Sí, señorita.', '\"Yes, miss.\"', '-Bai, andereño.')\n","('Sí.', 'Yes.', 'Bai.')\n","('-¡Ah!', '\"Ah!\"', '-Ah!')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('¡Ah!', 'Ah!', 'Ah!')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('¡No!', 'No!', 'Ez!')\n","('¿Cuándo?', 'When?', 'Noiz?')\n","('-le pregunté-.', 'I asked.', '-galdetu nion-.')\n","('-le pregunté-.', 'I asked.', '-galdetu nion-.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.\"', '-Ez.')\n","('Buenos días.', 'Good morning.\"', 'Egun on.')\n","('-¿Qué más?', '\"What next?\"', '-Eta gero?')\n","('-¡Oh!', '\"Oh!\"', '-O!')\n","('-¡Ah!', '\"Ah!\"', '-Ah!')\n","('Muy bien.', 'Very well.', 'Oso ongi.')\n","('Buenas noches.', 'Good-night.\"', 'Gabon.')\n","('I', 'CHAPTER I', '1')\n","('¡No!', 'No!', 'Ez!')\n","('II', 'CHAPTER II', '2')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik ez?')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-dijo-.', 'he said.', '-esan zion-.')\n","('-dijo-.', 'he said.', '-esan zuen-.')\n","('III', 'CHAPTER III', '3')\n","('¡No!', 'No!', 'Ez!')\n","('IV', 'CHAPTER IV', '4')\n","('-¡Oh!', '\"Oh!', '-O!')\n","('V', 'CHAPTER V', '5')\n","('-Sí.', '\"Yes?\"', '-Eta?')\n","('VI', 'CHAPTER VI', '6')\n","('VII', 'CHAPTER VII', '7')\n","('-No.', '\"No.', '-Ez.')\n","('¡Ah!', 'Ah!', 'Ene!')\n","('-¡Ah!', '\"Ah!\"', '-A!')\n","('I', 'CHAPTER I', '1')\n","('-¿Qué quiere usted decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('II', 'CHAPTER II', '2')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('¿Qué significaba esto?', 'What did it mean?', 'Zer esan nahi zuen horrek?')\n","('III', 'CHAPTER III', '3')\n","('-me preguntó.', 'he asked.', '-galdetu zidan.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('I', 'CHAPTER I', '1')\n","('II', 'CHAPTER II', '2')\n","('-le pregunté.', 'I asked.', '-galdetu nion nik.')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik ez?')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('III', 'CHAPTER III', '3')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('IV', 'CHAPTER IV', '4')\n","('No.', 'No.', 'Ez.')\n","('-exclamé-.', 'I exclaimed.', '-egin nuen oihu-.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('V', 'CHAPTER V', '5')\n","('No.', 'No.', 'Ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('VI', 'CHAPTER VI', '6')\n","('Muy bien.', 'Very well.', 'Ederki.')\n","('-¿Cuándo?', '\"When?', '-Noiz?')\n","('VII', 'CHAPTER VII', '7')\n","('-me dijo-.', 'she said.', '-esan zidan-.')\n","('-No.', '\"No.', '-Ez.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-Solo.', '\"Alone.\"', '-Bakarrik.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.', '-Ez.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-me dijo-.', 'she said.', '-esan zidan-.')\n","('VIII', 'CHAPTER VIII', '8')\n","('-Muy bien.', '\"Very good.', '-Ederki.')\n","('-No.', '\"No.\"', '-Ez.')\n","('IX', 'CHAPTER IX', '9')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-No.', '\"No.', '-Ez.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-me preguntó-.', 'he asked.', '-galdetu zidan-.')\n","('-¡Alto ahí!', '\"Stop!\"', '-Egon!')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('X', 'CHAPTER X', '10')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-le pregunté-.', 'I asked.', '-galdetu nion-.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¿Por qué?', '\"Why?\"', '-Zergatik?')\n","('-¿Por qué no?', '\"Why not?\"', '-Zergatik?')\n","('¿No?', 'No?', 'Ez?')\n","('¡No!', 'No!', 'Ez!')\n","('-le dije.', 'I said.', '-esan diot.')\n","('¡Sí!', 'Yes!', 'Bai!')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('-le dije-.', 'I said.', '-esan nion-.')\n","('-le pregunté.', 'I asked.', '-galdetu nion.')\n","('-le pregunté-.', 'I asked.', '-galdetu nion-.')\n","('-Sí, señor.', '\"Yes, sir.\"', '-Bai, jauna.')\n","('-le pregunté-.', 'I asked.', '-galdetu nion-.')\n","('-No.', '\"No.\"', '-Ez.')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('IV', 'IV', 'IV')\n","('V', 'V', 'V')\n","('I', 'I', 'I')\n","('II', 'II', 'II')\n","('III', 'III', 'III')\n","('La portilla estaba fría.', 'The gate was cold.', 'Langa hotza zegoen.')\n","('dijo Madre.', 'Mother said.', '\"Beldurra ematen dit\", esan zuen Amak.')\n","('\"Sí, señora\". dijo T.P.', '\"Yessum.\" T.P.', '\"Bai, etxeko\\'ndre\", esan zuen T.P.-k.')\n","('T.P.', 'T.P.', 'T.P.')\n","('\"Era Madre\". dijo Quentin.', '\"That was Mother.\" Quentin said.', '\"Ama zen\", esan zuen Quentinek.')\n","('T.P.', 'T.P.', 'T.P.')\n","('T.P.', 'T.P.', 'T.P.')\n","('Vamos\".', 'Come on.', 'Goazen\".')\n","('No era Padre.', \"It wasn't Father.\", 'Ez zen Aita.')\n","('Vamos.', 'Come on.', 'Goazen.')\n","('Dan aulló.', 'Dan howled.', 'Dan uluka ari zen.')\n","('T.P.', 'T.P.', 'T.P.')\n","('Jason lloraba.', 'Jason cried.', 'Jasonek negar egin zuen.')\n","('T.P.', 'T.P.', 'T.P.')\n","('T.P.', 'T.P.', 'T.P.')\n","('T.P.', 'T.P.', 'T.P.')\n","('\"Benjy\".', '\"Benjy.\"', '\"Benjy\", esan zuen T.P.-k behetik.')\n","('Caddy olía como los árboles.', 'Caddy smelled like trees.', 'Caddyk zuhaitz usaina zeukan.')\n","('Caddy olía como los árboles.', 'Caddy smelled like trees.', 'Caddyk zuhaitz usaina zeukan.')\n","('Eh.', 'Here.', 'Aizu.')\n","('\"Caddy\".', '\"Caddy.\"', '\"Caddy\", esan zuen Charliek.')\n","('Caddy olía como los árboles.', 'Caddy smelled like trees.', 'Caddyk zuhaitz usaina zeukan.')\n","('\"Cállese\". dijo Luster.', '\"Hush.\" Luster said.', '\"Ixo\", esan zuen Lusterrek.')\n","('Se pararon.', 'They stopped.', 'Gelditu egin ziren.')\n","('Vamos\".', 'Come on.\"', 'Goazen\".')\n","('Vamos\".', 'Come on.\"', 'Goazen\".')\n","('Eh.', 'Here.', 'Tori.')\n","('Me dio la flor.', 'He gave me the flower.', 'Lorea eman zidan.')\n","('dijo Luster.', 'Luster said.', '\"Ixo\", esan zuen Lusterrek.')\n","('Me callé.', 'I hushed.', 'Isildu egin nintzen.')\n","('\"Cállese\". dijo Luster.', '\"Hush.\" Luster said.', '\"Ixo\", esan zuen Lusterrek.')\n","('Empecé a llorar.', 'I began to cry.', 'Ni negarrez hasi nintzen.')\n","('Me callé.', 'I hushed.', 'Isildu egin nintzen.')\n","('Y por qué, dijo Dilsey.', 'How come it is, Dilsey said.', 'Nolatan, esan zuen Dilseyk.')\n","('Madre dijo,', 'Mother said,', 'Amak esan zuen,')\n","('\"Candace\".', '\"Candace.\"', '\"Candace\", esan zuen Amak.')\n","('Calla\".', 'Hush.\"', 'Ixo\".')\n","('No, no.', 'No, no.', 'Ez, ez.')\n","('Oíamos el tejado.', 'We could hear the roof.', 'Teilatua aditzen genuen.')\n","('Oíamos el tejado.', 'We could hear the roof.', 'Teilatua aditzen genuen.')\n","('Oíamos el fuego y el tejado.', 'We could hear the fire and the roof.', 'Sua eta teilatua aditzen genituen.')\n","('Oíamos el fuego y el tejado.', 'We could hear the fire and the roof.', 'Sua eta teilatua aditzen genituen.')\n","('\"Candace\".', '\"Candace.\"', '\"Candace\", esan zuen Amak.')\n","('\"Calla, Caroline\". dijo Padre.', '\"Hush, Caroline.\" Father said.', '\"Ixo, Caroline\", esan zuen Aitak.')\n","('Yo empecé a llorar.', 'I began to cry.', 'Ni negarrez hasi nintzen.')\n","('Su boca era roja.', 'Her mouth was red.', 'Bere ahoa gorri-gorri zegoen.')\n","('Ella olía como los árboles.', 'She smelled like trees.', 'Zuhaitz usaina zeukan.')\n","('dijo Dilsey.', 'Dilsey said.', '\"Ixo\", esan zuen Dilseyk.')\n","('Jason se calló.', 'Jason hushed.', 'Jason isildu egin zen.')\n","('dijo Dilsey.', 'Dilsey said.', '\"Ixo\", esan zuen Dilseyk.')\n","('La puerta se cerró.', 'The door closed.', 'Atea itxi zen.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Benjy.', 'Benjy.', 'Benjy.')\n","('Voy a escaparme.', \"I'm going to run away.\", 'Alde egin egingo dut.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Dalton Ames.', 'Dalton Ames.', 'Dalton Ames.')\n","('Tres días.', 'Three days.', 'Hiru egun.')\n","('Eres algo extraño, no.', \"You're funny, aren't you.\", 'Xelebrea zara, e.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('Otra vez.', 'Again.', 'Berriro.')\n","('\"No.', '\"No.', '\"Ez.')\n","('\"Sí.', '\"Yes.', '\"Bai.')\n","('Está bien.', 'All right.', 'Ondo da.')\n","('No:', 'No:', 'Ez:')\n","('Mejor.', 'Better.', 'Hobeto.')\n","('\"Sí.', '\"Yes.', '\"Bai.')\n","('\"Vamos a nadar al molino\", dijo el tercero.', '\"Let\\'s go to the mill and go swimming,\" the third said.', '\"Goazen errotara igeri egitera\", esan zuen hirugarrenak.')\n","('No:', 'No:', 'Ez:')\n","('¿Perdón?', 'Sir?', 'Jauna?')\n","('\"No, señora.', '\"No, ma\\'am.', '\"Ez, etxekoandre.')\n","('Salimos.', 'We went out.', 'Atera egin ginen.')\n","('\"Adiós\", dije.', '\"Goodbye,\" I said.', '\"Agur\", esan nuen.')\n","('\"¿Es usted de la universidad?\".', '\"You from the college?\"', '\"Estudiantea al zara?\"')\n","('\"Vamos, amiguita\".', '\"Come on, sister.\"', '\"Goazen, arrebatxo\".')\n","('Gracias.', 'Thanks.', 'Eskerrik asko.')\n","('¿Ahí?', 'There?', 'Han?')\n","('\"¿Qué yo he robado a su hermana?\" dije.', '\" Steal his sister?\" I said.', '\"Nik bere arreba lapurtu?\" esan nuen.')\n","('Me levanté.', 'I got up.', 'Zutitu egin nintzen.')\n","('Seguimos andando.', 'We went on.', 'Aurrera segi genuen.')\n","('Se la dije.', 'I told him.', 'Esan egin nion.')\n","('\"Hum\", dijo el Juez.', '\"H\\'m,\" the squire said.', '\"Mmm\", esan zuen epaileak.')\n","('\"Hum\", dijo el Juez.', '\"H\\'m,\" the squire said.', '\"Mmm\", esan zuen epaileak.')\n","('\"Hum\", dijo el Juez.', '\"H\\'m,\" the squire said.', '\"Mmm\", esan zuen epaileak.')\n","('Sí\".', 'Yes.\"', 'Bai\".')\n","('El tranvía se detuvo.', 'The car stopped.', 'Tranbia gelditu egin zen.')\n","('Shreve tiene una botella en su baúl.', 'Shreve has a bottle in his trunk.', 'Shrevek botila bat dauka bere baulean.')\n","('\"De acuerdo.', '\"All right.', '\"Ondo da.')\n","('No contesté.', \"I didn't answer.\", 'Ez nuen erantzun.')\n","('Entré.', 'I went in.', 'Sartu egin nintzen.')\n","('\"Eh, Jason\", dice.', '\"You, Jason,\" she says.', '\"Aizu, Jason\", dio.')\n","('\"No he querido ofenderle\", digo.', '\"No offense,\" I says.', '\"Ez gaizki hartu\", diot nik.')\n","('Miró a la tumba.', 'She looked at the grave.', 'Hilobira begiratu zuen.')\n","('No dije nada.', \"I didn't say anything.\", 'Ez nuen ezer esan.')\n","('Me detuve.', 'I stopped.', 'Gelditu egin nintzen.')\n","('\"Está bien.', '\"All right.', '\"Ondo da.')\n","('\"No.', '\"No.', '\"Ez.')\n","('Por favor, Jason.', 'Please, Jason.', 'Mesedez, Jason.')\n","('\"No\", dice.', '\"No,\" she says.', '\"Ez\", dio berak.')\n","('Se levantó.', 'She got up.', 'Zutitu egin zen.')\n","('Me levanté.', 'I got up.', 'Altxa egin nintzen.')\n","('Regresé a la tienda.', 'I went back to the store.', 'Dendara itzuli nintzen.')\n","('\"No\", dice.', '\"No,\" she says.', '\"Ez\", dio berak.')\n","('Luego continué.', 'Then I went on.', 'Gero aurrera segi nuen.')\n","('Volví a la tienda.', 'I went back to the store.', 'Dendara itzuli nintzen.')\n","('Earl dice,', 'Earl says,', 'Earlek esaten du,')\n","('\"Nada\", digo.', '\"Nothing,\" I says.', '\"Ezer ez\", diot nik.')\n","('Salí.', 'I went on out.', 'Atera egin nintzen.')\n","('\"Sí\", digo.', '\"Yes,\" I says.', '\"Bai\", diot nik.')\n","('\", digo.', 'I says.', 'diot nik.')\n","('\"No los tengo\", dice.', '\"I aint got dat much,\" he says.', '\"Ez daukat horrenbeste\", dio berak.')\n","('\"Vaya\", digo.', '\"All right,\" I says.', '\"Beno ba\", diot nik.')\n","('\"No\", dice.', '\"No,\" she says.', '\"Ez\", dio berak.')\n","('\"No.', '\"No.', '\"Ez.')\n","('Me miró.', 'She looked at me.', 'Begiratu egin zidan.')\n","('\"Jason\", dice.', '\"Jason,\" she says.', '\"Jason\", dio berak.')\n","('\"Bueno\", digo.', '\"All right,\" I says.', '\"Ondo da\", diot nik.')\n","('\"No.', '\"No.', '\"Ez.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\", dijo Dilsey.', 'Dilsey said.', 'esan zuen Dilseyk.')\n","('\"Quentin.', '\"Quentin.', '\"Quentin.')\n","('\", dijo Dilsey.', 'Dilsey said.', 'esan zuen Dilseyk.')\n","('No hubo respuesta.', 'There was no answer.', 'Ez zen erantzunik izan.')\n","('\", dijo Dilsey.', 'Dilsey said.', 'esan zuen Dilseyk.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Ay, abuela\".', '\"Aw, mammy.\"', '\"Ai, mammy\".')\n","('¡Jesús!', 'Jesus!', 'Jesus!')\n","('\", dijo Frony.', 'Frony said.', 'esan zuen Fronyk.')\n","('La señora Compson no dijo nada.', 'Mrs Compson said nothing.', 'Mrs Compsonek ez zuen ezer esan.')\n","('Dilsey salió.', 'Dilsey went out.', 'Dilsey atera egin zen.')\n","('\"Sí.', '\"Yes.', '\"Bai.')\n","('\"No.', '\"No.', '\"Ez.')\n","('\"No\", dijo Jason.', '\"No,\" Jason said.', '\"Ez\", esan zuen Jasonek.')\n","('\"Sí\", dijo Jason.', '\"Yes,\" Jason said.', '\"Bai\", esan zuen Jasonek.')\n","('Salieron.', 'They went out.', 'Atera egin ziren.')\n","('\", dijo Dilsey.', 'Dilsey said.', 'esan zuen Dilseyk.')\n","('Cállese\".', 'Hush.\"', 'Ixo\".')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Sí, abuela\", dijo Luster.', '\"Yessum,\" Luster said.', '\"Bai, etxeko\\'ndre\", esan zuen Lusterrek.')\n","('\"Arre, Queenie\".', '\"Hum up, Queenie.\"', '\"Arre, Queenie\".')\n","('-¡Piggy!', '\"Piggy!', '-Txerri!')\n","('-No.', '\"No.', '-Ez.')\n","('-No.', '\"No.\"', '-Ez.')\n","('-¡Piggy!', '\"Piggy!\"', '-Txerri!')\n","('¡Mira!', 'Look!\"', 'Begira!')\n","('-Sí.', '\"Yes.', '-Bai.')\n","('-Pero...', '\"But-\"', '-Baina...')\n","('-¿Dónde?', '\"Where?\"', '-Non?')\n","('Todos los días.', 'Every day.', 'Egunero.')\n","('Eso es todo.', 'That\\'s all.\"', 'Besterik ez.')\n","('-¿Qué?', '\"What?', '-Zer?')\n","('¿Dónde?', 'Where?', 'Non?')\n","('Ralph frunció el ceño.', 'Ralph frowned.', 'Ralphek betoskoa zimurtu:')\n","('-No.', '\"No.', '-Ez.')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ralph!', 'Ralph!\"', 'Ralph!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Vuelve!', '\"Come back!', '-Itzuli!')\n","('¡Vuelve!', 'Come back!\"', 'Itzuli!')\n","('-¡Mis gafas!', '\"My specs!\"', '-Nire lenteak!')\n","('-Y otra cosa.', '\"And another thing.', '-Eta beste gauza bat.')\n","('No.', 'No.', 'Ez.')\n","('-¿Cómo te llamas?', '\"What\\'s your name?\"', '-Nola duk izena?')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-Nada.', '\"Nothing.\"', '-Ezer ez.')\n","('-¿Eh?', '\"Huh?\"', '-Zer?')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¿Qué pasa?', '\"What\\'s the matter?\"', '-Zer gertatzen da?')\n","('¡Piggy!', 'Piggy!\"', 'Txerri!')\n","('-Y otra cosa.', '\"And another thing.', '-Eta beste gauza bat.')\n","('Suspiró.', 'He sighed.', 'Hasperen egin zuen.')\n","('-¡Jack!', '\"Jack!', '-Jack!')\n","('-Humo.', '\"Smoke.\"', '-Kea.')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-Mira.', '\"Look.\"', '-Begira.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Hubo un silencio.', 'There was silence.', 'Isiltasuna.')\n","('¿De verdad?', 'Really?\"', 'Benetan?')\n","('-¿Y mis cazadores, qué?', '\"What about my hunters?\"', '-Eta nire ehiztariak zer?')\n","('-¡Jack!', '\"Jack!\"', '-Jack!')\n","('-¿Qué?', '\"What?\"', '-Zer?')\n","('-No lo sé.', '\"I don\\'t know.\"', '-Ez diakiat.')\n","('-Y otra cosa.', '\"And another thing.', '-Eta beste gauza bat.')\n","('-¡Ahora!', '\"Now!\"', '-Orain!')\n","('-Aquí.', '\"Here.\"', '-Hemen.')\n","('¿Entiendes?', 'Understand?', 'Ulertzen?')\n","('-¿Han comido todos bastante?', '\"Has everybody eaten as much as they want?\"', '-Jan al duzue denok nahi beste?')\n","('Habló Jack:', 'Jack spoke.', 'Jack mintzatu zen:')\n","('-¡Mata a la fiera!', '\" Kill the beast!', '-Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('-¡Mata a la fiera!', '\" Kill the beast!', '-Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('-¡Mata a la fiera!', '\" Kill the beast!', '-Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('-Piggy.', '\"Piggy.\"', '-Txerri.')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-Piggy.', '\"Piggy.\"', '-Txerri.')\n","('-¿Eh?', '\"Uh?\"', '-Bai?')\n","('-Piggy.', '\"Piggy.\"', '-Txerri.')\n","('-Roger.', '\"Roger.\"', '-Roger.')\n","('-¿Por qué?', '\"What for?\"', '-Zer dela eta?')\n","('-¡No!', '\"No!\"', '-Ez!')\n","('-¿Sí?', '\"Yes?\"', '-Bai?')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ralph!', 'Ralph!\"', 'Ralph!')\n","('-¿Qué pasa?', '\"What is it?\"', '-Zer gertatzen da?')\n","('-¡Sam!', '\"Sam!', '-Sam!')\n","('¡Sam!', 'Sam!\"', 'Sam!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ralph!', 'Ralph!\"', 'Ralph!')\n","('-¡Piggy!', '\"Piggy!', '-Txerri!')\n","('-Está bien.', '\"All right.', '-Ondo da.')\n","('Ralph gritó:', 'Ralph shouted.', 'Ralphek oihu:')\n","('-Humo.', '\"Smoke.\"', '-Kea.')\n","('-¡Alto!', '\"Halt!', '-Alto!')\n","('¿Quién va?', 'Who goes there?\"', 'Nor dabil?')\n","('Silencio.', 'Silence.', 'Isiltasuna.')\n","('-Voy a reunir la asamblea.', '\"I\\'m calling an assembly.\"', '-Batzarrerako deia.')\n","('-¿Qué quieres?', '\"What do you want?\"', '-Zer nahi duk?')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('-¡Jack!', '\"Jack!\"', '-Jack!')\n","('-No.', '\"No.', '-Ez.')\n","('-¡Mata a la fiera!', '\" Kill the beast!', 'Hil piztia!')\n","('¡Córtale el cuello!', 'Cut his throat!', 'Ebaki zintzurra!')\n","('¡Derrama su sangre!', 'Spill his blood! \"', 'Isuri odola!')\n","('-¿Quién?', '\"Who?', '-Nork?')\n","('-¡Empujen!', '\"Heave!', '-Bultza!')\n","('¡Empujen!', 'Heave!', 'Bultza!')\n","('¡Empujen!', 'Heave!\"', 'Bultza!')\n","('-¡Empujen!', '\"Heave!', '-Bultza!')\n","('¡Empujen!', 'Heave!', 'Bultza!')\n","('¡Empujen!', 'Heave!\"', 'Bultza!')\n","('-¿Ves?', '\"See?', '-Ikusten?')\n","('-¡Humo!', '\"Smoke!\"', '-Kea!')\n","('-Piensa.', '\"Think.\"', '-Pentsa ezak.')\n","('No grites.', \"Don't scream.\", 'Ez egin garrasirik.')\n","('No grites.', \"Don't scream.\", 'Ez egin garrasirik.')\n","('-Hola.', '\"Hullo.\"', '-Kaixo.')\n","('-No, señor.', '\"No, sir.\"', '-Ez, jauna.')\n","('¿Por qué?', 'Why?', 'Zergatik?')\n","('-Sí.', '\"Yes.\"', '-Bai.')\n","('Capítulo II', 'CHAPTER TWO', 'II. KAPITULUA')\n","('Capítulo V', 'CHAPTER FIVE', 'V. KAPITULUA')\n","5375\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HfX-r3XyL8k9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1586976913602,"user_tz":-120,"elapsed":38758,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c43158ea-b593-4061-af92-f968ca465139"},"source":["print('Balidaziokoak entrenamendu \"hobetuan\":')\n","kont = 0\n","for es, en, eu in zip(val_es, val_en, val_eu):\n","    tupla = (es, en, eu)\n","    if tupla in esaldiak_hobea:\n","        print(tupla)\n","        kont += 1\n","print(kont)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Balidaziokoak entrenamendu \"hobetuan\":\n","('-¡Ralph!', '\"Ralph!', '-Ralph!')\n","('¡Ah!', 'Ah!', 'A!')\n","('¿Eh?', 'Eh?', 'E?')\n","('STEPHEN', 'STEPHEN:', 'STEPHEN')\n","('-¿Qué quieres decir?', '\"What do you mean?\"', '-Zer esan nahi duzu?')\n","('-¿Cuándo?', '\"When?\"', '-Noiz?')\n","('-No sé.', \"'I don't know.\", '-Ez dakit.')\n","7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_ts2VBBmr6fh","colab_type":"text"},"source":["# Lehen tokenizazioa eta BPE ikasi"]},{"cell_type":"code","metadata":{"id":"yEZP7rzdJ6Vc","colab_type":"code","colab":{}},"source":["!cat EhuHac/EhuHac-trainorig-es.txt OpenSubtitles/OS-train-es.txt > HACOSDatuak/origetaos1-train-es.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqOTWHGh1f3g","colab_type":"code","colab":{}},"source":["!cat EhuHac/EhuHac-trainorig-en.txt OpenSubtitles/OS-train-en.txt > HACOSDatuak/origetaos1-train-en.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJdb6SZV18Fj","colab_type":"code","colab":{}},"source":["!cat EhuHac/EhuHac-trainorig-eu.txt OpenSubtitles/OS-train-eu.txt > HACOSDatuak/origetaos1-train-eu.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FsT0hGwAfiUa","colab_type":"code","colab":{}},"source":["tokenizer = pyonmttok.Tokenizer(\"conservative\", joiner_annotate=True, case_markup=True, soft_case_regions=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MymvrW6TKebs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593028908022,"user_tz":-120,"elapsed":1612,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d211aefc-fc3b-4e5d-b9e7-bb43d2ba6e22"},"source":["tokens, _ = tokenizer.tokenize(\"Hotzak \\n ordea!...\")\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['｟mrk_case_modifier_C｠', 'hotzak', 'ordea', '￭!', '￭.', '￭.', '￭.']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"UpCTZVuwh50F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593028910652,"user_tz":-120,"elapsed":1485,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2889d611-7472-4611-e738-e37aa5777c94"},"source":["tokens, _ = tokenizer.tokenize(\"eReader-a\")\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['e￭', '｟mrk_case_modifier_C｠', 'reader-a']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"yHRU5A7LNxIT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593028915273,"user_tz":-120,"elapsed":2473,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"de933410-c5a5-4e10-c5d7-4541ce8ef32f"},"source":["tokenizer.detokenize(tokens)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'eReader-a'"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"_atDBCD9Yb3s","colab_type":"code","colab":{}},"source":["def tokenizatu(f_jatorrizkoa, f_tokenizatua):\n","    for lerroa in f_jatorrizkoa:\n","        tokens, _ = tokenizer.tokenize(lerroa)\n","        lerroa_tok = ' '.join(tokens)\n","        lerroa_tok = lerroa_tok.replace('｟mrk_case_modifier_C｠', '｟C')\n","        lerroa_tok = lerroa_tok.replace('｟mrk_begin_case_region_U｠', '｟B')\n","        lerroa_tok = lerroa_tok.replace('｟mrk_end_case_region_U｠', '｟E')\n","        f_tokenizatua.write(lerroa_tok+'\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISIeUpWGgsIw","colab_type":"code","colab":{}},"source":["def tokenizatu_str(lerroa):\n","    tokens, _ = tokenizer.tokenize(lerroa)\n","    lerroa_tok = ' '.join(tokens)\n","    lerroa_tok = lerroa_tok.replace('｟mrk_case_modifier_C｠', '｟C')\n","    lerroa_tok = lerroa_tok.replace('｟mrk_begin_case_region_U｠', '｟B')\n","    lerroa_tok = lerroa_tok.replace('｟mrk_end_case_region_U｠', '｟E')\n","    return lerroa_tok"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bh_8Ah8CZ-y","colab_type":"code","colab":{}},"source":["# Balidazio-multzoko helburukoan erabiltzeko\n","def tokenizatu_konparatzeko(f_jatorrizkoa, f_tokenizatua):\n","    tokenizer_konp = pyonmttok.Tokenizer(\"conservative\")#, joiner_annotate=True)\n","    for lerroa in f_jatorrizkoa:\n","        tokens, _ = tokenizer_konp.tokenize(lerroa)\n","        lerroa_tok = ' '.join(tokens)\n","        f_tokenizatua.write(lerroa_tok+'\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PtS3JMBSjp-K","colab_type":"code","colab":{}},"source":["def tokenizatu_konparatzeko_str(lerroa):\n","    tokenizer_konp = pyonmttok.Tokenizer(\"conservative\")#, joiner_annotate=True)\n","    tokens, _ = tokenizer_konp.tokenize(lerroa)\n","    lerroa_tok = ' '.join(tokens)\n","    return lerroa_tok"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueDgoal1C8on","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-train2-es.txt') as f_jatorrizkoa, \\\n","    open('OpenSubtitles/OS-train2-tok-es.txt', 'w') as f_tokenizatua:\n","    tokenizatu(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_v49qEp3_Ht","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-train2-en.txt') as f_jatorrizkoa, \\\n","    open('OpenSubtitles/OS-train2-tok-en.txt', 'w') as f_tokenizatua:\n","    tokenizatu(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqXKQOX4C-hf","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-train2-eu.txt') as f_jatorrizkoa, \\\n","    open('OpenSubtitles/OS-train2-tok-eu.txt', 'w') as f_tokenizatua:\n","    tokenizatu(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G1veOrWODFkm","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-val-es.txt') as f_jatorrizkoa, \\\n","    open('OpenSubtitles/OS-val-tok-es.txt', 'w') as f_tokenizatua:\n","    tokenizatu(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsfyuWcN4M9y","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-val-en.txt') as f_jatorrizkoa, \\\n","    open('OpenSubtitles/OS-val-tok-en.txt', 'w') as f_tokenizatua:\n","    tokenizatu(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0MbIVkwf4QdH","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-val-eu.txt') as f_jatorrizkoa, \\\n","    open('OpenSubtitles/OS-val-tok-eu.txt', 'w') as f_tokenizatua:\n","    tokenizatu_konparatzeko(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nCOXhZXmuqQB","colab_type":"code","colab":{}},"source":["with open('EhuHac/EhuHac-val-eu.txt') as f_jatorrizkoa, \\\n","    open('EhuHac/EhuHac-val-tok-eu.txt', 'w') as f_tokenizatua:\n","    tokenizatu_konparatzeko(f_jatorrizkoa, f_tokenizatua)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fFppZ0TODaye","colab_type":"code","colab":{}},"source":["!cat EhuHac/EhuHac-trainorig-tok-es.txt EhuHac/EhuHac-trainorig-tok-en.txt EhuHac/EhuHac-trainorig-tok-eu.txt > botatzeko.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCG91TPMEjaZ","colab_type":"code","colab":{}},"source":["bpe_hirurak = yttm.BPE.train('botatzeko.txt', 'EhuHac/bpe_hirurak2.model', 20000, 0.9999)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1l5iPJYE2FR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1594149207634,"user_tz":-120,"elapsed":1696,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c100609e-c651-4041-9677-b2ce600ee79b"},"source":["with open('EhuHac/EhuHac-trainorig-tok-en.txt') as f:\n","  for i, lerroa in enumerate(f):\n","    print(' '.join(\n","        bpe_hirurak.encode([lerroa], output_type=yttm.OutputType.SUBWORD)[0]))\n","    if i > 20:\n","      break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["▁｟C ▁arrival ▁at ▁｟C ▁grandmother ▁￭'￭ ▁s\n","▁｟C ▁we ▁arrive ▁from ▁the ▁｟C ▁big ▁｟C ▁town ▁￭.\n","▁｟C ▁we ▁￭'￭ ▁ve ▁been ▁travel ing ▁all ▁night ▁￭.\n","▁｟C ▁mother ▁￭'￭ ▁s ▁eyes ▁are ▁red ▁￭.\n","▁｟C ▁she ▁￭'￭ ▁s ▁carrying ▁a ▁big ▁card board ▁box ▁￭, ▁and ▁the ▁two ▁of ▁us ▁are ▁each ▁carrying ▁a ▁small ▁suit case ▁con taining ▁our ▁clothes ▁￭, ▁pl us ▁｟C ▁father ▁￭'￭ ▁s ▁big ▁dic tion ary ▁￭, ▁which ▁we ▁pass ▁back ▁and ▁forth ▁when ▁our ▁arms ▁get ▁tired ▁￭.\n","▁｟C ▁we ▁walk ▁for ▁a ▁long ▁time ▁￭.\n","▁｟C ▁grandmother ▁￭'￭ ▁s ▁house ▁is ▁far ▁from ▁the ▁station ▁￭, ▁at ▁the ▁other ▁end ▁of ▁the ▁｟C ▁little ▁｟C ▁town ▁￭.\n","▁｟C ▁there ▁are ▁no ▁tra ms ▁￭, ▁bus es ▁￭, ▁or ▁cars ▁here ▁￭.\n","▁｟C ▁just ▁a ▁few ▁army ▁truck s ▁driving ▁around ▁￭.\n","▁｟C ▁there ▁aren ▁￭'￭ ▁t ▁many ▁people ▁in ▁the ▁streets ▁￭.\n","▁｟C ▁the ▁town ▁is ▁very ▁quiet ▁￭.\n","▁｟C ▁our ▁fo ots te ps ▁echo ▁on ▁the ▁pa vement ▁￭;\n","▁we ▁walk ▁without ▁speaking ▁￭, ▁｟C ▁mother ▁in ▁the ▁middle ▁￭, ▁between ▁the ▁two ▁of ▁us ▁￭.\n","▁｟C ▁when ▁we ▁get ▁to ▁｟C ▁grandmother ▁￭'￭ ▁s ▁garden ▁gate ▁￭, ▁｟C ▁mother ▁says ▁￭:\n","▁\"￭ ▁｟C ▁wait ▁for ▁me ▁here ▁￭. ▁￭\"\n","\n","▁｟C ▁we ▁wait ▁for ▁a ▁while ▁￭, ▁then ▁we ▁go ▁into ▁the ▁garden ▁￭, ▁walk ▁around ▁the ▁house ▁￭, ▁and ▁cr ou ch ▁down ▁under ▁a ▁window ▁where ▁we ▁can ▁hear ▁voices ▁￭.\n","▁｟C ▁mother ▁￭'￭ ▁s ▁voice ▁says ▁￭:\n","▁\"￭ ▁｟C ▁there ▁￭'￭ ▁s ▁nothing ▁more ▁to ▁eat ▁at ▁home ▁￭, ▁no ▁bread ▁￭, ▁no ▁meat ▁￭, ▁no ▁vege tables ▁￭, ▁no ▁milk ▁￭.\n","▁｟C ▁nothing ▁￭.\n","▁｟C ▁i ▁can ▁￭'￭ ▁t ▁feed ▁them ▁anymore ▁￭. ▁￭\"\n","▁｟C ▁another ▁voice ▁says ▁￭:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vp6rYB7WFCNZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1594149236357,"user_tz":-120,"elapsed":2334,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2a0a469c-8fee-4895-d076-404315cceca1"},"source":["with open('EhuHac/EhuHac-trainorig-tok-es.txt') as f:\n","  for i, lerroa in enumerate(f):\n","    print(' '.join(\n","        bpe_hirurak.encode([lerroa], output_type=yttm.OutputType.SUBWORD)[0]))\n","    if i > 20:\n","      break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["▁｟C ▁la ▁llegada ▁a ▁casa ▁de ▁la ▁abuela\n","▁｟C ▁ven imos ▁de ▁la ▁ciudad ▁￭.\n","▁｟C ▁hemos ▁via jado ▁toda ▁la ▁noche ▁￭.\n","▁｟C ▁nuestra ▁madre ▁tiene ▁los ▁ojos ▁ro jos ▁￭.\n","▁｟C ▁lleva ▁una ▁caja ▁de ▁cart ón ▁grande ▁￭, ▁y ▁nosotros ▁dos ▁una ▁maleta ▁pequeña ▁cada ▁uno ▁con ▁su ▁ropa ▁￭, ▁y ▁además ▁el ▁dic cion ario ▁grande ▁de ▁nuestro ▁padre ▁￭, ▁que ▁nos ▁vamos ▁pasando ▁cuando ▁tenemos ▁los ▁brazos ▁cans ados ▁￭.\n","▁｟C ▁and amos ▁mucho ▁rato ▁￭.\n","▁｟C ▁la ▁casa ▁de ▁la ▁abuela ▁está ▁lejos ▁de ▁la ▁estación ▁￭, ▁en ▁la ▁otra ▁punta ▁del ▁pueblo ▁￭.\n","▁｟C ▁aquí ▁no ▁hay ▁tran vía ▁￭, ▁ni ▁autob ús ▁￭, ▁ni ▁coches ▁￭.\n","▁｟C ▁sólo ▁circ ulan ▁algunos ▁cam iones ▁militar es ▁￭.\n","▁｟C ▁los ▁camin antes ▁son ▁poco ▁num erosos ▁￭, ▁el ▁pueblo ▁está ▁silen cioso ▁￭.\n","▁｟C ▁se ▁oye ▁el ▁ruido ▁de ▁nuestros ▁pasos ▁￭.\n","\n","▁｟C ▁camin amos ▁sin ▁hablar ▁￭, ▁nuestra ▁madre ▁en ▁medio ▁￭, ▁entre ▁nosotros ▁dos ▁￭.\n","▁｟C ▁ante ▁la ▁puerta ▁del ▁jardín ▁de ▁la ▁abuela ▁￭, ▁nuestra ▁madre ▁dice ▁￭:\n","▁-￭ ▁｟C ▁esper adme ▁aquí ▁￭.\n","\n","▁｟C ▁esper amos ▁un ▁poco ▁y ▁después ▁entra mos ▁en ▁el ▁jardín ▁￭, ▁rode amos ▁la ▁casa ▁￭, ▁nos ▁ag ach amos ▁debajo ▁de ▁una ▁ventana ▁￭, ▁de ▁donde ▁vienen ▁las ▁voces ▁￭.\n","▁｟C ▁la ▁voz ▁de ▁nuestra ▁madre ▁dice ▁￭:\n","▁-￭ ▁｟C ▁ya ▁no ▁tenemos ▁nada ▁que ▁comer ▁en ▁casa ▁￭, ▁ni ▁pan ▁￭, ▁ni ▁carne ▁￭, ▁ni ▁ver d uras ▁￭, ▁ni ▁leche ▁￭.\n","▁｟C ▁nada ▁￭.\n","▁｟C ▁no ▁puedo ▁aliment arlos ▁￭.\n","▁｟C ▁otra ▁voz ▁dice ▁￭:\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l4pMaKelFm3h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"status":"ok","timestamp":1594149264658,"user_tz":-120,"elapsed":1769,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"45a4e55c-4c38-4b41-9680-6a7e2368537e"},"source":["with open('EhuHac/EhuHac-trainorig-tok-eu.txt') as f:\n","  for i, lerroa in enumerate(f):\n","    print(' '.join(\n","        bpe_hirurak.encode([lerroa], output_type=yttm.OutputType.SUBWORD)[0]))\n","    if i > 20:\n","      break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["▁｟C ▁amon aren era\n","▁｟C ▁hiri ▁｟C ▁hand itik ▁g atoz ▁￭.\n","▁｟C ▁gau ▁osoan ▁bida iatu ▁dugu ▁￭.\n","▁｟C ▁amak ▁gor rit urik ▁da uzka ▁begiak ▁￭.\n","▁｟C ▁kar to izko ▁kutxa ▁handi ▁bat ▁darama ▁￭; ▁eta ▁guk ▁biok ▁mal et atxo ▁bana ▁￭, ▁nork ▁bere ▁arrop ekin ▁￭, ▁eta ▁aitaren ▁hiz tegi ▁handia ▁￭, ▁zeina ▁￭, ▁besoak ▁nek atzen ▁zaizk ig unean ▁￭, ▁batak ▁besteari ▁pasatzen ▁baitio gu ▁￭.\n","▁｟C ▁ibili ▁g abiltza ▁luzaroan ▁￭.\n","▁｟C ▁amon aren ▁etxea ▁gelto k itik ▁urrun ▁dago ▁￭, ▁｟C ▁hiri ▁｟C ▁txik iaren ▁beste ▁mut urrean ▁￭.\n","▁｟C ▁hemen ▁ez ▁dago ▁tran bi arik ▁￭, ▁ez ▁autob us ik ▁￭, ▁ez ▁aut orik ▁￭.\n","▁｟C ▁kalean ▁ez ▁dabiltza ▁kam ioi ▁militar ▁batzuk ▁baino ▁￭.\n","▁｟C ▁jende ▁gutxi ▁dabil ▁kalean ▁￭;\n","▁hiria ▁isilik ▁dago ▁￭.\n","▁｟C ▁geure ▁pauso en ▁hotsa ▁entzun ▁dezakegu ▁￭;\n","▁hitzik ▁egin ▁gabe ▁goaz ▁￭, ▁｟C ▁ama ▁erdian ▁￭, ▁gu ▁bion ▁artean ▁￭.\n","▁｟C ▁amon aren ▁etxeko ▁bar atzearen ▁atean ▁￭, ▁｟C ▁amak ▁dios k u ▁￭:\n","▁-￭ ▁｟C ▁itxaro idazue ▁hementxe ▁￭.\n","▁｟C ▁apur ▁batean ▁itxaron ▁eta ▁bar atzean ▁sartzen ▁gara ▁￭;\n","▁etxea ▁ingur utzen ▁dugu ▁￭; ▁leiho ▁baten ▁azpian ▁ahots ▁batzuk ▁entzuten ▁ditugu ▁eta ▁hantxe ▁jartzen ▁gara ▁ko kor iko ▁￭.\n","▁｟C ▁amaren ▁ahotsak ▁dio ▁￭:\n","▁-￭ ▁｟C ▁gure an ▁ez ▁da ▁geratzen ▁jat ekorik ▁￭; ▁ez ▁og irik ▁￭, ▁ez ▁ok elarik ▁￭, ▁ez ▁b araz k irik ▁￭, ▁ez ▁es ner ik ▁￭.\n","▁｟C ▁deus ▁ez ▁￭.\n","▁｟C ▁ezin ▁ditut ▁manten du ▁￭.\n","▁｟C ▁beste ▁ahots ▁batek ▁dio ▁￭:\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3ESvmQWzFg8M","colab_type":"text"},"source":["# Entrenatu edo probatu baino lehen"]},{"cell_type":"markdown","metadata":{"id":"vsFGi5mi-MRg","colab_type":"text"},"source":["## Orain erabiltzen ez ditudanak"]},{"cell_type":"code","metadata":{"id":"UvyR6QkNFrDY","colab_type":"code","colab":{}},"source":["denak = []\n","luzeegiak = []\n","\n","with open('EhuHac/EhuHac-tok-es.txt') as f_jat1, \\\n","     open('EhuHac/EhuHac-tok-en.txt') as f_jat2, \\\n","     open('EhuHac/EhuHac-tok-eu.txt') as f_helb:\n","\n","    for i, (l_jat1, l_jat2, l_helb) in enumerate(zip(f_jat1, f_jat2, f_helb), \n","                                                 1):\n","        enc_jat1 = bpe_hirurak.encode([l_jat1], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        enc_jat2 = bpe_hirurak.encode([l_jat2], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        enc_helb = bpe_hirurak.encode([l_helb], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        if denak:\n","            azkena = denak[-1]\n","            if not all(azkena):\n","                denak.pop()\n","                enc_jat1 = azkena[0] + enc_jat1\n","                enc_jat2 = azkena[1] + enc_jat2\n","                enc_helb = azkena[2] + enc_helb\n","        gehitu = True\n","        if len(enc_jat1) > max_seq_len:\n","            luzeegiak.append(f'{i}_jat1')\n","            gehitu = False\n","        if len(enc_jat2) > max_seq_len:\n","            luzeegiak.append(f'{i}_jat2')\n","            gehitu = False\n","        if len(enc_helb) > max_seq_len-2:\n","            luzeegiak.append(f'{i}_helb')\n","            gehitu = False\n","        if gehitu:\n","            denak.append([enc_jat1, enc_jat2, enc_helb])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYV2oHG1RHBl","colab_type":"code","colab":{}},"source":["for esaldia in denak:\n","    esaldia[2] = [sos]+esaldia[2]+[eos]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOC1k5aXss96","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1580464583606,"user_tz":-60,"elapsed":38659,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4ddbab7e-760e-4103-c8c3-ecb91582f1a9"},"source":["len(denak)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["607328"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"WIJAJouXtU6-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1580464583607,"user_tz":-60,"elapsed":38632,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"34e6f869-f06d-43a5-eecf-c0ecad6c386f"},"source":["len(luzeegiak)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33766"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"KoIBPvvVOUgJ","colab_type":"code","colab":{}},"source":["random.Random(4).shuffle(denak)\n","dev = denak[:dev_kop]\n","train = denak[dev_kop:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JB09F2Bj-VFN","colab_type":"text"},"source":["## Hauek bai"]},{"cell_type":"code","metadata":{"id":"wig1xL-r6s2I","colab_type":"code","colab":{}},"source":["train_testua = set()\n","with open('EhuHac/EhuHac-trainhobea3-tok-es.txt') as f_jat1, \\\n","     open('EhuHac/EhuHac-trainhobea3-tok-en.txt') as f_jat2, \\\n","     open('EhuHac/EhuHac-trainhobea3-tok-eu.txt') as f_helb:\n","    for l_jat1, l_jat2, l_helb in zip(f_jat1, f_jat2, f_helb):\n","        train_testua.add((l_jat1, l_jat2, l_helb))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ps1thwk7QeC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595354509738,"user_tz":-120,"elapsed":6769,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"70003c69-415d-4bab-ed66-d1c82589b545"},"source":["len(train_testua)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["576755"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"imQG1vHIwM6l","colab_type":"code","colab":{}},"source":["berriak = []\n","with open('OpenSubtitles/OS-train2-tok-es.txt') as f_jat1, \\\n","     open('OpenSubtitles/OS-train2-tok-en.txt') as f_jat2, \\\n","     open('OpenSubtitles/OS-train2-tok-eu.txt') as f_helb:\n","    for hirukotea in zip(f_jat1, f_jat2, f_helb):\n","        if hirukotea not in train_testua:\n","            train_testua.add(hirukotea)\n","            berriak.append(hirukotea)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NlDVfOIXxyIi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594884140584,"user_tz":-120,"elapsed":11407,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"61bb91ff-f73f-4182-bb0e-b55286c94776"},"source":["len(berriak), len(train_testua)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(676842, 1318714)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"21rpcCXfx_pP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":989},"executionInfo":{"status":"ok","timestamp":1594884140586,"user_tz":-120,"elapsed":10930,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9d26a65f-56b1-4297-e93c-aa09c630d77f"},"source":["berriak[100_000:100_020]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('¡￭ ｟C en la canasta ￭!\\n',\n","  '｟C put it in the basket ￭, ｟C chief ￭!\\n',\n","  '｟C sartu saskian ￭, buruzagia ￭!\\n'),\n"," ('｟C las apuestas ￭.\\n', '｟C make the bets ￭.\\n', '｟C egin apustu ￭.\\n'),\n"," ('¿￭ ｟C qué es esto ￭?\\n',\n","  \"- ｟C what ￭'￭ s this ￭?\\n\",\n","  '- ｟C zer da hau ￭?\\n'),\n"," ('｟C hagan sus apuestas ￭.\\n',\n","  '- ｟C make the bets ￭.\\n',\n","  '- ｟C egin apustu ￭.\\n'),\n"," ('｟C son diez centavos ￭.\\n',\n","  \"｟C it ￭'￭ s a dime ￭, ｟C martini ￭.\\n\",\n","  '｟C hamar zentimo ￭, ｟C martini ￭.\\n'),\n"," ('｟C apuesto cinco centavos ￭.\\n',\n","  '｟C i bet a nickel ￭.\\n',\n","  '｟C bost jokatuko ditut ￭.\\n'),\n"," ('｟C diez centavos es lo mínimo ￭.\\n',\n","  \"｟C a dime ￭'￭ s the limit ￭, ｟C martini ￭.\\n\",\n","  '｟C muga hamar da ￭, ｟C martini ￭.\\n'),\n"," ('｟C apuesto diez centavos ￭.\\n',\n","  '｟C i bet a dime ￭.\\n',\n","  '｟C hamar jokatuko ditut ￭.\\n'),\n"," ('｟C esto no vale diez centavos ￭, ｟C martini ￭.\\n',\n","  '｟C this is not a dime ￭, ｟C martini ￭.\\n',\n","  '｟C hau ez da hamarrekoa ￭, ｟C martini ￭.\\n'),\n"," ('｟C esto vale diez centavos ￭.\\n',\n","  '｟C this is a dime ￭.\\n',\n","  '｟C hamarrekoa da ￭.\\n'),\n"," ('｟C si lo partes no obtienes dos que valen cinco ￭, no obtienes nada ￭.\\n',\n","  \"｟C if you break it in half you don ￭'￭ t get two nickels ￭, you get shit ￭.\\n\",\n","  '｟C bitan zatitzen baduzu ez dituzu jasotzen bosteko bi ￭, jasotzen duzu kaka zaharra ￭.\\n'),\n"," ('｟C trata de fumarlo ￭, ¿￭ entiendes ￭?\\n',\n","  '｟C try and smoke it ￭.\\n',\n","  '｟C tori eta erre ￭.\\n'),\n"," ('-￭ ｟C no entiendes ￭.\\n',\n","  \"- ｟C you don ￭'￭ t understand ￭.\\n\",\n","  '- ｟C ez duzu ulertzen ￭.\\n'),\n"," ('｟C bien ￭, aquí vienen ￭.\\n',\n","  '｟C all right ￭, here they come ￭.\\n',\n","  '｟C ederto ￭, banoa ￭.\\n'),\n"," ('｟C la ｟C reina a ｟C chester el ｟C rey para ｟C tabulaciones diez a ｟C billy para empatar ￭. ｟C tres al que da las cartas ￭.\\n',\n","  '｟C queen to the ｟C chesser ￭, big bull to ｟C tabelations 10 to ｟C billy to match his whang ￭, and the dealer gets a three ￭.\\n',\n","  '｟C erregina ｟C chesser-entzat ￭, erregea ｟C tabeli 10eko bat ｟C billy zakiliri ￭, eta banatzaileari ￭, hirukoa ￭.\\n'),\n"," ('｟C carta ￭.\\n', '｟C hit me ￭.\\n', '｟C eman niri ￭.\\n'),\n"," ('｟C no te puedo dar carta ￭, no es tu turno todavía ￭. ¿￭ ｟C entiendes ￭?\\n',\n","  \"｟C i bet a dime ￭. - ｟C i can ￭'￭ t hit you because it ain ￭'￭ t your turn yet ￭. ｟C you understand ￭?\\n\",\n","  '｟C hamarreko bat jokatuko dut ￭. - ｟C ezin dizut eman ez delako zure txanda ￭. ｟C ulertzen ￭?\\n'),\n"," ('¿￭ ｟C ves a los demás ￭?\\n',\n","  '｟C you see these other people ￭?\\n',\n","  '｟C ikusten dituzu beste hauek ￭?\\n'),\n"," ('｟C son ellos los que cuentan ￭.\\n',\n","  '｟C these are the real ones ￭.\\n',\n","  '｟C hauek benetakoak dira ￭.\\n'),\n"," ('｟C ellos cuentan de veras ￭.\\n',\n","  '｟C these are real people here ￭.\\n',\n","  '｟C benetako jendea ￭.\\n')]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"4SSI5B_x-ekC","colab_type":"code","colab":{}},"source":["train = []\n","hutsak = []\n","luzeegiak = []\n","guztira = 0\n","\n","for i, (l_jat1, l_jat2, l_helb) in enumerate(train_testua, 1):    \n","    enc_jat1 = bpe_hirurak.encode([l_jat1], \n","                                    output_type=yttm.OutputType.ID)[0]\n","    enc_jat2 = bpe_hirurak.encode([l_jat2], \n","                                    output_type=yttm.OutputType.ID)[0]\n","    enc_helb = bpe_hirurak.encode([l_helb], \n","                                    output_type=yttm.OutputType.ID)[0]\n","    gehitu = True\n","    if not enc_jat1 or not enc_jat2 or not enc_helb:\n","        hutsak.append(str(i))\n","        gehitu = False\n","    if len(enc_jat1) > max_seq_len:\n","        luzeegiak.append(f'{i}_jat1')\n","        gehitu = False\n","    if len(enc_jat2) > max_seq_len:\n","        luzeegiak.append(f'{i}_jat2')\n","        gehitu = False\n","    if len(enc_helb) > max_seq_len-2:\n","        luzeegiak.append(f'{i}_helb')\n","        gehitu = False\n","    if gehitu:\n","        train.append([enc_jat1, enc_jat2, enc_helb])\n","    guztira += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4HhIOrVbvKjV","colab_type":"code","colab":{}},"source":["# max_seq_len-2 jartzen duen tokian max_seq_len-1 izan beharko luke,\n","# eta decoder-ak ez luke azpihitzen ondoren 'eos' jaso beharko.\n","# Orain ez dut aldatuko."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fenI9aameShj","colab_type":"code","colab":{}},"source":["for esaldia in train:\n","    esaldia[2] = [sos]+esaldia[2]+[eos]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Q90FexWDIMp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595354555314,"user_tz":-120,"elapsed":42155,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ad7c3339-5986-4aec-f6fe-5b25dcc3a9ea"},"source":["                                  # Luzeragatik kendutako kasuak      Esaldi luzeegiak guztira     \n","guztira, len(train), len(hutsak), guztira - len(train) - len(hutsak), len(luzeegiak)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(576755, 562360, 6853, 7542, 13549)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"i_WFYEliLtLS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1595161828876,"user_tz":-120,"elapsed":3541,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"f03a54dd-6504-4d84-fca0-a3fe19db58f5"},"source":["dev1 = []\n","\n","with open('EhuHac/EhuHac-val-tok-es.txt') as f_jat1, \\\n","     open('EhuHac/EhuHac-val-tok-en.txt') as f_jat2, \\\n","     open('EhuHac/EhuHac-val-tok-eu.txt') as f_helb:\n","\n","    for i, (l_jat1, l_jat2, l_helb) in enumerate(zip(f_jat1, f_jat2, f_helb), \n","                                                 1):\n","        enc_jat1 = bpe_hirurak.encode([l_jat1], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        enc_jat2 = bpe_hirurak.encode([l_jat2], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        if len(enc_jat1) > max_seq_len:\n","            print(f'{i}_jat1')\n","        if len(enc_jat2) > max_seq_len:\n","            print(f'{i}_jat2')\n","        dev1.append([enc_jat1[:max_seq_len], \n","                     enc_jat2[:max_seq_len], \n","                     l_helb])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16_jat1\n","16_jat2\n","26_jat1\n","28_jat1\n","28_jat2\n","35_jat1\n","35_jat2\n","42_jat2\n","60_jat1\n","60_jat2\n","69_jat1\n","85_jat1\n","85_jat2\n","137_jat1\n","229_jat1\n","238_jat1\n","242_jat2\n","243_jat1\n","243_jat2\n","319_jat1\n","319_jat2\n","358_jat2\n","504_jat2\n","598_jat2\n","725_jat1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Ddtq7-N9LPl","colab_type":"code","colab":{}},"source":["dev2 = []\n","\n","with open('OpenSubtitles/OS-val-tok-es.txt') as f_jat1, \\\n","     open('OpenSubtitles/OS-val-tok-en.txt') as f_jat2, \\\n","     open('OpenSubtitles/OS-val-tok-eu.txt') as f_helb:\n","\n","    for i, (l_jat1, l_jat2, l_helb) in enumerate(zip(f_jat1, f_jat2, f_helb), \n","                                                 1):\n","        enc_jat1 = bpe_hirurak.encode([l_jat1], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        enc_jat2 = bpe_hirurak.encode([l_jat2], \n","                                      output_type=yttm.OutputType.ID)[0]\n","        if len(enc_jat1) > max_seq_len:\n","            print(f'{i}_jat1')\n","        if len(enc_jat2) > max_seq_len:\n","            print(f'{i}_jat2')\n","        dev2.append([enc_jat1[:max_seq_len], \n","                     enc_jat2[:max_seq_len], \n","                     l_helb])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnX2uhSoND4Q","colab_type":"code","colab":{}},"source":["def ordenatzeko(elem):\n","    return len(elem[0])\n","\n","def ordenatzeko1(elem):\n","    return len(elem[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"92yyhF6uVrpc","colab_type":"code","colab":{}},"source":["def sartu_padding(esaldia, luzera):\n","    return esaldia + (luzera-len(esaldia))*[pad]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-FXUxqCuaWg","colab_type":"code","colab":{}},"source":["def zuzendu_zenbakitua(model, src, b_s):\n","\t\n","    hasi = time.time()\n","\n","    model.eval()\n","   \n","    src = [(esaldia[0], esaldia[1], i) for i, esaldia in enumerate(src)]\n","    src.sort(key=ordenatzeko)\n","    idazteko = len(src) * [\"\\n\"]\n","\t\n","    for i in range(0, len(src), b_s):\n","        batch = src[i : i+b_s]\n","        luzeena = len(batch[-1][0])\n","        src1 = [sartu_padding(esaldia[0], luzeena) for esaldia in batch]\n","        luzeena = max([len(esaldia[1]) for esaldia in batch])\n","        src2 = [sartu_padding(esaldia[1], luzeena) for esaldia in batch]\n","        src1 = torch.LongTensor(src1)\n","        src2 = torch.LongTensor(src2)\n","\t  \n","        src1_mask = (src1 != pad).unsqueeze(-2).cuda()\n","        src2_mask = (src2 != pad).unsqueeze(-2).cuda()\n","        emb1 = model.embed(src1.cuda())\n","        e1_outputs = model.encoder(emb1, src1_mask)\n","        emb2 = model.embed(src2.cuda())\n","        e2_outputs = model.encoder(emb2, src2_mask)\n","\n","        outputs = torch.zeros(len(src1), max_seq_len, dtype=src1.dtype).cuda()\n","\n","        outputs[:, 0] = torch.LongTensor([sos])\n","\n","        for pos in range(1, max_seq_len):\t \n","            trg_mask = torch.tril(torch.ones(\n","                1, pos, pos, dtype=torch.uint8)).cuda()\n","            out = model.out(model.decoder(model.embed(outputs[:, :pos]), \n","                                          e1_outputs, e2_outputs, \n","                                          src1_mask, src2_mask, trg_mask))\n","            out = F.softmax(out, dim=-1)\n","            val, ix = out[:, -1].topk(1)\n","            outputs[:, pos] = ix[:, 0]\n","            # Esaldi guztiek jada \"eos\" badute, gelditu\n","            if outputs.eq(eos).any(1).all():\n","                break\n","\n","        for batch_ix, esaldia in enumerate(outputs):\n","            for pos in range(max_seq_len):\n","                if esaldia[pos] == eos:\n","                    break\n","            deskodetuta = bpe_hirurak.decode(esaldia[1:pos].tolist())[0]\n","            ordenatuko_ix = i + batch_ix\n","            jatorrizko_ix = src[ordenatuko_ix][2]\n","            idazteko[jatorrizko_ix] = deskodetuta\n","\t\n","    print(\"{} segundo behar izan ditu zuzentzeko.\".format(time.time()-hasi))\n","    return idazteko"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZqGX9gbne50g","colab_type":"code","colab":{}},"source":["# src-n jatorrizko bi hizkuntzak datoz. lang = 0 edo 1 hizkuntza aukeratzeko.\n","def zuzendu_zenbakitua_bakarra(model, src, lang, b_s):\n","\t\n","    hasi = time.time()\n","\n","    model.eval()\n","   \n","    src = [(esaldia[lang], i) for i, esaldia in enumerate(src)]\n","    src.sort(key=ordenatzeko)\n","    idazteko = len(src) * [\"\\n\"]\n","\t\n","    for i in range(0, len(src), b_s):\n","        batch = src[i : i+b_s]\n","        luzeena = len(batch[-1][0])\n","        src1 = [sartu_padding(esaldia[0], luzeena) for esaldia in batch]\n","        src1 = torch.LongTensor(src1)\n","\t  \n","        src1_mask = (src1 != pad).unsqueeze(-2).cuda()\n","        emb1 = model.embed(src1.cuda())\n","        e1_outputs = model.encoder(emb1, src1_mask)\n","\n","        outputs = torch.zeros(len(src1), max_seq_len, dtype=src1.dtype).cuda()\n","\n","        outputs[:, 0] = torch.LongTensor([sos])\n","\n","        for pos in range(1, max_seq_len):\t \n","            trg_mask = torch.tril(torch.ones(\n","                1, pos, pos, dtype=torch.uint8)).cuda()\n","            out = model.out(model.decoder(model.embed(outputs[:, :pos]), \n","                                          e1_outputs, \n","                                          src1_mask, trg_mask))\n","            out = F.softmax(out, dim=-1)\n","            val, ix = out[:, -1].topk(1)\n","            outputs[:, pos] = ix[:, 0]\n","            # Esaldi guztiek jada \"eos\" badute, gelditu\n","            if outputs.eq(eos).any(1).all():\n","                break\n","\n","        for batch_ix, esaldia in enumerate(outputs):\n","            for pos in range(max_seq_len):\n","                if esaldia[pos] == eos:\n","                    break\n","            deskodetuta = bpe_hirurak.decode(esaldia[1:pos].tolist())[0]\n","            ordenatuko_ix = i + batch_ix\n","            jatorrizko_ix = src[ordenatuko_ix][1]\n","            idazteko[jatorrizko_ix] = deskodetuta\n","\t\n","    print(\"{} segundo behar izan ditu zuzentzeko.\".format(time.time()-hasi))\n","    return idazteko"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Q4AMq2yG7X2","colab_type":"code","colab":{}},"source":["def berrezarri_maiuskulak(lerroa):\n","    destokenizer = pyonmttok.Tokenizer(\"conservative\", joiner_annotate=True, \n","                                    case_markup=True, soft_case_regions=True)\n","    bertokenizer = pyonmttok.Tokenizer(\"conservative\")#, joiner_annotate=True)\n","    lerroa = lerroa.replace('<UNK>', '')\n","    lerroa = lerroa.replace('｟C', '｟mrk_case_modifier_C｠')\n","    lerroa = lerroa.replace('｟B', '｟mrk_begin_case_region_U｠')\n","    lerroa = lerroa.replace('｟E', '｟mrk_end_case_region_U｠')\n","    jatorrizkoa = destokenizer.detokenize(lerroa.split())\n","    tokenizatua = bertokenizer.tokenize(jatorrizkoa)[0]\n","    # badaezpada, sinbolorik geratu bada:\n","    tokenizatua = [tok for tok in tokenizatua \n","                   if tok not in ['｟mrk_case_modifier_C｠', \n","                                  '｟mrk_begin_case_region_U｠',\n","                                  '｟mrk_end_case_region_U｠']]\n","    return tokenizatua"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0G1Nt_aTsJJo","colab_type":"text"},"source":["# Entrenatzeko"]},{"cell_type":"code","metadata":{"id":"7AVcA51gxJy3","colab_type":"code","colab":{}},"source":["def lortu_batchak():\n","    random.shuffle(train)\n","    for i in range(0, len(train), 10*batch_size):\n","        multzoa = train[i : i+10*batch_size]\n","        multzoa.sort(key=ordenatzeko)\n","        for j in range(0, len(multzoa), batch_size):\n","            batch = multzoa[j : j+batch_size]\n","            luzeena = len(batch[-1][0])\n","            jat1 = [sartu_padding(esaldia[0], luzeena) for esaldia in batch]\n","            luzeena = max([len(esaldia[1]) for esaldia in batch])\n","            jat2 = [sartu_padding(esaldia[1], luzeena) for esaldia in batch]\n","            luzeena = max([len(esaldia[2]) for esaldia in batch])\n","            helb = [sartu_padding(esaldia[2], luzeena) for esaldia in batch]\n","            \n","            jat1 = torch.LongTensor(jat1)\n","            jat2 = torch.LongTensor(jat2)\n","            helb = torch.LongTensor(helb)\n","            \n","            itzultzeko = {'Jatorrizkoa1' : jat1, \n","                          'Jatorrizkoa2' : jat2,\n","                          'Itzulpena' : helb}\n","            yield itzultzeko"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mB_A0t3vfpFB","colab_type":"code","colab":{}},"source":["def sortu_maskarak_dual(input_seq1, input_seq2, trg_input):\n","\n","    input_mask1 = (input_seq1 != pad).unsqueeze(-2)\n","\n","    input_mask2 = (input_seq2 != pad).unsqueeze(-2)\n","\n","    target_mask = (trg_input != pad).unsqueeze(-2)\n","    size = trg_input.size(1)\n","    nopeek_mask = torch.tril(torch.ones(1, size, size, dtype=torch.bool))\n","    target_mask = (target_mask & nopeek_mask)\n","\n","    return input_mask1, input_mask2, target_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvmOyVs8qv4b","colab_type":"code","colab":{}},"source":["def balidatu(dev):\n","    model.eval()\n","\n","    print(\"--- Balidazioa ---\")\n","\n","    references = [[esaldia[2].split()] for esaldia in dev]\n","\t\n","    zuzendua = zuzendu_zenbakitua(model, dev, batch_size_val)\n","    candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","    \n","    bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","\t\n","    print(\"Hasierakoak:\")\n","    print(zuzendua[:20])\n","    print(\"BLEU puntuazioa: {}\".format(bleu))\n","\t\n","    model.train()\n","  \n","    return bleu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YzKnRifl5WLN","colab_type":"code","colab":{}},"source":["def balidatu2(dev1, dev2):\n","    print(\"--- Balidazioa ---\")\n","\n","    references1 = [[esaldia[2].split()] for esaldia in dev1]\n","\t\n","    zuzendua1 = zuzendu_zenbakitua(model, dev1, batch_size_val)\n","    candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","    \n","    bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","    print(\"Batzuk (1):\")\n","    print(zuzendua1[:20])\n","    print(\"BLEU puntuazioa (1): {}\".format(bleu1))\n","\n","    references2 = [[esaldia[2].split()] for esaldia in dev2]\n","\t\n","    zuzendua2 = zuzendu_zenbakitua(model, dev2, batch_size_val)\n","    candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","    \n","    bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","    print(\"Batzuk (2):\")\n","    print(zuzendua2[100:120])\n","    print(\"BLEU puntuazioa (2): {}\".format(bleu2))\n","\n","    bleu3 = nltk.translate.bleu_score.corpus_bleu(references1 + references2,\n","                                                  candidates1 + candidates2)*100\n","\n","    print(\"BLEU puntuazioa (biak): {}\".format(bleu3))\n","\n","    model.train()\n","  \n","    return bleu3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrBexYEPf7un","colab_type":"code","colab":{}},"source":["def entrenatu(hasi_epoch=0):\n","\n","    start = time.time()\n","    temp = start\n","\n","    total_loss = 0\n","\n","    model.train()\n","\n","    for epoch in range(hasi_epoch, epochs):\n","\n","        for i, batch in enumerate(lortu_batchak(), 1):\n","            src1 = batch['Jatorrizkoa1']\n","            src2 = batch['Jatorrizkoa2']\n","            trg = batch['Itzulpena']\n","\n","            trg_input = trg[:, :-1]\n","\n","            targets = trg[:, 1:].reshape(-1)\n","\n","            src_mask1, src_mask2, trg_mask = sortu_maskarak_dual(src1, src2, \n","                                                                 trg_input)\n","\n","            preds = model(src1.cuda(), src2.cuda(), trg_input.cuda(), \n","                        src_mask1.cuda(), src_mask2.cuda(), trg_mask.cuda())\n","\n","            loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n","                targets.cuda(), ignore_index=pad)\n","            \n","            optim.zero_grad()\n","\n","            if fp16:\n","                with amp.scale_loss(loss, optim) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","            \n","            optim.step()\n","\n","            total_loss += loss.item()\n","            \n","            if i % zenbatero_idatzi == 0:\n","                loss_avg = total_loss / zenbatero_idatzi\n","                print(\"time = {}, epoch {}, iter = {}, loss = {}, {} s per {} iters\".format(\n","                (time.time() - start) // 60,\n","                epoch, i, loss_avg, time.time() - temp, zenbatero_idatzi))\n","                total_loss = 0\n","                #print(\"Hartutako memoria\", torch.cuda.max_memory_allocated(0))\n","                temp = time.time()  \n","        \n","        #torch.save(model.state_dict(), f\"EhuHac/modeloaorig-{epoch}.pt\")\n","        if fp16:\n","            checkpoint = {\n","                'model': model.state_dict(),\n","                #'optimizer': optim.state_dict(),\n","                'amp': amp.state_dict(),\n","            }\n","        else:\n","            checkpoint = {\n","                'model': model.state_dict(),\n","                'optimizer': optim.state_dict(),\n","            }\n","        torch.save(checkpoint, f\"HACOSDatuak/origetaos2-{epoch}.pt\")\n","\n","        balidatu2(dev1, dev2)\n","        \n","        temp = time.time()        \n","        total_loss = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQhniIxTbCTv","colab_type":"text"},"source":["# Iturri bakarrarekin entrenatzeko"]},{"cell_type":"code","metadata":{"id":"ERDVPPdMbGHp","colab_type":"code","colab":{}},"source":["def lortu_batchak_bakarra(lang):\n","    random.shuffle(train)\n","    for i in range(0, len(train), 10*batch_size):\n","        multzoa = train[i : i+10*batch_size]\n","        if lang == 0:\n","            multzoa.sort(key=ordenatzeko)\n","        else:\n","            multzoa.sort(key=ordenatzeko1)\n","        for j in range(0, len(multzoa), batch_size):\n","            batch = multzoa[j : j+batch_size]\n","            luzeena = len(batch[-1][lang])\n","            jat1 = [sartu_padding(esaldia[lang], luzeena) for esaldia in batch]\n","            luzeena = max([len(esaldia[2]) for esaldia in batch])\n","            helb = [sartu_padding(esaldia[2], luzeena) for esaldia in batch]\n","            \n","            jat1 = torch.LongTensor(jat1)\n","            helb = torch.LongTensor(helb)\n","            \n","            itzultzeko = {'Jatorrizkoa1' : jat1,\n","                          'Itzulpena' : helb}\n","            yield itzultzeko"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4H7P4-AFdJqy","colab_type":"code","colab":{}},"source":["def sortu_maskarak(input_seq, trg_input):\n","\n","  input_mask = (input_seq != pad).unsqueeze(-2)\n","\n","  target_mask = (trg_input != pad).unsqueeze(-2)\n","  size = trg_input.size(1)\n","  nopeek_mask = torch.tril(torch.ones(1, size, size, dtype=torch.bool))\n","  target_mask = (target_mask & nopeek_mask)\n","\n","  return input_mask, target_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0F-jFEM_dz5j","colab_type":"code","colab":{}},"source":["def balidatu2_bakarra(dev1, dev2, lang):\n","    print(\"--- Balidazioa ---\")\n","\n","    references1 = [[esaldia[2].split()] for esaldia in dev1]\n","\t\n","    zuzendua1 = zuzendu_zenbakitua_bakarra(model, dev1, lang, batch_size_val)\n","    candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","    \n","    bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","    print(\"Batzuk (1):\")\n","    print(zuzendua1[:20])\n","    print(\"BLEU puntuazioa (1): {}\".format(bleu1))\n","\n","    references2 = [[esaldia[2].split()] for esaldia in dev2]\n","\t\n","    zuzendua2 = zuzendu_zenbakitua_bakarra(model, dev2, lang, batch_size_val)\n","    candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","    \n","    bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","    print(\"Batzuk (2):\")\n","    print(zuzendua2[100:120])\n","    print(\"BLEU puntuazioa (2): {}\".format(bleu2))\n","\n","    bleu3 = nltk.translate.bleu_score.corpus_bleu(references1 + references2,\n","                                                  candidates1 + candidates2)*100\n","\n","    print(\"BLEU puntuazioa (biak): {}\".format(bleu3))\n","\n","    model.train()\n","  \n","    return bleu3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXsqFNLeiFx2","colab_type":"code","colab":{}},"source":["def entrenatu_bakarra(lang, hasi_epoch=0):\n","\n","    start = time.time()\n","    temp = start\n","\n","    total_loss = 0\n","\n","    model.train()\n","\n","    for epoch in range(hasi_epoch, epochs):\n","\n","        for i, batch in enumerate(lortu_batchak_bakarra(lang), 1):\n","            src1 = batch['Jatorrizkoa1']\n","            trg = batch['Itzulpena']\n","\n","            trg_input = trg[:, :-1]\n","\n","            targets = trg[:, 1:].reshape(-1)\n","\n","            src_mask1, trg_mask = sortu_maskarak(src1, trg_input)\n","\n","            preds = model(src1.cuda(), trg_input.cuda(), \n","                          src_mask1.cuda(), trg_mask.cuda())\n","\n","            loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n","                targets.cuda(), ignore_index=pad)\n","            \n","            optim.zero_grad()\n","\n","            if fp16:\n","                with amp.scale_loss(loss, optim) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","            \n","            optim.step()\n","\n","            total_loss += loss.item()\n","            \n","            if i % zenbatero_idatzi == 0:\n","                loss_avg = total_loss / zenbatero_idatzi\n","                print(\"time = {}, epoch {}, iter = {}, loss = {}, {} s per {} iters\".format(\n","                (time.time() - start) // 60,\n","                epoch, i, loss_avg, time.time() - temp, zenbatero_idatzi))\n","                total_loss = 0\n","                #print(\"Hartutako memoria\", torch.cuda.max_memory_allocated(0))\n","                temp = time.time()\n","        \n","        #torch.save(model.state_dict(), f\"EhuHac/modeloaorig-{epoch}.pt\")\n","        if fp16:\n","            checkpoint = {\n","                'model': model.state_dict(),\n","                #'optimizer': optim.state_dict(),\n","                'amp': amp.state_dict(),\n","            }\n","        else:\n","            checkpoint = {\n","                'model': model.state_dict(),\n","                'optimizer': optim.state_dict(),\n","            }\n","        torch.save(checkpoint, f\"HACOSDatuak/enbakarrik-{epoch}.pt\")\n","\n","        balidatu2_bakarra(dev1, dev2, lang)\n","        \n","        temp = time.time()        \n","        total_loss = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nFTzchG_t7RD","colab_type":"text"},"source":["# Hasieratik entrenatzeko"]},{"cell_type":"code","metadata":{"id":"LdMNbVZbXVxa","colab_type":"code","colab":{}},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuQdsptRemTL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594288902751,"user_tz":-120,"elapsed":48190,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"afe119ce-4998-42e2-aa6d-096f232130ad"},"source":["for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","        \n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"F9ZtMi7hfgjC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1594149879189,"user_tz":-120,"elapsed":1951,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"97e340c0-92c3-4ceb-f025-39e40e0d7a08"},"source":["optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","#optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k_n6bHkAadC6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594161091300,"user_tz":-120,"elapsed":11213049,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d6b86831-d015-4671-fb25-d7eb947b1966"},"source":["entrenatu()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time = 0.0, epoch 0, iter = 100, loss = 7.40493453502655, 39.09270262718201 s per 100 iters\n","time = 1.0, epoch 0, iter = 200, loss = 6.071168727874756, 37.91073656082153 s per 100 iters\n","time = 1.0, epoch 0, iter = 300, loss = 5.859578092098236, 37.97807693481445 s per 100 iters\n","time = 2.0, epoch 0, iter = 400, loss = 5.6731850934028625, 37.171194314956665 s per 100 iters\n","time = 3.0, epoch 0, iter = 500, loss = 5.598337354660035, 36.89394545555115 s per 100 iters\n","time = 3.0, epoch 0, iter = 600, loss = 5.486905906200409, 38.68329477310181 s per 100 iters\n","time = 4.0, epoch 0, iter = 700, loss = 5.327741959095001, 37.810707807540894 s per 100 iters\n","time = 5.0, epoch 0, iter = 800, loss = 5.208863472938537, 38.75238823890686 s per 100 iters\n","time = 5.0, epoch 0, iter = 900, loss = 5.124916846752167, 37.70358061790466 s per 100 iters\n","time = 6.0, epoch 0, iter = 1000, loss = 5.046025097370148, 37.900655031204224 s per 100 iters\n","time = 6.0, epoch 0, iter = 1100, loss = 5.013378136157989, 38.136672496795654 s per 100 iters\n","time = 7.0, epoch 0, iter = 1200, loss = 4.96773886680603, 38.214088439941406 s per 100 iters\n","time = 8.0, epoch 0, iter = 1300, loss = 4.892977147102356, 38.28152084350586 s per 100 iters\n","time = 8.0, epoch 0, iter = 1400, loss = 4.874634664058686, 38.243818044662476 s per 100 iters\n","time = 9.0, epoch 0, iter = 1500, loss = 4.808138785362243, 38.40065002441406 s per 100 iters\n","time = 10.0, epoch 0, iter = 1600, loss = 4.750036818981171, 37.294196367263794 s per 100 iters\n","time = 10.0, epoch 0, iter = 1700, loss = 4.7059660911560055, 37.858356952667236 s per 100 iters\n","time = 11.0, epoch 0, iter = 1800, loss = 4.707943453788757, 37.93076133728027 s per 100 iters\n","time = 12.0, epoch 0, iter = 1900, loss = 4.645480074882507, 38.48488259315491 s per 100 iters\n","time = 12.0, epoch 0, iter = 2000, loss = 4.616473982334137, 38.29371380805969 s per 100 iters\n","time = 13.0, epoch 0, iter = 2100, loss = 4.580980100631714, 38.284268856048584 s per 100 iters\n","time = 13.0, epoch 0, iter = 2200, loss = 4.558030025959015, 38.343997955322266 s per 100 iters\n","time = 14.0, epoch 0, iter = 2300, loss = 4.507015318870544, 38.36464047431946 s per 100 iters\n","time = 15.0, epoch 0, iter = 2400, loss = 4.477879509925843, 37.907453775405884 s per 100 iters\n","time = 15.0, epoch 0, iter = 2500, loss = 4.418411965370178, 38.41896343231201 s per 100 iters\n","time = 16.0, epoch 0, iter = 2600, loss = 4.361705210208893, 37.63626050949097 s per 100 iters\n","time = 17.0, epoch 0, iter = 2700, loss = 4.3530020952224735, 37.59198522567749 s per 100 iters\n","time = 17.0, epoch 0, iter = 2800, loss = 4.320572695732117, 37.47334313392639 s per 100 iters\n","time = 18.0, epoch 0, iter = 2900, loss = 4.2998963379859925, 37.44872689247131 s per 100 iters\n","time = 19.0, epoch 0, iter = 3000, loss = 4.282400908470154, 37.94512915611267 s per 100 iters\n","time = 19.0, epoch 0, iter = 3100, loss = 4.2236124658584595, 37.70984935760498 s per 100 iters\n","time = 20.0, epoch 0, iter = 3200, loss = 4.215000054836273, 37.77387881278992 s per 100 iters\n","time = 20.0, epoch 0, iter = 3300, loss = 4.188181357383728, 38.53476595878601 s per 100 iters\n","time = 21.0, epoch 0, iter = 3400, loss = 4.1445666956901555, 37.78610134124756 s per 100 iters\n","time = 22.0, epoch 0, iter = 3500, loss = 4.158320066928863, 38.301677227020264 s per 100 iters\n","time = 22.0, epoch 0, iter = 3600, loss = 4.114673779010773, 37.334331035614014 s per 100 iters\n","time = 23.0, epoch 0, iter = 3700, loss = 4.080211579799652, 37.57354950904846 s per 100 iters\n","time = 24.0, epoch 0, iter = 3800, loss = 4.057901136875152, 38.29439949989319 s per 100 iters\n","time = 24.0, epoch 0, iter = 3900, loss = 3.984295897483826, 38.17424535751343 s per 100 iters\n","time = 25.0, epoch 0, iter = 4000, loss = 3.9643059825897216, 37.68020963668823 s per 100 iters\n","time = 25.0, epoch 0, iter = 4100, loss = 3.967150568962097, 37.86820983886719 s per 100 iters\n","time = 26.0, epoch 0, iter = 4200, loss = 3.9569256997108457, 38.22390341758728 s per 100 iters\n","time = 27.0, epoch 0, iter = 4300, loss = 3.903504132032394, 38.25411891937256 s per 100 iters\n","time = 27.0, epoch 0, iter = 4400, loss = 3.8540613758563995, 37.41032814979553 s per 100 iters\n","time = 28.0, epoch 0, iter = 4500, loss = 3.852668468952179, 37.953181743621826 s per 100 iters\n","time = 29.0, epoch 0, iter = 4600, loss = 3.8657566010951996, 37.883246660232544 s per 100 iters\n","time = 29.0, epoch 0, iter = 4700, loss = 3.8156733989715574, 37.29729080200195 s per 100 iters\n","time = 30.0, epoch 0, iter = 4800, loss = 3.8121255612373353, 37.78889298439026 s per 100 iters\n","time = 30.0, epoch 0, iter = 4900, loss = 3.7740156686306, 37.26079869270325 s per 100 iters\n","time = 31.0, epoch 0, iter = 5000, loss = 3.7752663016319277, 37.60633087158203 s per 100 iters\n","time = 32.0, epoch 0, iter = 5100, loss = 3.7494386768341066, 37.81129431724548 s per 100 iters\n","time = 32.0, epoch 0, iter = 5200, loss = 3.7283078837394714, 38.04310059547424 s per 100 iters\n","time = 33.0, epoch 0, iter = 5300, loss = 3.684546378850937, 37.36643934249878 s per 100 iters\n","time = 34.0, epoch 0, iter = 5400, loss = 3.674038472175598, 37.94762325286865 s per 100 iters\n","time = 34.0, epoch 0, iter = 5500, loss = 3.6509466004371642, 38.06794357299805 s per 100 iters\n","time = 35.0, epoch 0, iter = 5600, loss = 3.657857497930527, 38.385825872421265 s per 100 iters\n","time = 36.0, epoch 0, iter = 5700, loss = 3.614946002960205, 38.72614765167236 s per 100 iters\n","time = 36.0, epoch 0, iter = 5800, loss = 3.6103205883502962, 37.567750453948975 s per 100 iters\n","time = 37.0, epoch 0, iter = 5900, loss = 3.598368366956711, 38.94727396965027 s per 100 iters\n","time = 37.0, epoch 0, iter = 6000, loss = 3.5553473591804505, 37.26288414001465 s per 100 iters\n","time = 38.0, epoch 0, iter = 6100, loss = 3.5460362231731413, 38.36477208137512 s per 100 iters\n","time = 39.0, epoch 0, iter = 6200, loss = 3.534363145828247, 38.061187744140625 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 39.0, epoch 0, iter = 6300, loss = 3.5165281093120573, 37.714245557785034 s per 100 iters\n","time = 40.0, epoch 0, iter = 6400, loss = 3.475475997924805, 37.56287121772766 s per 100 iters\n","time = 41.0, epoch 0, iter = 6500, loss = 3.4788393700122833, 38.51320123672485 s per 100 iters\n","time = 41.0, epoch 0, iter = 6600, loss = 3.4901322674751283, 37.98451519012451 s per 100 iters\n","time = 42.0, epoch 0, iter = 6700, loss = 3.4572353744506836, 37.59670400619507 s per 100 iters\n","time = 43.0, epoch 0, iter = 6800, loss = 3.4357105469703675, 38.863852977752686 s per 100 iters\n","time = 43.0, epoch 0, iter = 6900, loss = 3.403896842002869, 37.80873107910156 s per 100 iters\n","time = 44.0, epoch 0, iter = 7000, loss = 3.3985113918781282, 37.7278938293457 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 44.0, epoch 0, iter = 7100, loss = 3.376221367120743, 38.615962505340576 s per 100 iters\n","time = 45.0, epoch 0, iter = 7200, loss = 3.3542369854450227, 37.97160053253174 s per 100 iters\n","time = 46.0, epoch 0, iter = 7300, loss = 3.3460436236858366, 37.73055911064148 s per 100 iters\n","time = 46.0, epoch 0, iter = 7400, loss = 3.3273779118061064, 37.315369606018066 s per 100 iters\n","time = 47.0, epoch 0, iter = 7500, loss = 3.333161356449127, 38.642085790634155 s per 100 iters\n","time = 48.0, epoch 0, iter = 7600, loss = 3.281161768436432, 36.662267208099365 s per 100 iters\n","time = 48.0, epoch 0, iter = 7700, loss = 3.3106257092952727, 38.096579790115356 s per 100 iters\n","time = 49.0, epoch 0, iter = 7800, loss = 3.279490075111389, 38.29897475242615 s per 100 iters\n","time = 49.0, epoch 0, iter = 7900, loss = 3.2415125918388368, 37.06565976142883 s per 100 iters\n","time = 50.0, epoch 0, iter = 8000, loss = 3.258788458108902, 38.364760398864746 s per 100 iters\n","time = 51.0, epoch 0, iter = 8100, loss = 3.2146896111965177, 38.0403413772583 s per 100 iters\n","time = 51.0, epoch 0, iter = 8200, loss = 3.2171450090408324, 37.85439109802246 s per 100 iters\n","time = 52.0, epoch 0, iter = 8300, loss = 3.221734153032303, 38.52151656150818 s per 100 iters\n","time = 53.0, epoch 0, iter = 8400, loss = 3.2081373727321623, 37.66296863555908 s per 100 iters\n","time = 53.0, epoch 0, iter = 8500, loss = 3.1977937769889833, 37.91460919380188 s per 100 iters\n","time = 54.0, epoch 0, iter = 8600, loss = 3.1912150728702544, 38.060497522354126 s per 100 iters\n","time = 55.0, epoch 0, iter = 8700, loss = 3.1802468478679655, 38.026307582855225 s per 100 iters\n","time = 55.0, epoch 0, iter = 8800, loss = 3.1171693348884584, 37.79248023033142 s per 100 iters\n","time = 56.0, epoch 0, iter = 8900, loss = 3.127590184211731, 37.838274240493774 s per 100 iters\n","time = 56.0, epoch 0, iter = 9000, loss = 3.13224920630455, 37.16765856742859 s per 100 iters\n","time = 57.0, epoch 0, iter = 9100, loss = 3.146739114522934, 38.68897318840027 s per 100 iters\n","time = 58.0, epoch 0, iter = 9200, loss = 3.098594385385513, 37.75494313240051 s per 100 iters\n","time = 58.0, epoch 0, iter = 9300, loss = 3.0888017988204957, 38.70614314079285 s per 100 iters\n","time = 59.0, epoch 0, iter = 9400, loss = 3.0892491042613983, 38.04531455039978 s per 100 iters\n","time = 60.0, epoch 0, iter = 9500, loss = 3.0769944763183594, 37.337895154953 s per 100 iters\n","time = 60.0, epoch 0, iter = 9600, loss = 3.039494141340256, 37.05412006378174 s per 100 iters\n","time = 61.0, epoch 0, iter = 9700, loss = 3.0580153036117554, 37.96105337142944 s per 100 iters\n","time = 61.0, epoch 0, iter = 9800, loss = 3.0129274213314057, 37.20061373710632 s per 100 iters\n","time = 62.0, epoch 0, iter = 9900, loss = 3.0313652634620665, 37.64116096496582 s per 100 iters\n","time = 63.0, epoch 0, iter = 10000, loss = 3.0323778009414672, 37.769006967544556 s per 100 iters\n","time = 63.0, epoch 0, iter = 10100, loss = 3.0041195559501648, 38.83257794380188 s per 100 iters\n","time = 64.0, epoch 0, iter = 10200, loss = 3.012446712255478, 37.672990798950195 s per 100 iters\n","time = 65.0, epoch 0, iter = 10300, loss = 2.981911646127701, 37.29321312904358 s per 100 iters\n","time = 65.0, epoch 0, iter = 10400, loss = 2.975365937948227, 37.61932110786438 s per 100 iters\n","time = 66.0, epoch 0, iter = 10500, loss = 2.976953248977661, 37.932456254959106 s per 100 iters\n","time = 67.0, epoch 0, iter = 10600, loss = 2.9676219820976257, 38.63210988044739 s per 100 iters\n","time = 67.0, epoch 0, iter = 10700, loss = 2.962548861503601, 38.68133044242859 s per 100 iters\n","time = 68.0, epoch 0, iter = 10800, loss = 2.9544016015529633, 38.01851010322571 s per 100 iters\n","time = 68.0, epoch 0, iter = 10900, loss = 2.950542731285095, 37.90787196159363 s per 100 iters\n","time = 69.0, epoch 0, iter = 11000, loss = 2.9303386974334718, 37.81510853767395 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 70.0, epoch 0, iter = 11100, loss = 2.921932723522186, 37.107303857803345 s per 100 iters\n","time = 70.0, epoch 0, iter = 11200, loss = 2.919917221069336, 38.22245669364929 s per 100 iters\n","time = 71.0, epoch 0, iter = 11300, loss = 2.923995770215988, 37.74218511581421 s per 100 iters\n","time = 72.0, epoch 0, iter = 11400, loss = 2.905987664461136, 37.838927268981934 s per 100 iters\n","time = 72.0, epoch 0, iter = 11500, loss = 2.906340835094452, 37.70629906654358 s per 100 iters\n","time = 73.0, epoch 0, iter = 11600, loss = 2.8890458190441133, 38.518946170806885 s per 100 iters\n","time = 73.0, epoch 0, iter = 11700, loss = 2.8961710381507872, 38.13595485687256 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 74.0, epoch 0, iter = 11800, loss = 2.8632353961467745, 37.991302490234375 s per 100 iters\n","time = 75.0, epoch 0, iter = 11900, loss = 2.883088369369507, 38.73057270050049 s per 100 iters\n","time = 75.0, epoch 0, iter = 12000, loss = 2.8261620450019835, 37.551695823669434 s per 100 iters\n","time = 76.0, epoch 0, iter = 12100, loss = 2.8313159835338593, 37.755918979644775 s per 100 iters\n","time = 77.0, epoch 0, iter = 12200, loss = 2.8348682951927184, 36.95219707489014 s per 100 iters\n","time = 77.0, epoch 0, iter = 12300, loss = 2.8426937890052795, 37.75387907028198 s per 100 iters\n","time = 78.0, epoch 0, iter = 12400, loss = 2.8432401311397553, 38.435545921325684 s per 100 iters\n","time = 79.0, epoch 0, iter = 12500, loss = 2.8321252393722536, 38.294437885284424 s per 100 iters\n","time = 79.0, epoch 0, iter = 12600, loss = 2.814203459024429, 38.085869789123535 s per 100 iters\n","time = 80.0, epoch 0, iter = 12700, loss = 2.7991414880752563, 38.33424663543701 s per 100 iters\n","time = 80.0, epoch 0, iter = 12800, loss = 2.7901551938056945, 37.485905170440674 s per 100 iters\n","time = 81.0, epoch 0, iter = 12900, loss = 2.8151259696483613, 38.282360792160034 s per 100 iters\n","time = 82.0, epoch 0, iter = 13000, loss = 2.757122677564621, 38.27140140533447 s per 100 iters\n","time = 82.0, epoch 0, iter = 13100, loss = 2.7633915436267853, 37.62160348892212 s per 100 iters\n","time = 83.0, epoch 0, iter = 13200, loss = 2.817269028425217, 38.856618881225586 s per 100 iters\n","time = 84.0, epoch 0, iter = 13300, loss = 2.7707572960853577, 37.62944412231445 s per 100 iters\n","time = 84.0, epoch 0, iter = 13400, loss = 2.772927587032318, 38.952728509902954 s per 100 iters\n","time = 85.0, epoch 0, iter = 13500, loss = 2.7602604269981383, 38.33044981956482 s per 100 iters\n","time = 86.0, epoch 0, iter = 13600, loss = 2.7685049104690553, 37.74357581138611 s per 100 iters\n","time = 86.0, epoch 0, iter = 13700, loss = 2.7488659131526947, 38.08601403236389 s per 100 iters\n","time = 87.0, epoch 0, iter = 13800, loss = 2.766482127904892, 38.043267011642456 s per 100 iters\n","time = 87.0, epoch 0, iter = 13900, loss = 2.737308194637299, 37.885298013687134 s per 100 iters\n","time = 88.0, epoch 0, iter = 14000, loss = 2.717590082883835, 37.858275413513184 s per 100 iters\n","time = 89.0, epoch 0, iter = 14100, loss = 2.703573716878891, 37.39950609207153 s per 100 iters\n","time = 89.0, epoch 0, iter = 14200, loss = 2.7573100233078005, 38.23859763145447 s per 100 iters\n","time = 90.0, epoch 0, iter = 14300, loss = 2.7191137433052064, 37.3332724571228 s per 100 iters\n","--- Balidazioa ---\n","67.28432178497314 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C inius-ek ez du favaliahamarerik ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hori ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da bitxia ￭?', '｟C colinek berriro gelditu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da hain leiala eta betea ￭.', '｟C eta bere ｟C agentra ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C pirronetako neska ￭, eta ｟C pirronetako neska gazteen xarma ￭, eta ｟C donfonetako ｟C fabriziok ￭, ｟C donfageleko jauregiko ｟C kapitelaren eta ｟C kapitainak ez zela ustekoko jauregiko jauregiko jauregiko eroa zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C magistratuak eta beste ofizialek ￭, exekuzio eta exekuzio ￭, zigorra eta zigorra ￭, zigorra eta zigorra ￭, boterearen eta boterearen jabe den boterearen bidez ￭, ｟C erokorentzat ￭, ｟C pisonek ￭, ｟C pisonen eta ｟C ondasun guztiak ￭, ｟C pisonen eta ｟C pisonen ｟C gorputzeko ｟C boterearen gorputzeko boterearen jabeak ￭, ｟C pisonen ￭, ｟C boterearen eta ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C botere', '｟C jimmyk aurkitu zuenean ￭, ez zuen poliziari deitu ￭.', 'ideal hori ere bere ideal hori ￭, haientzat ￭, eta inork ez dute ￭, ez dute ￭, ez dute beste inork ￭, bere garaiko boterearen eta indartsuena ￭, bere gerriko eta indartsuena ￭, bere gerriko eta erlazioa ￭, bere sortzaileen eta erlazioa ￭, bere erlazioa ￭, eta bere erlazioa ￭, bere sorturiko erlazioa ￭, eta erlazioa ￭, eta erlazioa ￭, eta erlazioa ￭, hain zuzen ere ￭, eta bere baitan ￭, eta ￭, hain zuzen ere ￭, hain zuzen ere ￭, hain zuzen ere ￭, ez baita ￭, ez baita', '｟C hegoaldean ez dago esklabu gaixoik ez esklaburik ￭.', '｟C gutxienez ￭, ｟C hwatt eta orain ｟C maffiako ｟C salfatarekin ￭?']\n","BLEU puntuazioa (1): 5.161872480502838\n","9.886573553085327 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria hartzen duela ￭?', '｟C corvettearen historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikusiko ditugu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua etorri zela uste nuen mendekatzeko ￭.', '｟C dut jaunaren ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C basoan otso izango da ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ez zaizu axola ￭?', '1960an erakutsi eta 1940ko semearekin ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C zoaz lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t.￭ w ￭. ｟C went ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphine badakiela ￭?']\n","BLEU puntuazioa (2): 19.605134164767247\n","BLEU puntuazioa (biak): 8.386902620986259\n","time = 92.0, epoch 1, iter = 100, loss = 2.653516639471054, 39.401288986206055 s per 100 iters\n","time = 93.0, epoch 1, iter = 200, loss = 2.613620190620422, 37.845736026763916 s per 100 iters\n","time = 93.0, epoch 1, iter = 300, loss = 2.6128687119483947, 38.17499351501465 s per 100 iters\n","time = 94.0, epoch 1, iter = 400, loss = 2.6406526625156403, 38.38266444206238 s per 100 iters\n","time = 95.0, epoch 1, iter = 500, loss = 2.6097271037101746, 37.96807909011841 s per 100 iters\n","time = 95.0, epoch 1, iter = 600, loss = 2.6213920629024505, 37.93154335021973 s per 100 iters\n","time = 96.0, epoch 1, iter = 700, loss = 2.636368089914322, 37.81743001937866 s per 100 iters\n","time = 97.0, epoch 1, iter = 800, loss = 2.5778249645233156, 38.096014738082886 s per 100 iters\n","time = 97.0, epoch 1, iter = 900, loss = 2.628752411603928, 38.3389618396759 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 98.0, epoch 1, iter = 1000, loss = 2.6187482082843783, 37.803672552108765 s per 100 iters\n","time = 98.0, epoch 1, iter = 1100, loss = 2.626031806468964, 37.21096181869507 s per 100 iters\n","time = 99.0, epoch 1, iter = 1200, loss = 2.601353704929352, 37.59401893615723 s per 100 iters\n","time = 100.0, epoch 1, iter = 1300, loss = 2.5787957274913786, 37.21276307106018 s per 100 iters\n","time = 100.0, epoch 1, iter = 1400, loss = 2.5984029138088225, 38.53601956367493 s per 100 iters\n","time = 101.0, epoch 1, iter = 1500, loss = 2.5910612607002257, 38.458887577056885 s per 100 iters\n","time = 102.0, epoch 1, iter = 1600, loss = 2.580630873441696, 37.57975745201111 s per 100 iters\n","time = 102.0, epoch 1, iter = 1700, loss = 2.5720585978031156, 38.22466778755188 s per 100 iters\n","time = 103.0, epoch 1, iter = 1800, loss = 2.5878393399715423, 38.36309266090393 s per 100 iters\n","time = 104.0, epoch 1, iter = 1900, loss = 2.5524541771411897, 37.77453088760376 s per 100 iters\n","time = 104.0, epoch 1, iter = 2000, loss = 2.5452484035491945, 38.97239875793457 s per 100 iters\n","time = 105.0, epoch 1, iter = 2100, loss = 2.554088536500931, 38.126896381378174 s per 100 iters\n","time = 105.0, epoch 1, iter = 2200, loss = 2.5493335580825804, 36.92189121246338 s per 100 iters\n","time = 106.0, epoch 1, iter = 2300, loss = 2.5586030793190004, 37.943482637405396 s per 100 iters\n","time = 107.0, epoch 1, iter = 2400, loss = 2.566335120201111, 37.66046142578125 s per 100 iters\n","time = 107.0, epoch 1, iter = 2500, loss = 2.551031219959259, 38.46547818183899 s per 100 iters\n","time = 108.0, epoch 1, iter = 2600, loss = 2.513940165042877, 37.34444046020508 s per 100 iters\n","time = 109.0, epoch 1, iter = 2700, loss = 2.5519839334487915, 38.68930983543396 s per 100 iters\n","time = 109.0, epoch 1, iter = 2800, loss = 2.565184737443924, 37.966750144958496 s per 100 iters\n","time = 110.0, epoch 1, iter = 2900, loss = 2.5623552668094636, 38.22357940673828 s per 100 iters\n","time = 111.0, epoch 1, iter = 3000, loss = 2.551255986690521, 37.825982093811035 s per 100 iters\n","time = 111.0, epoch 1, iter = 3100, loss = 2.536960527896881, 38.54644775390625 s per 100 iters\n","time = 112.0, epoch 1, iter = 3200, loss = 2.526441729068756, 37.74638032913208 s per 100 iters\n","time = 112.0, epoch 1, iter = 3300, loss = 2.5012740671634672, 37.79330515861511 s per 100 iters\n","time = 113.0, epoch 1, iter = 3400, loss = 2.527110332250595, 37.704410552978516 s per 100 iters\n","time = 114.0, epoch 1, iter = 3500, loss = 2.538415938615799, 38.70317363739014 s per 100 iters\n","time = 114.0, epoch 1, iter = 3600, loss = 2.5290828132629395, 38.03054189682007 s per 100 iters\n","time = 115.0, epoch 1, iter = 3700, loss = 2.4965512013435363, 38.236698627471924 s per 100 iters\n","time = 116.0, epoch 1, iter = 3800, loss = 2.5088492047786715, 37.738131284713745 s per 100 iters\n","time = 116.0, epoch 1, iter = 3900, loss = 2.505851895809174, 38.383421897888184 s per 100 iters\n","time = 117.0, epoch 1, iter = 4000, loss = 2.4912843596935272, 37.138869524002075 s per 100 iters\n","time = 117.0, epoch 1, iter = 4100, loss = 2.503570213317871, 37.79975724220276 s per 100 iters\n","time = 118.0, epoch 1, iter = 4200, loss = 2.4996133744716644, 38.01914858818054 s per 100 iters\n","time = 119.0, epoch 1, iter = 4300, loss = 2.4800159054994584, 37.550472021102905 s per 100 iters\n","time = 119.0, epoch 1, iter = 4400, loss = 2.4742186284065246, 37.5356011390686 s per 100 iters\n","time = 120.0, epoch 1, iter = 4500, loss = 2.4803729891777038, 37.122105836868286 s per 100 iters\n","time = 121.0, epoch 1, iter = 4600, loss = 2.4777201306819916, 37.27845072746277 s per 100 iters\n","time = 121.0, epoch 1, iter = 4700, loss = 2.497844945192337, 38.09374785423279 s per 100 iters\n","time = 122.0, epoch 1, iter = 4800, loss = 2.4719769275188446, 37.84702754020691 s per 100 iters\n","time = 122.0, epoch 1, iter = 4900, loss = 2.462146544456482, 37.66664457321167 s per 100 iters\n","time = 123.0, epoch 1, iter = 5000, loss = 2.444332295656204, 37.512455463409424 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 124.0, epoch 1, iter = 5100, loss = 2.466265536546707, 37.871620655059814 s per 100 iters\n","time = 124.0, epoch 1, iter = 5200, loss = 2.4659029948711395, 38.37051486968994 s per 100 iters\n","time = 125.0, epoch 1, iter = 5300, loss = 2.473000246286392, 38.83989644050598 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 126.0, epoch 1, iter = 5400, loss = 2.43617045879364, 37.27020812034607 s per 100 iters\n","time = 126.0, epoch 1, iter = 5500, loss = 2.452717649936676, 37.303136110305786 s per 100 iters\n","time = 127.0, epoch 1, iter = 5600, loss = 2.456322741508484, 37.74697256088257 s per 100 iters\n","time = 128.0, epoch 1, iter = 5700, loss = 2.4423492777347566, 38.54040789604187 s per 100 iters\n","time = 128.0, epoch 1, iter = 5800, loss = 2.454443356990814, 37.69327259063721 s per 100 iters\n","time = 129.0, epoch 1, iter = 5900, loss = 2.4565673053264616, 38.044482469558716 s per 100 iters\n","time = 129.0, epoch 1, iter = 6000, loss = 2.438429809808731, 38.65587496757507 s per 100 iters\n","time = 130.0, epoch 1, iter = 6100, loss = 2.4360153067111967, 37.872060775756836 s per 100 iters\n","time = 131.0, epoch 1, iter = 6200, loss = 2.4247178757190704, 38.100560903549194 s per 100 iters\n","time = 131.0, epoch 1, iter = 6300, loss = 2.427589724063873, 37.52472543716431 s per 100 iters\n","time = 132.0, epoch 1, iter = 6400, loss = 2.4269886887073517, 37.15414571762085 s per 100 iters\n","time = 133.0, epoch 1, iter = 6500, loss = 2.427732733488083, 38.26734519004822 s per 100 iters\n","time = 133.0, epoch 1, iter = 6600, loss = 2.3963270378112793, 38.024521350860596 s per 100 iters\n","time = 134.0, epoch 1, iter = 6700, loss = 2.4171878439188004, 37.469074964523315 s per 100 iters\n","time = 135.0, epoch 1, iter = 6800, loss = 2.406231179237366, 37.98157572746277 s per 100 iters\n","time = 135.0, epoch 1, iter = 6900, loss = 2.4196261143684388, 37.733489990234375 s per 100 iters\n","time = 136.0, epoch 1, iter = 7000, loss = 2.406143311262131, 37.869062423706055 s per 100 iters\n","time = 136.0, epoch 1, iter = 7100, loss = 2.4030902540683745, 37.31376910209656 s per 100 iters\n","time = 137.0, epoch 1, iter = 7200, loss = 2.4127222800254824, 38.759520530700684 s per 100 iters\n","time = 138.0, epoch 1, iter = 7300, loss = 2.3993458116054533, 37.39457297325134 s per 100 iters\n","time = 138.0, epoch 1, iter = 7400, loss = 2.394134941101074, 38.66225862503052 s per 100 iters\n","time = 139.0, epoch 1, iter = 7500, loss = 2.3892677891254426, 38.12969708442688 s per 100 iters\n","time = 140.0, epoch 1, iter = 7600, loss = 2.3887021005153657, 38.034035444259644 s per 100 iters\n","time = 140.0, epoch 1, iter = 7700, loss = 2.383664828538895, 37.513771772384644 s per 100 iters\n","time = 141.0, epoch 1, iter = 7800, loss = 2.397371801137924, 37.708738803863525 s per 100 iters\n","time = 141.0, epoch 1, iter = 7900, loss = 2.407104399204254, 38.1056489944458 s per 100 iters\n","time = 142.0, epoch 1, iter = 8000, loss = 2.3975444841384888, 37.80768179893494 s per 100 iters\n","time = 143.0, epoch 1, iter = 8100, loss = 2.4081628262996673, 37.839449644088745 s per 100 iters\n","time = 143.0, epoch 1, iter = 8200, loss = 2.387420380115509, 38.079631328582764 s per 100 iters\n","time = 144.0, epoch 1, iter = 8300, loss = 2.35960001707077, 37.31593441963196 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 145.0, epoch 1, iter = 8400, loss = 2.348046748638153, 37.71001887321472 s per 100 iters\n","time = 145.0, epoch 1, iter = 8500, loss = 2.368386034965515, 37.791100025177 s per 100 iters\n","time = 146.0, epoch 1, iter = 8600, loss = 2.3652281439304352, 37.31864595413208 s per 100 iters\n","time = 147.0, epoch 1, iter = 8700, loss = 2.3971324658393858, 39.005237102508545 s per 100 iters\n","time = 147.0, epoch 1, iter = 8800, loss = 2.3885313761234284, 37.9314124584198 s per 100 iters\n","time = 148.0, epoch 1, iter = 8900, loss = 2.3611126708984376, 37.63835096359253 s per 100 iters\n","time = 148.0, epoch 1, iter = 9000, loss = 2.3534254455566406, 37.6689248085022 s per 100 iters\n","time = 149.0, epoch 1, iter = 9100, loss = 2.3489077711105346, 37.862417697906494 s per 100 iters\n","time = 150.0, epoch 1, iter = 9200, loss = 2.387412462234497, 38.48622536659241 s per 100 iters\n","time = 150.0, epoch 1, iter = 9300, loss = 2.352896671295166, 38.55469822883606 s per 100 iters\n","time = 151.0, epoch 1, iter = 9400, loss = 2.353044604063034, 38.56486201286316 s per 100 iters\n","time = 152.0, epoch 1, iter = 9500, loss = 2.359987211227417, 38.0294144153595 s per 100 iters\n","time = 152.0, epoch 1, iter = 9600, loss = 2.35286615729332, 38.1772825717926 s per 100 iters\n","time = 153.0, epoch 1, iter = 9700, loss = 2.3646375155448913, 38.21727204322815 s per 100 iters\n","time = 153.0, epoch 1, iter = 9800, loss = 2.3573649954795837, 38.214354038238525 s per 100 iters\n","time = 154.0, epoch 1, iter = 9900, loss = 2.3641558861732483, 38.196120500564575 s per 100 iters\n","time = 155.0, epoch 1, iter = 10000, loss = 2.3114622592926026, 37.71619749069214 s per 100 iters\n","time = 155.0, epoch 1, iter = 10100, loss = 2.336862659454346, 38.04483103752136 s per 100 iters\n","time = 156.0, epoch 1, iter = 10200, loss = 2.3323142886161805, 38.414873123168945 s per 100 iters\n","time = 157.0, epoch 1, iter = 10300, loss = 2.348167234659195, 37.79085326194763 s per 100 iters\n","time = 157.0, epoch 1, iter = 10400, loss = 2.305144966840744, 37.840630292892456 s per 100 iters\n","time = 158.0, epoch 1, iter = 10500, loss = 2.3383528459072114, 38.132115840911865 s per 100 iters\n","time = 159.0, epoch 1, iter = 10600, loss = 2.330099756717682, 37.63540554046631 s per 100 iters\n","time = 159.0, epoch 1, iter = 10700, loss = 2.346942776441574, 38.79272675514221 s per 100 iters\n","time = 160.0, epoch 1, iter = 10800, loss = 2.3373510909080504, 38.36310791969299 s per 100 iters\n","time = 160.0, epoch 1, iter = 10900, loss = 2.3395862936973573, 38.651036977767944 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 161.0, epoch 1, iter = 11000, loss = 2.344581927061081, 39.77970910072327 s per 100 iters\n","time = 162.0, epoch 1, iter = 11100, loss = 2.3336602836847304, 37.708083629608154 s per 100 iters\n","time = 162.0, epoch 1, iter = 11200, loss = 2.274958422780037, 37.53354620933533 s per 100 iters\n","time = 163.0, epoch 1, iter = 11300, loss = 2.287806658744812, 38.13587665557861 s per 100 iters\n","time = 164.0, epoch 1, iter = 11400, loss = 2.313858953714371, 38.625293016433716 s per 100 iters\n","time = 164.0, epoch 1, iter = 11500, loss = 2.3108478450775145, 38.70806622505188 s per 100 iters\n","time = 165.0, epoch 1, iter = 11600, loss = 2.2939499437808992, 37.86628460884094 s per 100 iters\n","time = 166.0, epoch 1, iter = 11700, loss = 2.3082347357273103, 37.948933362960815 s per 100 iters\n","time = 166.0, epoch 1, iter = 11800, loss = 2.2819816386699676, 38.515251874923706 s per 100 iters\n","time = 167.0, epoch 1, iter = 11900, loss = 2.3352339589595794, 37.854169607162476 s per 100 iters\n","time = 167.0, epoch 1, iter = 12000, loss = 2.2647559738159178, 37.803467750549316 s per 100 iters\n","time = 168.0, epoch 1, iter = 12100, loss = 2.299786251783371, 38.3978955745697 s per 100 iters\n","time = 169.0, epoch 1, iter = 12200, loss = 2.2984798061847687, 38.18329477310181 s per 100 iters\n","time = 169.0, epoch 1, iter = 12300, loss = 2.2994453597068785, 38.020403146743774 s per 100 iters\n","time = 170.0, epoch 1, iter = 12400, loss = 2.3116054332256315, 38.27704453468323 s per 100 iters\n","time = 171.0, epoch 1, iter = 12500, loss = 2.275925477743149, 37.616411447525024 s per 100 iters\n","time = 171.0, epoch 1, iter = 12600, loss = 2.3274097776412965, 39.82131266593933 s per 100 iters\n","time = 172.0, epoch 1, iter = 12700, loss = 2.281290689706802, 37.67595148086548 s per 100 iters\n","time = 173.0, epoch 1, iter = 12800, loss = 2.285432323217392, 38.5935161113739 s per 100 iters\n","time = 173.0, epoch 1, iter = 12900, loss = 2.24920422911644, 37.55411434173584 s per 100 iters\n","time = 174.0, epoch 1, iter = 13000, loss = 2.293086335659027, 37.76242113113403 s per 100 iters\n","time = 175.0, epoch 1, iter = 13100, loss = 2.2838406836986542, 38.6414909362793 s per 100 iters\n","time = 175.0, epoch 1, iter = 13200, loss = 2.290604588985443, 38.335758686065674 s per 100 iters\n","time = 176.0, epoch 1, iter = 13300, loss = 2.282310824394226, 38.82671880722046 s per 100 iters\n","time = 176.0, epoch 1, iter = 13400, loss = 2.263270758390427, 38.16676378250122 s per 100 iters\n","time = 177.0, epoch 1, iter = 13500, loss = 2.2629802453517915, 38.525116205215454 s per 100 iters\n","time = 178.0, epoch 1, iter = 13600, loss = 2.281588636636734, 38.40040111541748 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 178.0, epoch 1, iter = 13700, loss = 2.260839376449585, 37.90123987197876 s per 100 iters\n","time = 179.0, epoch 1, iter = 13800, loss = 2.2646120202541353, 38.32901430130005 s per 100 iters\n","time = 180.0, epoch 1, iter = 13900, loss = 2.271508699655533, 38.85472345352173 s per 100 iters\n","time = 180.0, epoch 1, iter = 14000, loss = 2.2489026761054993, 38.600412368774414 s per 100 iters\n","time = 181.0, epoch 1, iter = 14100, loss = 2.2591220676898955, 38.41573691368103 s per 100 iters\n","time = 182.0, epoch 1, iter = 14200, loss = 2.2585929894447325, 38.12957429885864 s per 100 iters\n","time = 182.0, epoch 1, iter = 14300, loss = 2.2504290175437927, 38.78505778312683 s per 100 iters\n","--- Balidazioa ---\n","42.292612075805664 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impiusek tam culta ez ｟C islandia milia habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hori ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da bitxia ￭?', '｟C colin berriro gelditu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta ｟C dulcinea ￭?', '｟C afarian ongi jan zuen ￭, ｟C siziliarrak ￭, eta nesken xarma ￭, eta ｟C pirroneko ｟C pirroneko don ｟C piratoneko printzeen xarma eta ｟C donnafatok ￭, ｟C caparoko ｟C gidaritzakoa zela konbentzitu zuten ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', 'magistratu eta beste ofizialek ￭, ｟C epaikada eta exekutiboarenak ￭, saria eta zigorra ￭, subiranotasunaren egilea ￭, zeinak ￭, subiranotasunaren sedzioa eta kide bakoitza bere egitekoa betetzeko mugitzeko mugatzen duten kidea ￭, gorputz naturalean ￭, aberastasuna eta aberastasuna ￭, ｟C populi ￭, ｟C estatuaren ｟C estatuaren ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen eta ｟C boterearen ｟C boterearen ｟C boterearen menpe daudenak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zuen poliziari deitu ￭.', 'ideal hura ere euren ideal ￭, beraiek ere ￭, eta agian ￭, inork ez dute ￭, gaur egun ￭, bere burua ￭, bere burugogorragoak ￭, gerlari eta esploratzaileen eta esploratzaileen troparik gorenena ￭, sedizio finko eta ulergarriena da ￭.', '｟C hegoaldean ez dago esklaburik esklaburik ez dutenik ￭.', '｟C gutxienez ￭, ｟C derwatt-en kasuan eta orain ｟C mafiako ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 8.12292154656756\n","8.426018714904785 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvette-ren istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekatzeko etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otso izango da basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '19600ko argazkiari eta bere semea 1940ko uniforme batean ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C lotara itzuli ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur al zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 23.394198192319713\n","BLEU puntuazioa (biak): 11.700235219185783\n","time = 184.0, epoch 2, iter = 100, loss = 2.1656084638834, 39.21785926818848 s per 100 iters\n","time = 185.0, epoch 2, iter = 200, loss = 2.1571755480766295, 38.116410970687866 s per 100 iters\n","time = 185.0, epoch 2, iter = 300, loss = 2.1634278976917267, 37.9440336227417 s per 100 iters\n","time = 186.0, epoch 2, iter = 400, loss = 2.160319242477417, 38.719109296798706 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-8671ba09295f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentrenatu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-59-3280eebef4ed>\u001b[0m in \u001b[0;36mentrenatu\u001b[0;34m(hasi_epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n\u001b[0;32m---> 28\u001b[0;31m                 targets.cuda(), ignore_index=pad)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"rBYnTBOgjtmh","colab_type":"text"},"source":["# Bakarrarekin hasieratik entrenatzeko"]},{"cell_type":"code","metadata":{"id":"RRKCj-w2jz0X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"10331c20-a752-4406-c3cf-d4073cc35945"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","        \n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","#optim = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","entrenatu_bakarra(lang=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","time = 0.0, epoch 0, iter = 100, loss = 7.424107656478882, 24.585298776626587 s per 100 iters\n","time = 0.0, epoch 0, iter = 200, loss = 6.111597018241882, 22.587113857269287 s per 100 iters\n","time = 1.0, epoch 0, iter = 300, loss = 5.91784770488739, 22.333367347717285 s per 100 iters\n","time = 1.0, epoch 0, iter = 400, loss = 5.77491961479187, 22.75731348991394 s per 100 iters\n","time = 1.0, epoch 0, iter = 500, loss = 5.690699188709259, 23.08562922477722 s per 100 iters\n","time = 2.0, epoch 0, iter = 600, loss = 5.51815098285675, 22.736825227737427 s per 100 iters\n","time = 2.0, epoch 0, iter = 700, loss = 5.39643640756607, 22.57046365737915 s per 100 iters\n","time = 3.0, epoch 0, iter = 800, loss = 5.296370415687561, 23.371721267700195 s per 100 iters\n","time = 3.0, epoch 0, iter = 900, loss = 5.225673041343689, 23.876638412475586 s per 100 iters\n","time = 3.0, epoch 0, iter = 1000, loss = 5.140262265205383, 23.47366166114807 s per 100 iters\n","time = 4.0, epoch 0, iter = 1100, loss = 5.091455607414246, 23.039504289627075 s per 100 iters\n","time = 4.0, epoch 0, iter = 1200, loss = 5.047120263576508, 23.1024911403656 s per 100 iters\n","time = 5.0, epoch 0, iter = 1300, loss = 4.999521224498749, 22.70084047317505 s per 100 iters\n","time = 5.0, epoch 0, iter = 1400, loss = 4.976248939037323, 22.984333992004395 s per 100 iters\n","time = 5.0, epoch 0, iter = 1500, loss = 4.935124094486237, 24.405280113220215 s per 100 iters\n","time = 6.0, epoch 0, iter = 1600, loss = 4.9059033918380734, 24.27057194709778 s per 100 iters\n","time = 6.0, epoch 0, iter = 1700, loss = 4.830579800605774, 22.64883589744568 s per 100 iters\n","time = 6.0, epoch 0, iter = 1800, loss = 4.811135177612305, 23.992091178894043 s per 100 iters\n","time = 7.0, epoch 0, iter = 1900, loss = 4.744081945419311, 23.442707777023315 s per 100 iters\n","time = 7.0, epoch 0, iter = 2000, loss = 4.750443916320801, 23.87756872177124 s per 100 iters\n","time = 8.0, epoch 0, iter = 2100, loss = 4.699640114307403, 22.934848308563232 s per 100 iters\n","time = 8.0, epoch 0, iter = 2200, loss = 4.658490538597107, 22.77803087234497 s per 100 iters\n","time = 8.0, epoch 0, iter = 2300, loss = 4.623263545036316, 22.868462085723877 s per 100 iters\n","time = 9.0, epoch 0, iter = 2400, loss = 4.5808703804016115, 23.62036395072937 s per 100 iters\n","time = 9.0, epoch 0, iter = 2500, loss = 4.5911991810798645, 24.015142917633057 s per 100 iters\n","time = 10.0, epoch 0, iter = 2600, loss = 4.5674139022827145, 23.382879734039307 s per 100 iters\n","time = 10.0, epoch 0, iter = 2700, loss = 4.515768165588379, 23.345569849014282 s per 100 iters\n","time = 10.0, epoch 0, iter = 2800, loss = 4.481000521183014, 23.47773504257202 s per 100 iters\n","time = 11.0, epoch 0, iter = 2900, loss = 4.483284425735474, 23.783688068389893 s per 100 iters\n","time = 11.0, epoch 0, iter = 3000, loss = 4.429571447372436, 24.316974878311157 s per 100 iters\n","time = 12.0, epoch 0, iter = 3100, loss = 4.406516916751862, 24.248939275741577 s per 100 iters\n","time = 12.0, epoch 0, iter = 3200, loss = 4.357726964950562, 22.94857120513916 s per 100 iters\n","time = 12.0, epoch 0, iter = 3300, loss = 4.3107589554786685, 23.69136953353882 s per 100 iters\n","time = 13.0, epoch 0, iter = 3400, loss = 4.32756739616394, 23.603648900985718 s per 100 iters\n","time = 13.0, epoch 0, iter = 3500, loss = 4.264647023677826, 23.314650297164917 s per 100 iters\n","time = 14.0, epoch 0, iter = 3600, loss = 4.264428851604461, 24.134536027908325 s per 100 iters\n","time = 14.0, epoch 0, iter = 3700, loss = 4.2483106398582455, 23.307011127471924 s per 100 iters\n","time = 14.0, epoch 0, iter = 3800, loss = 4.215154478549957, 23.49828600883484 s per 100 iters\n","time = 15.0, epoch 0, iter = 3900, loss = 4.182723195552826, 23.372665882110596 s per 100 iters\n","time = 15.0, epoch 0, iter = 4000, loss = 4.1639534378051755, 22.570013761520386 s per 100 iters\n","time = 15.0, epoch 0, iter = 4100, loss = 4.128610520362854, 23.05279779434204 s per 100 iters\n","time = 16.0, epoch 0, iter = 4200, loss = 4.104119713306427, 23.187055587768555 s per 100 iters\n","time = 16.0, epoch 0, iter = 4300, loss = 4.1107804346084595, 23.220609188079834 s per 100 iters\n","time = 17.0, epoch 0, iter = 4400, loss = 4.014991190433502, 22.955338954925537 s per 100 iters\n","time = 17.0, epoch 0, iter = 4500, loss = 4.049071171283722, 22.71957015991211 s per 100 iters\n","time = 17.0, epoch 0, iter = 4600, loss = 4.053213171958923, 24.016295671463013 s per 100 iters\n","time = 18.0, epoch 0, iter = 4700, loss = 4.03972380399704, 23.749125242233276 s per 100 iters\n","time = 18.0, epoch 0, iter = 4800, loss = 3.997709002494812, 22.905411958694458 s per 100 iters\n","time = 19.0, epoch 0, iter = 4900, loss = 3.9793277525901796, 22.722017526626587 s per 100 iters\n","time = 19.0, epoch 0, iter = 5000, loss = 3.9576938700675965, 23.26161026954651 s per 100 iters\n","time = 19.0, epoch 0, iter = 5100, loss = 3.9199621629714967, 23.836755752563477 s per 100 iters\n","time = 20.0, epoch 0, iter = 5200, loss = 3.9191351675987245, 23.638214826583862 s per 100 iters\n","time = 20.0, epoch 0, iter = 5300, loss = 3.870065703392029, 23.23043990135193 s per 100 iters\n","time = 21.0, epoch 0, iter = 5400, loss = 3.90499552488327, 23.27691888809204 s per 100 iters\n","time = 21.0, epoch 0, iter = 5500, loss = 3.8319923448562623, 22.60843563079834 s per 100 iters\n","time = 21.0, epoch 0, iter = 5600, loss = 3.816207106113434, 23.599161624908447 s per 100 iters\n","time = 22.0, epoch 0, iter = 5700, loss = 3.8393133521080016, 23.32089924812317 s per 100 iters\n","time = 22.0, epoch 0, iter = 5800, loss = 3.7746659469604493, 23.43309736251831 s per 100 iters\n","time = 22.0, epoch 0, iter = 5900, loss = 3.7959219670295714, 23.528252124786377 s per 100 iters\n","time = 23.0, epoch 0, iter = 6000, loss = 3.7470514464378355, 23.035852909088135 s per 100 iters\n","time = 23.0, epoch 0, iter = 6100, loss = 3.7795089507102966, 22.99482536315918 s per 100 iters\n","time = 24.0, epoch 0, iter = 6200, loss = 3.7347005224227905, 23.178202152252197 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 24.0, epoch 0, iter = 6300, loss = 3.7312086629867554, 22.82566499710083 s per 100 iters\n","time = 24.0, epoch 0, iter = 6400, loss = 3.7439181995391846, 23.93641996383667 s per 100 iters\n","time = 25.0, epoch 0, iter = 6500, loss = 3.6970026206970217, 22.79352331161499 s per 100 iters\n","time = 25.0, epoch 0, iter = 6600, loss = 3.6722251212596895, 23.73646855354309 s per 100 iters\n","time = 26.0, epoch 0, iter = 6700, loss = 3.676973202228546, 23.111075162887573 s per 100 iters\n","time = 26.0, epoch 0, iter = 6800, loss = 3.677607352733612, 23.59472107887268 s per 100 iters\n","time = 26.0, epoch 0, iter = 6900, loss = 3.6063310313224792, 23.28003430366516 s per 100 iters\n","time = 27.0, epoch 0, iter = 7000, loss = 3.623900589942932, 23.804115056991577 s per 100 iters\n","time = 27.0, epoch 0, iter = 7100, loss = 3.612816848754883, 23.438737869262695 s per 100 iters\n","time = 27.0, epoch 0, iter = 7200, loss = 3.612936432361603, 22.83026671409607 s per 100 iters\n","time = 28.0, epoch 0, iter = 7300, loss = 3.6234966719150545, 23.40294075012207 s per 100 iters\n","time = 28.0, epoch 0, iter = 7400, loss = 3.5656402170658112, 23.331743240356445 s per 100 iters\n","time = 29.0, epoch 0, iter = 7500, loss = 3.5564741957187653, 23.503578662872314 s per 100 iters\n","time = 29.0, epoch 0, iter = 7600, loss = 3.5344876503944396, 22.770201444625854 s per 100 iters\n","time = 29.0, epoch 0, iter = 7700, loss = 3.562138230800629, 23.409224271774292 s per 100 iters\n","time = 30.0, epoch 0, iter = 7800, loss = 3.546490068435669, 22.984023094177246 s per 100 iters\n","time = 30.0, epoch 0, iter = 7900, loss = 3.5248252153396606, 22.884084701538086 s per 100 iters\n","time = 31.0, epoch 0, iter = 8000, loss = 3.5057136607170105, 23.508683919906616 s per 100 iters\n","time = 31.0, epoch 0, iter = 8100, loss = 3.465328538417816, 23.858307361602783 s per 100 iters\n","time = 31.0, epoch 0, iter = 8200, loss = 3.480093365907669, 23.331230401992798 s per 100 iters\n","time = 32.0, epoch 0, iter = 8300, loss = 3.46646360874176, 22.6648690700531 s per 100 iters\n","time = 32.0, epoch 0, iter = 8400, loss = 3.4576468205451967, 23.004650115966797 s per 100 iters\n","time = 33.0, epoch 0, iter = 8500, loss = 3.4354508149623872, 23.270139932632446 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 33.0, epoch 0, iter = 8600, loss = 3.4377046000957487, 23.007110357284546 s per 100 iters\n","time = 33.0, epoch 0, iter = 8700, loss = 3.4426818227767946, 23.827152013778687 s per 100 iters\n","time = 34.0, epoch 0, iter = 8800, loss = 3.4144177889823912, 23.45686364173889 s per 100 iters\n","time = 34.0, epoch 0, iter = 8900, loss = 3.393804100751877, 23.044502019882202 s per 100 iters\n","time = 34.0, epoch 0, iter = 9000, loss = 3.40003471493721, 22.983490467071533 s per 100 iters\n","time = 35.0, epoch 0, iter = 9100, loss = 3.371214860677719, 22.357173442840576 s per 100 iters\n","time = 35.0, epoch 0, iter = 9200, loss = 3.388166066408157, 23.37870717048645 s per 100 iters\n","time = 36.0, epoch 0, iter = 9300, loss = 3.371196973323822, 23.509602785110474 s per 100 iters\n","time = 36.0, epoch 0, iter = 9400, loss = 3.353310786485672, 23.610698223114014 s per 100 iters\n","time = 36.0, epoch 0, iter = 9500, loss = 3.353514289855957, 23.999455451965332 s per 100 iters\n","time = 37.0, epoch 0, iter = 9600, loss = 3.3130966484546662, 23.657682180404663 s per 100 iters\n","time = 37.0, epoch 0, iter = 9700, loss = 3.334699366092682, 23.491662740707397 s per 100 iters\n","time = 38.0, epoch 0, iter = 9800, loss = 3.31754944562912, 22.823979377746582 s per 100 iters\n","time = 38.0, epoch 0, iter = 9900, loss = 3.331892011165619, 23.466187953948975 s per 100 iters\n","time = 38.0, epoch 0, iter = 10000, loss = 3.3101864969730377, 23.431705474853516 s per 100 iters\n","time = 39.0, epoch 0, iter = 10100, loss = 3.281504397392273, 22.987055778503418 s per 100 iters\n","time = 39.0, epoch 0, iter = 10200, loss = 3.2825444769859313, 23.3649959564209 s per 100 iters\n","time = 40.0, epoch 0, iter = 10300, loss = 3.2925596487522126, 22.700778245925903 s per 100 iters\n","time = 40.0, epoch 0, iter = 10400, loss = 3.265739161968231, 23.514611959457397 s per 100 iters\n","time = 40.0, epoch 0, iter = 10500, loss = 3.280386173725128, 23.721563577651978 s per 100 iters\n","time = 41.0, epoch 0, iter = 10600, loss = 3.2607522332668304, 22.310813426971436 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 41.0, epoch 0, iter = 10700, loss = 3.2421519696712493, 22.205084562301636 s per 100 iters\n","time = 41.0, epoch 0, iter = 10800, loss = 3.233214707374573, 23.125596523284912 s per 100 iters\n","time = 42.0, epoch 0, iter = 10900, loss = 3.219643312692642, 23.99829649925232 s per 100 iters\n","time = 42.0, epoch 0, iter = 11000, loss = 3.2364125835895536, 23.63450574874878 s per 100 iters\n","time = 43.0, epoch 0, iter = 11100, loss = 3.2438203930854796, 24.03524684906006 s per 100 iters\n","time = 43.0, epoch 0, iter = 11200, loss = 3.2047993397712706, 23.703411102294922 s per 100 iters\n","time = 43.0, epoch 0, iter = 11300, loss = 3.2355675220489504, 23.797346591949463 s per 100 iters\n","time = 44.0, epoch 0, iter = 11400, loss = 3.1941743731498717, 23.40736484527588 s per 100 iters\n","time = 44.0, epoch 0, iter = 11500, loss = 3.19261514544487, 22.88304567337036 s per 100 iters\n","time = 45.0, epoch 0, iter = 11600, loss = 3.17046666264534, 22.7083523273468 s per 100 iters\n","time = 45.0, epoch 0, iter = 11700, loss = 3.1445330226421357, 23.856340885162354 s per 100 iters\n","time = 45.0, epoch 0, iter = 11800, loss = 3.1530351388454436, 23.452940940856934 s per 100 iters\n","time = 46.0, epoch 0, iter = 11900, loss = 3.175956974029541, 24.241445779800415 s per 100 iters\n","time = 46.0, epoch 0, iter = 12000, loss = 3.1382873129844664, 23.659087896347046 s per 100 iters\n","time = 47.0, epoch 0, iter = 12100, loss = 3.1462986385822296, 23.260244369506836 s per 100 iters\n","time = 47.0, epoch 0, iter = 12200, loss = 3.13582758307457, 23.580541610717773 s per 100 iters\n","time = 47.0, epoch 0, iter = 12300, loss = 3.117913444042206, 23.273895263671875 s per 100 iters\n","time = 48.0, epoch 0, iter = 12400, loss = 3.1616081631183626, 23.739274263381958 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 48.0, epoch 0, iter = 12500, loss = 3.1181103003025057, 23.449058532714844 s per 100 iters\n","time = 48.0, epoch 0, iter = 12600, loss = 3.065305449962616, 22.88718557357788 s per 100 iters\n","time = 49.0, epoch 0, iter = 12700, loss = 3.099624662399292, 23.136451959609985 s per 100 iters\n","time = 49.0, epoch 0, iter = 12800, loss = 3.0996736884117126, 23.66525626182556 s per 100 iters\n","time = 50.0, epoch 0, iter = 12900, loss = 3.071467329263687, 22.478967666625977 s per 100 iters\n","time = 50.0, epoch 0, iter = 13000, loss = 3.0904346883296965, 23.189372539520264 s per 100 iters\n","time = 50.0, epoch 0, iter = 13100, loss = 3.088078554868698, 23.799166679382324 s per 100 iters\n","time = 51.0, epoch 0, iter = 13200, loss = 3.060626015663147, 23.789049863815308 s per 100 iters\n","time = 51.0, epoch 0, iter = 13300, loss = 3.0668624019622803, 23.100398778915405 s per 100 iters\n","time = 52.0, epoch 0, iter = 13400, loss = 3.0879665863513948, 23.72337245941162 s per 100 iters\n","time = 52.0, epoch 0, iter = 13500, loss = 3.074622974395752, 23.11514139175415 s per 100 iters\n","time = 52.0, epoch 0, iter = 13600, loss = 3.0651660466194155, 23.572572469711304 s per 100 iters\n","time = 53.0, epoch 0, iter = 13700, loss = 3.0484108364582063, 23.06063961982727 s per 100 iters\n","time = 53.0, epoch 0, iter = 13800, loss = 3.0327867472171786, 22.92134690284729 s per 100 iters\n","time = 54.0, epoch 0, iter = 13900, loss = 3.0557226264476776, 22.561641931533813 s per 100 iters\n","time = 54.0, epoch 0, iter = 14000, loss = 3.0611009752750395, 23.42019748687744 s per 100 iters\n","time = 54.0, epoch 0, iter = 14100, loss = 3.0260267055034635, 24.37941074371338 s per 100 iters\n","time = 55.0, epoch 0, iter = 14200, loss = 3.0436036086082456, 23.550198793411255 s per 100 iters\n","time = 55.0, epoch 0, iter = 14300, loss = 3.0323783910274504, 24.026469945907593 s per 100 iters\n","--- Balidazioa ---\n","53.391465187072754 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['-￭ ｟C inius ｟C tamifiko kultura ez da milia milia milia milia ￭.', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosannak ￭.', '｟C ez al da arraroa ￭?', '｟C colinek berriro gelditu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da hain tristea eta betea ￭.', '｟C eta bere ｟C agornea ￭?', '｟C bitartean ￭, ｟C siziliako neska ｟C siziliako nesken aurrean jan zuen ￭, eta ｟C pirronen ｟C belir ￭, ｟C pirronen ￭, ｟C don ｟C fabrizio ￭, ｟C fabriziok ￭, ｟C fabriziok ￭, ｟C martiri eta ｟C marfirreko jauregi eta ｟C martiri ￭, ｟C maritxu eta ｟C frantziako jauregi hura bizirik utzi zuen ￭.', '｟C denak erosten ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C magistratuak ￭, eta beste ｟C juduen ｟C akademiako ofizialak ￭, ｟C joyn ￭, ｟C akynyn ￭, ｟C akynes ￭, ｟C akademiako ｟C akademiako ｟C manser ￭, ｟C aker ￭, ｟C arses ￭, ｟C mans ￭, ｟C ars ￭, ｟C ars ￭, ｟C ars ￭, ｟C ars ￭, ｟C ars ￭, ｟C ars ￭, ｟C ars ￭, ｟C arer ￭, ｟C aker ￭, ｟C ak ￭, ｟C aker ￭, ｟C ak ￭, ｟C ak ￭, ｟C ak ￭, ｟C ak ￭, ｟C ak ￭, ｟C aker ￭,', '｟C jimmy aurkitu zenean ￭, ez zuen poliziari deitu ￭.', '｟C hori ￭, ordea ￭, bere baitan ￭, ez da inoiz beste inor ￭, ez baita bere produktuaren eta bere heziketa ￭, bere heziketa eta bere heziketa eta bere sorgorra ￭, eta bere azti eta azti eta bere azti eta azti eta azti eta aztiaren eta bere eroa ￭.', '｟C hegoaldean ez dago familiarik esklaboa ez izatea ￭.', '｟C gutxienez ￭, ｟C diwatt ￭, gauza bat ￭, eta orain ｟C mafiako ｟C mafiak ￭?']\n","BLEU puntuazioa (1): 2.83542480721297\n","10.98744010925293 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria zen ￭.', '｟C non uste duzu ｟C nick ｟C gure janaria dela ￭?', '-￭ ｟C corvettek ezagutzen dugu ￭, ｟C matt ￭.', '｟C ikusten ditugu ￭.', '｟C jaunok ￭, ｟C windom ｟C twin ｟C peaks iritsi zenean ￭, mendekua hartu nuen ￭.', '｟C dut jaunaren ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoen gorpuak izango dira ￭?', '｟C marchal jauna ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ez duzu axola ￭?', '｟C eta nik neuk erakutsi diot 19600ean eta bere semea ￭.', '｟C orduan dena aldatu zen ￭.', '-￭ ｟C zer txartel ￭?', '｟C lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B wance ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphine ￭?']\n","BLEU puntuazioa (2): 14.844369533090887\n","BLEU puntuazioa (biak): 5.219718649576527\n","time = 57.0, epoch 1, iter = 100, loss = 2.9770500361919403, 25.98748278617859 s per 100 iters\n","time = 57.0, epoch 1, iter = 200, loss = 2.933141642808914, 23.098177433013916 s per 100 iters\n","time = 58.0, epoch 1, iter = 300, loss = 2.922394095659256, 23.6015682220459 s per 100 iters\n","time = 58.0, epoch 1, iter = 400, loss = 2.938914610147476, 23.18891167640686 s per 100 iters\n","time = 58.0, epoch 1, iter = 500, loss = 2.9616255402565, 23.503321170806885 s per 100 iters\n","time = 59.0, epoch 1, iter = 600, loss = 2.9356281149387358, 24.026815176010132 s per 100 iters\n","time = 59.0, epoch 1, iter = 700, loss = 2.929310213327408, 23.180673837661743 s per 100 iters\n","time = 60.0, epoch 1, iter = 800, loss = 2.935222854614258, 24.08919596672058 s per 100 iters\n","time = 60.0, epoch 1, iter = 900, loss = 2.9181991720199587, 23.050997018814087 s per 100 iters\n","time = 60.0, epoch 1, iter = 1000, loss = 2.9503989005088807, 23.956217765808105 s per 100 iters\n","time = 61.0, epoch 1, iter = 1100, loss = 2.916536765098572, 23.69681668281555 s per 100 iters\n","time = 61.0, epoch 1, iter = 1200, loss = 2.922158988714218, 23.13232445716858 s per 100 iters\n","time = 62.0, epoch 1, iter = 1300, loss = 2.904255751371384, 24.14125394821167 s per 100 iters\n","time = 62.0, epoch 1, iter = 1400, loss = 2.9160794496536253, 23.611527681350708 s per 100 iters\n","time = 62.0, epoch 1, iter = 1500, loss = 2.9234791445732116, 23.978289365768433 s per 100 iters\n","time = 63.0, epoch 1, iter = 1600, loss = 2.8929067039489746, 23.77509355545044 s per 100 iters\n","time = 63.0, epoch 1, iter = 1700, loss = 2.8902406692504883, 24.862367153167725 s per 100 iters\n","time = 64.0, epoch 1, iter = 1800, loss = 2.876726565361023, 23.801826238632202 s per 100 iters\n","time = 64.0, epoch 1, iter = 1900, loss = 2.907676658630371, 24.260677576065063 s per 100 iters\n","time = 64.0, epoch 1, iter = 2000, loss = 2.8658599877357482, 23.303028106689453 s per 100 iters\n","time = 65.0, epoch 1, iter = 2100, loss = 2.918591730594635, 23.801084995269775 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 65.0, epoch 1, iter = 2200, loss = 2.856160204410553, 23.517144203186035 s per 100 iters\n","time = 65.0, epoch 1, iter = 2300, loss = 2.853613623380661, 23.819353580474854 s per 100 iters\n","time = 66.0, epoch 1, iter = 2400, loss = 2.851163377761841, 24.358267307281494 s per 100 iters\n","time = 66.0, epoch 1, iter = 2500, loss = 2.8829054188728334, 23.512502431869507 s per 100 iters\n","time = 67.0, epoch 1, iter = 2600, loss = 2.855056949853897, 23.25153160095215 s per 100 iters\n","time = 67.0, epoch 1, iter = 2700, loss = 2.8541721653938295, 23.669524908065796 s per 100 iters\n","time = 67.0, epoch 1, iter = 2800, loss = 2.8496713674068452, 23.833946466445923 s per 100 iters\n","time = 68.0, epoch 1, iter = 2900, loss = 2.8736377143859864, 23.436821222305298 s per 100 iters\n","time = 68.0, epoch 1, iter = 3000, loss = 2.863847541809082, 23.790937185287476 s per 100 iters\n","time = 69.0, epoch 1, iter = 3100, loss = 2.829082400798798, 23.587934017181396 s per 100 iters\n","time = 69.0, epoch 1, iter = 3200, loss = 2.8527502596378325, 23.66862726211548 s per 100 iters\n","time = 69.0, epoch 1, iter = 3300, loss = 2.855362000465393, 23.972307920455933 s per 100 iters\n","time = 70.0, epoch 1, iter = 3400, loss = 2.8602856540679933, 24.12542200088501 s per 100 iters\n","time = 70.0, epoch 1, iter = 3500, loss = 2.8414229774475097, 23.70689630508423 s per 100 iters\n","time = 71.0, epoch 1, iter = 3600, loss = 2.830709933042526, 24.57376718521118 s per 100 iters\n","time = 71.0, epoch 1, iter = 3700, loss = 2.8472490561008454, 23.962566137313843 s per 100 iters\n","time = 71.0, epoch 1, iter = 3800, loss = 2.8228205168247222, 24.094962120056152 s per 100 iters\n","time = 72.0, epoch 1, iter = 3900, loss = 2.807976245880127, 23.487568616867065 s per 100 iters\n","time = 72.0, epoch 1, iter = 4000, loss = 2.793752111196518, 24.209072828292847 s per 100 iters\n","time = 73.0, epoch 1, iter = 4100, loss = 2.8190920042991636, 23.38481903076172 s per 100 iters\n","time = 73.0, epoch 1, iter = 4200, loss = 2.8339107644557955, 23.31813073158264 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 73.0, epoch 1, iter = 4300, loss = 2.831206622123718, 24.468567848205566 s per 100 iters\n","time = 74.0, epoch 1, iter = 4400, loss = 2.8128880989551543, 24.011980056762695 s per 100 iters\n","time = 74.0, epoch 1, iter = 4500, loss = 2.8154665100574494, 23.932398796081543 s per 100 iters\n","time = 75.0, epoch 1, iter = 4600, loss = 2.765321135520935, 23.316200733184814 s per 100 iters\n","time = 75.0, epoch 1, iter = 4700, loss = 2.7931679272651673, 24.081032514572144 s per 100 iters\n","time = 75.0, epoch 1, iter = 4800, loss = 2.7809656274318697, 24.08106565475464 s per 100 iters\n","time = 76.0, epoch 1, iter = 4900, loss = 2.790655826330185, 23.37252640724182 s per 100 iters\n","time = 76.0, epoch 1, iter = 5000, loss = 2.791548203229904, 23.735761165618896 s per 100 iters\n","time = 77.0, epoch 1, iter = 5100, loss = 2.784360749721527, 23.47773575782776 s per 100 iters\n","time = 77.0, epoch 1, iter = 5200, loss = 2.7858847975730896, 24.101348161697388 s per 100 iters\n","time = 77.0, epoch 1, iter = 5300, loss = 2.786016263961792, 23.31246304512024 s per 100 iters\n","time = 78.0, epoch 1, iter = 5400, loss = 2.7838765501976015, 23.876048803329468 s per 100 iters\n","time = 78.0, epoch 1, iter = 5500, loss = 2.7513538670539854, 22.897782802581787 s per 100 iters\n","time = 79.0, epoch 1, iter = 5600, loss = 2.7598174834251403, 23.26238751411438 s per 100 iters\n","time = 79.0, epoch 1, iter = 5700, loss = 2.762393990755081, 23.753875494003296 s per 100 iters\n","time = 79.0, epoch 1, iter = 5800, loss = 2.7480929028987884, 23.83041286468506 s per 100 iters\n","time = 80.0, epoch 1, iter = 5900, loss = 2.759660172462463, 24.033701181411743 s per 100 iters\n","time = 80.0, epoch 1, iter = 6000, loss = 2.7549804842472074, 23.72599959373474 s per 100 iters\n","time = 81.0, epoch 1, iter = 6100, loss = 2.7652770566940306, 24.61189866065979 s per 100 iters\n","time = 81.0, epoch 1, iter = 6200, loss = 2.7526689875125885, 23.891635417938232 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n","time = 81.0, epoch 1, iter = 6300, loss = 2.7621683514118196, 23.627675533294678 s per 100 iters\n","time = 82.0, epoch 1, iter = 6400, loss = 2.771706153154373, 23.783743143081665 s per 100 iters\n","time = 82.0, epoch 1, iter = 6500, loss = 2.7626680624485016, 24.06437373161316 s per 100 iters\n","time = 83.0, epoch 1, iter = 6600, loss = 2.7501890623569487, 24.416438341140747 s per 100 iters\n","time = 83.0, epoch 1, iter = 6700, loss = 2.735944616794586, 23.844926834106445 s per 100 iters\n","time = 83.0, epoch 1, iter = 6800, loss = 2.7283969676494597, 24.713804483413696 s per 100 iters\n","time = 84.0, epoch 1, iter = 6900, loss = 2.7300840520858767, 24.153736352920532 s per 100 iters\n","time = 84.0, epoch 1, iter = 7000, loss = 2.739138720035553, 23.743518590927124 s per 100 iters\n","time = 85.0, epoch 1, iter = 7100, loss = 2.7572351360321044, 24.591848850250244 s per 100 iters\n","time = 85.0, epoch 1, iter = 7200, loss = 2.7304982817173005, 23.494852542877197 s per 100 iters\n","time = 85.0, epoch 1, iter = 7300, loss = 2.7431580030918123, 23.675166606903076 s per 100 iters\n","time = 86.0, epoch 1, iter = 7400, loss = 2.71264906167984, 24.415364027023315 s per 100 iters\n","time = 86.0, epoch 1, iter = 7500, loss = 2.7270509779453276, 24.004491567611694 s per 100 iters\n","time = 87.0, epoch 1, iter = 7600, loss = 2.731367691755295, 24.69166326522827 s per 100 iters\n","time = 87.0, epoch 1, iter = 7700, loss = 2.727820769548416, 23.577176094055176 s per 100 iters\n","time = 87.0, epoch 1, iter = 7800, loss = 2.717093470096588, 24.324815273284912 s per 100 iters\n","time = 88.0, epoch 1, iter = 7900, loss = 2.6947384870052336, 23.298503637313843 s per 100 iters\n","time = 88.0, epoch 1, iter = 8000, loss = 2.729936097860336, 23.595366954803467 s per 100 iters\n","time = 89.0, epoch 1, iter = 8100, loss = 2.716018693447113, 24.364995002746582 s per 100 iters\n","time = 89.0, epoch 1, iter = 8200, loss = 2.7043833649158477, 23.47320318222046 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 89.0, epoch 1, iter = 8300, loss = 2.688468495607376, 23.637402057647705 s per 100 iters\n","time = 90.0, epoch 1, iter = 8400, loss = 2.6833724188804626, 23.4753634929657 s per 100 iters\n","time = 90.0, epoch 1, iter = 8500, loss = 2.7030213367938996, 24.413201332092285 s per 100 iters\n","time = 91.0, epoch 1, iter = 8600, loss = 2.7046288061141968, 24.055010557174683 s per 100 iters\n","time = 91.0, epoch 1, iter = 8700, loss = 2.7122778272628785, 24.43524432182312 s per 100 iters\n","time = 91.0, epoch 1, iter = 8800, loss = 2.7015663242340087, 23.477123022079468 s per 100 iters\n","time = 92.0, epoch 1, iter = 8900, loss = 2.7197106897830965, 23.48012089729309 s per 100 iters\n","time = 92.0, epoch 1, iter = 9000, loss = 2.7022048258781433, 23.76882266998291 s per 100 iters\n","time = 93.0, epoch 1, iter = 9100, loss = 2.6856460881233217, 24.196422576904297 s per 100 iters\n","time = 93.0, epoch 1, iter = 9200, loss = 2.6654259288311004, 24.08687973022461 s per 100 iters\n","time = 93.0, epoch 1, iter = 9300, loss = 2.668138166666031, 23.830764293670654 s per 100 iters\n","time = 94.0, epoch 1, iter = 9400, loss = 2.6866271328926086, 23.43960976600647 s per 100 iters\n","time = 94.0, epoch 1, iter = 9500, loss = 2.684675693511963, 23.886213541030884 s per 100 iters\n","time = 95.0, epoch 1, iter = 9600, loss = 2.6551142036914825, 24.119450092315674 s per 100 iters\n","time = 95.0, epoch 1, iter = 9700, loss = 2.648836445808411, 23.852115392684937 s per 100 iters\n","time = 95.0, epoch 1, iter = 9800, loss = 2.707107688188553, 24.42212724685669 s per 100 iters\n","time = 96.0, epoch 1, iter = 9900, loss = 2.6783175480365755, 23.455024480819702 s per 100 iters\n","time = 96.0, epoch 1, iter = 10000, loss = 2.689922708272934, 24.33099055290222 s per 100 iters\n","time = 97.0, epoch 1, iter = 10100, loss = 2.675865774154663, 24.477213621139526 s per 100 iters\n","time = 97.0, epoch 1, iter = 10200, loss = 2.6608393394947054, 23.742186784744263 s per 100 iters\n","time = 97.0, epoch 1, iter = 10300, loss = 2.6993375384807585, 24.693896055221558 s per 100 iters\n","time = 98.0, epoch 1, iter = 10400, loss = 2.6515331292152404, 23.699301719665527 s per 100 iters\n","time = 98.0, epoch 1, iter = 10500, loss = 2.6471675884723664, 24.56592082977295 s per 100 iters\n","time = 99.0, epoch 1, iter = 10600, loss = 2.658844555616379, 23.871951580047607 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 99.0, epoch 1, iter = 10700, loss = 2.6379292464256285, 23.967056035995483 s per 100 iters\n","time = 99.0, epoch 1, iter = 10800, loss = 2.6723417472839355, 24.505695343017578 s per 100 iters\n","time = 100.0, epoch 1, iter = 10900, loss = 2.6548665952682495, 23.9065580368042 s per 100 iters\n","time = 100.0, epoch 1, iter = 11000, loss = 2.6458647441864014, 23.996758699417114 s per 100 iters\n","time = 101.0, epoch 1, iter = 11100, loss = 2.6497389495372774, 24.211175441741943 s per 100 iters\n","time = 101.0, epoch 1, iter = 11200, loss = 2.6528486394882203, 23.72084069252014 s per 100 iters\n","time = 101.0, epoch 1, iter = 11300, loss = 2.6342556190490725, 24.01419734954834 s per 100 iters\n","time = 102.0, epoch 1, iter = 11400, loss = 2.6731707561016083, 24.1475350856781 s per 100 iters\n","time = 102.0, epoch 1, iter = 11500, loss = 2.670512762069702, 24.336841821670532 s per 100 iters\n","time = 103.0, epoch 1, iter = 11600, loss = 2.6192015731334686, 23.08551836013794 s per 100 iters\n","time = 103.0, epoch 1, iter = 11700, loss = 2.647850517034531, 23.889564752578735 s per 100 iters\n","time = 103.0, epoch 1, iter = 11800, loss = 2.624037207365036, 23.585340976715088 s per 100 iters\n","time = 104.0, epoch 1, iter = 11900, loss = 2.641653836965561, 23.74319076538086 s per 100 iters\n","time = 104.0, epoch 1, iter = 12000, loss = 2.6134035456180573, 23.29690146446228 s per 100 iters\n","time = 105.0, epoch 1, iter = 12100, loss = 2.6012591457366945, 23.482673168182373 s per 100 iters\n","time = 105.0, epoch 1, iter = 12200, loss = 2.637645733356476, 24.046306610107422 s per 100 iters\n","time = 105.0, epoch 1, iter = 12300, loss = 2.608978576660156, 23.349403858184814 s per 100 iters\n","time = 106.0, epoch 1, iter = 12400, loss = 2.635470212697983, 23.88333559036255 s per 100 iters\n","time = 106.0, epoch 1, iter = 12500, loss = 2.620985699892044, 24.183316707611084 s per 100 iters\n","time = 106.0, epoch 1, iter = 12600, loss = 2.610463433265686, 24.24912738800049 s per 100 iters\n","time = 107.0, epoch 1, iter = 12700, loss = 2.603720647096634, 23.399227619171143 s per 100 iters\n","time = 107.0, epoch 1, iter = 12800, loss = 2.6123761415481566, 23.601957321166992 s per 100 iters\n","time = 108.0, epoch 1, iter = 12900, loss = 2.6215201103687287, 24.212450981140137 s per 100 iters\n","time = 108.0, epoch 1, iter = 13000, loss = 2.6028385269641876, 24.371447801589966 s per 100 iters\n","time = 108.0, epoch 1, iter = 13100, loss = 2.613865020275116, 23.536680221557617 s per 100 iters\n","time = 109.0, epoch 1, iter = 13200, loss = 2.6017500042915342, 24.29531717300415 s per 100 iters\n","time = 109.0, epoch 1, iter = 13300, loss = 2.581074723005295, 23.426807403564453 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 110.0, epoch 1, iter = 13400, loss = 2.6126226496696474, 24.68187189102173 s per 100 iters\n","time = 110.0, epoch 1, iter = 13500, loss = 2.6220793461799623, 24.20209550857544 s per 100 iters\n","time = 110.0, epoch 1, iter = 13600, loss = 2.5937310326099396, 24.018112182617188 s per 100 iters\n","time = 111.0, epoch 1, iter = 13700, loss = 2.5862483859062193, 24.150015592575073 s per 100 iters\n","time = 111.0, epoch 1, iter = 13800, loss = 2.6028373575210573, 24.00685143470764 s per 100 iters\n","time = 112.0, epoch 1, iter = 13900, loss = 2.5804181611537933, 23.933368921279907 s per 100 iters\n","time = 112.0, epoch 1, iter = 14000, loss = 2.573179236650467, 23.44487166404724 s per 100 iters\n","time = 112.0, epoch 1, iter = 14100, loss = 2.577150871753693, 23.874754190444946 s per 100 iters\n","time = 113.0, epoch 1, iter = 14200, loss = 2.596706918478012, 23.93480920791626 s per 100 iters\n","time = 113.0, epoch 1, iter = 14300, loss = 2.5847633087635042, 24.790678024291992 s per 100 iters\n","--- Balidazioa ---\n","37.93016600608826 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C in inius haec tam kultura ez da novalia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '-￭ ｟B rosanna lantza ｟E', '｟C ez al da arraroa ￭?', '｟C colinek berriro gelditu egin zuen ￭.', '-￭ ｟C ralph ￭!', '｟C oso melodia eta betea dago ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C bazkalorduan ￭, ｟C siziliako lehen aldiz jan zuen ｟C siziliako oiloan ￭, eta nesken xarma ￭, ｟C pirronen ￭, ｟C don ｟C fabriziok ￭, eta ｟C donfamatoko jauregiko handitasun handiaz jabetu zen ｟C marfilaminoko jauregiko jauregiko nagusia ez zela ｟C cappitora joan eta han geratuko zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', '｟C magistratu eta beste funtzionario batzuk ￭, ｟C joynes ｟C juduen eta ｟C josen ￭, ｟C legea ￭, eta zigorra ￭, subiranotasunaren eta ｟C zigorra ￭, ｟C infekzioaren eta ｟C koineskorrentzat ￭, ｟C aristotelesen aberastasuna ￭, ｟C aristotelesen eta ｟C aristotelesen ｟C fedeko ｟C gobernua ￭, ｟C aristotelesen eta ｟C fededun ￭, ｟C fededun ￭, ｟C fededun eta ｟C fedeko ｟C gobernatzaileen eta ｟C gobernatzaileen ｟C gobernatzaileen ｟C gobernatzaileen ｟C gobernuak ￭, ｟C gobernuak ￭, ｟C', '｟C jimmyk aurkitu zuenean ￭, ez zuen poliziari deitu ￭.', '｟C ideal hori ￭, ideal hori ￭, orain ￭, eta agian beste inor ez dute ￭, bere sormen espiritualik handienak dira ￭, eta bere ibilbideen eta inbidiagarriena ￭, bere ausart eta seduzitzaileen arteko lehia eta seduzitzaileen arteko lehia eta seduzitzaileen eta aniztasun eta aniztasun eta antsitoa ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez izateko ￭.', '｟C gutxienez ￭, ｟C derwatt-en gauzaarekin ￭, eta orain ｟C mafiako akusatua ￭?']\n","BLEU puntuazioa (1): 6.055766628612607\n","11.192489624023438 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharra gure janaria prestatzen ari dela ￭?', '- ｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C peaksera iritsi zenean ￭, mendekua hartu nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jauna ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ez zaizu inporta ￭?', '｟C eta nik 1960ko argazkia erakutsi diot ￭, eta bere semea 1940 uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C zoaz lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C delphine ziur zaude ￭?']\n","BLEU puntuazioa (2): 18.27226395181862\n","BLEU puntuazioa (biak): 8.965853969007139\n","time = 115.0, epoch 2, iter = 100, loss = 2.5038055276870725, 25.537999153137207 s per 100 iters\n","time = 115.0, epoch 2, iter = 200, loss = 2.466916012763977, 24.14577341079712 s per 100 iters\n","time = 116.0, epoch 2, iter = 300, loss = 2.4958746325969696, 23.096978187561035 s per 100 iters\n","time = 116.0, epoch 2, iter = 400, loss = 2.4913816440105436, 23.711591482162476 s per 100 iters\n","time = 116.0, epoch 2, iter = 500, loss = 2.508138105869293, 23.691879749298096 s per 100 iters\n","time = 117.0, epoch 2, iter = 600, loss = 2.518453623056412, 24.00884222984314 s per 100 iters\n","time = 117.0, epoch 2, iter = 700, loss = 2.4929191422462464, 24.51771330833435 s per 100 iters\n","time = 117.0, epoch 2, iter = 800, loss = 2.4950122141838076, 23.789166927337646 s per 100 iters\n","time = 118.0, epoch 2, iter = 900, loss = 2.52665456533432, 24.042537212371826 s per 100 iters\n","time = 118.0, epoch 2, iter = 1000, loss = 2.4890822899341583, 23.863242149353027 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 119.0, epoch 2, iter = 1100, loss = 2.473683241605759, 23.58353304862976 s per 100 iters\n","time = 119.0, epoch 2, iter = 1200, loss = 2.484642926454544, 24.249550104141235 s per 100 iters\n","time = 119.0, epoch 2, iter = 1300, loss = 2.5048541164398195, 23.67007851600647 s per 100 iters\n","time = 120.0, epoch 2, iter = 1400, loss = 2.5136621403694153, 24.012184858322144 s per 100 iters\n","time = 120.0, epoch 2, iter = 1500, loss = 2.4982943069934844, 24.353135108947754 s per 100 iters\n","time = 121.0, epoch 2, iter = 1600, loss = 2.465542596578598, 24.401137113571167 s per 100 iters\n","time = 121.0, epoch 2, iter = 1700, loss = 2.4989305317401884, 23.90833067893982 s per 100 iters\n","time = 121.0, epoch 2, iter = 1800, loss = 2.4459160387516024, 23.3277006149292 s per 100 iters\n","time = 122.0, epoch 2, iter = 1900, loss = 2.498864023685455, 23.88906502723694 s per 100 iters\n","time = 122.0, epoch 2, iter = 2000, loss = 2.5070742321014405, 23.77112102508545 s per 100 iters\n","time = 123.0, epoch 2, iter = 2100, loss = 2.4956811332702635, 24.02908158302307 s per 100 iters\n","time = 123.0, epoch 2, iter = 2200, loss = 2.479304413795471, 24.04009461402893 s per 100 iters\n","time = 123.0, epoch 2, iter = 2300, loss = 2.5087951183319093, 23.778968572616577 s per 100 iters\n","time = 124.0, epoch 2, iter = 2400, loss = 2.492391048669815, 24.16401219367981 s per 100 iters\n","time = 124.0, epoch 2, iter = 2500, loss = 2.5135986006259916, 24.47619867324829 s per 100 iters\n","time = 125.0, epoch 2, iter = 2600, loss = 2.476181569099426, 24.815749168395996 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 125.0, epoch 2, iter = 2700, loss = 2.4915468549728392, 23.658995389938354 s per 100 iters\n","time = 125.0, epoch 2, iter = 2800, loss = 2.5072168028354644, 23.729825019836426 s per 100 iters\n","time = 126.0, epoch 2, iter = 2900, loss = 2.485663865804672, 23.49473476409912 s per 100 iters\n","time = 126.0, epoch 2, iter = 3000, loss = 2.478989295959473, 24.074129581451416 s per 100 iters\n","time = 127.0, epoch 2, iter = 3100, loss = 2.487558951377869, 22.84627676010132 s per 100 iters\n","time = 127.0, epoch 2, iter = 3200, loss = 2.492686402797699, 23.649255514144897 s per 100 iters\n","time = 127.0, epoch 2, iter = 3300, loss = 2.4934500753879547, 24.29984760284424 s per 100 iters\n","time = 128.0, epoch 2, iter = 3400, loss = 2.4938615226745604, 24.19634175300598 s per 100 iters\n","time = 128.0, epoch 2, iter = 3500, loss = 2.4757529413700103, 23.852439165115356 s per 100 iters\n","time = 129.0, epoch 2, iter = 3600, loss = 2.4888099384307862, 24.030972957611084 s per 100 iters\n","time = 129.0, epoch 2, iter = 3700, loss = 2.5088060009479523, 24.357361555099487 s per 100 iters\n","time = 129.0, epoch 2, iter = 3800, loss = 2.4690020847320557, 24.62853455543518 s per 100 iters\n","time = 130.0, epoch 2, iter = 3900, loss = 2.4503164768218992, 24.31294322013855 s per 100 iters\n","time = 130.0, epoch 2, iter = 4000, loss = 2.487438942193985, 24.814706087112427 s per 100 iters\n","time = 131.0, epoch 2, iter = 4100, loss = 2.4654499292373657, 24.052907705307007 s per 100 iters\n","time = 131.0, epoch 2, iter = 4200, loss = 2.4535734379291534, 23.91618800163269 s per 100 iters\n","time = 132.0, epoch 2, iter = 4300, loss = 2.451467410326004, 24.285549640655518 s per 100 iters\n","time = 132.0, epoch 2, iter = 4400, loss = 2.468387097120285, 23.572760581970215 s per 100 iters\n","time = 132.0, epoch 2, iter = 4500, loss = 2.481569768190384, 24.310079097747803 s per 100 iters\n","time = 133.0, epoch 2, iter = 4600, loss = 2.462107194662094, 24.12840247154236 s per 100 iters\n","time = 133.0, epoch 2, iter = 4700, loss = 2.4648615920543673, 23.97778296470642 s per 100 iters\n","time = 133.0, epoch 2, iter = 4800, loss = 2.458577140569687, 23.21822500228882 s per 100 iters\n","time = 134.0, epoch 2, iter = 4900, loss = 2.466011657714844, 23.91043496131897 s per 100 iters\n","time = 134.0, epoch 2, iter = 5000, loss = 2.4580100953578947, 23.753894567489624 s per 100 iters\n","time = 135.0, epoch 2, iter = 5100, loss = 2.434108004570007, 23.97923707962036 s per 100 iters\n","time = 135.0, epoch 2, iter = 5200, loss = 2.4342245876789095, 24.34235715866089 s per 100 iters\n","time = 135.0, epoch 2, iter = 5300, loss = 2.4566472220420836, 23.48287272453308 s per 100 iters\n","time = 136.0, epoch 2, iter = 5400, loss = 2.449580409526825, 24.29638385772705 s per 100 iters\n","time = 136.0, epoch 2, iter = 5500, loss = 2.4518695080280306, 24.192662954330444 s per 100 iters\n","time = 137.0, epoch 2, iter = 5600, loss = 2.459479606151581, 23.70419192314148 s per 100 iters\n","time = 137.0, epoch 2, iter = 5700, loss = 2.461022881269455, 23.642072439193726 s per 100 iters\n","time = 137.0, epoch 2, iter = 5800, loss = 2.461607700586319, 24.2910373210907 s per 100 iters\n","time = 138.0, epoch 2, iter = 5900, loss = 2.4635786604881287, 23.766608476638794 s per 100 iters\n","time = 138.0, epoch 2, iter = 6000, loss = 2.4436085188388823, 23.412935733795166 s per 100 iters\n","time = 139.0, epoch 2, iter = 6100, loss = 2.44926128745079, 23.90981912612915 s per 100 iters\n","time = 139.0, epoch 2, iter = 6200, loss = 2.466809712648392, 23.767123460769653 s per 100 iters\n","time = 139.0, epoch 2, iter = 6300, loss = 2.4761380422115327, 23.819711923599243 s per 100 iters\n","time = 140.0, epoch 2, iter = 6400, loss = 2.472249345779419, 23.67878818511963 s per 100 iters\n","time = 140.0, epoch 2, iter = 6500, loss = 2.469190114736557, 24.937159776687622 s per 100 iters\n","time = 141.0, epoch 2, iter = 6600, loss = 2.452097933292389, 24.159586191177368 s per 100 iters\n","time = 141.0, epoch 2, iter = 6700, loss = 2.490290005207062, 24.675172567367554 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 141.0, epoch 2, iter = 6800, loss = 2.4574350094795228, 23.38466167449951 s per 100 iters\n","time = 142.0, epoch 2, iter = 6900, loss = 2.4628575539588926, 23.674999475479126 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 142.0, epoch 2, iter = 7000, loss = 2.467421443462372, 25.483848571777344 s per 100 iters\n","time = 143.0, epoch 2, iter = 7100, loss = 2.4530925869941713, 24.683828353881836 s per 100 iters\n","time = 143.0, epoch 2, iter = 7200, loss = 2.4708873426914213, 24.118197441101074 s per 100 iters\n","time = 144.0, epoch 2, iter = 7300, loss = 2.453722165822983, 23.98446798324585 s per 100 iters\n","time = 144.0, epoch 2, iter = 7400, loss = 2.452729514837265, 24.164042711257935 s per 100 iters\n","time = 144.0, epoch 2, iter = 7500, loss = 2.426586592197418, 22.99992799758911 s per 100 iters\n","time = 145.0, epoch 2, iter = 7600, loss = 2.4599470782279966, 23.123744249343872 s per 100 iters\n","time = 145.0, epoch 2, iter = 7700, loss = 2.437395677566528, 24.561718702316284 s per 100 iters\n","time = 145.0, epoch 2, iter = 7800, loss = 2.439183555841446, 24.330567598342896 s per 100 iters\n","time = 146.0, epoch 2, iter = 7900, loss = 2.4619493639469145, 24.06823444366455 s per 100 iters\n","time = 146.0, epoch 2, iter = 8000, loss = 2.470072979927063, 23.623311042785645 s per 100 iters\n","time = 147.0, epoch 2, iter = 8100, loss = 2.422922763824463, 24.52345561981201 s per 100 iters\n","time = 147.0, epoch 2, iter = 8200, loss = 2.4326960158348085, 23.57539176940918 s per 100 iters\n","time = 147.0, epoch 2, iter = 8300, loss = 2.4530395638942717, 23.409902811050415 s per 100 iters\n","time = 148.0, epoch 2, iter = 8400, loss = 2.417134883403778, 23.397311687469482 s per 100 iters\n","time = 148.0, epoch 2, iter = 8500, loss = 2.444080090522766, 24.813497304916382 s per 100 iters\n","time = 149.0, epoch 2, iter = 8600, loss = 2.4027988851070403, 23.160234451293945 s per 100 iters\n","time = 149.0, epoch 2, iter = 8700, loss = 2.4326135301589966, 23.381927967071533 s per 100 iters\n","time = 149.0, epoch 2, iter = 8800, loss = 2.421125359535217, 23.850836038589478 s per 100 iters\n","time = 150.0, epoch 2, iter = 8900, loss = 2.4303082931041717, 24.15365505218506 s per 100 iters\n","time = 150.0, epoch 2, iter = 9000, loss = 2.414549663066864, 24.034790754318237 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 151.0, epoch 2, iter = 9100, loss = 2.416345640420914, 23.571802854537964 s per 100 iters\n","time = 151.0, epoch 2, iter = 9200, loss = 2.4310928177833557, 23.17711567878723 s per 100 iters\n","time = 151.0, epoch 2, iter = 9300, loss = 2.4425202214717867, 24.67906379699707 s per 100 iters\n","time = 152.0, epoch 2, iter = 9400, loss = 2.422494589090347, 23.827784061431885 s per 100 iters\n","time = 152.0, epoch 2, iter = 9500, loss = 2.409769381284714, 23.227325201034546 s per 100 iters\n","time = 153.0, epoch 2, iter = 9600, loss = 2.4316362738609314, 23.6481351852417 s per 100 iters\n","time = 153.0, epoch 2, iter = 9700, loss = 2.4554791951179507, 24.442296028137207 s per 100 iters\n","time = 153.0, epoch 2, iter = 9800, loss = 2.4457901549339294, 24.05997896194458 s per 100 iters\n","time = 154.0, epoch 2, iter = 9900, loss = 2.4148556327819826, 23.28385853767395 s per 100 iters\n","time = 154.0, epoch 2, iter = 10000, loss = 2.4176994979381563, 23.635889291763306 s per 100 iters\n","time = 155.0, epoch 2, iter = 10100, loss = 2.417126817703247, 23.683585166931152 s per 100 iters\n","time = 155.0, epoch 2, iter = 10200, loss = 2.4154544997215273, 23.343146800994873 s per 100 iters\n","time = 155.0, epoch 2, iter = 10300, loss = 2.438271051645279, 23.512767553329468 s per 100 iters\n","time = 156.0, epoch 2, iter = 10400, loss = 2.4273311424255373, 24.337064504623413 s per 100 iters\n","time = 156.0, epoch 2, iter = 10500, loss = 2.4223334157466887, 23.73697590827942 s per 100 iters\n","time = 157.0, epoch 2, iter = 10600, loss = 2.443784784078598, 25.00891375541687 s per 100 iters\n","time = 157.0, epoch 2, iter = 10700, loss = 2.4279781770706177, 24.365281343460083 s per 100 iters\n","time = 157.0, epoch 2, iter = 10800, loss = 2.423707877397537, 24.624919891357422 s per 100 iters\n","time = 158.0, epoch 2, iter = 10900, loss = 2.4058741331100464, 24.16022276878357 s per 100 iters\n","time = 158.0, epoch 2, iter = 11000, loss = 2.4094282031059264, 24.358967542648315 s per 100 iters\n","time = 159.0, epoch 2, iter = 11100, loss = 2.3891205263137816, 23.49231266975403 s per 100 iters\n","time = 159.0, epoch 2, iter = 11200, loss = 2.4066218733787537, 24.282685041427612 s per 100 iters\n","time = 159.0, epoch 2, iter = 11300, loss = 2.4151728665828704, 24.081292390823364 s per 100 iters\n","time = 160.0, epoch 2, iter = 11400, loss = 2.4176092636585236, 23.885782480239868 s per 100 iters\n","time = 160.0, epoch 2, iter = 11500, loss = 2.4150560688972473, 24.613088607788086 s per 100 iters\n","time = 161.0, epoch 2, iter = 11600, loss = 2.4374718976020815, 24.00129771232605 s per 100 iters\n","time = 161.0, epoch 2, iter = 11700, loss = 2.3789976716041563, 23.469486236572266 s per 100 iters\n","time = 161.0, epoch 2, iter = 11800, loss = 2.4080425560474397, 24.4864718914032 s per 100 iters\n","time = 162.0, epoch 2, iter = 11900, loss = 2.3762517964839933, 24.476210594177246 s per 100 iters\n","time = 162.0, epoch 2, iter = 12000, loss = 2.3764028298854827, 23.256680965423584 s per 100 iters\n","time = 163.0, epoch 2, iter = 12100, loss = 2.395596742630005, 23.71414613723755 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 163.0, epoch 2, iter = 12200, loss = 2.4100349128246306, 23.463062286376953 s per 100 iters\n","time = 163.0, epoch 2, iter = 12300, loss = 2.4196042943000795, 23.673513889312744 s per 100 iters\n","time = 164.0, epoch 2, iter = 12400, loss = 2.395350292921066, 23.737800121307373 s per 100 iters\n","time = 164.0, epoch 2, iter = 12500, loss = 2.4072528636455535, 24.269408464431763 s per 100 iters\n","time = 165.0, epoch 2, iter = 12600, loss = 2.399477915763855, 24.01577591896057 s per 100 iters\n","time = 165.0, epoch 2, iter = 12700, loss = 2.384719029664993, 23.59053134918213 s per 100 iters\n","time = 165.0, epoch 2, iter = 12800, loss = 2.3955251848697663, 23.73878002166748 s per 100 iters\n","time = 166.0, epoch 2, iter = 12900, loss = 2.416875193119049, 24.053422451019287 s per 100 iters\n","time = 166.0, epoch 2, iter = 13000, loss = 2.4061021113395693, 23.57143759727478 s per 100 iters\n","time = 167.0, epoch 2, iter = 13100, loss = 2.3907668840885163, 23.010068655014038 s per 100 iters\n","time = 167.0, epoch 2, iter = 13200, loss = 2.38832555770874, 23.919596672058105 s per 100 iters\n","time = 167.0, epoch 2, iter = 13300, loss = 2.4086520206928252, 24.04284644126892 s per 100 iters\n","time = 168.0, epoch 2, iter = 13400, loss = 2.408439676761627, 24.276355266571045 s per 100 iters\n","time = 168.0, epoch 2, iter = 13500, loss = 2.3965594112873077, 23.309109926223755 s per 100 iters\n","time = 169.0, epoch 2, iter = 13600, loss = 2.387187200784683, 23.821284294128418 s per 100 iters\n","time = 169.0, epoch 2, iter = 13700, loss = 2.388679687976837, 23.699772357940674 s per 100 iters\n","time = 169.0, epoch 2, iter = 13800, loss = 2.390185146331787, 23.77473783493042 s per 100 iters\n","time = 170.0, epoch 2, iter = 13900, loss = 2.4254301369190214, 24.338228940963745 s per 100 iters\n","time = 170.0, epoch 2, iter = 14000, loss = 2.373247344493866, 23.589632272720337 s per 100 iters\n","time = 171.0, epoch 2, iter = 14100, loss = 2.3945926558971404, 23.88121509552002 s per 100 iters\n","time = 171.0, epoch 2, iter = 14200, loss = 2.3904235792160033, 23.52239203453064 s per 100 iters\n","time = 171.0, epoch 2, iter = 14300, loss = 2.4056232416629793, 23.69252347946167 s per 100 iters\n","--- Balidazioa ---\n","26.46340847015381 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam kultura novalia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da bitxia ￭?', '｟C colinek berriro gelditu zuen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C bazkalondoan ondo jan zuen ｟C siziliako lehen aldiz ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneen zaletasuna ￭, eta ｟C don ｟C fabriziok ￭, ｟C donnafugata jauregia ez zela ｟C donnafugatson ￭, eta han bizi zen ￭, seguru aski ￭, eta han utziko zuen ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi dauzkat ￭.', '｟C epaileak eta beste funtzionario batzuk ￭, juduen eta borreroen funtzionario ￭, artifizialak ￭, ｟C joyn eta ｟C zigorra (￭ ｟C jainkoaren eserlekura ￭) ￭, eta ｟C izpiritu ｟C naturalen baitan ￭, ｟C gorputzean ￭, ｟C aristotelesen eta ｟C populen ￭, ｟C nazioen ｟C elkarteak ￭, ｟C nazioen ｟C elkarteak ￭, ｟C elkarteak ￭, ｟C nazio ｟C nazio ｟C elkarteak ￭, ｟C nazio ｟C aberatsak ￭, ｟C kristoren ｟C elkarteak ￭, ｟C izpiritu ｟C elkarteak ￭, ｟C izpiritu ｟C elkarteak ￭, ｟C fedro eta ｟C elkarteak ￭, ｟C elkarteak ￭,', '｟C jimmy aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori beren ideal hori ￭, gaur egun eta agian beste inor ez da ￭, beren burua izpiritualki ￭, bere burua ￭, bere garaitzaile eta eskaerak ￭, seduzitzaile eta seduzitzaileen forma delikatua eta erakargarriena ￭.', '｟C hegoaldean ez dago familiarik ￭, esklaborik ez izateko bezain gaixo ￭.', '｟C duela gutxi ￭, ｟C derwatt-en gauza ￭, eta orain ｟C mafia salatu zuen ￭?']\n","BLEU puntuazioa (1): 7.41153882521173\n","9.918102979660034 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria zen ￭.', '｟C non uste duzu ｟C nick zaharra gure janaria jasotzen duela ￭?', '- ｟C corvette istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle iritsi zenean ￭, ｟C twin ｟C peaksen ￭, mendekua hartzera etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak basoan egongo dira ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ｟C ez zaizu axola ￭?', '｟C eta argazki bat daukat 1960ean eta bere semea 1940 uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C lo egin ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 19.72701406355431\n","BLEU puntuazioa (biak): 10.26937527287232\n","time = 173.0, epoch 3, iter = 100, loss = 2.2854975485801696, 25.132981777191162 s per 100 iters\n","time = 173.0, epoch 3, iter = 200, loss = 2.2894928193092348, 23.48213529586792 s per 100 iters\n","time = 173.0, epoch 3, iter = 300, loss = 2.2732437777519228, 23.729542016983032 s per 100 iters\n","time = 174.0, epoch 3, iter = 400, loss = 2.2779226315021517, 24.12627363204956 s per 100 iters\n","time = 174.0, epoch 3, iter = 500, loss = 2.2755017948150633, 23.256924390792847 s per 100 iters\n","time = 175.0, epoch 3, iter = 600, loss = 2.2721671330928803, 23.621856927871704 s per 100 iters\n","time = 175.0, epoch 3, iter = 700, loss = 2.284250935316086, 24.414854049682617 s per 100 iters\n","time = 175.0, epoch 3, iter = 800, loss = 2.3446568500995637, 24.645119428634644 s per 100 iters\n","time = 176.0, epoch 3, iter = 900, loss = 2.2948245775699614, 24.386322736740112 s per 100 iters\n","time = 176.0, epoch 3, iter = 1000, loss = 2.296202232837677, 23.775659561157227 s per 100 iters\n","time = 177.0, epoch 3, iter = 1100, loss = 2.295163186788559, 23.717981100082397 s per 100 iters\n","time = 177.0, epoch 3, iter = 1200, loss = 2.285674295425415, 23.7932550907135 s per 100 iters\n","time = 177.0, epoch 3, iter = 1300, loss = 2.3148476707935335, 24.447620153427124 s per 100 iters\n","time = 178.0, epoch 3, iter = 1400, loss = 2.291650321483612, 23.78707981109619 s per 100 iters\n","time = 178.0, epoch 3, iter = 1500, loss = 2.282639275789261, 23.986428260803223 s per 100 iters\n","time = 179.0, epoch 3, iter = 1600, loss = 2.277340840101242, 23.345721006393433 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 179.0, epoch 3, iter = 1700, loss = 2.2900071680545806, 23.864877223968506 s per 100 iters\n","time = 179.0, epoch 3, iter = 1800, loss = 2.2770107305049896, 23.823384046554565 s per 100 iters\n","time = 180.0, epoch 3, iter = 1900, loss = 2.2989770698547365, 24.01953959465027 s per 100 iters\n","time = 180.0, epoch 3, iter = 2000, loss = 2.262965669631958, 23.27068853378296 s per 100 iters\n","time = 181.0, epoch 3, iter = 2100, loss = 2.3130912482738495, 23.659086227416992 s per 100 iters\n","time = 181.0, epoch 3, iter = 2200, loss = 2.2818109810352327, 23.695571899414062 s per 100 iters\n","time = 181.0, epoch 3, iter = 2300, loss = 2.279730007648468, 24.118760108947754 s per 100 iters\n","time = 182.0, epoch 3, iter = 2400, loss = 2.2837159395217896, 23.555448055267334 s per 100 iters\n","time = 182.0, epoch 3, iter = 2500, loss = 2.328182965517044, 24.47638702392578 s per 100 iters\n","time = 183.0, epoch 3, iter = 2600, loss = 2.2937263667583467, 24.47780179977417 s per 100 iters\n","time = 183.0, epoch 3, iter = 2700, loss = 2.2981143951416017, 24.412105798721313 s per 100 iters\n","time = 183.0, epoch 3, iter = 2800, loss = 2.2687716245651246, 23.237523317337036 s per 100 iters\n","time = 184.0, epoch 3, iter = 2900, loss = 2.282269434928894, 23.693620681762695 s per 100 iters\n","time = 184.0, epoch 3, iter = 3000, loss = 2.275939049720764, 23.845772981643677 s per 100 iters\n","time = 185.0, epoch 3, iter = 3100, loss = 2.259183099269867, 24.17758011817932 s per 100 iters\n","time = 185.0, epoch 3, iter = 3200, loss = 2.2838664650917053, 24.14202618598938 s per 100 iters\n","time = 185.0, epoch 3, iter = 3300, loss = 2.310383017063141, 24.407968521118164 s per 100 iters\n","time = 186.0, epoch 3, iter = 3400, loss = 2.276461156606674, 23.607268810272217 s per 100 iters\n","time = 186.0, epoch 3, iter = 3500, loss = 2.3083404159545897, 23.746094703674316 s per 100 iters\n","time = 187.0, epoch 3, iter = 3600, loss = 2.299629338979721, 24.10624861717224 s per 100 iters\n","time = 187.0, epoch 3, iter = 3700, loss = 2.2887043821811677, 24.16797375679016 s per 100 iters\n","time = 187.0, epoch 3, iter = 3800, loss = 2.2914487326145174, 23.866434335708618 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 188.0, epoch 3, iter = 3900, loss = 2.282513347864151, 23.54901647567749 s per 100 iters\n","time = 188.0, epoch 3, iter = 4000, loss = 2.300849244594574, 24.44151759147644 s per 100 iters\n","time = 189.0, epoch 3, iter = 4100, loss = 2.2814763045310973, 23.90788698196411 s per 100 iters\n","time = 189.0, epoch 3, iter = 4200, loss = 2.304024728536606, 23.286768198013306 s per 100 iters\n","time = 189.0, epoch 3, iter = 4300, loss = 2.2970963525772095, 24.1548068523407 s per 100 iters\n","time = 190.0, epoch 3, iter = 4400, loss = 2.2934697484970092, 23.88186812400818 s per 100 iters\n","time = 190.0, epoch 3, iter = 4500, loss = 2.2795556712150575, 23.66648530960083 s per 100 iters\n","time = 191.0, epoch 3, iter = 4600, loss = 2.2904100215435026, 24.64479160308838 s per 100 iters\n","time = 191.0, epoch 3, iter = 4700, loss = 2.30892968416214, 24.08153223991394 s per 100 iters\n","time = 191.0, epoch 3, iter = 4800, loss = 2.309100457429886, 23.840110063552856 s per 100 iters\n","time = 192.0, epoch 3, iter = 4900, loss = 2.2897073292732237, 24.57056498527527 s per 100 iters\n","time = 192.0, epoch 3, iter = 5000, loss = 2.3130740439891815, 23.972813367843628 s per 100 iters\n","time = 193.0, epoch 3, iter = 5100, loss = 2.306662970781326, 24.516136646270752 s per 100 iters\n","time = 193.0, epoch 3, iter = 5200, loss = 2.2833093082904816, 23.93906545639038 s per 100 iters\n","time = 193.0, epoch 3, iter = 5300, loss = 2.2833903574943544, 23.77848505973816 s per 100 iters\n","time = 194.0, epoch 3, iter = 5400, loss = 2.268396844863892, 23.304704904556274 s per 100 iters\n","time = 194.0, epoch 3, iter = 5500, loss = 2.304476623535156, 24.17756414413452 s per 100 iters\n","time = 195.0, epoch 3, iter = 5600, loss = 2.2751053833961485, 24.278152465820312 s per 100 iters\n","time = 195.0, epoch 3, iter = 5700, loss = 2.293173557519913, 23.72338628768921 s per 100 iters\n","time = 195.0, epoch 3, iter = 5800, loss = 2.2946724784374237, 24.239215850830078 s per 100 iters\n","time = 196.0, epoch 3, iter = 5900, loss = 2.2905219912528993, 23.95010757446289 s per 100 iters\n","time = 196.0, epoch 3, iter = 6000, loss = 2.275279780626297, 23.525882482528687 s per 100 iters\n","time = 196.0, epoch 3, iter = 6100, loss = 2.2897801744937896, 23.47535729408264 s per 100 iters\n","time = 197.0, epoch 3, iter = 6200, loss = 2.2828280365467073, 24.09693670272827 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 197.0, epoch 3, iter = 6300, loss = 2.272875748872757, 23.738946676254272 s per 100 iters\n","time = 198.0, epoch 3, iter = 6400, loss = 2.280143948793411, 24.386448621749878 s per 100 iters\n","time = 198.0, epoch 3, iter = 6500, loss = 2.2806647038459777, 23.29162359237671 s per 100 iters\n","time = 198.0, epoch 3, iter = 6600, loss = 2.3204282689094544, 24.58223795890808 s per 100 iters\n","time = 199.0, epoch 3, iter = 6700, loss = 2.2728827214241027, 24.084468364715576 s per 100 iters\n","time = 199.0, epoch 3, iter = 6800, loss = 2.2771916234493257, 23.52493381500244 s per 100 iters\n","time = 200.0, epoch 3, iter = 6900, loss = 2.2866899132728578, 24.34132170677185 s per 100 iters\n","time = 200.0, epoch 3, iter = 7000, loss = 2.2987881338596345, 23.67660617828369 s per 100 iters\n","time = 200.0, epoch 3, iter = 7100, loss = 2.2866268968582153, 23.200865030288696 s per 100 iters\n","time = 201.0, epoch 3, iter = 7200, loss = 2.3056573259830473, 23.992058515548706 s per 100 iters\n","time = 201.0, epoch 3, iter = 7300, loss = 2.2776997101306917, 23.642573356628418 s per 100 iters\n","time = 202.0, epoch 3, iter = 7400, loss = 2.29512663602829, 24.07231116294861 s per 100 iters\n","time = 202.0, epoch 3, iter = 7500, loss = 2.270292191505432, 23.670323610305786 s per 100 iters\n","time = 202.0, epoch 3, iter = 7600, loss = 2.294852639436722, 23.717001914978027 s per 100 iters\n","time = 203.0, epoch 3, iter = 7700, loss = 2.2836423552036287, 23.822078704833984 s per 100 iters\n","time = 203.0, epoch 3, iter = 7800, loss = 2.2907886731624605, 23.934078454971313 s per 100 iters\n","time = 204.0, epoch 3, iter = 7900, loss = 2.2924989891052245, 24.302145957946777 s per 100 iters\n","time = 204.0, epoch 3, iter = 8000, loss = 2.2886747443675994, 23.343016386032104 s per 100 iters\n","time = 204.0, epoch 3, iter = 8100, loss = 2.266939481496811, 23.928309202194214 s per 100 iters\n","time = 205.0, epoch 3, iter = 8200, loss = 2.2932095086574553, 22.453743934631348 s per 100 iters\n","time = 205.0, epoch 3, iter = 8300, loss = 2.303256688117981, 23.892772674560547 s per 100 iters\n","time = 206.0, epoch 3, iter = 8400, loss = 2.2832018446922304, 24.48089361190796 s per 100 iters\n","time = 206.0, epoch 3, iter = 8500, loss = 2.300791301727295, 24.835217237472534 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 206.0, epoch 3, iter = 8600, loss = 2.285989366769791, 23.73164939880371 s per 100 iters\n","time = 207.0, epoch 3, iter = 8700, loss = 2.250164984464645, 24.01993227005005 s per 100 iters\n","time = 207.0, epoch 3, iter = 8800, loss = 2.2993027436733247, 23.93471670150757 s per 100 iters\n","time = 208.0, epoch 3, iter = 8900, loss = 2.310982496738434, 24.498876333236694 s per 100 iters\n","time = 208.0, epoch 3, iter = 9000, loss = 2.269175716638565, 24.33499789237976 s per 100 iters\n","time = 208.0, epoch 3, iter = 9100, loss = 2.2678589749336244, 24.08159899711609 s per 100 iters\n","time = 209.0, epoch 3, iter = 9200, loss = 2.2854954838752746, 23.68034029006958 s per 100 iters\n","time = 209.0, epoch 3, iter = 9300, loss = 2.2482058131694793, 23.75688910484314 s per 100 iters\n","time = 210.0, epoch 3, iter = 9400, loss = 2.2463536822795866, 23.95298743247986 s per 100 iters\n","time = 210.0, epoch 3, iter = 9500, loss = 2.305206135511398, 24.175863027572632 s per 100 iters\n","time = 210.0, epoch 3, iter = 9600, loss = 2.2843693709373474, 24.183335542678833 s per 100 iters\n","time = 211.0, epoch 3, iter = 9700, loss = 2.300423626899719, 25.09298348426819 s per 100 iters\n","time = 211.0, epoch 3, iter = 9800, loss = 2.2857939982414246, 24.04417371749878 s per 100 iters\n","time = 212.0, epoch 3, iter = 9900, loss = 2.2827015805244444, 24.347739934921265 s per 100 iters\n","time = 212.0, epoch 3, iter = 10000, loss = 2.293312828540802, 24.252469539642334 s per 100 iters\n","time = 212.0, epoch 3, iter = 10100, loss = 2.282216374874115, 24.43937921524048 s per 100 iters\n","time = 213.0, epoch 3, iter = 10200, loss = 2.2966349864006044, 24.103607654571533 s per 100 iters\n","time = 213.0, epoch 3, iter = 10300, loss = 2.2813060915470125, 23.397541046142578 s per 100 iters\n","time = 214.0, epoch 3, iter = 10400, loss = 2.298122926950455, 24.144050121307373 s per 100 iters\n","time = 214.0, epoch 3, iter = 10500, loss = 2.2667866063117983, 23.933070182800293 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 214.0, epoch 3, iter = 10600, loss = 2.2842028486728667, 24.82021737098694 s per 100 iters\n","time = 215.0, epoch 3, iter = 10700, loss = 2.2783246099948884, 24.328617334365845 s per 100 iters\n","time = 215.0, epoch 3, iter = 10800, loss = 2.2696885931491853, 24.103271484375 s per 100 iters\n","time = 216.0, epoch 3, iter = 10900, loss = 2.266213158369064, 23.729710578918457 s per 100 iters\n","time = 216.0, epoch 3, iter = 11000, loss = 2.2712484014034273, 23.42172360420227 s per 100 iters\n","time = 216.0, epoch 3, iter = 11100, loss = 2.258975965976715, 23.57913374900818 s per 100 iters\n","time = 217.0, epoch 3, iter = 11200, loss = 2.2733515179157258, 23.778325080871582 s per 100 iters\n","time = 217.0, epoch 3, iter = 11300, loss = 2.2765595006942747, 24.598701238632202 s per 100 iters\n","time = 218.0, epoch 3, iter = 11400, loss = 2.2778890800476073, 24.018601655960083 s per 100 iters\n","time = 218.0, epoch 3, iter = 11500, loss = 2.2851121258735656, 24.3532452583313 s per 100 iters\n","time = 218.0, epoch 3, iter = 11600, loss = 2.289807595014572, 24.534206867218018 s per 100 iters\n","time = 219.0, epoch 3, iter = 11700, loss = 2.3012087666988372, 25.058093070983887 s per 100 iters\n","time = 219.0, epoch 3, iter = 11800, loss = 2.2791588521003723, 24.21468162536621 s per 100 iters\n","time = 220.0, epoch 3, iter = 11900, loss = 2.2628358793258667, 24.096606016159058 s per 100 iters\n","time = 220.0, epoch 3, iter = 12000, loss = 2.2717657804489138, 23.52967882156372 s per 100 iters\n","time = 221.0, epoch 3, iter = 12100, loss = 2.2947750997543337, 24.98313808441162 s per 100 iters\n","time = 221.0, epoch 3, iter = 12200, loss = 2.2540350210666658, 23.487813234329224 s per 100 iters\n","time = 221.0, epoch 3, iter = 12300, loss = 2.2933477354049683, 24.510738372802734 s per 100 iters\n","time = 222.0, epoch 3, iter = 12400, loss = 2.2865060102939605, 24.559258460998535 s per 100 iters\n","time = 222.0, epoch 3, iter = 12500, loss = 2.2611338615417482, 24.965794563293457 s per 100 iters\n","time = 223.0, epoch 3, iter = 12600, loss = 2.2651629519462584, 24.160403728485107 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 223.0, epoch 3, iter = 12700, loss = 2.289168819189072, 24.498156547546387 s per 100 iters\n","time = 223.0, epoch 3, iter = 12800, loss = 2.255537648200989, 23.465992212295532 s per 100 iters\n","time = 224.0, epoch 3, iter = 12900, loss = 2.260983258485794, 24.116698503494263 s per 100 iters\n","time = 224.0, epoch 3, iter = 13000, loss = 2.2800679183006287, 24.32303762435913 s per 100 iters\n","time = 225.0, epoch 3, iter = 13100, loss = 2.2723249804973604, 23.87434220314026 s per 100 iters\n","time = 225.0, epoch 3, iter = 13200, loss = 2.259404011964798, 23.89901113510132 s per 100 iters\n","time = 225.0, epoch 3, iter = 13300, loss = 2.267189759016037, 23.43435549736023 s per 100 iters\n","time = 226.0, epoch 3, iter = 13400, loss = 2.2919979763031004, 24.022664308547974 s per 100 iters\n","time = 226.0, epoch 3, iter = 13500, loss = 2.2745478284358978, 24.36422348022461 s per 100 iters\n","time = 227.0, epoch 3, iter = 13600, loss = 2.2511514842510225, 23.634058952331543 s per 100 iters\n","time = 227.0, epoch 3, iter = 13700, loss = 2.271720687150955, 23.98908519744873 s per 100 iters\n","time = 227.0, epoch 3, iter = 13800, loss = 2.2759290742874145, 24.137971878051758 s per 100 iters\n","time = 228.0, epoch 3, iter = 13900, loss = 2.283830243349075, 24.580596208572388 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 228.0, epoch 3, iter = 14000, loss = 2.2697638654708863, 24.3010151386261 s per 100 iters\n","time = 229.0, epoch 3, iter = 14100, loss = 2.2434729027748106, 23.72148633003235 s per 100 iters\n","time = 229.0, epoch 3, iter = 14200, loss = 2.267785099744797, 24.066190719604492 s per 100 iters\n","time = 229.0, epoch 3, iter = 14300, loss = 2.2772293984889984, 24.433647394180298 s per 100 iters\n","--- Balidazioa ---\n","27.02987504005432 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colinek berriro ere gelditu egin zen ￭.', '-￭ ｟C ralph ￭!', '｟C oso melodia eta betea dago ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen ｟C siziliako lehen oinetan ￭, eta ｟C aitaren ｟C pirroneren xarma ￭, eta ｟C don ｟C fabriziok ￭, berriz ￭, ｟C donnafugata-ko ｟C kaporalaren jauregia ez zela bizirik irtengo ziurtatu zion ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaile eta exekuzio judizialen beste ofizial batzuk ￭, ｟C joynes artifizialak ￭, saria eta zigorra (￭ eta zigorrak ￭) ￭, eta bakoitzak bere eginkizuna betetzeko mugimendua eta osasuna bera betetzeko mugimendua ￭, gorputz naturalen gorputz naturalen artean ￭, gorputz naturalen eta ondasunen artean ￭, aberastasun partikularrak ￭, herrien ondasunak eta ondasun guztiak ￭, ｟C salbo eta ｟C salbo eta ｟C salboisen ｟C herrien ｟C gobernuak ￭, ｟C salbo eta ｟C herrien ｟C gobernuak ￭, ｟C gobernuak ￭, ｟C estatu ｟C gobernuak ￭, ｟C estatu ｟C estatu ｟C estatu', '｟C jimmyk aurkitu zuenean ￭, ez zuen poliziari deitu ￭.', 'ideal hori ￭, gaur egun ￭, bere ideala ordezkatzen dute ￭, eta agian ez beste inorena ￭, bere produktu izpiritualik gabea ￭, bere garaikide eta esploratzaileen aurreratuenak ￭, bere erakarpen delikatuets eta delikatuetsikorik delikatuena ￭.', '｟C hegoaldean ez dago familiarik ￭, ez esklaboak izateko ￭.', '｟C gutxienez ￭, ｟C derwatt-en gauza eta orain ｟C mafiaren salatzailea ￭?']\n","BLEU puntuazioa (1): 7.56496815400534\n","8.335923433303833 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria jasoko duela ￭?', '- ｟C ezagutzen dugu ｟C corvette istorio hori ￭, ｟C matt ￭.', '｟C oraindik ikusten ditugu ￭.', '｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ez zaizu axola ￭?', '｟C eta argazki bat erakutsi diot 1960an eta bere semea 1940 uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 20.012436249946603\n","BLEU puntuazioa (biak): 10.489077013158067\n","time = 231.0, epoch 4, iter = 100, loss = 2.138271052837372, 24.811011791229248 s per 100 iters\n","time = 231.0, epoch 4, iter = 200, loss = 2.144180405139923, 23.95971393585205 s per 100 iters\n","time = 231.0, epoch 4, iter = 300, loss = 2.1556780457496645, 24.069357872009277 s per 100 iters\n","time = 232.0, epoch 4, iter = 400, loss = 2.166726372241974, 24.006447792053223 s per 100 iters\n","time = 232.0, epoch 4, iter = 500, loss = 2.1645222091674805, 23.86488962173462 s per 100 iters\n","time = 233.0, epoch 4, iter = 600, loss = 2.16389524102211, 24.602556228637695 s per 100 iters\n","time = 233.0, epoch 4, iter = 700, loss = 2.155827280282974, 23.805676221847534 s per 100 iters\n","time = 233.0, epoch 4, iter = 800, loss = 2.164477345943451, 23.210259914398193 s per 100 iters\n","time = 234.0, epoch 4, iter = 900, loss = 2.183811140060425, 24.57806921005249 s per 100 iters\n","time = 234.0, epoch 4, iter = 1000, loss = 2.147340711355209, 23.085404634475708 s per 100 iters\n","time = 235.0, epoch 4, iter = 1100, loss = 2.169086899757385, 24.03462529182434 s per 100 iters\n","time = 235.0, epoch 4, iter = 1200, loss = 2.1506340396404267, 23.62990093231201 s per 100 iters\n","time = 235.0, epoch 4, iter = 1300, loss = 2.1665237951278686, 24.2767276763916 s per 100 iters\n","time = 236.0, epoch 4, iter = 1400, loss = 2.1474841010570525, 24.02955651283264 s per 100 iters\n","time = 236.0, epoch 4, iter = 1500, loss = 2.138214271068573, 23.76186466217041 s per 100 iters\n","time = 237.0, epoch 4, iter = 1600, loss = 2.192862330675125, 23.984317302703857 s per 100 iters\n","time = 237.0, epoch 4, iter = 1700, loss = 2.162865742444992, 23.857004404067993 s per 100 iters\n","time = 237.0, epoch 4, iter = 1800, loss = 2.131114536523819, 23.955011129379272 s per 100 iters\n","time = 238.0, epoch 4, iter = 1900, loss = 2.1749665331840515, 24.052809238433838 s per 100 iters\n","time = 238.0, epoch 4, iter = 2000, loss = 2.1621203529834747, 24.609894037246704 s per 100 iters\n","time = 239.0, epoch 4, iter = 2100, loss = 2.170905792713165, 24.11326265335083 s per 100 iters\n","time = 239.0, epoch 4, iter = 2200, loss = 2.18650887966156, 24.250971794128418 s per 100 iters\n","time = 239.0, epoch 4, iter = 2300, loss = 2.1744604337215425, 24.252349376678467 s per 100 iters\n","time = 240.0, epoch 4, iter = 2400, loss = 2.1830787467956543, 24.38107991218567 s per 100 iters\n","time = 240.0, epoch 4, iter = 2500, loss = 2.152814176082611, 24.00797176361084 s per 100 iters\n","time = 241.0, epoch 4, iter = 2600, loss = 2.1686682152748107, 23.82967185974121 s per 100 iters\n","time = 241.0, epoch 4, iter = 2700, loss = 2.128361886739731, 23.125171899795532 s per 100 iters\n","time = 241.0, epoch 4, iter = 2800, loss = 2.1584148454666137, 23.64131808280945 s per 100 iters\n","time = 242.0, epoch 4, iter = 2900, loss = 2.1721099185943604, 23.549927711486816 s per 100 iters\n","time = 242.0, epoch 4, iter = 3000, loss = 2.1756697833538055, 24.207388401031494 s per 100 iters\n","time = 243.0, epoch 4, iter = 3100, loss = 2.171032545566559, 24.063066244125366 s per 100 iters\n","time = 243.0, epoch 4, iter = 3200, loss = 2.1605995571613312, 24.151348114013672 s per 100 iters\n","time = 243.0, epoch 4, iter = 3300, loss = 2.165912353992462, 25.527127504348755 s per 100 iters\n","time = 244.0, epoch 4, iter = 3400, loss = 2.195092544555664, 24.80552363395691 s per 100 iters\n","time = 244.0, epoch 4, iter = 3500, loss = 2.172483184337616, 24.20953941345215 s per 100 iters\n","time = 245.0, epoch 4, iter = 3600, loss = 2.1757379937171937, 24.31217050552368 s per 100 iters\n","time = 245.0, epoch 4, iter = 3700, loss = 2.186894954442978, 24.31438899040222 s per 100 iters\n","time = 245.0, epoch 4, iter = 3800, loss = 2.1939495885372162, 24.322441577911377 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 246.0, epoch 4, iter = 3900, loss = 2.182711900472641, 23.622679471969604 s per 100 iters\n","time = 246.0, epoch 4, iter = 4000, loss = 2.169150074720383, 23.568750858306885 s per 100 iters\n","time = 247.0, epoch 4, iter = 4100, loss = 2.1785837984085084, 24.486255407333374 s per 100 iters\n","time = 247.0, epoch 4, iter = 4200, loss = 2.1775021815299986, 23.97899031639099 s per 100 iters\n","time = 247.0, epoch 4, iter = 4300, loss = 2.160462683439255, 24.103434085845947 s per 100 iters\n","time = 248.0, epoch 4, iter = 4400, loss = 2.165103260278702, 23.457430601119995 s per 100 iters\n","time = 248.0, epoch 4, iter = 4500, loss = 2.1808646583557127, 24.496776342391968 s per 100 iters\n","time = 249.0, epoch 4, iter = 4600, loss = 2.1739727807044984, 23.82710027694702 s per 100 iters\n","time = 249.0, epoch 4, iter = 4700, loss = 2.1891902792453766, 24.080375909805298 s per 100 iters\n","time = 249.0, epoch 4, iter = 4800, loss = 2.1685524368286133, 23.764683485031128 s per 100 iters\n","time = 250.0, epoch 4, iter = 4900, loss = 2.148279423713684, 23.57672095298767 s per 100 iters\n","time = 250.0, epoch 4, iter = 5000, loss = 2.2022498953342438, 24.125221729278564 s per 100 iters\n","time = 251.0, epoch 4, iter = 5100, loss = 2.179486677646637, 23.712566614151 s per 100 iters\n","time = 251.0, epoch 4, iter = 5200, loss = 2.1632153999805452, 23.3633975982666 s per 100 iters\n","time = 251.0, epoch 4, iter = 5300, loss = 2.1567199754714967, 23.499908685684204 s per 100 iters\n","time = 252.0, epoch 4, iter = 5400, loss = 2.194977940320969, 24.437280654907227 s per 100 iters\n","time = 252.0, epoch 4, iter = 5500, loss = 2.179617096185684, 24.354482889175415 s per 100 iters\n","time = 253.0, epoch 4, iter = 5600, loss = 2.156092423200607, 24.223743438720703 s per 100 iters\n","time = 253.0, epoch 4, iter = 5700, loss = 2.183433150053024, 25.39432692527771 s per 100 iters\n","time = 253.0, epoch 4, iter = 5800, loss = 2.1689097356796263, 23.961549282073975 s per 100 iters\n","time = 254.0, epoch 4, iter = 5900, loss = 2.186435604095459, 23.73266863822937 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 254.0, epoch 4, iter = 6000, loss = 2.1746758341789247, 24.307196617126465 s per 100 iters\n","time = 255.0, epoch 4, iter = 6100, loss = 2.172495015859604, 23.165952920913696 s per 100 iters\n","time = 255.0, epoch 4, iter = 6200, loss = 2.153090089559555, 24.013399362564087 s per 100 iters\n","time = 255.0, epoch 4, iter = 6300, loss = 2.168749643564224, 24.296894550323486 s per 100 iters\n","time = 256.0, epoch 4, iter = 6400, loss = 2.180713014602661, 24.28933835029602 s per 100 iters\n","time = 256.0, epoch 4, iter = 6500, loss = 2.206887490749359, 24.03185486793518 s per 100 iters\n","time = 257.0, epoch 4, iter = 6600, loss = 2.170600303411484, 23.793222904205322 s per 100 iters\n","time = 257.0, epoch 4, iter = 6700, loss = 2.185185502767563, 24.23219323158264 s per 100 iters\n","time = 257.0, epoch 4, iter = 6800, loss = 2.1771798133850098, 24.07224941253662 s per 100 iters\n","time = 258.0, epoch 4, iter = 6900, loss = 2.1793887329101564, 24.26871919631958 s per 100 iters\n","time = 258.0, epoch 4, iter = 7000, loss = 2.181190687417984, 24.32793164253235 s per 100 iters\n","time = 259.0, epoch 4, iter = 7100, loss = 2.168462953567505, 23.697752237319946 s per 100 iters\n","time = 259.0, epoch 4, iter = 7200, loss = 2.202875419855118, 24.787102937698364 s per 100 iters\n","time = 259.0, epoch 4, iter = 7300, loss = 2.1581439447402953, 24.48486590385437 s per 100 iters\n","time = 260.0, epoch 4, iter = 7400, loss = 2.18593959569931, 23.896333932876587 s per 100 iters\n","time = 260.0, epoch 4, iter = 7500, loss = 2.1887333750724793, 23.868001699447632 s per 100 iters\n","time = 261.0, epoch 4, iter = 7600, loss = 2.1751586425304414, 23.947759866714478 s per 100 iters\n","time = 261.0, epoch 4, iter = 7700, loss = 2.1630751621723174, 24.33820343017578 s per 100 iters\n","time = 261.0, epoch 4, iter = 7800, loss = 2.173637011051178, 23.530384063720703 s per 100 iters\n","time = 262.0, epoch 4, iter = 7900, loss = 2.1875445640087126, 24.24054503440857 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 262.0, epoch 4, iter = 8000, loss = 2.185257910490036, 23.72169280052185 s per 100 iters\n","time = 263.0, epoch 4, iter = 8100, loss = 2.1658556377887725, 23.388211727142334 s per 100 iters\n","time = 263.0, epoch 4, iter = 8200, loss = 2.179338654279709, 23.53890824317932 s per 100 iters\n","time = 263.0, epoch 4, iter = 8300, loss = 2.187983694076538, 23.423393964767456 s per 100 iters\n","time = 264.0, epoch 4, iter = 8400, loss = 2.135847046375275, 23.073988914489746 s per 100 iters\n","time = 264.0, epoch 4, iter = 8500, loss = 2.1789916872978212, 24.077413082122803 s per 100 iters\n","time = 265.0, epoch 4, iter = 8600, loss = 2.1394105327129362, 24.180894136428833 s per 100 iters\n","time = 265.0, epoch 4, iter = 8700, loss = 2.1762820410728456, 23.687037706375122 s per 100 iters\n","time = 265.0, epoch 4, iter = 8800, loss = 2.149435601234436, 23.226868629455566 s per 100 iters\n","time = 266.0, epoch 4, iter = 8900, loss = 2.210575110912323, 24.42038631439209 s per 100 iters\n","time = 266.0, epoch 4, iter = 9000, loss = 2.192864158153534, 24.112528800964355 s per 100 iters\n","time = 267.0, epoch 4, iter = 9100, loss = 2.1804306399822235, 24.609222650527954 s per 100 iters\n","time = 267.0, epoch 4, iter = 9200, loss = 2.191760905981064, 23.61155605316162 s per 100 iters\n","time = 267.0, epoch 4, iter = 9300, loss = 2.1933087480068205, 24.059558629989624 s per 100 iters\n","time = 268.0, epoch 4, iter = 9400, loss = 2.185409265756607, 23.920315980911255 s per 100 iters\n","time = 268.0, epoch 4, iter = 9500, loss = 2.179164470434189, 23.907257556915283 s per 100 iters\n","time = 269.0, epoch 4, iter = 9600, loss = 2.1841882777214052, 24.343769788742065 s per 100 iters\n","time = 269.0, epoch 4, iter = 9700, loss = 2.171635591983795, 23.902592420578003 s per 100 iters\n","time = 269.0, epoch 4, iter = 9800, loss = 2.1869038355350496, 24.346298933029175 s per 100 iters\n","time = 270.0, epoch 4, iter = 9900, loss = 2.1499075388908384, 23.748527765274048 s per 100 iters\n","time = 270.0, epoch 4, iter = 10000, loss = 2.175779312849045, 23.996968984603882 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 271.0, epoch 4, iter = 10100, loss = 2.19726624250412, 24.07758855819702 s per 100 iters\n","time = 271.0, epoch 4, iter = 10200, loss = 2.1469238793849943, 23.276884078979492 s per 100 iters\n","time = 271.0, epoch 4, iter = 10300, loss = 2.1940166103839873, 23.71008801460266 s per 100 iters\n","time = 272.0, epoch 4, iter = 10400, loss = 2.1576421105861665, 23.75581383705139 s per 100 iters\n","time = 272.0, epoch 4, iter = 10500, loss = 2.1604905223846433, 24.122090578079224 s per 100 iters\n","time = 273.0, epoch 4, iter = 10600, loss = 2.1621899259090425, 23.7554714679718 s per 100 iters\n","time = 273.0, epoch 4, iter = 10700, loss = 2.1882404899597168, 23.773353815078735 s per 100 iters\n","time = 273.0, epoch 4, iter = 10800, loss = 2.187555389404297, 23.884923934936523 s per 100 iters\n","time = 274.0, epoch 4, iter = 10900, loss = 2.1728018248081207, 23.850324153900146 s per 100 iters\n","time = 274.0, epoch 4, iter = 11000, loss = 2.1784729397296907, 23.81017780303955 s per 100 iters\n","time = 275.0, epoch 4, iter = 11100, loss = 2.1497249615192415, 24.57332730293274 s per 100 iters\n","time = 275.0, epoch 4, iter = 11200, loss = 2.205236656665802, 24.3509361743927 s per 100 iters\n","time = 275.0, epoch 4, iter = 11300, loss = 2.1902231109142303, 23.960079193115234 s per 100 iters\n","time = 276.0, epoch 4, iter = 11400, loss = 2.19389355301857, 24.189072847366333 s per 100 iters\n","time = 276.0, epoch 4, iter = 11500, loss = 2.16684246301651, 23.56890892982483 s per 100 iters\n","time = 277.0, epoch 4, iter = 11600, loss = 2.192349009513855, 23.34626269340515 s per 100 iters\n","time = 277.0, epoch 4, iter = 11700, loss = 2.1939899063110353, 23.54456901550293 s per 100 iters\n","time = 277.0, epoch 4, iter = 11800, loss = 2.190025337934494, 25.27549719810486 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 278.0, epoch 4, iter = 11900, loss = 2.172840813398361, 23.845949172973633 s per 100 iters\n","time = 278.0, epoch 4, iter = 12000, loss = 2.1883053934574126, 23.76274847984314 s per 100 iters\n","time = 279.0, epoch 4, iter = 12100, loss = 2.1910556507110597, 24.34284520149231 s per 100 iters\n","time = 279.0, epoch 4, iter = 12200, loss = 2.185685566663742, 24.510220527648926 s per 100 iters\n","time = 279.0, epoch 4, iter = 12300, loss = 2.1767796897888183, 23.877408266067505 s per 100 iters\n","time = 280.0, epoch 4, iter = 12400, loss = 2.1703201973438264, 24.601437091827393 s per 100 iters\n","time = 280.0, epoch 4, iter = 12500, loss = 2.1289453876018523, 23.447418928146362 s per 100 iters\n","time = 281.0, epoch 4, iter = 12600, loss = 2.1669012367725373, 23.507938623428345 s per 100 iters\n","time = 281.0, epoch 4, iter = 12700, loss = 2.1594285345077515, 23.18428635597229 s per 100 iters\n","time = 281.0, epoch 4, iter = 12800, loss = 2.169020209312439, 23.47323179244995 s per 100 iters\n","time = 282.0, epoch 4, iter = 12900, loss = 2.192370344400406, 24.078147411346436 s per 100 iters\n","time = 282.0, epoch 4, iter = 13000, loss = 2.179347194433212, 24.03001117706299 s per 100 iters\n","time = 283.0, epoch 4, iter = 13100, loss = 2.188620615005493, 24.33185863494873 s per 100 iters\n","time = 283.0, epoch 4, iter = 13200, loss = 2.1349345541000364, 23.58194375038147 s per 100 iters\n","time = 283.0, epoch 4, iter = 13300, loss = 2.1566449546813966, 23.440617561340332 s per 100 iters\n","time = 284.0, epoch 4, iter = 13400, loss = 2.1442130863666535, 23.56303358078003 s per 100 iters\n","time = 284.0, epoch 4, iter = 13500, loss = 2.1726635694503784, 23.66783618927002 s per 100 iters\n","time = 284.0, epoch 4, iter = 13600, loss = 2.141817270517349, 23.83565878868103 s per 100 iters\n","time = 285.0, epoch 4, iter = 13700, loss = 2.172540068626404, 24.310548067092896 s per 100 iters\n","time = 285.0, epoch 4, iter = 13800, loss = 2.164755619764328, 23.229984283447266 s per 100 iters\n","time = 286.0, epoch 4, iter = 13900, loss = 2.185512659549713, 24.797435522079468 s per 100 iters\n","time = 286.0, epoch 4, iter = 14000, loss = 2.177856665849686, 23.56765651702881 s per 100 iters\n","time = 286.0, epoch 4, iter = 14100, loss = 2.168082321882248, 23.870747804641724 s per 100 iters\n","time = 287.0, epoch 4, iter = 14200, loss = 2.1748270380496977, 23.382051944732666 s per 100 iters\n","time = 287.0, epoch 4, iter = 14300, loss = 2.1574731707572936, 23.82055425643921 s per 100 iters\n","--- Balidazioa ---\n","24.952913999557495 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impio haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afaltzean ￭, ｟C siziliako lurmuturrean ￭, eta nesken xaramela ￭, ｟C aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok ｟C donnafugatako jauregia ez zela ｟C capramen anpamina ￭, eta han bizirik utziko zuela seguru aski ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', '｟C magistratuak eta exekuzio judizialak ￭, artisauak ￭, ｟C joynsak eta ｟C zigor ｟C zigortuak (￭ ｟C subiranotasunaren eserlekura bizkortu eta elkartea bete behar dutenentzat ￭) nerbio guztiak gorputzean daude ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori ￭, gaur egun eta agian gaur egun ￭, errepresentazio gisa ￭, bere ekoizpen izpiritualik gabea da ￭, bere burua defendatzen du ￭, bere gatazka eta esploratzaileen aurreratuena ￭, bere erakarpen-forma delikagarri eta txit delikagarriena ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez edukitzeko bezain pobrea ￭.', '｟C duela gutxi ￭, behintzat ￭, ｟C derwatt-en gauzarekin ￭, eta orain ｟C mafiari leporatu zion ￭?']\n","BLEU puntuazioa (1): 7.8032451929274185\n","8.414852380752563 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria ekarriko duela ￭?', '- ｟C ezagutzen dugu ｟C corvette historia ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egin behar duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C emaztea beste gizon batekin dago eta ￭. ￭. ￭. ｟C ez zaizu axola ￭?', '｟C eta argazki bat daukat 1960ean eta bere semea 1940ko uniformean erakusten ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C lo egin ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 21.633308743706277\n","BLEU puntuazioa (biak): 11.044777800995416\n","time = 288.0, epoch 5, iter = 100, loss = 2.0601400792598725, 25.04368233680725 s per 100 iters\n","time = 289.0, epoch 5, iter = 200, loss = 2.04031201839447, 24.825753211975098 s per 100 iters\n","time = 289.0, epoch 5, iter = 300, loss = 2.0570349526405334, 23.736077785491943 s per 100 iters\n","time = 290.0, epoch 5, iter = 400, loss = 2.0593072211742403, 23.73769998550415 s per 100 iters\n","time = 290.0, epoch 5, iter = 500, loss = 2.0284227323532105, 24.258771657943726 s per 100 iters\n","time = 290.0, epoch 5, iter = 600, loss = 2.0573275470733643, 23.972699880599976 s per 100 iters\n","time = 291.0, epoch 5, iter = 700, loss = 2.0600873732566836, 24.461556673049927 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 291.0, epoch 5, iter = 800, loss = 2.082892210483551, 24.527711153030396 s per 100 iters\n","time = 292.0, epoch 5, iter = 900, loss = 2.043436796665192, 22.81769609451294 s per 100 iters\n","time = 292.0, epoch 5, iter = 1000, loss = 2.067178114056587, 24.478673219680786 s per 100 iters\n","time = 292.0, epoch 5, iter = 1100, loss = 2.087748110294342, 24.633842945098877 s per 100 iters\n","time = 293.0, epoch 5, iter = 1200, loss = 2.0700372469425203, 23.94249963760376 s per 100 iters\n","time = 293.0, epoch 5, iter = 1300, loss = 2.062211413383484, 24.22247886657715 s per 100 iters\n","time = 294.0, epoch 5, iter = 1400, loss = 2.1008700299263, 24.16660976409912 s per 100 iters\n","time = 294.0, epoch 5, iter = 1500, loss = 2.062993401288986, 24.556488037109375 s per 100 iters\n","time = 294.0, epoch 5, iter = 1600, loss = 2.0690352940559387, 24.170425415039062 s per 100 iters\n","time = 295.0, epoch 5, iter = 1700, loss = 2.076749708652496, 23.83538317680359 s per 100 iters\n","time = 295.0, epoch 5, iter = 1800, loss = 2.068325062990189, 23.521082162857056 s per 100 iters\n","time = 296.0, epoch 5, iter = 1900, loss = 2.0720597660541533, 24.53170895576477 s per 100 iters\n","time = 296.0, epoch 5, iter = 2000, loss = 2.0729025447368623, 23.867671966552734 s per 100 iters\n","time = 296.0, epoch 5, iter = 2100, loss = 2.058678079843521, 24.070419549942017 s per 100 iters\n","time = 297.0, epoch 5, iter = 2200, loss = 2.069014232158661, 23.645580053329468 s per 100 iters\n","time = 297.0, epoch 5, iter = 2300, loss = 2.06939311504364, 23.637280702590942 s per 100 iters\n","time = 298.0, epoch 5, iter = 2400, loss = 2.0693215525150297, 23.779282808303833 s per 100 iters\n","time = 298.0, epoch 5, iter = 2500, loss = 2.0655347502231596, 23.383461475372314 s per 100 iters\n","time = 298.0, epoch 5, iter = 2600, loss = 2.086244260072708, 23.873003005981445 s per 100 iters\n","time = 299.0, epoch 5, iter = 2700, loss = 2.0987841057777405, 24.107598304748535 s per 100 iters\n","time = 299.0, epoch 5, iter = 2800, loss = 2.0629423987865447, 24.301653385162354 s per 100 iters\n","time = 300.0, epoch 5, iter = 2900, loss = 2.081080820560455, 23.452722549438477 s per 100 iters\n","time = 300.0, epoch 5, iter = 3000, loss = 2.095068483352661, 24.493079900741577 s per 100 iters\n","time = 300.0, epoch 5, iter = 3100, loss = 2.0610497868061066, 23.902408599853516 s per 100 iters\n","time = 301.0, epoch 5, iter = 3200, loss = 2.0919534265995026, 23.69096851348877 s per 100 iters\n","time = 301.0, epoch 5, iter = 3300, loss = 2.078986945748329, 24.495952129364014 s per 100 iters\n","time = 302.0, epoch 5, iter = 3400, loss = 2.0832024228572847, 24.07281517982483 s per 100 iters\n","time = 302.0, epoch 5, iter = 3500, loss = 2.0914328479766846, 25.073652744293213 s per 100 iters\n","time = 302.0, epoch 5, iter = 3600, loss = 2.066008622646332, 23.318408727645874 s per 100 iters\n","time = 303.0, epoch 5, iter = 3700, loss = 2.0774192178249358, 24.36231780052185 s per 100 iters\n","time = 303.0, epoch 5, iter = 3800, loss = 2.110042368173599, 24.831575393676758 s per 100 iters\n","time = 304.0, epoch 5, iter = 3900, loss = 2.0759809792041777, 24.02991819381714 s per 100 iters\n","time = 304.0, epoch 5, iter = 4000, loss = 2.092357269525528, 23.875540494918823 s per 100 iters\n","time = 304.0, epoch 5, iter = 4100, loss = 2.0446518123149873, 23.805626392364502 s per 100 iters\n","time = 305.0, epoch 5, iter = 4200, loss = 2.077227280139923, 24.8027126789093 s per 100 iters\n","time = 305.0, epoch 5, iter = 4300, loss = 2.096053912639618, 24.08719301223755 s per 100 iters\n","time = 306.0, epoch 5, iter = 4400, loss = 2.0817400777339934, 23.843223094940186 s per 100 iters\n","time = 306.0, epoch 5, iter = 4500, loss = 2.076685998439789, 23.596182107925415 s per 100 iters\n","time = 306.0, epoch 5, iter = 4600, loss = 2.071857409477234, 23.86232089996338 s per 100 iters\n","time = 307.0, epoch 5, iter = 4700, loss = 2.08078264772892, 23.62135362625122 s per 100 iters\n","time = 307.0, epoch 5, iter = 4800, loss = 2.093957071304321, 23.883933067321777 s per 100 iters\n","time = 308.0, epoch 5, iter = 4900, loss = 2.112659273147583, 23.45077395439148 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 308.0, epoch 5, iter = 5000, loss = 2.0500958359241483, 23.468050956726074 s per 100 iters\n","time = 308.0, epoch 5, iter = 5100, loss = 2.082510222196579, 24.037091493606567 s per 100 iters\n","time = 309.0, epoch 5, iter = 5200, loss = 2.082743846178055, 24.021527767181396 s per 100 iters\n","time = 309.0, epoch 5, iter = 5300, loss = 2.08364622592926, 24.28612470626831 s per 100 iters\n","time = 310.0, epoch 5, iter = 5400, loss = 2.116350619792938, 24.70725440979004 s per 100 iters\n","time = 310.0, epoch 5, iter = 5500, loss = 2.087799143791199, 24.787800312042236 s per 100 iters\n","time = 310.0, epoch 5, iter = 5600, loss = 2.0744385385513304, 23.750627517700195 s per 100 iters\n","time = 311.0, epoch 5, iter = 5700, loss = 2.108304280042648, 23.61353826522827 s per 100 iters\n","time = 311.0, epoch 5, iter = 5800, loss = 2.1018298876285555, 23.687493801116943 s per 100 iters\n","time = 312.0, epoch 5, iter = 5900, loss = 2.076887286901474, 23.428009510040283 s per 100 iters\n","time = 312.0, epoch 5, iter = 6000, loss = 2.090625910758972, 24.359922170639038 s per 100 iters\n","time = 312.0, epoch 5, iter = 6100, loss = 2.086862165927887, 23.818050622940063 s per 100 iters\n","time = 313.0, epoch 5, iter = 6200, loss = 2.090482076406479, 24.063456296920776 s per 100 iters\n","time = 313.0, epoch 5, iter = 6300, loss = 2.081832364797592, 24.021519422531128 s per 100 iters\n","time = 314.0, epoch 5, iter = 6400, loss = 2.0663974261283875, 23.361943244934082 s per 100 iters\n","time = 314.0, epoch 5, iter = 6500, loss = 2.0912945115566255, 24.533183574676514 s per 100 iters\n","time = 314.0, epoch 5, iter = 6600, loss = 2.0909495508670806, 23.85041308403015 s per 100 iters\n","time = 315.0, epoch 5, iter = 6700, loss = 2.0877406287193296, 24.426567554473877 s per 100 iters\n","time = 315.0, epoch 5, iter = 6800, loss = 2.0849099278450014, 23.810356616973877 s per 100 iters\n","time = 316.0, epoch 5, iter = 6900, loss = 2.086032499074936, 24.50395655632019 s per 100 iters\n","time = 316.0, epoch 5, iter = 7000, loss = 2.0764452838897705, 24.26095199584961 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 316.0, epoch 5, iter = 7100, loss = 2.1207051157951353, 24.137179613113403 s per 100 iters\n","time = 317.0, epoch 5, iter = 7200, loss = 2.10162916302681, 24.660789012908936 s per 100 iters\n","time = 317.0, epoch 5, iter = 7300, loss = 2.079859929084778, 23.516125679016113 s per 100 iters\n","time = 318.0, epoch 5, iter = 7400, loss = 2.0731636929512023, 24.365479230880737 s per 100 iters\n","time = 318.0, epoch 5, iter = 7500, loss = 2.106204946041107, 23.935267210006714 s per 100 iters\n","time = 318.0, epoch 5, iter = 7600, loss = 2.0728423964977263, 23.6909761428833 s per 100 iters\n","time = 319.0, epoch 5, iter = 7700, loss = 2.0885112583637238, 24.227919340133667 s per 100 iters\n","time = 319.0, epoch 5, iter = 7800, loss = 2.1060117173194883, 24.003232717514038 s per 100 iters\n","time = 320.0, epoch 5, iter = 7900, loss = 2.0855641174316406, 23.82754898071289 s per 100 iters\n","time = 320.0, epoch 5, iter = 8000, loss = 2.1020862317085265, 24.683634757995605 s per 100 iters\n","time = 321.0, epoch 5, iter = 8100, loss = 2.082089079618454, 24.22264266014099 s per 100 iters\n","time = 321.0, epoch 5, iter = 8200, loss = 2.0840010249614718, 23.950700759887695 s per 100 iters\n","time = 321.0, epoch 5, iter = 8300, loss = 2.1041975522041323, 23.365927696228027 s per 100 iters\n","time = 322.0, epoch 5, iter = 8400, loss = 2.100386016368866, 23.171907424926758 s per 100 iters\n","time = 322.0, epoch 5, iter = 8500, loss = 2.0738824570178984, 24.368572235107422 s per 100 iters\n","time = 322.0, epoch 5, iter = 8600, loss = 2.116025471687317, 23.837299823760986 s per 100 iters\n","time = 323.0, epoch 5, iter = 8700, loss = 2.0892086362838747, 23.597728967666626 s per 100 iters\n","time = 323.0, epoch 5, iter = 8800, loss = 2.0839652538299562, 23.54136085510254 s per 100 iters\n","time = 324.0, epoch 5, iter = 8900, loss = 2.122988148331642, 23.647277116775513 s per 100 iters\n","time = 324.0, epoch 5, iter = 9000, loss = 2.105064766407013, 23.54853868484497 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 324.0, epoch 5, iter = 9100, loss = 2.1108661448955535, 22.799906730651855 s per 100 iters\n","time = 325.0, epoch 5, iter = 9200, loss = 2.0946800577640534, 23.518336534500122 s per 100 iters\n","time = 325.0, epoch 5, iter = 9300, loss = 2.112941793203354, 23.231969833374023 s per 100 iters\n","time = 326.0, epoch 5, iter = 9400, loss = 2.10347909450531, 23.928613662719727 s per 100 iters\n","time = 326.0, epoch 5, iter = 9500, loss = 2.085107650756836, 23.679133892059326 s per 100 iters\n","time = 326.0, epoch 5, iter = 9600, loss = 2.1103491449356078, 24.229219436645508 s per 100 iters\n","time = 327.0, epoch 5, iter = 9700, loss = 2.0851907789707185, 22.454541206359863 s per 100 iters\n","time = 327.0, epoch 5, iter = 9800, loss = 2.105652856826782, 24.4819118976593 s per 100 iters\n","time = 328.0, epoch 5, iter = 9900, loss = 2.1168166053295137, 23.703256130218506 s per 100 iters\n","time = 328.0, epoch 5, iter = 10000, loss = 2.096747624874115, 23.05272388458252 s per 100 iters\n","time = 328.0, epoch 5, iter = 10100, loss = 2.085018593072891, 23.221511363983154 s per 100 iters\n","time = 329.0, epoch 5, iter = 10200, loss = 2.089146534204483, 23.753933429718018 s per 100 iters\n","time = 329.0, epoch 5, iter = 10300, loss = 2.107431584596634, 22.62318754196167 s per 100 iters\n","time = 330.0, epoch 5, iter = 10400, loss = 2.1079913783073425, 23.00139546394348 s per 100 iters\n","time = 330.0, epoch 5, iter = 10500, loss = 2.0767305409908294, 22.699315309524536 s per 100 iters\n","time = 330.0, epoch 5, iter = 10600, loss = 2.0923426151275635, 23.493035078048706 s per 100 iters\n","time = 331.0, epoch 5, iter = 10700, loss = 2.098687468767166, 23.25766158103943 s per 100 iters\n","time = 331.0, epoch 5, iter = 10800, loss = 2.0949484169483186, 23.411651372909546 s per 100 iters\n","time = 331.0, epoch 5, iter = 10900, loss = 2.1066204380989073, 23.58787727355957 s per 100 iters\n","time = 332.0, epoch 5, iter = 11000, loss = 2.0869342243671416, 23.211533069610596 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 332.0, epoch 5, iter = 11100, loss = 2.080032411813736, 23.290494918823242 s per 100 iters\n","time = 333.0, epoch 5, iter = 11200, loss = 2.1184179198741915, 23.810752391815186 s per 100 iters\n","time = 333.0, epoch 5, iter = 11300, loss = 2.0937029564380647, 23.42169761657715 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 333.0, epoch 5, iter = 11400, loss = 2.0857966685295106, 23.34670901298523 s per 100 iters\n","time = 334.0, epoch 5, iter = 11500, loss = 2.077958060503006, 23.106969833374023 s per 100 iters\n","time = 334.0, epoch 5, iter = 11600, loss = 2.0950311625003817, 23.362300157546997 s per 100 iters\n","time = 335.0, epoch 5, iter = 11700, loss = 2.0981055665016175, 23.255879402160645 s per 100 iters\n","time = 335.0, epoch 5, iter = 11800, loss = 2.0982793307304384, 23.984119176864624 s per 100 iters\n","time = 335.0, epoch 5, iter = 11900, loss = 2.0972412633895874, 23.857433080673218 s per 100 iters\n","time = 336.0, epoch 5, iter = 12000, loss = 2.085021756887436, 22.81785750389099 s per 100 iters\n","time = 336.0, epoch 5, iter = 12100, loss = 2.0948387241363524, 23.683757543563843 s per 100 iters\n","time = 337.0, epoch 5, iter = 12200, loss = 2.0882934165000915, 23.46773862838745 s per 100 iters\n","time = 337.0, epoch 5, iter = 12300, loss = 2.0974080884456634, 23.961915493011475 s per 100 iters\n","time = 337.0, epoch 5, iter = 12400, loss = 2.0906537270545957, 23.350075244903564 s per 100 iters\n","time = 338.0, epoch 5, iter = 12500, loss = 2.076950696706772, 23.584532976150513 s per 100 iters\n","time = 338.0, epoch 5, iter = 12600, loss = 2.10423935174942, 23.54794216156006 s per 100 iters\n","time = 339.0, epoch 5, iter = 12700, loss = 2.1232107615470888, 23.94837713241577 s per 100 iters\n","time = 339.0, epoch 5, iter = 12800, loss = 2.0977050375938417, 23.1340913772583 s per 100 iters\n","time = 339.0, epoch 5, iter = 12900, loss = 2.0984791207313536, 23.334669589996338 s per 100 iters\n","time = 340.0, epoch 5, iter = 13000, loss = 2.106970467567444, 23.24563431739807 s per 100 iters\n","time = 340.0, epoch 5, iter = 13100, loss = 2.123646340370178, 23.284286499023438 s per 100 iters\n","time = 340.0, epoch 5, iter = 13200, loss = 2.109395228624344, 23.46193218231201 s per 100 iters\n","time = 341.0, epoch 5, iter = 13300, loss = 2.086612719297409, 23.308411836624146 s per 100 iters\n","time = 341.0, epoch 5, iter = 13400, loss = 2.1116366720199586, 23.657045125961304 s per 100 iters\n","time = 342.0, epoch 5, iter = 13500, loss = 2.0856846451759337, 22.8736891746521 s per 100 iters\n","time = 342.0, epoch 5, iter = 13600, loss = 2.0805274653434753, 23.36202049255371 s per 100 iters\n","time = 342.0, epoch 5, iter = 13700, loss = 2.084803010225296, 23.161184072494507 s per 100 iters\n","time = 343.0, epoch 5, iter = 13800, loss = 2.0976987612247466, 23.665660619735718 s per 100 iters\n","time = 343.0, epoch 5, iter = 13900, loss = 2.0778534030914306, 22.780646800994873 s per 100 iters\n","time = 344.0, epoch 5, iter = 14000, loss = 2.1127703380584717, 24.423495054244995 s per 100 iters\n","time = 344.0, epoch 5, iter = 14100, loss = 2.0926419043540956, 22.98469567298889 s per 100 iters\n","time = 344.0, epoch 5, iter = 14200, loss = 2.0992031610012054, 23.681729078292847 s per 100 iters\n","time = 345.0, epoch 5, iter = 14300, loss = 2.1024533569812776, 24.455153465270996 s per 100 iters\n","--- Balidazioa ---\n","18.783118963241577 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟B rosanna lantza ｟E', '｟C ez al da arraroa ￭?', '｟C colinek berriro ere gelditu zuen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere dulcinea ￭?', '｟C afalondoan ondo jan zuen ｟C siziliako urdearen gainean ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok konbentziturik utzi zuen ｟C don ｟C don ｟C fabriziok ｟C don ｟C don ｟C fabriziok ｟C caprardaren jauregia ez zela ￭, bizirik utziko zituela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', '｟C epaile eta exekuzio eta exekuzioen beste funtzionari batzuk ￭, ｟C joynts artifizialak ￭, zigor eta zigorrak (￭ subiranotasunaren eserlekura bizkortuz eta kide bakoitza bere eginbeharrak betetzeko ￭) ￭, gorputz naturalean bizi diren gorputzean ￭, aberastasunak eta aberastasunak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zuen poliziari deitu ￭.', '｟C ideal hori ￭, gaur egun ￭, errepresentazio gisa ￭, eta agian beste inor ez ￭, bere eragiketarik izpiritualenak dira ￭, bere borrokalarien eta esploratzaileen aurreratuenak ￭, bere erakarpen-itxura delikatuena ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain pobreak ￭.', '｟C duela gutxi ￭, ｟C derwatt-en gauza horrekin ￭, eta orain ｟C mafiaren aztikeria ￭?']\n","BLEU puntuazioa (1): 8.13666740159072\n","4.747149467468262 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria jasotzen duela ￭?', '- ｟C ezagutzen dugu ｟C corvette istorio hori ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera zetorrela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C basoan otsoak egongo dira ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ｟C ez zaizu axola ￭?', '｟C eta argazkia daukat 1960ean eta semea 1940 uniforme batean ￭.', '｟C gero dena aldatu zen ￭.', '-￭ ｟C zer txartel ￭?', '｟C lo egizu ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 20.892789757575102\n","BLEU puntuazioa (biak): 11.111746177970554\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 346.0, epoch 6, iter = 100, loss = 1.9743209826946257, 24.034451246261597 s per 100 iters\n","time = 346.0, epoch 6, iter = 200, loss = 1.9721201193332671, 23.200678825378418 s per 100 iters\n","time = 346.0, epoch 6, iter = 300, loss = 1.9777194368839264, 22.803379774093628 s per 100 iters\n","time = 347.0, epoch 6, iter = 400, loss = 1.9396447134017945, 22.857380628585815 s per 100 iters\n","time = 347.0, epoch 6, iter = 500, loss = 1.971355574131012, 22.98336148262024 s per 100 iters\n","time = 348.0, epoch 6, iter = 600, loss = 1.9713423621654511, 23.11450457572937 s per 100 iters\n","time = 348.0, epoch 6, iter = 700, loss = 1.9908733320236207, 23.650404453277588 s per 100 iters\n","time = 348.0, epoch 6, iter = 800, loss = 1.9863000869750977, 23.387500047683716 s per 100 iters\n","time = 349.0, epoch 6, iter = 900, loss = 1.9674768793582915, 22.778522491455078 s per 100 iters\n","time = 349.0, epoch 6, iter = 1000, loss = 1.984875042438507, 23.808497667312622 s per 100 iters\n","time = 350.0, epoch 6, iter = 1100, loss = 1.9879931616783142, 22.883184909820557 s per 100 iters\n","time = 350.0, epoch 6, iter = 1200, loss = 1.9832776498794555, 23.51761245727539 s per 100 iters\n","time = 350.0, epoch 6, iter = 1300, loss = 1.9805948996543885, 23.505983352661133 s per 100 iters\n","time = 351.0, epoch 6, iter = 1400, loss = 2.0100729763507843, 23.55466651916504 s per 100 iters\n","time = 351.0, epoch 6, iter = 1500, loss = 1.9593018412590026, 22.75633406639099 s per 100 iters\n","time = 352.0, epoch 6, iter = 1600, loss = 2.0022449278831482, 23.618461847305298 s per 100 iters\n","time = 352.0, epoch 6, iter = 1700, loss = 2.0018639731407166, 22.80457353591919 s per 100 iters\n","time = 352.0, epoch 6, iter = 1800, loss = 1.981221227645874, 22.905158519744873 s per 100 iters\n","time = 353.0, epoch 6, iter = 1900, loss = 1.9713873279094696, 22.975204944610596 s per 100 iters\n","time = 353.0, epoch 6, iter = 2000, loss = 1.9782498383522034, 23.284307718276978 s per 100 iters\n","time = 353.0, epoch 6, iter = 2100, loss = 2.027688890695572, 24.625284433364868 s per 100 iters\n","time = 354.0, epoch 6, iter = 2200, loss = 2.014574991464615, 23.318949699401855 s per 100 iters\n","time = 354.0, epoch 6, iter = 2300, loss = 2.0201510894298553, 23.816012859344482 s per 100 iters\n","time = 355.0, epoch 6, iter = 2400, loss = 1.9969584834575653, 22.969292879104614 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 355.0, epoch 6, iter = 2500, loss = 1.9937711679935455, 23.24981999397278 s per 100 iters\n","time = 355.0, epoch 6, iter = 2600, loss = 2.003681161403656, 23.118794441223145 s per 100 iters\n","time = 356.0, epoch 6, iter = 2700, loss = 1.9912951695919037, 23.33229899406433 s per 100 iters\n","time = 356.0, epoch 6, iter = 2800, loss = 1.9952824079990388, 22.94653868675232 s per 100 iters\n","time = 357.0, epoch 6, iter = 2900, loss = 1.9901168489456176, 23.020822286605835 s per 100 iters\n","time = 357.0, epoch 6, iter = 3000, loss = 1.99289927482605, 22.989181518554688 s per 100 iters\n","time = 357.0, epoch 6, iter = 3100, loss = 2.01407012462616, 23.040579795837402 s per 100 iters\n","time = 358.0, epoch 6, iter = 3200, loss = 2.0098183262348175, 23.145479917526245 s per 100 iters\n","time = 358.0, epoch 6, iter = 3300, loss = 1.9822138941287994, 22.909367561340332 s per 100 iters\n","time = 358.0, epoch 6, iter = 3400, loss = 2.0137729907035826, 23.651033401489258 s per 100 iters\n","time = 359.0, epoch 6, iter = 3500, loss = 2.0166140472888947, 22.41042423248291 s per 100 iters\n","time = 359.0, epoch 6, iter = 3600, loss = 2.0091348838806153, 23.39751100540161 s per 100 iters\n","time = 360.0, epoch 6, iter = 3700, loss = 2.004668107032776, 23.06045126914978 s per 100 iters\n","time = 360.0, epoch 6, iter = 3800, loss = 2.000256111621857, 23.749419450759888 s per 100 iters\n","time = 360.0, epoch 6, iter = 3900, loss = 2.0308776760101317, 23.137829303741455 s per 100 iters\n","time = 361.0, epoch 6, iter = 4000, loss = 2.042995955944061, 23.672457218170166 s per 100 iters\n","time = 361.0, epoch 6, iter = 4100, loss = 2.02164076089859, 22.71364665031433 s per 100 iters\n","time = 362.0, epoch 6, iter = 4200, loss = 2.0178435325622557, 23.44155478477478 s per 100 iters\n","time = 362.0, epoch 6, iter = 4300, loss = 1.9983400583267212, 23.688189029693604 s per 100 iters\n","time = 362.0, epoch 6, iter = 4400, loss = 2.011038739681244, 23.0173602104187 s per 100 iters\n","time = 363.0, epoch 6, iter = 4500, loss = 2.0036353492736816, 23.010489225387573 s per 100 iters\n","time = 363.0, epoch 6, iter = 4600, loss = 2.0049138188362123, 23.12213683128357 s per 100 iters\n","time = 364.0, epoch 6, iter = 4700, loss = 2.0061810410022733, 22.71363663673401 s per 100 iters\n","time = 364.0, epoch 6, iter = 4800, loss = 2.03659411072731, 24.057045221328735 s per 100 iters\n","time = 364.0, epoch 6, iter = 4900, loss = 1.9860126864910126, 22.33305311203003 s per 100 iters\n","time = 365.0, epoch 6, iter = 5000, loss = 2.019039282798767, 23.018738746643066 s per 100 iters\n","time = 365.0, epoch 6, iter = 5100, loss = 1.9900911712646485, 22.885034322738647 s per 100 iters\n","time = 365.0, epoch 6, iter = 5200, loss = 2.0309466671943666, 23.11193323135376 s per 100 iters\n","time = 366.0, epoch 6, iter = 5300, loss = 2.0095960807800295, 23.101560354232788 s per 100 iters\n","time = 366.0, epoch 6, iter = 5400, loss = 2.0216417121887207, 22.937697172164917 s per 100 iters\n","time = 367.0, epoch 6, iter = 5500, loss = 2.016122967004776, 23.88761258125305 s per 100 iters\n","time = 367.0, epoch 6, iter = 5600, loss = 2.018421264886856, 22.679296493530273 s per 100 iters\n","time = 367.0, epoch 6, iter = 5700, loss = 2.023318296670914, 23.59732961654663 s per 100 iters\n","time = 368.0, epoch 6, iter = 5800, loss = 2.021507924795151, 23.331563472747803 s per 100 iters\n","time = 368.0, epoch 6, iter = 5900, loss = 2.0163775181770323, 22.891843795776367 s per 100 iters\n","time = 369.0, epoch 6, iter = 6000, loss = 2.0314878284931184, 24.079052448272705 s per 100 iters\n","time = 369.0, epoch 6, iter = 6100, loss = 2.027858076095581, 23.300068378448486 s per 100 iters\n","time = 369.0, epoch 6, iter = 6200, loss = 2.0121822917461394, 22.965206384658813 s per 100 iters\n","time = 370.0, epoch 6, iter = 6300, loss = 2.0369377088546754, 24.387889623641968 s per 100 iters\n","time = 370.0, epoch 6, iter = 6400, loss = 2.025083637237549, 24.162420511245728 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 371.0, epoch 6, iter = 6500, loss = 2.008430519104004, 23.274686336517334 s per 100 iters\n","time = 371.0, epoch 6, iter = 6600, loss = 2.0296419179439544, 22.233670949935913 s per 100 iters\n","time = 371.0, epoch 6, iter = 6700, loss = 2.0045125591754913, 23.726820707321167 s per 100 iters\n","time = 372.0, epoch 6, iter = 6800, loss = 2.027644819021225, 23.373717784881592 s per 100 iters\n","time = 372.0, epoch 6, iter = 6900, loss = 2.036888301372528, 23.92292094230652 s per 100 iters\n","time = 372.0, epoch 6, iter = 7000, loss = 2.0327591717243196, 22.98548197746277 s per 100 iters\n","time = 373.0, epoch 6, iter = 7100, loss = 2.0018246853351593, 23.405858993530273 s per 100 iters\n","time = 373.0, epoch 6, iter = 7200, loss = 2.0308788061141967, 23.845993757247925 s per 100 iters\n","time = 374.0, epoch 6, iter = 7300, loss = 2.0445365500450134, 23.888200998306274 s per 100 iters\n","time = 374.0, epoch 6, iter = 7400, loss = 2.027573926448822, 24.20562243461609 s per 100 iters\n","time = 374.0, epoch 6, iter = 7500, loss = 2.0169278812408447, 23.008314847946167 s per 100 iters\n","time = 375.0, epoch 6, iter = 7600, loss = 2.023747457265854, 23.271493434906006 s per 100 iters\n","time = 375.0, epoch 6, iter = 7700, loss = 2.0378131473064425, 23.05830454826355 s per 100 iters\n","time = 376.0, epoch 6, iter = 7800, loss = 2.034357956647873, 23.51554822921753 s per 100 iters\n","time = 376.0, epoch 6, iter = 7900, loss = 2.016403136253357, 23.357719659805298 s per 100 iters\n","time = 376.0, epoch 6, iter = 8000, loss = 2.0604014348983766, 23.586580753326416 s per 100 iters\n","time = 377.0, epoch 6, iter = 8100, loss = 2.0371567821502685, 23.667412757873535 s per 100 iters\n","time = 377.0, epoch 6, iter = 8200, loss = 2.022160128355026, 23.19942283630371 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 378.0, epoch 6, iter = 8300, loss = 2.0300326097011565, 23.21068286895752 s per 100 iters\n","time = 378.0, epoch 6, iter = 8400, loss = 2.0446520757675173, 23.440847158432007 s per 100 iters\n","time = 378.0, epoch 6, iter = 8500, loss = 2.03074032664299, 23.665789127349854 s per 100 iters\n","time = 379.0, epoch 6, iter = 8600, loss = 2.022700906991959, 23.633430004119873 s per 100 iters\n","time = 379.0, epoch 6, iter = 8700, loss = 2.037523651123047, 23.74435019493103 s per 100 iters\n","time = 379.0, epoch 6, iter = 8800, loss = 2.031638585329056, 23.235180377960205 s per 100 iters\n","time = 380.0, epoch 6, iter = 8900, loss = 2.0283299398422243, 23.764909744262695 s per 100 iters\n","time = 380.0, epoch 6, iter = 9000, loss = 2.040404477119446, 23.706059217453003 s per 100 iters\n","time = 381.0, epoch 6, iter = 9100, loss = 2.037782143354416, 23.311781644821167 s per 100 iters\n","time = 381.0, epoch 6, iter = 9200, loss = 2.002292609214783, 23.11011004447937 s per 100 iters\n","time = 381.0, epoch 6, iter = 9300, loss = 2.0026449692249297, 22.541579008102417 s per 100 iters\n","time = 382.0, epoch 6, iter = 9400, loss = 2.0061858010292055, 23.050369262695312 s per 100 iters\n","time = 382.0, epoch 6, iter = 9500, loss = 1.997720708847046, 23.054330110549927 s per 100 iters\n","time = 383.0, epoch 6, iter = 9600, loss = 2.0221792805194854, 23.522660732269287 s per 100 iters\n","time = 383.0, epoch 6, iter = 9700, loss = 2.0345753014087675, 23.961578369140625 s per 100 iters\n","time = 383.0, epoch 6, iter = 9800, loss = 2.034318401813507, 24.29989218711853 s per 100 iters\n","time = 384.0, epoch 6, iter = 9900, loss = 2.01178893327713, 24.22996735572815 s per 100 iters\n","time = 384.0, epoch 6, iter = 10000, loss = 2.028521454334259, 23.388202667236328 s per 100 iters\n","time = 385.0, epoch 6, iter = 10100, loss = 2.0298784804344177, 23.038065671920776 s per 100 iters\n","time = 385.0, epoch 6, iter = 10200, loss = 2.029499053955078, 23.467828273773193 s per 100 iters\n","time = 385.0, epoch 6, iter = 10300, loss = 2.0303896582126617, 22.509942054748535 s per 100 iters\n","time = 386.0, epoch 6, iter = 10400, loss = 2.0223034483194353, 23.26351833343506 s per 100 iters\n","time = 386.0, epoch 6, iter = 10500, loss = 2.0402413988113404, 23.136911392211914 s per 100 iters\n","time = 387.0, epoch 6, iter = 10600, loss = 2.0258451855182646, 23.386415243148804 s per 100 iters\n","time = 387.0, epoch 6, iter = 10700, loss = 2.0642259335517883, 23.57193946838379 s per 100 iters\n","time = 387.0, epoch 6, iter = 10800, loss = 2.0061690008640287, 23.27868366241455 s per 100 iters\n","time = 388.0, epoch 6, iter = 10900, loss = 2.0423401284217833, 23.30771279335022 s per 100 iters\n","time = 388.0, epoch 6, iter = 11000, loss = 2.0384195852279663, 23.492454767227173 s per 100 iters\n","time = 388.0, epoch 6, iter = 11100, loss = 2.0649377942085265, 23.07456922531128 s per 100 iters\n","time = 389.0, epoch 6, iter = 11200, loss = 2.0414053773880005, 23.439461708068848 s per 100 iters\n","time = 389.0, epoch 6, iter = 11300, loss = 2.04308137178421, 23.82970666885376 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 390.0, epoch 6, iter = 11400, loss = 2.0273786330223085, 23.580281257629395 s per 100 iters\n","time = 390.0, epoch 6, iter = 11500, loss = 2.008867920637131, 23.573092699050903 s per 100 iters\n","time = 390.0, epoch 6, iter = 11600, loss = 2.0006165146827697, 23.31596565246582 s per 100 iters\n","time = 391.0, epoch 6, iter = 11700, loss = 2.0311312317848205, 22.411991596221924 s per 100 iters\n","time = 391.0, epoch 6, iter = 11800, loss = 2.048761124610901, 23.852150917053223 s per 100 iters\n","time = 392.0, epoch 6, iter = 11900, loss = 2.024868997335434, 22.769330978393555 s per 100 iters\n","time = 392.0, epoch 6, iter = 12000, loss = 2.0457413482666014, 23.914050817489624 s per 100 iters\n","time = 392.0, epoch 6, iter = 12100, loss = 2.0413103210926056, 23.36721920967102 s per 100 iters\n","time = 393.0, epoch 6, iter = 12200, loss = 2.049062888622284, 23.184929609298706 s per 100 iters\n","time = 393.0, epoch 6, iter = 12300, loss = 2.049077056646347, 24.14821696281433 s per 100 iters\n","time = 394.0, epoch 6, iter = 12400, loss = 2.012478885650635, 23.09432888031006 s per 100 iters\n","time = 394.0, epoch 6, iter = 12500, loss = 2.021276293992996, 22.948166131973267 s per 100 iters\n","time = 394.0, epoch 6, iter = 12600, loss = 2.0268126738071444, 23.335277795791626 s per 100 iters\n","time = 395.0, epoch 6, iter = 12700, loss = 2.023901957273483, 22.65029001235962 s per 100 iters\n","time = 395.0, epoch 6, iter = 12800, loss = 2.0457302594184874, 22.904416799545288 s per 100 iters\n","time = 395.0, epoch 6, iter = 12900, loss = 2.0478405582904817, 23.48638343811035 s per 100 iters\n","time = 396.0, epoch 6, iter = 13000, loss = 2.0526414310932157, 23.97922945022583 s per 100 iters\n","time = 396.0, epoch 6, iter = 13100, loss = 2.0530535197257995, 23.148700952529907 s per 100 iters\n","time = 397.0, epoch 6, iter = 13200, loss = 2.0401128661632537, 22.568063259124756 s per 100 iters\n","time = 397.0, epoch 6, iter = 13300, loss = 2.022102541923523, 23.92382001876831 s per 100 iters\n","time = 397.0, epoch 6, iter = 13400, loss = 2.030547995567322, 22.721585273742676 s per 100 iters\n","time = 398.0, epoch 6, iter = 13500, loss = 2.0331566441059112, 22.971882820129395 s per 100 iters\n","time = 398.0, epoch 6, iter = 13600, loss = 2.0208860206604005, 23.307143449783325 s per 100 iters\n","time = 399.0, epoch 6, iter = 13700, loss = 2.030799391269684, 23.158308744430542 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 399.0, epoch 6, iter = 13800, loss = 2.053949816226959, 24.351386547088623 s per 100 iters\n","time = 399.0, epoch 6, iter = 13900, loss = 2.0305709624290467, 23.227802991867065 s per 100 iters\n","time = 400.0, epoch 6, iter = 14000, loss = 2.0480153834819794, 23.483249187469482 s per 100 iters\n","time = 400.0, epoch 6, iter = 14100, loss = 2.027305028438568, 22.52766442298889 s per 100 iters\n","time = 400.0, epoch 6, iter = 14200, loss = 2.025802891254425, 23.43140721321106 s per 100 iters\n","time = 401.0, epoch 6, iter = 14300, loss = 2.02344553232193, 23.07478618621826 s per 100 iters\n","--- Balidazioa ---\n","22.136516571044922 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟B rosanna lantza-￭ zuzendaria ｟E', '｟C ez al da arraroa ￭?', '｟C colinek berriro ere gelditu zuen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere dulcinea ￭?', '｟C afaritan ￭, ｟C siziliako itsasertzean ￭, lehenengo aldiz ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok ｟C donnafugatako jauregia ez zela ｟C capraroko ezkongaia ￭, eta seguru aski bizirik utziko zituen ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C epaileen eta exekuzioaren beste funtzionari batzuk ￭, ｟C joynsen artifizialak ￭, saria eta zigorra (￭ zigortzen duena subiranotasunaren eta kide bakoitza bere betebeharra betetzeko ￭) mugatzen da ￭, nerbioek gorputzean duten nerbio eta aberastasunak eta aberastasunak ￭, herrien boterea da ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori ￭, beren ideala besterik ez da ￭, gaur egun eta agian beste inor ez dutenez ￭, beren sorkuntza izpiritualik zorrotzenak dira ￭, haren borrokalari eta esploratzaileen aurreratuenak ￭, bere sedukzioaren forma delikagarri eta delikatu eta fidagarriena ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez izateko bezain pobrea ￭.', '｟C duela gutxi ￭, ｟C derwatt-en gauza horrekin ￭, eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 8.6538163858324\n","5.062117099761963 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, oso musika interesgarria izan zen ￭.', '｟C nick zaharrak nola jaten du gure janaria ￭?', '- ｟C korvette historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earl ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorria zela uste nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C argazkia daukat 1960ean eta bere semea 1940eko uniformean erakusten ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C lotara itzuli ￭, maitea ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 21.44205285923714\n","BLEU puntuazioa (biak): 11.633117422373157\n","time = 402.0, epoch 7, iter = 100, loss = 1.9002175837755204, 24.0283522605896 s per 100 iters\n","time = 402.0, epoch 7, iter = 200, loss = 1.8879449009895324, 23.165327072143555 s per 100 iters\n","time = 403.0, epoch 7, iter = 300, loss = 1.9041535878181457, 23.637001514434814 s per 100 iters\n","time = 403.0, epoch 7, iter = 400, loss = 1.8887047207355498, 23.21544599533081 s per 100 iters\n","time = 403.0, epoch 7, iter = 500, loss = 1.9198304748535155, 23.478782176971436 s per 100 iters\n","time = 404.0, epoch 7, iter = 600, loss = 1.91167267203331, 23.29092836380005 s per 100 iters\n","time = 404.0, epoch 7, iter = 700, loss = 1.9074256193637849, 23.381195783615112 s per 100 iters\n","time = 405.0, epoch 7, iter = 800, loss = 1.9153337514400481, 22.513044118881226 s per 100 iters\n","time = 405.0, epoch 7, iter = 900, loss = 1.9219380128383636, 22.685997009277344 s per 100 iters\n","time = 405.0, epoch 7, iter = 1000, loss = 1.9381974196434022, 23.924296140670776 s per 100 iters\n","time = 406.0, epoch 7, iter = 1100, loss = 1.9395355874300002, 24.111199140548706 s per 100 iters\n","time = 406.0, epoch 7, iter = 1200, loss = 1.9331724739074707, 23.343564748764038 s per 100 iters\n","time = 407.0, epoch 7, iter = 1300, loss = 1.9216007047891617, 23.103553295135498 s per 100 iters\n","time = 407.0, epoch 7, iter = 1400, loss = 1.941068197488785, 23.463669300079346 s per 100 iters\n","time = 407.0, epoch 7, iter = 1500, loss = 1.9360279512405396, 23.34280014038086 s per 100 iters\n","time = 408.0, epoch 7, iter = 1600, loss = 1.9383785742521287, 22.935597896575928 s per 100 iters\n","time = 408.0, epoch 7, iter = 1700, loss = 1.936949074268341, 23.828808307647705 s per 100 iters\n","time = 409.0, epoch 7, iter = 1800, loss = 1.9314417815208436, 23.14731001853943 s per 100 iters\n","time = 409.0, epoch 7, iter = 1900, loss = 1.9213437682390213, 23.06902313232422 s per 100 iters\n","time = 409.0, epoch 7, iter = 2000, loss = 1.919038828611374, 23.042677879333496 s per 100 iters\n","time = 410.0, epoch 7, iter = 2100, loss = 1.9465148615837098, 23.15825629234314 s per 100 iters\n","time = 410.0, epoch 7, iter = 2200, loss = 1.9294632124900817, 23.277589797973633 s per 100 iters\n","time = 410.0, epoch 7, iter = 2300, loss = 1.9306432008743286, 23.47753620147705 s per 100 iters\n","time = 411.0, epoch 7, iter = 2400, loss = 1.9386203372478485, 23.796502113342285 s per 100 iters\n","time = 411.0, epoch 7, iter = 2500, loss = 1.9341167145967484, 23.415313959121704 s per 100 iters\n","time = 412.0, epoch 7, iter = 2600, loss = 1.9659412276744843, 23.443018674850464 s per 100 iters\n","time = 412.0, epoch 7, iter = 2700, loss = 1.960844419002533, 23.682939291000366 s per 100 iters\n","time = 412.0, epoch 7, iter = 2800, loss = 1.9198378753662109, 22.672465324401855 s per 100 iters\n","time = 413.0, epoch 7, iter = 2900, loss = 1.9211952042579652, 22.702070474624634 s per 100 iters\n","time = 413.0, epoch 7, iter = 3000, loss = 1.94201047539711, 23.507293462753296 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 414.0, epoch 7, iter = 3100, loss = 1.91937728703022, 22.545846223831177 s per 100 iters\n","time = 414.0, epoch 7, iter = 3200, loss = 1.9248610210418702, 23.794716358184814 s per 100 iters\n","time = 414.0, epoch 7, iter = 3300, loss = 1.9614253306388856, 23.238421201705933 s per 100 iters\n","time = 415.0, epoch 7, iter = 3400, loss = 1.9555249285697938, 24.143017292022705 s per 100 iters\n","time = 415.0, epoch 7, iter = 3500, loss = 1.9261712527275086, 23.124873161315918 s per 100 iters\n","time = 416.0, epoch 7, iter = 3600, loss = 1.9474712920188904, 23.242663383483887 s per 100 iters\n","time = 416.0, epoch 7, iter = 3700, loss = 1.9381994414329529, 23.348623275756836 s per 100 iters\n","time = 416.0, epoch 7, iter = 3800, loss = 1.9582281881570816, 22.712629079818726 s per 100 iters\n","time = 417.0, epoch 7, iter = 3900, loss = 1.9431979620456696, 23.437118768692017 s per 100 iters\n","time = 417.0, epoch 7, iter = 4000, loss = 1.9409835839271545, 23.639995098114014 s per 100 iters\n","time = 417.0, epoch 7, iter = 4100, loss = 1.943475051522255, 22.923368453979492 s per 100 iters\n","time = 418.0, epoch 7, iter = 4200, loss = 1.9549430406093598, 23.45088815689087 s per 100 iters\n","time = 418.0, epoch 7, iter = 4300, loss = 1.9598135471343994, 23.848121404647827 s per 100 iters\n","time = 419.0, epoch 7, iter = 4400, loss = 1.9423735082149505, 22.94865131378174 s per 100 iters\n","time = 419.0, epoch 7, iter = 4500, loss = 1.9345702135562897, 22.614137887954712 s per 100 iters\n","time = 419.0, epoch 7, iter = 4600, loss = 1.9531109261512756, 23.279576301574707 s per 100 iters\n","time = 420.0, epoch 7, iter = 4700, loss = 1.9627738046646117, 23.435621738433838 s per 100 iters\n","time = 420.0, epoch 7, iter = 4800, loss = 1.9690195953845977, 23.58724355697632 s per 100 iters\n","time = 421.0, epoch 7, iter = 4900, loss = 1.9713469791412352, 24.125317811965942 s per 100 iters\n","time = 421.0, epoch 7, iter = 5000, loss = 1.9509870183467866, 23.05646252632141 s per 100 iters\n","time = 421.0, epoch 7, iter = 5100, loss = 1.9530706131458282, 23.867270469665527 s per 100 iters\n","time = 422.0, epoch 7, iter = 5200, loss = 1.9194648897647857, 23.452072143554688 s per 100 iters\n","time = 422.0, epoch 7, iter = 5300, loss = 1.9464819699525833, 22.810187578201294 s per 100 iters\n","time = 423.0, epoch 7, iter = 5400, loss = 1.970730813741684, 24.465065240859985 s per 100 iters\n","time = 423.0, epoch 7, iter = 5500, loss = 1.953209215402603, 22.3906512260437 s per 100 iters\n","time = 423.0, epoch 7, iter = 5600, loss = 1.9489596748352052, 22.602322578430176 s per 100 iters\n","time = 424.0, epoch 7, iter = 5700, loss = 1.9442443227767945, 23.210468530654907 s per 100 iters\n","time = 424.0, epoch 7, iter = 5800, loss = 1.9560757422447204, 23.194844722747803 s per 100 iters\n","time = 424.0, epoch 7, iter = 5900, loss = 1.9478544199466705, 23.616862773895264 s per 100 iters\n","time = 425.0, epoch 7, iter = 6000, loss = 1.9748502826690675, 23.77503204345703 s per 100 iters\n","time = 425.0, epoch 7, iter = 6100, loss = 1.9277723157405853, 22.623425722122192 s per 100 iters\n","time = 426.0, epoch 7, iter = 6200, loss = 1.961499079465866, 23.088600397109985 s per 100 iters\n","time = 426.0, epoch 7, iter = 6300, loss = 1.9617852342128754, 23.553415536880493 s per 100 iters\n","time = 426.0, epoch 7, iter = 6400, loss = 1.9695270383358001, 24.092280626296997 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 427.0, epoch 7, iter = 6500, loss = 1.9568778705596923, 24.491811513900757 s per 100 iters\n","time = 427.0, epoch 7, iter = 6600, loss = 1.9505125725269317, 22.9941987991333 s per 100 iters\n","time = 428.0, epoch 7, iter = 6700, loss = 1.9391521072387696, 22.725843906402588 s per 100 iters\n","time = 428.0, epoch 7, iter = 6800, loss = 1.98778510928154, 23.652250289916992 s per 100 iters\n","time = 428.0, epoch 7, iter = 6900, loss = 1.9762852585315704, 23.160056114196777 s per 100 iters\n","time = 429.0, epoch 7, iter = 7000, loss = 1.9580217063426972, 24.22126579284668 s per 100 iters\n","time = 429.0, epoch 7, iter = 7100, loss = 1.9808585345745087, 23.796202421188354 s per 100 iters\n","time = 430.0, epoch 7, iter = 7200, loss = 1.9496903264522552, 22.782905101776123 s per 100 iters\n","time = 430.0, epoch 7, iter = 7300, loss = 1.9669323682785034, 23.189512729644775 s per 100 iters\n","time = 430.0, epoch 7, iter = 7400, loss = 1.9382412576675414, 22.929912090301514 s per 100 iters\n","time = 431.0, epoch 7, iter = 7500, loss = 1.9750505590438843, 22.954838037490845 s per 100 iters\n","time = 431.0, epoch 7, iter = 7600, loss = 1.9735448253154755, 22.92629909515381 s per 100 iters\n","time = 431.0, epoch 7, iter = 7700, loss = 1.9517880189418793, 22.836196660995483 s per 100 iters\n","time = 432.0, epoch 7, iter = 7800, loss = 1.9688350427150727, 23.086567640304565 s per 100 iters\n","time = 432.0, epoch 7, iter = 7900, loss = 1.9810340619087219, 23.1747784614563 s per 100 iters\n","time = 433.0, epoch 7, iter = 8000, loss = 1.9760456609725952, 23.978078603744507 s per 100 iters\n","time = 433.0, epoch 7, iter = 8100, loss = 1.9752188897132874, 22.80296301841736 s per 100 iters\n","time = 433.0, epoch 7, iter = 8200, loss = 1.9751814472675324, 22.963490962982178 s per 100 iters\n","time = 434.0, epoch 7, iter = 8300, loss = 1.9383649122714997, 22.671207666397095 s per 100 iters\n","time = 434.0, epoch 7, iter = 8400, loss = 1.960682669878006, 23.409493684768677 s per 100 iters\n","time = 435.0, epoch 7, iter = 8500, loss = 1.9770655560493469, 24.561726331710815 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 435.0, epoch 7, iter = 8600, loss = 1.9637881207466126, 23.25706434249878 s per 100 iters\n","time = 435.0, epoch 7, iter = 8700, loss = 1.976804485321045, 23.098042249679565 s per 100 iters\n","time = 436.0, epoch 7, iter = 8800, loss = 1.9758915996551514, 23.921677589416504 s per 100 iters\n","time = 436.0, epoch 7, iter = 8900, loss = 1.9724197232723235, 23.413740158081055 s per 100 iters\n","time = 436.0, epoch 7, iter = 9000, loss = 1.986045274734497, 22.384483337402344 s per 100 iters\n","time = 437.0, epoch 7, iter = 9100, loss = 1.9747287654876708, 23.52617859840393 s per 100 iters\n","time = 437.0, epoch 7, iter = 9200, loss = 1.9687324142456055, 23.23548650741577 s per 100 iters\n","time = 438.0, epoch 7, iter = 9300, loss = 1.9413096958398819, 22.38931679725647 s per 100 iters\n","time = 438.0, epoch 7, iter = 9400, loss = 1.9731721484661102, 23.64708971977234 s per 100 iters\n","time = 438.0, epoch 7, iter = 9500, loss = 1.9741346609592438, 23.244468688964844 s per 100 iters\n","time = 439.0, epoch 7, iter = 9600, loss = 1.9697658610343933, 23.599154710769653 s per 100 iters\n","time = 439.0, epoch 7, iter = 9700, loss = 1.9346243619918824, 22.140986442565918 s per 100 iters\n","time = 440.0, epoch 7, iter = 9800, loss = 1.975777087211609, 24.090315580368042 s per 100 iters\n","time = 440.0, epoch 7, iter = 9900, loss = 1.991291788816452, 23.103294610977173 s per 100 iters\n","time = 440.0, epoch 7, iter = 10000, loss = 1.9919098484516145, 24.490674257278442 s per 100 iters\n","time = 441.0, epoch 7, iter = 10100, loss = 1.981683340072632, 23.525229454040527 s per 100 iters\n","time = 441.0, epoch 7, iter = 10200, loss = 1.9949193108081817, 23.975332498550415 s per 100 iters\n","time = 442.0, epoch 7, iter = 10300, loss = 1.9516146719455718, 23.281687021255493 s per 100 iters\n","time = 442.0, epoch 7, iter = 10400, loss = 1.9948307371139526, 24.604140043258667 s per 100 iters\n","time = 442.0, epoch 7, iter = 10500, loss = 1.9743946290016174, 23.758261919021606 s per 100 iters\n","time = 443.0, epoch 7, iter = 10600, loss = 1.9825226855278015, 22.51383638381958 s per 100 iters\n","time = 443.0, epoch 7, iter = 10700, loss = 1.9756202840805053, 23.457383394241333 s per 100 iters\n","time = 444.0, epoch 7, iter = 10800, loss = 1.9788284277915955, 23.82484483718872 s per 100 iters\n","time = 444.0, epoch 7, iter = 10900, loss = 1.9668135964870452, 23.78339958190918 s per 100 iters\n","time = 444.0, epoch 7, iter = 11000, loss = 2.001136615276337, 23.36944270133972 s per 100 iters\n","time = 445.0, epoch 7, iter = 11100, loss = 1.9829913103580474, 24.384491205215454 s per 100 iters\n","time = 445.0, epoch 7, iter = 11200, loss = 1.9483257961273193, 23.78407382965088 s per 100 iters\n","time = 445.0, epoch 7, iter = 11300, loss = 1.9970666861534119, 23.692802906036377 s per 100 iters\n","time = 446.0, epoch 7, iter = 11400, loss = 2.01222785115242, 24.007641315460205 s per 100 iters\n","time = 446.0, epoch 7, iter = 11500, loss = 1.9986431670188904, 24.18422293663025 s per 100 iters\n","time = 447.0, epoch 7, iter = 11600, loss = 1.988892982006073, 24.391869068145752 s per 100 iters\n","time = 447.0, epoch 7, iter = 11700, loss = 2.005059014558792, 23.957552671432495 s per 100 iters\n","time = 448.0, epoch 7, iter = 11800, loss = 1.9311200296878814, 23.568644523620605 s per 100 iters\n","time = 448.0, epoch 7, iter = 11900, loss = 1.9770629811286926, 24.166473865509033 s per 100 iters\n","time = 448.0, epoch 7, iter = 12000, loss = 1.9802884900569915, 23.808635473251343 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 449.0, epoch 7, iter = 12100, loss = 1.9826509690284728, 23.662546634674072 s per 100 iters\n","time = 449.0, epoch 7, iter = 12200, loss = 1.9777475011348724, 24.067400217056274 s per 100 iters\n","time = 449.0, epoch 7, iter = 12300, loss = 1.9965826714038848, 23.43261456489563 s per 100 iters\n","time = 450.0, epoch 7, iter = 12400, loss = 2.0236079704761507, 23.43049931526184 s per 100 iters\n","time = 450.0, epoch 7, iter = 12500, loss = 1.9784142649173737, 23.262344360351562 s per 100 iters\n","time = 451.0, epoch 7, iter = 12600, loss = 1.9548387825489044, 23.632273197174072 s per 100 iters\n","time = 451.0, epoch 7, iter = 12700, loss = 1.9761327695846558, 23.899816036224365 s per 100 iters\n","time = 451.0, epoch 7, iter = 12800, loss = 1.9559865808486938, 23.848225593566895 s per 100 iters\n","time = 452.0, epoch 7, iter = 12900, loss = 1.983550033569336, 23.23508930206299 s per 100 iters\n","time = 452.0, epoch 7, iter = 13000, loss = 1.9976531314849852, 24.626867294311523 s per 100 iters\n","time = 453.0, epoch 7, iter = 13100, loss = 1.977337020635605, 23.633079051971436 s per 100 iters\n","time = 453.0, epoch 7, iter = 13200, loss = 1.9904890596866607, 23.996168851852417 s per 100 iters\n","time = 453.0, epoch 7, iter = 13300, loss = 1.9856965744495392, 24.523728370666504 s per 100 iters\n","time = 454.0, epoch 7, iter = 13400, loss = 1.9651963424682617, 22.895228624343872 s per 100 iters\n","time = 454.0, epoch 7, iter = 13500, loss = 1.9984095883369446, 23.912251234054565 s per 100 iters\n","time = 455.0, epoch 7, iter = 13600, loss = 1.9782941675186156, 22.87713074684143 s per 100 iters\n","time = 455.0, epoch 7, iter = 13700, loss = 1.988461492061615, 23.032369375228882 s per 100 iters\n","time = 455.0, epoch 7, iter = 13800, loss = 1.99806072473526, 23.56284213066101 s per 100 iters\n","time = 456.0, epoch 7, iter = 13900, loss = 1.988076012134552, 24.376262664794922 s per 100 iters\n","time = 456.0, epoch 7, iter = 14000, loss = 1.985223970413208, 23.894234895706177 s per 100 iters\n","time = 457.0, epoch 7, iter = 14100, loss = 1.9642991948127746, 23.66898775100708 s per 100 iters\n","time = 457.0, epoch 7, iter = 14200, loss = 1.9681201457977295, 23.160279273986816 s per 100 iters\n","time = 457.0, epoch 7, iter = 14300, loss = 1.9898839235305785, 24.520648956298828 s per 100 iters\n","--- Balidazioa ---\n","23.437185525894165 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afaritan ￭, ｟C siziliako itsasertzean oinak jarri zituen lehenengo aldiz ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austeritatearena ￭, eta ｟C don ｟C fabriziok ｟C donnafugata jauregia ez zela ｟C capraroko anbaroa ￭, eta han biziko zela seguru asko ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaile eta exekutiboen beste ofizialek ￭, bai eta bai exekutibo artifizialenek ere ￭, bai zigorra eta zigorra ￭, subiranotasunaren jarlekura azkarki mugitua delarik ￭, edozein joskin eta kideek bere eginkizuna betearazteko ￭, gorputz naturalean egiten duten nerbioek ￭, eta gizarte partikularrek ￭, beren aberastasunak eta aberastasunak ￭, ｟C salulsoak ￭, ｟C populus ￭, ｟C popularrak ￭, ｟C populus ￭, ｟C herriak ￭, ｟C apokles ￭, ｟C apezpiku ｟C fedon ￭, ｟C khan ￭, ｟C apok ￭, ｟C ap', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori beren idealaren ordezkaritza da ￭, gaur egun eta beharbada beste inor ez ￭, bere ekoizkin espiritualenak dira ￭, bere garaikide eta esploratzaileen bilketa aurreratuena ￭, bere sedukzioaren forma delikatuena eta elfoena ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez izateko bezain pobre ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kontuarekin ￭, eta orain ｟C mafiaren akusazioa ￭?']\n","BLEU puntuazioa (1): 9.092485672723981\n","5.204480409622192 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C eta ｟C nick zaharrak janaria ekartzen digula uste duzu ￭?', '- ｟C ezagutzen dugu ｟C corvette ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorria zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ｟C ez dizu axola ￭?', '｟C argazki bat atera diot 1960an eta bere semea 1940ko uniformean ￭.', '｟C gero dena aldatu zen ￭.', '-￭ ｟C zer txartel ￭?', '｟C lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaks-era doa ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 21.246781015713008\n","BLEU puntuazioa (biak): 11.906853245956103\n","time = 458.0, epoch 8, iter = 100, loss = 1.8614084392786026, 25.107256174087524 s per 100 iters\n","time = 459.0, epoch 8, iter = 200, loss = 1.8429638504981996, 24.04834294319153 s per 100 iters\n","time = 459.0, epoch 8, iter = 300, loss = 1.856143753528595, 24.153628826141357 s per 100 iters\n","time = 460.0, epoch 8, iter = 400, loss = 1.868893175125122, 23.153807640075684 s per 100 iters\n","time = 460.0, epoch 8, iter = 500, loss = 1.837857844233513, 23.794211387634277 s per 100 iters\n","time = 460.0, epoch 8, iter = 600, loss = 1.8381581127643585, 23.154558658599854 s per 100 iters\n","time = 461.0, epoch 8, iter = 700, loss = 1.8631363028287888, 23.700395822525024 s per 100 iters\n","time = 461.0, epoch 8, iter = 800, loss = 1.8685578310489654, 23.714343547821045 s per 100 iters\n","time = 462.0, epoch 8, iter = 900, loss = 1.8408800196647643, 23.209835290908813 s per 100 iters\n","time = 462.0, epoch 8, iter = 1000, loss = 1.879608861207962, 24.22834801673889 s per 100 iters\n","time = 462.0, epoch 8, iter = 1100, loss = 1.8769581401348114, 22.71060872077942 s per 100 iters\n","time = 463.0, epoch 8, iter = 1200, loss = 1.8628486204147339, 23.18888521194458 s per 100 iters\n","time = 463.0, epoch 8, iter = 1300, loss = 1.8582542783021927, 22.988298892974854 s per 100 iters\n","time = 464.0, epoch 8, iter = 1400, loss = 1.8768168765306472, 24.054236888885498 s per 100 iters\n","time = 464.0, epoch 8, iter = 1500, loss = 1.8445665806531906, 23.083204746246338 s per 100 iters\n","time = 464.0, epoch 8, iter = 1600, loss = 1.8695697659254074, 23.54035711288452 s per 100 iters\n","time = 465.0, epoch 8, iter = 1700, loss = 1.8575240981578827, 23.707476139068604 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 465.0, epoch 8, iter = 1800, loss = 1.864555585384369, 23.19059157371521 s per 100 iters\n","time = 466.0, epoch 8, iter = 1900, loss = 1.8767245221138, 24.188063621520996 s per 100 iters\n","time = 466.0, epoch 8, iter = 2000, loss = 1.8800464272499084, 22.952701091766357 s per 100 iters\n","time = 466.0, epoch 8, iter = 2100, loss = 1.8801196753978728, 24.307706117630005 s per 100 iters\n","time = 467.0, epoch 8, iter = 2200, loss = 1.877663072347641, 23.819379329681396 s per 100 iters\n","time = 467.0, epoch 8, iter = 2300, loss = 1.897590172290802, 23.626808643341064 s per 100 iters\n","time = 467.0, epoch 8, iter = 2400, loss = 1.8960801923274995, 23.330947160720825 s per 100 iters\n","time = 468.0, epoch 8, iter = 2500, loss = 1.8614227867126465, 22.477907180786133 s per 100 iters\n","time = 468.0, epoch 8, iter = 2600, loss = 1.8870329332351685, 23.527920722961426 s per 100 iters\n","time = 469.0, epoch 8, iter = 2700, loss = 1.8814939069747925, 23.35567021369934 s per 100 iters\n","time = 469.0, epoch 8, iter = 2800, loss = 1.8739168167114257, 23.13611388206482 s per 100 iters\n","time = 469.0, epoch 8, iter = 2900, loss = 1.8776816445589066, 22.783473014831543 s per 100 iters\n","time = 470.0, epoch 8, iter = 3000, loss = 1.8736281561851502, 22.763208150863647 s per 100 iters\n","time = 470.0, epoch 8, iter = 3100, loss = 1.879892339706421, 23.160398483276367 s per 100 iters\n","time = 471.0, epoch 8, iter = 3200, loss = 1.890285611152649, 23.74870467185974 s per 100 iters\n","time = 471.0, epoch 8, iter = 3300, loss = 1.8850459086894988, 22.81080412864685 s per 100 iters\n","time = 471.0, epoch 8, iter = 3400, loss = 1.8844816076755524, 23.876960515975952 s per 100 iters\n","time = 472.0, epoch 8, iter = 3500, loss = 1.899147071838379, 23.89589500427246 s per 100 iters\n","time = 472.0, epoch 8, iter = 3600, loss = 1.8897399067878724, 22.986084461212158 s per 100 iters\n","time = 473.0, epoch 8, iter = 3700, loss = 1.9027333402633666, 23.35527539253235 s per 100 iters\n","time = 473.0, epoch 8, iter = 3800, loss = 1.905968917608261, 23.588709831237793 s per 100 iters\n","time = 473.0, epoch 8, iter = 3900, loss = 1.9031580901145935, 23.388036966323853 s per 100 iters\n","time = 474.0, epoch 8, iter = 4000, loss = 1.9011393976211548, 22.988636255264282 s per 100 iters\n","time = 474.0, epoch 8, iter = 4100, loss = 1.8754948103427886, 22.738112688064575 s per 100 iters\n","time = 474.0, epoch 8, iter = 4200, loss = 1.8931919080018997, 23.6147301197052 s per 100 iters\n","time = 475.0, epoch 8, iter = 4300, loss = 1.915315111875534, 23.720452308654785 s per 100 iters\n","time = 475.0, epoch 8, iter = 4400, loss = 1.907204931974411, 23.405649423599243 s per 100 iters\n","time = 476.0, epoch 8, iter = 4500, loss = 1.8875461095571517, 22.497559785842896 s per 100 iters\n","time = 476.0, epoch 8, iter = 4600, loss = 1.9077694582939149, 23.966554403305054 s per 100 iters\n","time = 476.0, epoch 8, iter = 4700, loss = 1.8682227098941804, 23.295469760894775 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 477.0, epoch 8, iter = 4800, loss = 1.9024568057060243, 22.86113739013672 s per 100 iters\n","time = 477.0, epoch 8, iter = 4900, loss = 1.9035451543331146, 22.979753732681274 s per 100 iters\n","time = 478.0, epoch 8, iter = 5000, loss = 1.893310739994049, 22.831671714782715 s per 100 iters\n","time = 478.0, epoch 8, iter = 5100, loss = 1.9166976124048234, 23.38476800918579 s per 100 iters\n","time = 478.0, epoch 8, iter = 5200, loss = 1.9183100950717926, 23.48547077178955 s per 100 iters\n","time = 479.0, epoch 8, iter = 5300, loss = 1.9295699554681778, 23.03746271133423 s per 100 iters\n","time = 479.0, epoch 8, iter = 5400, loss = 1.906705495119095, 23.567264318466187 s per 100 iters\n","time = 480.0, epoch 8, iter = 5500, loss = 1.9156202065944672, 23.812725067138672 s per 100 iters\n","time = 480.0, epoch 8, iter = 5600, loss = 1.886969838142395, 23.04564332962036 s per 100 iters\n","time = 480.0, epoch 8, iter = 5700, loss = 1.898416621685028, 24.2942795753479 s per 100 iters\n","time = 481.0, epoch 8, iter = 5800, loss = 1.929444506764412, 23.573866367340088 s per 100 iters\n","time = 481.0, epoch 8, iter = 5900, loss = 1.9086346054077148, 23.688477993011475 s per 100 iters\n","time = 481.0, epoch 8, iter = 6000, loss = 1.916296284198761, 23.09325098991394 s per 100 iters\n","time = 482.0, epoch 8, iter = 6100, loss = 1.8923995929956436, 22.88944101333618 s per 100 iters\n","time = 482.0, epoch 8, iter = 6200, loss = 1.9155858480930328, 23.78430676460266 s per 100 iters\n","time = 483.0, epoch 8, iter = 6300, loss = 1.9135494369268418, 23.07422137260437 s per 100 iters\n","time = 483.0, epoch 8, iter = 6400, loss = 1.9138674825429915, 23.174003839492798 s per 100 iters\n","time = 483.0, epoch 8, iter = 6500, loss = 1.916628019809723, 22.877957105636597 s per 100 iters\n","time = 484.0, epoch 8, iter = 6600, loss = 1.9122061014175415, 23.13388204574585 s per 100 iters\n","time = 484.0, epoch 8, iter = 6700, loss = 1.9153168666362763, 22.94413733482361 s per 100 iters\n","time = 485.0, epoch 8, iter = 6800, loss = 1.9072539561986923, 23.5255606174469 s per 100 iters\n","time = 485.0, epoch 8, iter = 6900, loss = 1.9101472675800324, 22.924702167510986 s per 100 iters\n","time = 485.0, epoch 8, iter = 7000, loss = 1.934772115945816, 23.54361367225647 s per 100 iters\n","time = 486.0, epoch 8, iter = 7100, loss = 1.9241513454914092, 23.425567388534546 s per 100 iters\n","time = 486.0, epoch 8, iter = 7200, loss = 1.9227816879749298, 23.227575063705444 s per 100 iters\n","time = 486.0, epoch 8, iter = 7300, loss = 1.898505563735962, 22.87291646003723 s per 100 iters\n","time = 487.0, epoch 8, iter = 7400, loss = 1.8914059269428254, 22.987003803253174 s per 100 iters\n","time = 487.0, epoch 8, iter = 7500, loss = 1.9016401171684265, 23.10563063621521 s per 100 iters\n","time = 488.0, epoch 8, iter = 7600, loss = 1.9047240865230561, 23.032997131347656 s per 100 iters\n","time = 488.0, epoch 8, iter = 7700, loss = 1.9239034390449523, 24.239553928375244 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 488.0, epoch 8, iter = 7800, loss = 1.9364113533496856, 24.03336763381958 s per 100 iters\n","time = 489.0, epoch 8, iter = 7900, loss = 1.920296174287796, 22.85120916366577 s per 100 iters\n","time = 489.0, epoch 8, iter = 8000, loss = 1.889675611257553, 23.243111610412598 s per 100 iters\n","time = 490.0, epoch 8, iter = 8100, loss = 1.9193176090717317, 23.187384128570557 s per 100 iters\n","time = 490.0, epoch 8, iter = 8200, loss = 1.9096222305297852, 23.17770791053772 s per 100 iters\n","time = 490.0, epoch 8, iter = 8300, loss = 1.912158238887787, 23.483341693878174 s per 100 iters\n","time = 491.0, epoch 8, iter = 8400, loss = 1.9435298883914947, 23.856353521347046 s per 100 iters\n","time = 491.0, epoch 8, iter = 8500, loss = 1.9176269370317458, 24.034003257751465 s per 100 iters\n","time = 492.0, epoch 8, iter = 8600, loss = 1.9170552265644074, 23.27532196044922 s per 100 iters\n","time = 492.0, epoch 8, iter = 8700, loss = 1.9201134526729584, 23.890283346176147 s per 100 iters\n","time = 492.0, epoch 8, iter = 8800, loss = 1.9192875599861146, 23.816241979599 s per 100 iters\n","time = 493.0, epoch 8, iter = 8900, loss = 1.9069112098217011, 23.031352996826172 s per 100 iters\n","time = 493.0, epoch 8, iter = 9000, loss = 1.9437015515565872, 24.00323247909546 s per 100 iters\n","time = 494.0, epoch 8, iter = 9100, loss = 1.950020388364792, 24.461091995239258 s per 100 iters\n","time = 494.0, epoch 8, iter = 9200, loss = 1.9122566890716552, 22.568705081939697 s per 100 iters\n","time = 494.0, epoch 8, iter = 9300, loss = 1.93508345246315, 23.548653841018677 s per 100 iters\n","time = 495.0, epoch 8, iter = 9400, loss = 1.9382561790943145, 23.86999797821045 s per 100 iters\n","time = 495.0, epoch 8, iter = 9500, loss = 1.9083523732423782, 23.245429754257202 s per 100 iters\n","time = 495.0, epoch 8, iter = 9600, loss = 1.931524978876114, 23.550638437271118 s per 100 iters\n","time = 496.0, epoch 8, iter = 9700, loss = 1.9430454325675965, 24.240659475326538 s per 100 iters\n","time = 496.0, epoch 8, iter = 9800, loss = 1.9211486566066742, 23.71860098838806 s per 100 iters\n","time = 497.0, epoch 8, iter = 9900, loss = 1.9106953787803649, 23.05027985572815 s per 100 iters\n","time = 497.0, epoch 8, iter = 10000, loss = 1.9207013070583343, 23.579388856887817 s per 100 iters\n","time = 497.0, epoch 8, iter = 10100, loss = 1.922448183298111, 22.84651827812195 s per 100 iters\n","time = 498.0, epoch 8, iter = 10200, loss = 1.911092957854271, 23.041855335235596 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 498.0, epoch 8, iter = 10300, loss = 1.9266648370027541, 22.96155571937561 s per 100 iters\n","time = 499.0, epoch 8, iter = 10400, loss = 1.9391336297988893, 23.387909650802612 s per 100 iters\n","time = 499.0, epoch 8, iter = 10500, loss = 1.917622059583664, 22.665783405303955 s per 100 iters\n","time = 499.0, epoch 8, iter = 10600, loss = 1.92087296128273, 23.63551092147827 s per 100 iters\n","time = 500.0, epoch 8, iter = 10700, loss = 1.9143023490905762, 23.634126901626587 s per 100 iters\n","time = 500.0, epoch 8, iter = 10800, loss = 1.9192254555225372, 22.677568912506104 s per 100 iters\n","time = 501.0, epoch 8, iter = 10900, loss = 1.8976391994953155, 23.23818302154541 s per 100 iters\n","time = 501.0, epoch 8, iter = 11000, loss = 1.9302285063266753, 23.565443754196167 s per 100 iters\n","time = 501.0, epoch 8, iter = 11100, loss = 1.925533537864685, 23.549614191055298 s per 100 iters\n","time = 502.0, epoch 8, iter = 11200, loss = 1.9395004320144653, 23.358761310577393 s per 100 iters\n","time = 502.0, epoch 8, iter = 11300, loss = 1.9179479122161864, 23.35393524169922 s per 100 iters\n","time = 503.0, epoch 8, iter = 11400, loss = 1.9321558129787446, 23.88585138320923 s per 100 iters\n","time = 503.0, epoch 8, iter = 11500, loss = 1.9154222333431243, 22.87509799003601 s per 100 iters\n","time = 503.0, epoch 8, iter = 11600, loss = 1.9388029313087463, 22.81639838218689 s per 100 iters\n","time = 504.0, epoch 8, iter = 11700, loss = 1.9572879135608674, 24.288170337677002 s per 100 iters\n","time = 504.0, epoch 8, iter = 11800, loss = 1.947059017419815, 23.854816436767578 s per 100 iters\n","time = 504.0, epoch 8, iter = 11900, loss = 1.9343015050888062, 24.171889781951904 s per 100 iters\n","time = 505.0, epoch 8, iter = 12000, loss = 1.962838802933693, 23.04424500465393 s per 100 iters\n","time = 505.0, epoch 8, iter = 12100, loss = 1.9421523463726045, 23.603781938552856 s per 100 iters\n","time = 506.0, epoch 8, iter = 12200, loss = 1.9462407052516937, 23.419694185256958 s per 100 iters\n","time = 506.0, epoch 8, iter = 12300, loss = 1.919126852750778, 23.50948166847229 s per 100 iters\n","time = 506.0, epoch 8, iter = 12400, loss = 1.945054543018341, 24.55708909034729 s per 100 iters\n","time = 507.0, epoch 8, iter = 12500, loss = 1.939341379404068, 23.085494995117188 s per 100 iters\n","time = 507.0, epoch 8, iter = 12600, loss = 1.94766454577446, 23.45443058013916 s per 100 iters\n","time = 508.0, epoch 8, iter = 12700, loss = 1.9152249324321746, 22.9837589263916 s per 100 iters\n","time = 508.0, epoch 8, iter = 12800, loss = 1.920088872909546, 23.08544111251831 s per 100 iters\n","time = 508.0, epoch 8, iter = 12900, loss = 1.944814876317978, 23.86527991294861 s per 100 iters\n","time = 509.0, epoch 8, iter = 13000, loss = 1.944362429380417, 23.699140310287476 s per 100 iters\n","time = 509.0, epoch 8, iter = 13100, loss = 1.9268343460559845, 23.429438829421997 s per 100 iters\n","time = 510.0, epoch 8, iter = 13200, loss = 1.9240341091156006, 23.343372583389282 s per 100 iters\n","time = 510.0, epoch 8, iter = 13300, loss = 1.9468104195594789, 23.67858648300171 s per 100 iters\n","time = 510.0, epoch 8, iter = 13400, loss = 1.9242204236984253, 23.243361711502075 s per 100 iters\n","time = 511.0, epoch 8, iter = 13500, loss = 1.9265586531162262, 23.208590507507324 s per 100 iters\n","time = 511.0, epoch 8, iter = 13600, loss = 1.9461614382266998, 24.49447989463806 s per 100 iters\n","time = 512.0, epoch 8, iter = 13700, loss = 1.9446257412433625, 23.059152364730835 s per 100 iters\n","time = 512.0, epoch 8, iter = 13800, loss = 1.9257499980926513, 23.90412998199463 s per 100 iters\n","time = 512.0, epoch 8, iter = 13900, loss = 1.9391378116607667, 23.640302419662476 s per 100 iters\n","time = 513.0, epoch 8, iter = 14000, loss = 1.9433699750900268, 23.704842567443848 s per 100 iters\n","time = 513.0, epoch 8, iter = 14100, loss = 1.9365962743759155, 23.990063667297363 s per 100 iters\n","time = 513.0, epoch 8, iter = 14200, loss = 1.9412496829032897, 22.832240104675293 s per 100 iters\n","time = 514.0, epoch 8, iter = 14300, loss = 1.9232163137197495, 23.592244386672974 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","--- Balidazioa ---\n","30.63304352760315 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere dulcinea ￭?', '｟C afaritan ondo jan zuen ｟C siziliako ur gainean oinak jarri eta nesken xarma ￭, ｟C aita ｟C pirrononeen austeritatea ￭, eta ｟C don ｟C fabriziok argi eta garbi adierazi zion ｟C donnafugatako jauregia ez zela ｟C capraroko orkidea-ehiztaria ￭, eta bizirik utziko zuela ￭.', '｟C denek erosten zuten ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C epaileak eta exekuzio judizialeko beste funtzionarioak ￭, artisau artifizialak ￭, sarien eta zigorraren (￭ subiranoaren eserlekura bizkor igoz ￭) ￭, gorputz naturalean dauden nerbioak dira ￭, eta aberastasunak eta ondasunak ￭, herrien indarra ￭, ｟C sali ｟C populuak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori haien ideala da ￭, orain errepresentazio gisa errepresentatzen dute ￭, eta beharbada beste inorengan ere ez ￭, bere produkturik izpiritualenak dira ￭, bere inbasio eta esploratzaileen aurreratuenak ￭, bere seduzitzaileen eta abileziazko formarik eztien eta abilena ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez edukitzeko bezain pobreak ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kontuarekin ￭, eta orain ｟C mafiaren akusazioa ￭?']\n","BLEU puntuazioa (1): 9.215803056409479\n","8.184111833572388 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak janaria lortzen duela ￭?', '- ｟C ezagutzen dugu ｟C corvette historia ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendekua hartzera etorria zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C basoan otsoak egongo dira ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez dizu axola ￭?', '｟C argazki bat atera diot 1960ean eta bere semea 1940ko uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C lo egizu berriro ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.480119588628906\n","BLEU puntuazioa (biak): 12.283597615503366\n","time = 515.0, epoch 9, iter = 100, loss = 1.7987292635440826, 24.858296871185303 s per 100 iters\n","time = 516.0, epoch 9, iter = 200, loss = 1.8230025964975356, 24.546727657318115 s per 100 iters\n","time = 516.0, epoch 9, iter = 300, loss = 1.805728650689125, 23.820420265197754 s per 100 iters\n","time = 516.0, epoch 9, iter = 400, loss = 1.7964580589532853, 23.520655155181885 s per 100 iters\n","time = 517.0, epoch 9, iter = 500, loss = 1.791032269001007, 23.527422666549683 s per 100 iters\n","time = 517.0, epoch 9, iter = 600, loss = 1.8203710520267486, 23.831827878952026 s per 100 iters\n","time = 517.0, epoch 9, iter = 700, loss = 1.798200802206993, 23.66424798965454 s per 100 iters\n","time = 518.0, epoch 9, iter = 800, loss = 1.8063089215755463, 23.392725944519043 s per 100 iters\n","time = 518.0, epoch 9, iter = 900, loss = 1.8300528460741043, 23.74503493309021 s per 100 iters\n","time = 519.0, epoch 9, iter = 1000, loss = 1.8034161871671677, 22.790497303009033 s per 100 iters\n","time = 519.0, epoch 9, iter = 1100, loss = 1.821524572968483, 23.356751680374146 s per 100 iters\n","time = 519.0, epoch 9, iter = 1200, loss = 1.812008000612259, 22.686274528503418 s per 100 iters\n","time = 520.0, epoch 9, iter = 1300, loss = 1.8204631727933884, 23.51481056213379 s per 100 iters\n","time = 520.0, epoch 9, iter = 1400, loss = 1.826818002462387, 23.582684993743896 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 521.0, epoch 9, iter = 1500, loss = 1.8060281461477279, 23.255507946014404 s per 100 iters\n","time = 521.0, epoch 9, iter = 1600, loss = 1.8272029167413713, 23.255043745040894 s per 100 iters\n","time = 521.0, epoch 9, iter = 1700, loss = 1.8330495482683182, 24.32966661453247 s per 100 iters\n","time = 522.0, epoch 9, iter = 1800, loss = 1.8001989674568177, 23.412657976150513 s per 100 iters\n","time = 522.0, epoch 9, iter = 1900, loss = 1.8292172950506211, 22.81068468093872 s per 100 iters\n","time = 523.0, epoch 9, iter = 2000, loss = 1.842192223072052, 23.764562845230103 s per 100 iters\n","time = 523.0, epoch 9, iter = 2100, loss = 1.8121697968244552, 23.587066411972046 s per 100 iters\n","time = 523.0, epoch 9, iter = 2200, loss = 1.8409268105030059, 23.75942587852478 s per 100 iters\n","time = 524.0, epoch 9, iter = 2300, loss = 1.8403060036897658, 23.28284978866577 s per 100 iters\n","time = 524.0, epoch 9, iter = 2400, loss = 1.8270376271009445, 23.890440702438354 s per 100 iters\n","time = 525.0, epoch 9, iter = 2500, loss = 1.8210065776109696, 23.546644687652588 s per 100 iters\n","time = 525.0, epoch 9, iter = 2600, loss = 1.8413022613525392, 24.188345909118652 s per 100 iters\n","time = 525.0, epoch 9, iter = 2700, loss = 1.826017141342163, 23.553839921951294 s per 100 iters\n","time = 526.0, epoch 9, iter = 2800, loss = 1.8256479787826538, 22.69517683982849 s per 100 iters\n","time = 526.0, epoch 9, iter = 2900, loss = 1.8201376074552535, 23.28062653541565 s per 100 iters\n","time = 526.0, epoch 9, iter = 3000, loss = 1.8463902473449707, 23.6792950630188 s per 100 iters\n","time = 527.0, epoch 9, iter = 3100, loss = 1.8325121414661407, 22.870364665985107 s per 100 iters\n","time = 527.0, epoch 9, iter = 3200, loss = 1.8290598392486572, 23.29965090751648 s per 100 iters\n","time = 528.0, epoch 9, iter = 3300, loss = 1.8521459275484085, 23.485079526901245 s per 100 iters\n","time = 528.0, epoch 9, iter = 3400, loss = 1.8469710564613342, 23.643285989761353 s per 100 iters\n","time = 528.0, epoch 9, iter = 3500, loss = 1.864600933790207, 24.132116079330444 s per 100 iters\n","time = 529.0, epoch 9, iter = 3600, loss = 1.8581444078683853, 22.644003868103027 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 529.0, epoch 9, iter = 3700, loss = 1.857113739848137, 23.328818559646606 s per 100 iters\n","time = 530.0, epoch 9, iter = 3800, loss = 1.8415712577104568, 23.725563049316406 s per 100 iters\n","time = 530.0, epoch 9, iter = 3900, loss = 1.8365859800577164, 23.581525087356567 s per 100 iters\n","time = 530.0, epoch 9, iter = 4000, loss = 1.8537744987010956, 23.390039920806885 s per 100 iters\n","time = 531.0, epoch 9, iter = 4100, loss = 1.8394869554042816, 23.767431497573853 s per 100 iters\n","time = 531.0, epoch 9, iter = 4200, loss = 1.8413281178474425, 23.57808208465576 s per 100 iters\n","time = 532.0, epoch 9, iter = 4300, loss = 1.8484977853298188, 24.40986680984497 s per 100 iters\n","time = 532.0, epoch 9, iter = 4400, loss = 1.8638700437545777, 23.950687885284424 s per 100 iters\n","time = 532.0, epoch 9, iter = 4500, loss = 1.8654550403356551, 23.457388401031494 s per 100 iters\n","time = 533.0, epoch 9, iter = 4600, loss = 1.8839747035503387, 23.19461417198181 s per 100 iters\n","time = 533.0, epoch 9, iter = 4700, loss = 1.848007220029831, 23.50598430633545 s per 100 iters\n","time = 534.0, epoch 9, iter = 4800, loss = 1.8459149897098541, 23.065468788146973 s per 100 iters\n","time = 534.0, epoch 9, iter = 4900, loss = 1.8445123827457428, 24.166557788848877 s per 100 iters\n","time = 534.0, epoch 9, iter = 5000, loss = 1.8715473049879074, 23.390653610229492 s per 100 iters\n","time = 535.0, epoch 9, iter = 5100, loss = 1.8850087994337081, 23.892322063446045 s per 100 iters\n","time = 535.0, epoch 9, iter = 5200, loss = 1.8552514851093291, 23.595853090286255 s per 100 iters\n","time = 535.0, epoch 9, iter = 5300, loss = 1.8577086687088014, 22.263733863830566 s per 100 iters\n","time = 536.0, epoch 9, iter = 5400, loss = 1.876090214252472, 23.479490995407104 s per 100 iters\n","time = 536.0, epoch 9, iter = 5500, loss = 1.8635599547624588, 23.118919372558594 s per 100 iters\n","time = 537.0, epoch 9, iter = 5600, loss = 1.8576992809772492, 23.378599643707275 s per 100 iters\n","time = 537.0, epoch 9, iter = 5700, loss = 1.874045234322548, 23.422043800354004 s per 100 iters\n","time = 537.0, epoch 9, iter = 5800, loss = 1.8508785152435303, 23.396608352661133 s per 100 iters\n","time = 538.0, epoch 9, iter = 5900, loss = 1.8767052245140077, 23.912996530532837 s per 100 iters\n","time = 538.0, epoch 9, iter = 6000, loss = 1.8605644261837007, 23.586743593215942 s per 100 iters\n","time = 539.0, epoch 9, iter = 6100, loss = 1.8500203239917754, 22.956175804138184 s per 100 iters\n","time = 539.0, epoch 9, iter = 6200, loss = 1.850951002240181, 24.140485763549805 s per 100 iters\n","time = 539.0, epoch 9, iter = 6300, loss = 1.86824405670166, 23.213366746902466 s per 100 iters\n","time = 540.0, epoch 9, iter = 6400, loss = 1.860472811460495, 23.675310611724854 s per 100 iters\n","time = 540.0, epoch 9, iter = 6500, loss = 1.8561175167560577, 23.631608963012695 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 541.0, epoch 9, iter = 6600, loss = 1.862831404209137, 23.025853633880615 s per 100 iters\n","time = 541.0, epoch 9, iter = 6700, loss = 1.8566179275512695, 23.463473081588745 s per 100 iters\n","time = 541.0, epoch 9, iter = 6800, loss = 1.8455375242233276, 23.107730388641357 s per 100 iters\n","time = 542.0, epoch 9, iter = 6900, loss = 1.8473578429222106, 23.623753309249878 s per 100 iters\n","time = 542.0, epoch 9, iter = 7000, loss = 1.8707852530479432, 23.95804738998413 s per 100 iters\n","time = 543.0, epoch 9, iter = 7100, loss = 1.8537046188116073, 23.316854000091553 s per 100 iters\n","time = 543.0, epoch 9, iter = 7200, loss = 1.881025297641754, 24.153766870498657 s per 100 iters\n","time = 543.0, epoch 9, iter = 7300, loss = 1.8575882863998414, 23.085777282714844 s per 100 iters\n","time = 544.0, epoch 9, iter = 7400, loss = 1.8656944048404693, 22.837132453918457 s per 100 iters\n","time = 544.0, epoch 9, iter = 7500, loss = 1.877506685256958, 22.988775491714478 s per 100 iters\n","time = 544.0, epoch 9, iter = 7600, loss = 1.8647161364555358, 23.44355869293213 s per 100 iters\n","time = 545.0, epoch 9, iter = 7700, loss = 1.8446126091480255, 22.908496141433716 s per 100 iters\n","time = 545.0, epoch 9, iter = 7800, loss = 1.8792101204395295, 23.259257555007935 s per 100 iters\n","time = 546.0, epoch 9, iter = 7900, loss = 1.8627618193626403, 23.053586959838867 s per 100 iters\n","time = 546.0, epoch 9, iter = 8000, loss = 1.8774876272678376, 23.76652503013611 s per 100 iters\n","time = 546.0, epoch 9, iter = 8100, loss = 1.8812947404384612, 23.75343918800354 s per 100 iters\n","time = 547.0, epoch 9, iter = 8200, loss = 1.8673040527105331, 23.26564359664917 s per 100 iters\n","time = 547.0, epoch 9, iter = 8300, loss = 1.8835426414012908, 23.25572896003723 s per 100 iters\n","time = 548.0, epoch 9, iter = 8400, loss = 1.880865148305893, 23.05768370628357 s per 100 iters\n","time = 548.0, epoch 9, iter = 8500, loss = 1.888878790140152, 23.54984402656555 s per 100 iters\n","time = 548.0, epoch 9, iter = 8600, loss = 1.8641935342550278, 23.28313660621643 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 549.0, epoch 9, iter = 8700, loss = 1.88960134267807, 23.720273971557617 s per 100 iters\n","time = 549.0, epoch 9, iter = 8800, loss = 1.8672002869844437, 23.94438934326172 s per 100 iters\n","time = 550.0, epoch 9, iter = 8900, loss = 1.8896116691827773, 23.121106147766113 s per 100 iters\n","time = 550.0, epoch 9, iter = 9000, loss = 1.8746152532100677, 23.203365087509155 s per 100 iters\n","time = 550.0, epoch 9, iter = 9100, loss = 1.8689672017097474, 23.70818853378296 s per 100 iters\n","time = 551.0, epoch 9, iter = 9200, loss = 1.8893101263046264, 23.459368467330933 s per 100 iters\n","time = 551.0, epoch 9, iter = 9300, loss = 1.8725894379615784, 22.9849214553833 s per 100 iters\n","time = 551.0, epoch 9, iter = 9400, loss = 1.8890660893917084, 24.033132553100586 s per 100 iters\n","time = 552.0, epoch 9, iter = 9500, loss = 1.8650231677293778, 22.50486183166504 s per 100 iters\n","time = 552.0, epoch 9, iter = 9600, loss = 1.882515901327133, 23.0970401763916 s per 100 iters\n","time = 553.0, epoch 9, iter = 9700, loss = 1.886734756231308, 23.4923152923584 s per 100 iters\n","time = 553.0, epoch 9, iter = 9800, loss = 1.8791767001152038, 24.28173851966858 s per 100 iters\n","time = 553.0, epoch 9, iter = 9900, loss = 1.8845064449310303, 23.8394136428833 s per 100 iters\n","time = 554.0, epoch 9, iter = 10000, loss = 1.8963679385185241, 23.46017289161682 s per 100 iters\n","time = 554.0, epoch 9, iter = 10100, loss = 1.8829796874523164, 23.468656063079834 s per 100 iters\n","time = 555.0, epoch 9, iter = 10200, loss = 1.8824634754657745, 23.453161001205444 s per 100 iters\n","time = 555.0, epoch 9, iter = 10300, loss = 1.8943226951360703, 23.83476972579956 s per 100 iters\n","time = 555.0, epoch 9, iter = 10400, loss = 1.8813478136062622, 23.522113800048828 s per 100 iters\n","time = 556.0, epoch 9, iter = 10500, loss = 1.8803073608875274, 23.328627586364746 s per 100 iters\n","time = 556.0, epoch 9, iter = 10600, loss = 1.900676624774933, 23.42657446861267 s per 100 iters\n","time = 557.0, epoch 9, iter = 10700, loss = 1.8931640493869781, 23.580458402633667 s per 100 iters\n","time = 557.0, epoch 9, iter = 10800, loss = 1.8624935150146484, 23.96908211708069 s per 100 iters\n","time = 557.0, epoch 9, iter = 10900, loss = 1.89127867102623, 23.79538106918335 s per 100 iters\n","time = 558.0, epoch 9, iter = 11000, loss = 1.8650480490922927, 23.302209615707397 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 558.0, epoch 9, iter = 11100, loss = 1.8625901305675507, 22.498827934265137 s per 100 iters\n","time = 559.0, epoch 9, iter = 11200, loss = 1.8926954805850982, 23.40205955505371 s per 100 iters\n","time = 559.0, epoch 9, iter = 11300, loss = 1.9017502969503404, 23.851528644561768 s per 100 iters\n","time = 559.0, epoch 9, iter = 11400, loss = 1.8775800836086274, 23.71636962890625 s per 100 iters\n","time = 560.0, epoch 9, iter = 11500, loss = 1.873973377943039, 23.14712357521057 s per 100 iters\n","time = 560.0, epoch 9, iter = 11600, loss = 1.8668745124340058, 23.140860557556152 s per 100 iters\n","time = 560.0, epoch 9, iter = 11700, loss = 1.8892782878875733, 23.709253549575806 s per 100 iters\n","time = 561.0, epoch 9, iter = 11800, loss = 1.888085812330246, 23.082157373428345 s per 100 iters\n","time = 561.0, epoch 9, iter = 11900, loss = 1.8891093063354492, 21.992245197296143 s per 100 iters\n","time = 562.0, epoch 9, iter = 12000, loss = 1.8933595061302184, 23.75229239463806 s per 100 iters\n","time = 562.0, epoch 9, iter = 12100, loss = 1.8882673859596253, 23.416388034820557 s per 100 iters\n","time = 562.0, epoch 9, iter = 12200, loss = 1.8997924053668975, 23.300002336502075 s per 100 iters\n","time = 563.0, epoch 9, iter = 12300, loss = 1.8888855934143067, 23.1138813495636 s per 100 iters\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vs6nosOxt_w_","colab_type":"text"},"source":["# Checkpointetik entrenatzeko"]},{"cell_type":"code","metadata":{"id":"7bWnCKHC35eg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594232689919,"user_tz":-120,"elapsed":12408717,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"4df52c9c-7518-4357-bf61-bf9b4b8556b7"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/origetaos2-1.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu(2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 2, iter = 100, loss = 2.1668292355537413, 33.36848187446594 s per 100 iters\n","time = 1.0, epoch 2, iter = 200, loss = 2.1721127700805662, 32.900964975357056 s per 100 iters\n","time = 1.0, epoch 2, iter = 300, loss = 2.165080285668373, 33.767239570617676 s per 100 iters\n","time = 2.0, epoch 2, iter = 400, loss = 2.1827990120649337, 35.48062324523926 s per 100 iters\n","time = 2.0, epoch 2, iter = 500, loss = 2.174663429260254, 36.098050117492676 s per 100 iters\n","time = 3.0, epoch 2, iter = 600, loss = 2.1645878863334658, 34.02560639381409 s per 100 iters\n","time = 4.0, epoch 2, iter = 700, loss = 2.153641883134842, 35.26838159561157 s per 100 iters\n","time = 4.0, epoch 2, iter = 800, loss = 2.1353523474931717, 33.49988842010498 s per 100 iters\n","time = 5.0, epoch 2, iter = 900, loss = 2.165843459367752, 33.96131110191345 s per 100 iters\n","time = 5.0, epoch 2, iter = 1000, loss = 2.1758923053741457, 34.99210023880005 s per 100 iters\n","time = 6.0, epoch 2, iter = 1100, loss = 2.193341865539551, 34.74964380264282 s per 100 iters\n","time = 6.0, epoch 2, iter = 1200, loss = 2.170237191915512, 34.38475012779236 s per 100 iters\n","time = 7.0, epoch 2, iter = 1300, loss = 2.1544578808546064, 34.172306299209595 s per 100 iters\n","time = 8.0, epoch 2, iter = 1400, loss = 2.168129403591156, 35.44937753677368 s per 100 iters\n","time = 8.0, epoch 2, iter = 1500, loss = 2.164206837415695, 35.07203483581543 s per 100 iters\n","time = 9.0, epoch 2, iter = 1600, loss = 2.1387841367721556, 33.841193199157715 s per 100 iters\n","time = 9.0, epoch 2, iter = 1700, loss = 2.1705786919593812, 34.61244559288025 s per 100 iters\n","time = 10.0, epoch 2, iter = 1800, loss = 2.151615646481514, 34.80480098724365 s per 100 iters\n","time = 10.0, epoch 2, iter = 1900, loss = 2.159175893068314, 34.080647706985474 s per 100 iters\n","time = 11.0, epoch 2, iter = 2000, loss = 2.1352290320396423, 34.89319944381714 s per 100 iters\n","time = 12.0, epoch 2, iter = 2100, loss = 2.156487374305725, 34.93104791641235 s per 100 iters\n","time = 12.0, epoch 2, iter = 2200, loss = 2.159077805876732, 35.011744260787964 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 13.0, epoch 2, iter = 2300, loss = 2.1193114161491393, 33.86500072479248 s per 100 iters\n","time = 13.0, epoch 2, iter = 2400, loss = 2.172360211610794, 34.10417914390564 s per 100 iters\n","time = 14.0, epoch 2, iter = 2500, loss = 2.1638783502578733, 34.56073498725891 s per 100 iters\n","time = 14.0, epoch 2, iter = 2600, loss = 2.1403630530834197, 34.17118549346924 s per 100 iters\n","time = 15.0, epoch 2, iter = 2700, loss = 2.1317701852321624, 35.53022122383118 s per 100 iters\n","time = 16.0, epoch 2, iter = 2800, loss = 2.153087509274483, 34.8437922000885 s per 100 iters\n","time = 16.0, epoch 2, iter = 2900, loss = 2.1651350331306456, 35.253753662109375 s per 100 iters\n","time = 17.0, epoch 2, iter = 3000, loss = 2.130219213962555, 34.66166377067566 s per 100 iters\n","time = 17.0, epoch 2, iter = 3100, loss = 2.1386843407154084, 35.28597450256348 s per 100 iters\n","time = 18.0, epoch 2, iter = 3200, loss = 2.183827130794525, 36.44685745239258 s per 100 iters\n","time = 19.0, epoch 2, iter = 3300, loss = 2.1396263539791107, 34.45259356498718 s per 100 iters\n","time = 19.0, epoch 2, iter = 3400, loss = 2.1537647473812105, 35.659480571746826 s per 100 iters\n","time = 20.0, epoch 2, iter = 3500, loss = 2.141036775112152, 35.14331841468811 s per 100 iters\n","time = 20.0, epoch 2, iter = 3600, loss = 2.153540906906128, 36.29474353790283 s per 100 iters\n","time = 21.0, epoch 2, iter = 3700, loss = 2.124350460767746, 34.50724720954895 s per 100 iters\n","time = 21.0, epoch 2, iter = 3800, loss = 2.1540008878707884, 35.35125422477722 s per 100 iters\n","time = 22.0, epoch 2, iter = 3900, loss = 2.149034708738327, 34.94240665435791 s per 100 iters\n","time = 23.0, epoch 2, iter = 4000, loss = 2.1322530019283295, 34.82055878639221 s per 100 iters\n","time = 23.0, epoch 2, iter = 4100, loss = 2.1497399580478667, 34.83735227584839 s per 100 iters\n","time = 24.0, epoch 2, iter = 4200, loss = 2.131500168442726, 34.88436412811279 s per 100 iters\n","time = 24.0, epoch 2, iter = 4300, loss = 2.149666489362717, 35.44552659988403 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 25.0, epoch 2, iter = 4400, loss = 2.1368107253313067, 34.31213164329529 s per 100 iters\n","time = 26.0, epoch 2, iter = 4500, loss = 2.147841761112213, 34.79810404777527 s per 100 iters\n","time = 26.0, epoch 2, iter = 4600, loss = 2.133146002292633, 35.175272941589355 s per 100 iters\n","time = 27.0, epoch 2, iter = 4700, loss = 2.128797767162323, 34.912689208984375 s per 100 iters\n","time = 27.0, epoch 2, iter = 4800, loss = 2.1427991044521333, 34.29110097885132 s per 100 iters\n","time = 28.0, epoch 2, iter = 4900, loss = 2.1387279921770097, 35.12765169143677 s per 100 iters\n","time = 28.0, epoch 2, iter = 5000, loss = 2.140909684896469, 34.012362003326416 s per 100 iters\n","time = 29.0, epoch 2, iter = 5100, loss = 2.107422525882721, 35.18005919456482 s per 100 iters\n","time = 30.0, epoch 2, iter = 5200, loss = 2.1488068461418153, 34.01467156410217 s per 100 iters\n","time = 30.0, epoch 2, iter = 5300, loss = 2.1403863513469696, 34.856865644454956 s per 100 iters\n","time = 31.0, epoch 2, iter = 5400, loss = 2.1485405814647676, 33.87648940086365 s per 100 iters\n","time = 31.0, epoch 2, iter = 5500, loss = 2.132815283536911, 35.40556478500366 s per 100 iters\n","time = 32.0, epoch 2, iter = 5600, loss = 2.1378378355503083, 35.82611036300659 s per 100 iters\n","time = 33.0, epoch 2, iter = 5700, loss = 2.1353641068935394, 34.65411567687988 s per 100 iters\n","time = 33.0, epoch 2, iter = 5800, loss = 2.1177919042110442, 35.26463770866394 s per 100 iters\n","time = 34.0, epoch 2, iter = 5900, loss = 2.1140667396783828, 34.431880712509155 s per 100 iters\n","time = 34.0, epoch 2, iter = 6000, loss = 2.155400674343109, 34.797428607940674 s per 100 iters\n","time = 35.0, epoch 2, iter = 6100, loss = 2.11175101518631, 34.6786949634552 s per 100 iters\n","time = 35.0, epoch 2, iter = 6200, loss = 2.1205131042003633, 35.25204110145569 s per 100 iters\n","time = 36.0, epoch 2, iter = 6300, loss = 2.141392011642456, 35.25358533859253 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 37.0, epoch 2, iter = 6400, loss = 2.122142845392227, 35.12502646446228 s per 100 iters\n","time = 37.0, epoch 2, iter = 6500, loss = 2.11107746720314, 35.1009886264801 s per 100 iters\n","time = 38.0, epoch 2, iter = 6600, loss = 2.1255891519784926, 34.91694355010986 s per 100 iters\n","time = 38.0, epoch 2, iter = 6700, loss = 2.1221472573280336, 34.14227914810181 s per 100 iters\n","time = 39.0, epoch 2, iter = 6800, loss = 2.134101309776306, 35.306111574172974 s per 100 iters\n","time = 39.0, epoch 2, iter = 6900, loss = 2.1407246053218842, 34.80283188819885 s per 100 iters\n","time = 40.0, epoch 2, iter = 7000, loss = 2.1184275376796724, 34.43434762954712 s per 100 iters\n","time = 41.0, epoch 2, iter = 7100, loss = 2.125542423725128, 34.73076915740967 s per 100 iters\n","time = 41.0, epoch 2, iter = 7200, loss = 2.1353520047664643, 34.591217279434204 s per 100 iters\n","time = 42.0, epoch 2, iter = 7300, loss = 2.1421817260980607, 35.72269082069397 s per 100 iters\n","time = 42.0, epoch 2, iter = 7400, loss = 2.1184923481941222, 34.71614074707031 s per 100 iters\n","time = 43.0, epoch 2, iter = 7500, loss = 2.149131751060486, 35.77678561210632 s per 100 iters\n","time = 44.0, epoch 2, iter = 7600, loss = 2.0963219171762466, 34.49485445022583 s per 100 iters\n","time = 44.0, epoch 2, iter = 7700, loss = 2.0957838177680967, 34.83983254432678 s per 100 iters\n","time = 45.0, epoch 2, iter = 7800, loss = 2.1321761524677276, 34.36701440811157 s per 100 iters\n","time = 45.0, epoch 2, iter = 7900, loss = 2.0974899560213087, 33.92892146110535 s per 100 iters\n","time = 46.0, epoch 2, iter = 8000, loss = 2.1202894926071165, 34.256537675857544 s per 100 iters\n","time = 46.0, epoch 2, iter = 8100, loss = 2.0929702633619307, 35.04430556297302 s per 100 iters\n","time = 47.0, epoch 2, iter = 8200, loss = 2.1045973575115204, 34.71177577972412 s per 100 iters\n","time = 48.0, epoch 2, iter = 8300, loss = 2.1040868854522703, 35.17046594619751 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 48.0, epoch 2, iter = 8400, loss = 2.10551163315773, 34.8286018371582 s per 100 iters\n","time = 49.0, epoch 2, iter = 8500, loss = 2.0835416853427886, 34.411110639572144 s per 100 iters\n","time = 49.0, epoch 2, iter = 8600, loss = 2.1083401703834532, 35.722747802734375 s per 100 iters\n","time = 50.0, epoch 2, iter = 8700, loss = 2.1094638931751253, 34.63587927818298 s per 100 iters\n","time = 51.0, epoch 2, iter = 8800, loss = 2.102485579252243, 35.35485124588013 s per 100 iters\n","time = 51.0, epoch 2, iter = 8900, loss = 2.1022850918769835, 34.37526822090149 s per 100 iters\n","time = 52.0, epoch 2, iter = 9000, loss = 2.097959635257721, 34.39797759056091 s per 100 iters\n","time = 52.0, epoch 2, iter = 9100, loss = 2.0927881741523744, 34.530550956726074 s per 100 iters\n","time = 53.0, epoch 2, iter = 9200, loss = 2.1036918181180955, 34.52803015708923 s per 100 iters\n","time = 53.0, epoch 2, iter = 9300, loss = 2.101179258823395, 35.06901168823242 s per 100 iters\n","time = 54.0, epoch 2, iter = 9400, loss = 2.112755088210106, 34.744495153427124 s per 100 iters\n","time = 55.0, epoch 2, iter = 9500, loss = 2.1271748197078706, 34.1513090133667 s per 100 iters\n","time = 55.0, epoch 2, iter = 9600, loss = 2.095962437391281, 35.264580726623535 s per 100 iters\n","time = 56.0, epoch 2, iter = 9700, loss = 2.101154525279999, 35.124345779418945 s per 100 iters\n","time = 56.0, epoch 2, iter = 9800, loss = 2.077723191380501, 34.80594611167908 s per 100 iters\n","time = 57.0, epoch 2, iter = 9900, loss = 2.1029277634620667, 35.39422869682312 s per 100 iters\n","time = 57.0, epoch 2, iter = 10000, loss = 2.103213881254196, 34.76082754135132 s per 100 iters\n","time = 58.0, epoch 2, iter = 10100, loss = 2.0754199588298796, 35.11719346046448 s per 100 iters\n","time = 59.0, epoch 2, iter = 10200, loss = 2.086531859636307, 35.46608901023865 s per 100 iters\n","time = 59.0, epoch 2, iter = 10300, loss = 2.075586875081062, 34.78141188621521 s per 100 iters\n","time = 60.0, epoch 2, iter = 10400, loss = 2.0957957351207734, 34.73132920265198 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 60.0, epoch 2, iter = 10500, loss = 2.0822801929712296, 34.02177572250366 s per 100 iters\n","time = 61.0, epoch 2, iter = 10600, loss = 2.0744532001018525, 34.62752175331116 s per 100 iters\n","time = 62.0, epoch 2, iter = 10700, loss = 2.0761073338985443, 34.24282717704773 s per 100 iters\n","time = 62.0, epoch 2, iter = 10800, loss = 2.06866525053978, 35.23455214500427 s per 100 iters\n","time = 63.0, epoch 2, iter = 10900, loss = 2.097729511260986, 35.45340132713318 s per 100 iters\n","time = 63.0, epoch 2, iter = 11000, loss = 2.0680637121200562, 34.0028510093689 s per 100 iters\n","time = 64.0, epoch 2, iter = 11100, loss = 2.0923037099838258, 34.1888108253479 s per 100 iters\n","time = 64.0, epoch 2, iter = 11200, loss = 2.104227830171585, 35.34447693824768 s per 100 iters\n","time = 65.0, epoch 2, iter = 11300, loss = 2.076047246456146, 34.73787760734558 s per 100 iters\n","time = 66.0, epoch 2, iter = 11400, loss = 2.099813610315323, 34.80690789222717 s per 100 iters\n","time = 66.0, epoch 2, iter = 11500, loss = 2.0804918563365935, 34.262006998062134 s per 100 iters\n","time = 67.0, epoch 2, iter = 11600, loss = 2.0662102729082106, 34.64745020866394 s per 100 iters\n","time = 67.0, epoch 2, iter = 11700, loss = 2.057865637540817, 34.91704344749451 s per 100 iters\n","time = 68.0, epoch 2, iter = 11800, loss = 2.046832091808319, 34.37672019004822 s per 100 iters\n","time = 68.0, epoch 2, iter = 11900, loss = 2.0611331284046175, 34.46258044242859 s per 100 iters\n","time = 69.0, epoch 2, iter = 12000, loss = 2.083580539226532, 35.18142557144165 s per 100 iters\n","time = 70.0, epoch 2, iter = 12100, loss = 2.0766935658454897, 35.03648662567139 s per 100 iters\n","time = 70.0, epoch 2, iter = 12200, loss = 2.0877773582935335, 34.91577172279358 s per 100 iters\n","time = 71.0, epoch 2, iter = 12300, loss = 2.0794527781009675, 34.4074182510376 s per 100 iters\n","time = 71.0, epoch 2, iter = 12400, loss = 2.067351957559586, 34.98185753822327 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 72.0, epoch 2, iter = 12500, loss = 2.0869484770298006, 33.6227753162384 s per 100 iters\n","time = 73.0, epoch 2, iter = 12600, loss = 2.0695620715618133, 35.190747022628784 s per 100 iters\n","time = 73.0, epoch 2, iter = 12700, loss = 2.084412402510643, 34.16860294342041 s per 100 iters\n","time = 74.0, epoch 2, iter = 12800, loss = 2.079711217880249, 35.405980587005615 s per 100 iters\n","time = 74.0, epoch 2, iter = 12900, loss = 2.056658629179001, 34.3192241191864 s per 100 iters\n","time = 75.0, epoch 2, iter = 13000, loss = 2.045980498790741, 34.81768608093262 s per 100 iters\n","time = 75.0, epoch 2, iter = 13100, loss = 2.0825708210468292, 35.477811098098755 s per 100 iters\n","time = 76.0, epoch 2, iter = 13200, loss = 2.0614920336008073, 34.80543923377991 s per 100 iters\n","time = 77.0, epoch 2, iter = 13300, loss = 2.069887802004814, 34.56361937522888 s per 100 iters\n","time = 77.0, epoch 2, iter = 13400, loss = 2.068952301740646, 34.08248448371887 s per 100 iters\n","time = 78.0, epoch 2, iter = 13500, loss = 2.0544729328155515, 35.33131957054138 s per 100 iters\n","time = 78.0, epoch 2, iter = 13600, loss = 2.0628397530317306, 34.20891880989075 s per 100 iters\n","time = 79.0, epoch 2, iter = 13700, loss = 2.0470810812711715, 34.93972182273865 s per 100 iters\n","time = 79.0, epoch 2, iter = 13800, loss = 2.0679062670469284, 35.41969561576843 s per 100 iters\n","time = 80.0, epoch 2, iter = 13900, loss = 2.0789658713340757, 34.920193910598755 s per 100 iters\n","time = 81.0, epoch 2, iter = 14000, loss = 2.0942183089256288, 34.21703052520752 s per 100 iters\n","time = 81.0, epoch 2, iter = 14100, loss = 2.055149257183075, 35.01339626312256 s per 100 iters\n","time = 82.0, epoch 2, iter = 14200, loss = 2.058327747583389, 33.86101317405701 s per 100 iters\n","time = 82.0, epoch 2, iter = 14300, loss = 2.046970535516739, 34.599082946777344 s per 100 iters\n","--- Balidazioa ---\n","23.489468812942505 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milika habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hori ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta ｟C dulcinea ￭?', '｟C afarian ongi jan zuen lehen aldiz ￭, ｟C siziliarren artean lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C pirronen aita ｟C don ｟C fabriziok ￭, ｟C donnafugata jauregiko domugrata ez zela ｟C caparoko lapurra eta segur aski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C magistratuak eta ｟C judutarko ｟C epaile eta exekutiboaren beste ofizialak ￭, sari eta zigorra ￭, subiranotasunaren eserlekua eta partaide bakoitza bere eginkizunaren burutzera mugatzen dutenak ￭, ｟C gorputz naturalean eta ondasunen jabeak egiten dituztenek ￭, ｟C popululus ｟C populus ｟C agintarien ｟C ondasun guztiak ￭, ｟C subiranotasunaren eta ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen eta ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen ｟C boterearen eta ｟C botere', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura ere ideal bera da ￭, berak ere ez dute beste inor irudikatzen ￭, gaur egun ￭, berek berek sorturiko bere buru izpiritualik handiena dute ￭, gerlariak eta eskaerien troparik hurbilena ￭, delikatua ￭, seduzzio formarik finkoena ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez duten bezain gaixo ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 9.331326087103104\n","7.486616849899292 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendeku hartzeko etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '1960ean argazkia erakutsi eta bere semea 1940ko uniformean ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 24.24615916690041\n","BLEU puntuazioa (biak): 12.796537491022441\n","time = 84.0, epoch 3, iter = 100, loss = 1.9731712073087693, 35.902307987213135 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n","time = 84.0, epoch 3, iter = 200, loss = 1.9484735816717147, 33.977224588394165 s per 100 iters\n","time = 85.0, epoch 3, iter = 300, loss = 1.9396161830425263, 35.316529512405396 s per 100 iters\n","time = 85.0, epoch 3, iter = 400, loss = 1.9393252593278885, 34.318121671676636 s per 100 iters\n","time = 86.0, epoch 3, iter = 500, loss = 1.9600440186262131, 35.464412689208984 s per 100 iters\n","time = 87.0, epoch 3, iter = 600, loss = 1.9703570592403412, 34.06979751586914 s per 100 iters\n","time = 87.0, epoch 3, iter = 700, loss = 1.9500244820117951, 35.31869387626648 s per 100 iters\n","time = 88.0, epoch 3, iter = 800, loss = 1.9669754350185393, 35.97052216529846 s per 100 iters\n","time = 88.0, epoch 3, iter = 900, loss = 1.937016289830208, 34.08286786079407 s per 100 iters\n","time = 89.0, epoch 3, iter = 1000, loss = 1.9482996606826781, 34.399908781051636 s per 100 iters\n","time = 90.0, epoch 3, iter = 1100, loss = 1.956097624897957, 34.908835887908936 s per 100 iters\n","time = 90.0, epoch 3, iter = 1200, loss = 1.9447298657894134, 35.34100294113159 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 91.0, epoch 3, iter = 1300, loss = 1.9517807644605636, 34.656152963638306 s per 100 iters\n","time = 91.0, epoch 3, iter = 1400, loss = 1.9402114176750183, 34.5490562915802 s per 100 iters\n","time = 92.0, epoch 3, iter = 1500, loss = 1.9346810644865036, 34.642295837402344 s per 100 iters\n","time = 92.0, epoch 3, iter = 1600, loss = 1.962209609746933, 34.940746545791626 s per 100 iters\n","time = 93.0, epoch 3, iter = 1700, loss = 1.970680034160614, 34.89223670959473 s per 100 iters\n","time = 94.0, epoch 3, iter = 1800, loss = 1.978006585240364, 35.744141578674316 s per 100 iters\n","time = 94.0, epoch 3, iter = 1900, loss = 1.958717142343521, 36.04942989349365 s per 100 iters\n","time = 95.0, epoch 3, iter = 2000, loss = 1.956683730483055, 34.528552770614624 s per 100 iters\n","time = 95.0, epoch 3, iter = 2100, loss = 1.9703250765800475, 34.92135143280029 s per 100 iters\n","time = 96.0, epoch 3, iter = 2200, loss = 1.952322505712509, 34.886128664016724 s per 100 iters\n","time = 97.0, epoch 3, iter = 2300, loss = 1.9760307627916336, 34.168190479278564 s per 100 iters\n","time = 97.0, epoch 3, iter = 2400, loss = 1.9579093337059021, 35.012622117996216 s per 100 iters\n","time = 98.0, epoch 3, iter = 2500, loss = 1.9707599043846131, 35.33282113075256 s per 100 iters\n","time = 98.0, epoch 3, iter = 2600, loss = 1.9549393236637116, 34.838188886642456 s per 100 iters\n","time = 99.0, epoch 3, iter = 2700, loss = 1.9555808252096176, 35.04853010177612 s per 100 iters\n","time = 99.0, epoch 3, iter = 2800, loss = 1.9734607750177384, 34.64121627807617 s per 100 iters\n","time = 100.0, epoch 3, iter = 2900, loss = 1.9488264000415803, 34.87093424797058 s per 100 iters\n","time = 101.0, epoch 3, iter = 3000, loss = 1.9571678763628007, 34.282102823257446 s per 100 iters\n","time = 101.0, epoch 3, iter = 3100, loss = 1.9869206255674363, 36.15488147735596 s per 100 iters\n","time = 102.0, epoch 3, iter = 3200, loss = 1.960111883878708, 34.9968900680542 s per 100 iters\n","time = 102.0, epoch 3, iter = 3300, loss = 1.9576978659629822, 34.85307502746582 s per 100 iters\n","time = 103.0, epoch 3, iter = 3400, loss = 1.929412322640419, 34.174110651016235 s per 100 iters\n","time = 104.0, epoch 3, iter = 3500, loss = 1.9382680600881577, 35.840920209884644 s per 100 iters\n","time = 104.0, epoch 3, iter = 3600, loss = 1.9621201694011687, 34.23699903488159 s per 100 iters\n","time = 105.0, epoch 3, iter = 3700, loss = 1.9893803995847703, 34.04226207733154 s per 100 iters\n","time = 105.0, epoch 3, iter = 3800, loss = 1.9521363013982773, 34.72475814819336 s per 100 iters\n","time = 106.0, epoch 3, iter = 3900, loss = 1.9647926980257033, 35.748337745666504 s per 100 iters\n","time = 106.0, epoch 3, iter = 4000, loss = 1.9884740829467773, 35.318304777145386 s per 100 iters\n","time = 107.0, epoch 3, iter = 4100, loss = 1.9398347800970077, 35.221925258636475 s per 100 iters\n","time = 108.0, epoch 3, iter = 4200, loss = 1.9582033270597459, 35.470452308654785 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 108.0, epoch 3, iter = 4300, loss = 1.948110818862915, 34.03663945198059 s per 100 iters\n","time = 109.0, epoch 3, iter = 4400, loss = 1.9657611000537871, 35.465540409088135 s per 100 iters\n","time = 109.0, epoch 3, iter = 4500, loss = 1.9589052957296371, 35.15974545478821 s per 100 iters\n","time = 110.0, epoch 3, iter = 4600, loss = 1.9574879109859467, 35.706547498703 s per 100 iters\n","time = 111.0, epoch 3, iter = 4700, loss = 1.95335773229599, 34.934821128845215 s per 100 iters\n","time = 111.0, epoch 3, iter = 4800, loss = 1.994141573905945, 34.92970585823059 s per 100 iters\n","time = 112.0, epoch 3, iter = 4900, loss = 1.9352837407588959, 34.97512745857239 s per 100 iters\n","time = 112.0, epoch 3, iter = 5000, loss = 1.9434352034330369, 34.43671011924744 s per 100 iters\n","time = 113.0, epoch 3, iter = 5100, loss = 1.9432676166296006, 34.81148147583008 s per 100 iters\n","time = 113.0, epoch 3, iter = 5200, loss = 1.9492166316509247, 33.64859223365784 s per 100 iters\n","time = 114.0, epoch 3, iter = 5300, loss = 1.9666315060853958, 35.74268627166748 s per 100 iters\n","time = 115.0, epoch 3, iter = 5400, loss = 1.9672056579589843, 34.76373219490051 s per 100 iters\n","time = 115.0, epoch 3, iter = 5500, loss = 1.9427983731031417, 35.05786395072937 s per 100 iters\n","time = 116.0, epoch 3, iter = 5600, loss = 1.9435500168800355, 35.1370530128479 s per 100 iters\n","time = 116.0, epoch 3, iter = 5700, loss = 1.967123429775238, 34.9059042930603 s per 100 iters\n","time = 117.0, epoch 3, iter = 5800, loss = 1.937734722495079, 34.004915952682495 s per 100 iters\n","time = 117.0, epoch 3, iter = 5900, loss = 1.9452551019191742, 34.724289417266846 s per 100 iters\n","time = 118.0, epoch 3, iter = 6000, loss = 1.9597228026390077, 34.42808794975281 s per 100 iters\n","time = 119.0, epoch 3, iter = 6100, loss = 1.9050218135118484, 34.38422775268555 s per 100 iters\n","time = 119.0, epoch 3, iter = 6200, loss = 1.9283690863847733, 34.83895826339722 s per 100 iters\n","time = 120.0, epoch 3, iter = 6300, loss = 1.949118504524231, 34.660499572753906 s per 100 iters\n","time = 120.0, epoch 3, iter = 6400, loss = 1.9742405962944032, 35.69775319099426 s per 100 iters\n","time = 121.0, epoch 3, iter = 6500, loss = 1.960300920009613, 34.55634689331055 s per 100 iters\n","time = 122.0, epoch 3, iter = 6600, loss = 1.965348179936409, 35.22023344039917 s per 100 iters\n","time = 122.0, epoch 3, iter = 6700, loss = 1.9542704230546952, 35.37821578979492 s per 100 iters\n","time = 123.0, epoch 3, iter = 6800, loss = 1.955793609023094, 34.34344410896301 s per 100 iters\n","time = 123.0, epoch 3, iter = 6900, loss = 1.96118583381176, 35.44827723503113 s per 100 iters\n","time = 124.0, epoch 3, iter = 7000, loss = 1.9746482169628143, 35.126662492752075 s per 100 iters\n","time = 124.0, epoch 3, iter = 7100, loss = 1.9694089710712432, 35.185622692108154 s per 100 iters\n","time = 125.0, epoch 3, iter = 7200, loss = 1.9645997494459153, 34.96434235572815 s per 100 iters\n","time = 126.0, epoch 3, iter = 7300, loss = 1.9351526767015457, 34.20117521286011 s per 100 iters\n","time = 126.0, epoch 3, iter = 7400, loss = 1.9439406526088714, 35.06084632873535 s per 100 iters\n","time = 127.0, epoch 3, iter = 7500, loss = 1.927626577615738, 35.06535053253174 s per 100 iters\n","time = 127.0, epoch 3, iter = 7600, loss = 1.9532610416412353, 35.29142117500305 s per 100 iters\n","time = 128.0, epoch 3, iter = 7700, loss = 1.9704136168956756, 34.12739944458008 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 128.0, epoch 3, iter = 7800, loss = 1.9498370325565337, 34.222471952438354 s per 100 iters\n","time = 129.0, epoch 3, iter = 7900, loss = 1.9577545130252838, 34.8077666759491 s per 100 iters\n","time = 130.0, epoch 3, iter = 8000, loss = 1.9508451342582702, 34.57573628425598 s per 100 iters\n","time = 130.0, epoch 3, iter = 8100, loss = 1.9568461549282075, 34.76563334465027 s per 100 iters\n","time = 131.0, epoch 3, iter = 8200, loss = 1.9399321299791337, 34.257169246673584 s per 100 iters\n","time = 131.0, epoch 3, iter = 8300, loss = 1.9615372657775878, 34.17261362075806 s per 100 iters\n","time = 132.0, epoch 3, iter = 8400, loss = 1.946505961418152, 33.71595072746277 s per 100 iters\n","time = 133.0, epoch 3, iter = 8500, loss = 1.9501628398895263, 34.72067379951477 s per 100 iters\n","time = 133.0, epoch 3, iter = 8600, loss = 1.9593542182445527, 34.97157859802246 s per 100 iters\n","time = 134.0, epoch 3, iter = 8700, loss = 1.9681041216850281, 36.55549097061157 s per 100 iters\n","time = 134.0, epoch 3, iter = 8800, loss = 1.953503838777542, 34.30134677886963 s per 100 iters\n","time = 135.0, epoch 3, iter = 8900, loss = 1.9370523262023926, 34.26077890396118 s per 100 iters\n","time = 135.0, epoch 3, iter = 9000, loss = 1.9599660694599152, 35.31234836578369 s per 100 iters\n","time = 136.0, epoch 3, iter = 9100, loss = 1.954967815876007, 34.332491636276245 s per 100 iters\n","time = 137.0, epoch 3, iter = 9200, loss = 1.9476982188224792, 35.80037832260132 s per 100 iters\n","time = 137.0, epoch 3, iter = 9300, loss = 1.9810079169273376, 36.12633728981018 s per 100 iters\n","time = 138.0, epoch 3, iter = 9400, loss = 1.9446413779258729, 34.262866258621216 s per 100 iters\n","time = 138.0, epoch 3, iter = 9500, loss = 1.9438360440731048, 35.0793559551239 s per 100 iters\n","time = 139.0, epoch 3, iter = 9600, loss = 1.9459566086530686, 34.75481390953064 s per 100 iters\n","time = 140.0, epoch 3, iter = 9700, loss = 1.950527440905571, 34.71436905860901 s per 100 iters\n","time = 140.0, epoch 3, iter = 9800, loss = 1.947284574508667, 33.915945529937744 s per 100 iters\n","time = 141.0, epoch 3, iter = 9900, loss = 1.9726948428153992, 35.25102972984314 s per 100 iters\n","time = 141.0, epoch 3, iter = 10000, loss = 1.9259932696819306, 34.38760590553284 s per 100 iters\n","time = 142.0, epoch 3, iter = 10100, loss = 1.9324487221240998, 34.153117656707764 s per 100 iters\n","time = 142.0, epoch 3, iter = 10200, loss = 1.9343109089136123, 34.881765365600586 s per 100 iters\n","time = 143.0, epoch 3, iter = 10300, loss = 1.9399899113178254, 35.002564668655396 s per 100 iters\n","time = 144.0, epoch 3, iter = 10400, loss = 1.9535812389850618, 34.47075176239014 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 144.0, epoch 3, iter = 10500, loss = 1.9550023472309113, 34.49243235588074 s per 100 iters\n","time = 145.0, epoch 3, iter = 10600, loss = 1.9585870730876922, 35.0616569519043 s per 100 iters\n","time = 145.0, epoch 3, iter = 10700, loss = 1.9489719247817994, 34.472110986709595 s per 100 iters\n","time = 146.0, epoch 3, iter = 10800, loss = 1.9454289555549622, 35.47636127471924 s per 100 iters\n","time = 146.0, epoch 3, iter = 10900, loss = 1.9463376581668854, 33.9495005607605 s per 100 iters\n","time = 147.0, epoch 3, iter = 11000, loss = 1.9551951032876969, 34.20373582839966 s per 100 iters\n","time = 148.0, epoch 3, iter = 11100, loss = 1.9672904008626937, 35.65187072753906 s per 100 iters\n","time = 148.0, epoch 3, iter = 11200, loss = 1.9204899436235428, 34.16204881668091 s per 100 iters\n","time = 149.0, epoch 3, iter = 11300, loss = 1.9044831115007401, 34.39575934410095 s per 100 iters\n","time = 149.0, epoch 3, iter = 11400, loss = 1.9234784120321273, 34.488795042037964 s per 100 iters\n","time = 150.0, epoch 3, iter = 11500, loss = 1.9606034064292908, 35.20341205596924 s per 100 iters\n","time = 150.0, epoch 3, iter = 11600, loss = 1.9340869039297104, 34.26845026016235 s per 100 iters\n","time = 151.0, epoch 3, iter = 11700, loss = 1.9583853393793107, 33.950936794281006 s per 100 iters\n","time = 152.0, epoch 3, iter = 11800, loss = 1.9298959916830063, 34.31308364868164 s per 100 iters\n","time = 152.0, epoch 3, iter = 11900, loss = 1.9216802603006362, 35.39663290977478 s per 100 iters\n","time = 153.0, epoch 3, iter = 12000, loss = 1.9700535696744919, 34.88295888900757 s per 100 iters\n","time = 153.0, epoch 3, iter = 12100, loss = 1.9546823656558991, 34.50567007064819 s per 100 iters\n","time = 154.0, epoch 3, iter = 12200, loss = 1.939053534269333, 34.72381114959717 s per 100 iters\n","time = 155.0, epoch 3, iter = 12300, loss = 1.9524985712766647, 34.5862398147583 s per 100 iters\n","time = 155.0, epoch 3, iter = 12400, loss = 1.9340615576505662, 35.26354098320007 s per 100 iters\n","time = 156.0, epoch 3, iter = 12500, loss = 1.9256506860256195, 33.74815368652344 s per 100 iters\n","time = 156.0, epoch 3, iter = 12600, loss = 1.9337762182950973, 34.25843167304993 s per 100 iters\n","time = 157.0, epoch 3, iter = 12700, loss = 1.9290294659137726, 34.640265226364136 s per 100 iters\n","time = 157.0, epoch 3, iter = 12800, loss = 1.923968266248703, 34.83298969268799 s per 100 iters\n","time = 158.0, epoch 3, iter = 12900, loss = 1.9092726516723633, 35.093886375427246 s per 100 iters\n","time = 159.0, epoch 3, iter = 13000, loss = 1.9032273763418197, 34.29289197921753 s per 100 iters\n","time = 159.0, epoch 3, iter = 13100, loss = 1.9324662071466445, 34.957130670547485 s per 100 iters\n","time = 160.0, epoch 3, iter = 13200, loss = 1.9603009021282196, 34.908207654953 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 160.0, epoch 3, iter = 13300, loss = 1.9308305144309998, 34.343416929244995 s per 100 iters\n","time = 161.0, epoch 3, iter = 13400, loss = 1.9479256302118302, 35.32969641685486 s per 100 iters\n","time = 161.0, epoch 3, iter = 13500, loss = 1.9184010970592498, 34.82820248603821 s per 100 iters\n","time = 162.0, epoch 3, iter = 13600, loss = 1.9587150925397874, 34.88604712486267 s per 100 iters\n","time = 163.0, epoch 3, iter = 13700, loss = 1.942585815191269, 34.42176842689514 s per 100 iters\n","time = 163.0, epoch 3, iter = 13800, loss = 1.9528235626220702, 33.498024463653564 s per 100 iters\n","time = 164.0, epoch 3, iter = 13900, loss = 1.921940906047821, 34.330787658691406 s per 100 iters\n","time = 164.0, epoch 3, iter = 14000, loss = 1.9524370330572127, 35.8587110042572 s per 100 iters\n","time = 165.0, epoch 3, iter = 14100, loss = 1.9303912335634232, 34.58962345123291 s per 100 iters\n","time = 166.0, epoch 3, iter = 14200, loss = 1.946157117486, 34.92198324203491 s per 100 iters\n","time = 166.0, epoch 3, iter = 14300, loss = 1.9183332598209382, 35.20055341720581 s per 100 iters\n","--- Balidazioa ---\n","25.865232706069946 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia novalia mile habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez da arraroa ￭?', '｟C colinek berriro gelditu zuen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako ortoetan lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austertasuna eta ｟C donfugatako ｟C fabriziok konbentzitu zuten ｟C donnafugata jauregia ez zela ｟C caparoko bandamaroaren antroa ￭, eta segur aski bizirik aterako zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi dauzkat ￭.', '｟C magistratu eta exekutiboaren beste ofizialak ￭, salaketa eta zigortza ￭, zeinek salaketa eta subiranotasunaren eserleku eta partaide baitira ￭, bere eginkizuna betetzeko ￭, nerbioak dira ￭, gorputz naturalean egiten dutenak ￭, aberastasun partikularrak eta aberastasun partikularrak ￭, herriarentzat ￭, askatasunaren eta askatasunaren indarra ￭, hau da ￭, eta botere artifizialak ￭, boterearen eta askatasunaren jabe den guztia ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura ere beren ideala da ￭, eta agian ez dute beste inork ￭, gaur egun ￭, berek berek beren buru izpiritualena dute ￭, bere gerlariak eta esploratzaileen tropa aurreratuagoak ￭, bere liluragarriena ￭, sedukzioaren forma sentigarriena ￭.', '｟C hegoaldean ez dago esklaburik ez duten familiarik ￭.', '｟C derwatt-en kasuan ￭, eta orain ｟C mafiari madarikatu hori ￭?']\n","BLEU puntuazioa (1): 10.249494558420029\n","7.061032772064209 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvette-ren historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendekatzeko etorria zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu inporta ￭?', '｟C argazkia erakutsi nahi diot 1960ko eta bere semea 1940ko uniformea jantzita ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 24.8193490713977\n","BLEU puntuazioa (biak): 13.609061841099951\n","time = 168.0, epoch 4, iter = 100, loss = 1.8128802853822708, 36.63411593437195 s per 100 iters\n","time = 168.0, epoch 4, iter = 200, loss = 1.8036897999048234, 34.22257113456726 s per 100 iters\n","time = 169.0, epoch 4, iter = 300, loss = 1.8151851600408555, 34.25541925430298 s per 100 iters\n","time = 169.0, epoch 4, iter = 400, loss = 1.7968671560287475, 35.5430634021759 s per 100 iters\n","time = 170.0, epoch 4, iter = 500, loss = 1.818729574084282, 35.74359202384949 s per 100 iters\n","time = 170.0, epoch 4, iter = 600, loss = 1.8151169055700302, 34.31944227218628 s per 100 iters\n","time = 171.0, epoch 4, iter = 700, loss = 1.8011271172761918, 34.6893367767334 s per 100 iters\n","time = 172.0, epoch 4, iter = 800, loss = 1.821498246192932, 35.33057141304016 s per 100 iters\n","time = 172.0, epoch 4, iter = 900, loss = 1.8252231335639955, 35.230024576187134 s per 100 iters\n","time = 173.0, epoch 4, iter = 1000, loss = 1.7971922433376313, 33.79901432991028 s per 100 iters\n","time = 173.0, epoch 4, iter = 1100, loss = 1.789930298924446, 34.82443165779114 s per 100 iters\n","time = 174.0, epoch 4, iter = 1200, loss = 1.8321152132749559, 35.23160433769226 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 174.0, epoch 4, iter = 1300, loss = 1.8395609426498414, 34.81826996803284 s per 100 iters\n","time = 175.0, epoch 4, iter = 1400, loss = 1.8419510942697526, 34.95142674446106 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 176.0, epoch 4, iter = 1500, loss = 1.8162591642141341, 34.116262912750244 s per 100 iters\n","time = 176.0, epoch 4, iter = 1600, loss = 1.8314521300792694, 34.37026810646057 s per 100 iters\n","time = 177.0, epoch 4, iter = 1700, loss = 1.8109684348106385, 33.69056057929993 s per 100 iters\n","time = 177.0, epoch 4, iter = 1800, loss = 1.8531800520420074, 35.25056076049805 s per 100 iters\n","time = 178.0, epoch 4, iter = 1900, loss = 1.8257415777444839, 34.48664426803589 s per 100 iters\n","time = 179.0, epoch 4, iter = 2000, loss = 1.8446655285358429, 35.017502546310425 s per 100 iters\n","time = 179.0, epoch 4, iter = 2100, loss = 1.828422650694847, 34.99827003479004 s per 100 iters\n","time = 180.0, epoch 4, iter = 2200, loss = 1.8336265820264817, 34.92238759994507 s per 100 iters\n","time = 180.0, epoch 4, iter = 2300, loss = 1.83512231528759, 35.34070158004761 s per 100 iters\n","time = 181.0, epoch 4, iter = 2400, loss = 1.8244462716579437, 35.093424558639526 s per 100 iters\n","time = 181.0, epoch 4, iter = 2500, loss = 1.828526012301445, 35.148078203201294 s per 100 iters\n","time = 182.0, epoch 4, iter = 2600, loss = 1.8516531258821487, 35.517884731292725 s per 100 iters\n","time = 183.0, epoch 4, iter = 2700, loss = 1.834867981672287, 33.884013414382935 s per 100 iters\n","time = 183.0, epoch 4, iter = 2800, loss = 1.839270786046982, 34.5990252494812 s per 100 iters\n","time = 184.0, epoch 4, iter = 2900, loss = 1.831965343952179, 34.944756507873535 s per 100 iters\n","time = 184.0, epoch 4, iter = 3000, loss = 1.8570790803432464, 34.28836441040039 s per 100 iters\n","time = 185.0, epoch 4, iter = 3100, loss = 1.8668151491880416, 35.102548599243164 s per 100 iters\n","time = 185.0, epoch 4, iter = 3200, loss = 1.8484372228384018, 35.146352767944336 s per 100 iters\n","time = 186.0, epoch 4, iter = 3300, loss = 1.8144650113582612, 34.62923526763916 s per 100 iters\n","time = 187.0, epoch 4, iter = 3400, loss = 1.8129549539089203, 34.15803384780884 s per 100 iters\n","time = 187.0, epoch 4, iter = 3500, loss = 1.8469276714324951, 35.16146802902222 s per 100 iters\n","time = 188.0, epoch 4, iter = 3600, loss = 1.8366091525554658, 34.32078504562378 s per 100 iters\n","time = 188.0, epoch 4, iter = 3700, loss = 1.8328302592039107, 32.91792273521423 s per 100 iters\n","time = 189.0, epoch 4, iter = 3800, loss = 1.826986837387085, 33.62579703330994 s per 100 iters\n","time = 190.0, epoch 4, iter = 3900, loss = 1.8213423705101013, 36.55172348022461 s per 100 iters\n","time = 190.0, epoch 4, iter = 4000, loss = 1.8541388297080994, 34.874144077301025 s per 100 iters\n","time = 191.0, epoch 4, iter = 4100, loss = 1.872657935023308, 35.38367414474487 s per 100 iters\n","time = 191.0, epoch 4, iter = 4200, loss = 1.8380809104442597, 34.74697160720825 s per 100 iters\n","time = 192.0, epoch 4, iter = 4300, loss = 1.8403483629226685, 35.5858039855957 s per 100 iters\n","time = 192.0, epoch 4, iter = 4400, loss = 1.8079446262121202, 34.36260962486267 s per 100 iters\n","time = 193.0, epoch 4, iter = 4500, loss = 1.8348358649015426, 35.36303091049194 s per 100 iters\n","time = 194.0, epoch 4, iter = 4600, loss = 1.8387959069013595, 35.06046152114868 s per 100 iters\n","time = 194.0, epoch 4, iter = 4700, loss = 1.8327253651618958, 34.30117607116699 s per 100 iters\n","time = 195.0, epoch 4, iter = 4800, loss = 1.8257476687431335, 34.85824012756348 s per 100 iters\n","time = 195.0, epoch 4, iter = 4900, loss = 1.8303232216835021, 35.016566038131714 s per 100 iters\n","time = 196.0, epoch 4, iter = 5000, loss = 1.8379503792524339, 34.70167374610901 s per 100 iters\n","time = 196.0, epoch 4, iter = 5100, loss = 1.8240673232078553, 34.1086630821228 s per 100 iters\n","time = 197.0, epoch 4, iter = 5200, loss = 1.856442567706108, 34.26402950286865 s per 100 iters\n","time = 198.0, epoch 4, iter = 5300, loss = 1.8229624778032303, 35.13417935371399 s per 100 iters\n","time = 198.0, epoch 4, iter = 5400, loss = 1.823978054523468, 35.313225507736206 s per 100 iters\n","time = 199.0, epoch 4, iter = 5500, loss = 1.8206459587812425, 34.24025297164917 s per 100 iters\n","time = 199.0, epoch 4, iter = 5600, loss = 1.851964648962021, 34.9436252117157 s per 100 iters\n","time = 200.0, epoch 4, iter = 5700, loss = 1.843192697763443, 35.38372182846069 s per 100 iters\n","time = 201.0, epoch 4, iter = 5800, loss = 1.842491676211357, 34.73475670814514 s per 100 iters\n","time = 201.0, epoch 4, iter = 5900, loss = 1.8441602659225464, 34.74298071861267 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 202.0, epoch 4, iter = 6000, loss = 1.8360192501544952, 34.731069564819336 s per 100 iters\n","time = 202.0, epoch 4, iter = 6100, loss = 1.8507277196645737, 34.51061296463013 s per 100 iters\n","time = 203.0, epoch 4, iter = 6200, loss = 1.8406231862306595, 35.179577350616455 s per 100 iters\n","time = 203.0, epoch 4, iter = 6300, loss = 1.8333199948072434, 34.259339332580566 s per 100 iters\n","time = 204.0, epoch 4, iter = 6400, loss = 1.838086866736412, 34.94406795501709 s per 100 iters\n","time = 205.0, epoch 4, iter = 6500, loss = 1.8509057825803756, 34.73455047607422 s per 100 iters\n","time = 205.0, epoch 4, iter = 6600, loss = 1.8536006850004196, 35.24889159202576 s per 100 iters\n","time = 206.0, epoch 4, iter = 6700, loss = 1.8357986956834793, 35.426090478897095 s per 100 iters\n","time = 206.0, epoch 4, iter = 6800, loss = 1.8422594743967056, 35.01703453063965 s per 100 iters\n","time = 207.0, epoch 4, iter = 6900, loss = 1.825752328634262, 34.64372205734253 s per 100 iters\n","time = 208.0, epoch 4, iter = 7000, loss = 1.837919825911522, 34.432419776916504 s per 100 iters\n","time = 208.0, epoch 4, iter = 7100, loss = 1.8420980739593507, 34.778313636779785 s per 100 iters\n","time = 209.0, epoch 4, iter = 7200, loss = 1.8560667473077774, 34.662933588027954 s per 100 iters\n","time = 209.0, epoch 4, iter = 7300, loss = 1.8105494093894958, 34.26429533958435 s per 100 iters\n","time = 210.0, epoch 4, iter = 7400, loss = 1.856741452217102, 34.338988065719604 s per 100 iters\n","time = 210.0, epoch 4, iter = 7500, loss = 1.8480098366737365, 35.063390493392944 s per 100 iters\n","time = 211.0, epoch 4, iter = 7600, loss = 1.867797989845276, 35.557435750961304 s per 100 iters\n","time = 212.0, epoch 4, iter = 7700, loss = 1.8426742655038835, 34.27182936668396 s per 100 iters\n","time = 212.0, epoch 4, iter = 7800, loss = 1.8664867639541627, 35.31391716003418 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 213.0, epoch 4, iter = 7900, loss = 1.83371477663517, 33.934882402420044 s per 100 iters\n","time = 213.0, epoch 4, iter = 8000, loss = 1.8279097521305083, 34.77652883529663 s per 100 iters\n","time = 214.0, epoch 4, iter = 8100, loss = 1.8409213769435882, 36.03627967834473 s per 100 iters\n","time = 214.0, epoch 4, iter = 8200, loss = 1.8356658017635346, 34.614309310913086 s per 100 iters\n","time = 215.0, epoch 4, iter = 8300, loss = 1.819570107460022, 34.307533740997314 s per 100 iters\n","time = 216.0, epoch 4, iter = 8400, loss = 1.874002360701561, 35.69343066215515 s per 100 iters\n","time = 216.0, epoch 4, iter = 8500, loss = 1.857434211373329, 34.37091946601868 s per 100 iters\n","time = 217.0, epoch 4, iter = 8600, loss = 1.8539581000804901, 35.29924035072327 s per 100 iters\n","time = 217.0, epoch 4, iter = 8700, loss = 1.8442366939783097, 35.08993101119995 s per 100 iters\n","time = 218.0, epoch 4, iter = 8800, loss = 1.8105211120843887, 34.38879346847534 s per 100 iters\n","time = 219.0, epoch 4, iter = 8900, loss = 1.840012680888176, 35.32666540145874 s per 100 iters\n","time = 219.0, epoch 4, iter = 9000, loss = 1.8619627660512925, 34.98659563064575 s per 100 iters\n","time = 220.0, epoch 4, iter = 9100, loss = 1.874656207561493, 35.155112504959106 s per 100 iters\n","time = 220.0, epoch 4, iter = 9200, loss = 1.8537141692638397, 34.82841205596924 s per 100 iters\n","time = 221.0, epoch 4, iter = 9300, loss = 1.8545667427778243, 34.06295299530029 s per 100 iters\n","time = 221.0, epoch 4, iter = 9400, loss = 1.819801354408264, 34.52983546257019 s per 100 iters\n","time = 222.0, epoch 4, iter = 9500, loss = 1.8442170226573944, 34.939741373062134 s per 100 iters\n","time = 223.0, epoch 4, iter = 9600, loss = 1.861613243818283, 34.97058844566345 s per 100 iters\n","time = 223.0, epoch 4, iter = 9700, loss = 1.839232286810875, 34.40789031982422 s per 100 iters\n","time = 224.0, epoch 4, iter = 9800, loss = 1.8538127261400223, 35.06432819366455 s per 100 iters\n","time = 224.0, epoch 4, iter = 9900, loss = 1.839929403066635, 34.96534538269043 s per 100 iters\n","time = 225.0, epoch 4, iter = 10000, loss = 1.860764720439911, 35.63214826583862 s per 100 iters\n","time = 226.0, epoch 4, iter = 10100, loss = 1.8455321449041366, 34.86026096343994 s per 100 iters\n","time = 226.0, epoch 4, iter = 10200, loss = 1.8297938710451127, 34.3857204914093 s per 100 iters\n","time = 227.0, epoch 4, iter = 10300, loss = 1.8468361949920655, 35.039438247680664 s per 100 iters\n","time = 227.0, epoch 4, iter = 10400, loss = 1.8172799283266068, 35.265432357788086 s per 100 iters\n","time = 228.0, epoch 4, iter = 10500, loss = 1.8518376004695893, 35.104158878326416 s per 100 iters\n","time = 228.0, epoch 4, iter = 10600, loss = 1.8405401080846786, 34.243112325668335 s per 100 iters\n","time = 229.0, epoch 4, iter = 10700, loss = 1.8535960698127747, 34.75769782066345 s per 100 iters\n","time = 230.0, epoch 4, iter = 10800, loss = 1.831067743897438, 34.19690728187561 s per 100 iters\n","time = 230.0, epoch 4, iter = 10900, loss = 1.8433266347646713, 35.13946223258972 s per 100 iters\n","time = 231.0, epoch 4, iter = 11000, loss = 1.8367269122600556, 34.81572127342224 s per 100 iters\n","time = 231.0, epoch 4, iter = 11100, loss = 1.8524462592601776, 34.771833658218384 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 232.0, epoch 4, iter = 11200, loss = 1.82790931224823, 34.77327251434326 s per 100 iters\n","time = 232.0, epoch 4, iter = 11300, loss = 1.8644967448711396, 35.296252727508545 s per 100 iters\n","time = 233.0, epoch 4, iter = 11400, loss = 1.8320028048753738, 35.367918491363525 s per 100 iters\n","time = 234.0, epoch 4, iter = 11500, loss = 1.852402748465538, 33.968196630477905 s per 100 iters\n","time = 234.0, epoch 4, iter = 11600, loss = 1.8580423295497894, 35.152995109558105 s per 100 iters\n","time = 235.0, epoch 4, iter = 11700, loss = 1.8250558793544769, 34.628281354904175 s per 100 iters\n","time = 235.0, epoch 4, iter = 11800, loss = 1.834467033147812, 34.180166482925415 s per 100 iters\n","time = 236.0, epoch 4, iter = 11900, loss = 1.858079417347908, 35.37141513824463 s per 100 iters\n","time = 237.0, epoch 4, iter = 12000, loss = 1.8535035794973374, 34.271034479141235 s per 100 iters\n","time = 237.0, epoch 4, iter = 12100, loss = 1.8526563262939453, 34.81756591796875 s per 100 iters\n","time = 238.0, epoch 4, iter = 12200, loss = 1.8604480254650115, 34.731619358062744 s per 100 iters\n","time = 238.0, epoch 4, iter = 12300, loss = 1.8315647846460343, 34.254873275756836 s per 100 iters\n","time = 239.0, epoch 4, iter = 12400, loss = 1.8482249718904495, 33.85966086387634 s per 100 iters\n","time = 239.0, epoch 4, iter = 12500, loss = 1.8676880341768265, 36.16596245765686 s per 100 iters\n","time = 240.0, epoch 4, iter = 12600, loss = 1.852408544421196, 34.66940999031067 s per 100 iters\n","time = 241.0, epoch 4, iter = 12700, loss = 1.8432874178886414, 34.54487228393555 s per 100 iters\n","time = 241.0, epoch 4, iter = 12800, loss = 1.8462714570760728, 34.648682832717896 s per 100 iters\n","time = 242.0, epoch 4, iter = 12900, loss = 1.8516037660837172, 34.93994688987732 s per 100 iters\n","time = 242.0, epoch 4, iter = 13000, loss = 1.8513877260684968, 35.01646137237549 s per 100 iters\n","time = 243.0, epoch 4, iter = 13100, loss = 1.8776586544513703, 35.63724327087402 s per 100 iters\n","time = 244.0, epoch 4, iter = 13200, loss = 1.865516221523285, 35.3502516746521 s per 100 iters\n","time = 244.0, epoch 4, iter = 13300, loss = 1.8299467027187348, 35.10225868225098 s per 100 iters\n","time = 245.0, epoch 4, iter = 13400, loss = 1.8568884378671646, 34.59515643119812 s per 100 iters\n","time = 245.0, epoch 4, iter = 13500, loss = 1.8252583599090577, 34.76424288749695 s per 100 iters\n","time = 246.0, epoch 4, iter = 13600, loss = 1.8375175684690475, 34.551859617233276 s per 100 iters\n","time = 246.0, epoch 4, iter = 13700, loss = 1.8458691215515137, 34.326526403427124 s per 100 iters\n","time = 247.0, epoch 4, iter = 13800, loss = 1.8336819946765899, 34.79489541053772 s per 100 iters\n","time = 248.0, epoch 4, iter = 13900, loss = 1.8339980363845825, 33.902353048324585 s per 100 iters\n","time = 248.0, epoch 4, iter = 14000, loss = 1.8422025293111801, 34.9605975151062 s per 100 iters\n","time = 249.0, epoch 4, iter = 14100, loss = 1.8629649710655212, 35.28304743766785 s per 100 iters\n","time = 249.0, epoch 4, iter = 14200, loss = 1.8461142432689668, 35.78051519393921 s per 100 iters\n","time = 250.0, epoch 4, iter = 14300, loss = 1.8544288343191146, 35.17928886413574 s per 100 iters\n","--- Balidazioa ---\n","25.799108505249023 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia mile habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '｟B rosanna spearman ｟E ￭\" ￭.', '｟C ez da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ￭, ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austeritatea eta ｟C don ｟C fabrizioren portaera handia ￭, ｟C donnafugata jauregia ez zela ｟C capraro banderaren antro-parea ￭, eta ziurrenik bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta beste ofizialak ￭, epaile eta exekutiboarenak ￭, ordainketa eta zigorra ￭, subiranotasunaren eserleku bakoitza eta bere eginkizunaren mugitzeko mugatzen direnek ￭, gorputz naturalean gauza bera egiten duten nerbioak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideala da ￭, eta agian beste inor ez ￭, gaur bertan errepresentatzen dute ￭, berek sortzen dizkiote bere buru espiritualagogorra ￭, gudari eta eskaatzaileen tropa aurreratua ￭, delikatua ￭, liluratzeko forma delikatua ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C gutxienez ￭, oraintsu ￭, ｟C derwattenten kasuan eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 10.722900374438817\n","7.187892198562622 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendekua hartzeko etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia erakutsi nahi diot 1960ean eta bere semea 1940ko uniformean ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.571330943948073\n","BLEU puntuazioa (biak): 14.417476511227834\n","time = 251.0, epoch 5, iter = 100, loss = 1.689978551864624, 34.55464482307434 s per 100 iters\n","time = 252.0, epoch 5, iter = 200, loss = 1.7208212697505951, 35.23389744758606 s per 100 iters\n","time = 252.0, epoch 5, iter = 300, loss = 1.7268520557880402, 34.577476263046265 s per 100 iters\n","time = 253.0, epoch 5, iter = 400, loss = 1.7132274627685546, 34.52191662788391 s per 100 iters\n","time = 254.0, epoch 5, iter = 500, loss = 1.7092796725034713, 34.73844909667969 s per 100 iters\n","time = 254.0, epoch 5, iter = 600, loss = 1.7282943803071975, 35.166327238082886 s per 100 iters\n","time = 255.0, epoch 5, iter = 700, loss = 1.7202061295509339, 34.18821358680725 s per 100 iters\n","time = 255.0, epoch 5, iter = 800, loss = 1.7358712369203568, 35.865896463394165 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 256.0, epoch 5, iter = 900, loss = 1.717825348377228, 34.4883131980896 s per 100 iters\n","time = 256.0, epoch 5, iter = 1000, loss = 1.721510928273201, 34.067896127700806 s per 100 iters\n","time = 257.0, epoch 5, iter = 1100, loss = 1.7416777634620666, 35.40399432182312 s per 100 iters\n","time = 258.0, epoch 5, iter = 1200, loss = 1.7140179938077926, 34.53886151313782 s per 100 iters\n","time = 258.0, epoch 5, iter = 1300, loss = 1.7368256318569184, 34.46118378639221 s per 100 iters\n","time = 259.0, epoch 5, iter = 1400, loss = 1.7588810175657272, 35.01295828819275 s per 100 iters\n","time = 259.0, epoch 5, iter = 1500, loss = 1.729502054452896, 34.369872093200684 s per 100 iters\n","time = 260.0, epoch 5, iter = 1600, loss = 1.7431406545639039, 34.661592960357666 s per 100 iters\n","time = 261.0, epoch 5, iter = 1700, loss = 1.7412974750995636, 35.85386776924133 s per 100 iters\n","time = 261.0, epoch 5, iter = 1800, loss = 1.7365338915586472, 34.118656873703 s per 100 iters\n","time = 262.0, epoch 5, iter = 1900, loss = 1.741767984032631, 35.02769732475281 s per 100 iters\n","time = 262.0, epoch 5, iter = 2000, loss = 1.7284253859519958, 34.335967779159546 s per 100 iters\n","time = 263.0, epoch 5, iter = 2100, loss = 1.7389044851064681, 35.06290888786316 s per 100 iters\n","time = 263.0, epoch 5, iter = 2200, loss = 1.74878364443779, 35.487165689468384 s per 100 iters\n","time = 264.0, epoch 5, iter = 2300, loss = 1.7250666368007659, 35.161702156066895 s per 100 iters\n","time = 265.0, epoch 5, iter = 2400, loss = 1.7336167466640473, 35.29997277259827 s per 100 iters\n","time = 265.0, epoch 5, iter = 2500, loss = 1.7317167204618453, 34.535863399505615 s per 100 iters\n","time = 266.0, epoch 5, iter = 2600, loss = 1.7573994988203048, 34.25812888145447 s per 100 iters\n","time = 266.0, epoch 5, iter = 2700, loss = 1.7326730769872665, 34.10522651672363 s per 100 iters\n","time = 267.0, epoch 5, iter = 2800, loss = 1.7346743589639664, 35.11148190498352 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 268.0, epoch 5, iter = 2900, loss = 1.7376760935783386, 34.56180453300476 s per 100 iters\n","time = 268.0, epoch 5, iter = 3000, loss = 1.7476251119375228, 35.806182861328125 s per 100 iters\n","time = 269.0, epoch 5, iter = 3100, loss = 1.7346402132511138, 34.60816311836243 s per 100 iters\n","time = 269.0, epoch 5, iter = 3200, loss = 1.74646338224411, 34.91103792190552 s per 100 iters\n","time = 270.0, epoch 5, iter = 3300, loss = 1.764117142558098, 35.28689694404602 s per 100 iters\n","time = 270.0, epoch 5, iter = 3400, loss = 1.7494406110048295, 34.362104415893555 s per 100 iters\n","time = 271.0, epoch 5, iter = 3500, loss = 1.7465515851974487, 34.03201723098755 s per 100 iters\n","time = 272.0, epoch 5, iter = 3600, loss = 1.7373461616039276, 33.60825443267822 s per 100 iters\n","time = 272.0, epoch 5, iter = 3700, loss = 1.7613901352882386, 35.54646348953247 s per 100 iters\n","time = 273.0, epoch 5, iter = 3800, loss = 1.7437764453887938, 34.5826141834259 s per 100 iters\n","time = 273.0, epoch 5, iter = 3900, loss = 1.7422217750549316, 35.28688669204712 s per 100 iters\n","time = 274.0, epoch 5, iter = 4000, loss = 1.7482231271266937, 34.57739305496216 s per 100 iters\n","time = 274.0, epoch 5, iter = 4100, loss = 1.739169619679451, 35.51262640953064 s per 100 iters\n","time = 275.0, epoch 5, iter = 4200, loss = 1.7722639632225037, 35.34019923210144 s per 100 iters\n","time = 276.0, epoch 5, iter = 4300, loss = 1.7465481984615325, 34.84743309020996 s per 100 iters\n","time = 276.0, epoch 5, iter = 4400, loss = 1.7324451285600662, 34.644651651382446 s per 100 iters\n","time = 277.0, epoch 5, iter = 4500, loss = 1.7647192972898482, 35.07327365875244 s per 100 iters\n","time = 277.0, epoch 5, iter = 4600, loss = 1.7526557141542434, 34.25325870513916 s per 100 iters\n","time = 278.0, epoch 5, iter = 4700, loss = 1.753006290793419, 35.006282567977905 s per 100 iters\n","time = 279.0, epoch 5, iter = 4800, loss = 1.7542762649059296, 35.109994888305664 s per 100 iters\n","time = 279.0, epoch 5, iter = 4900, loss = 1.7812054854631425, 35.1327543258667 s per 100 iters\n","time = 280.0, epoch 5, iter = 5000, loss = 1.7413554018735886, 34.29848647117615 s per 100 iters\n","time = 280.0, epoch 5, iter = 5100, loss = 1.745625656247139, 33.98518395423889 s per 100 iters\n","time = 281.0, epoch 5, iter = 5200, loss = 1.750842415690422, 34.29517483711243 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 281.0, epoch 5, iter = 5300, loss = 1.7445628029108047, 35.32555103302002 s per 100 iters\n","time = 282.0, epoch 5, iter = 5400, loss = 1.7562844800949096, 34.90394473075867 s per 100 iters\n","time = 283.0, epoch 5, iter = 5500, loss = 1.7385319995880126, 34.18562340736389 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 283.0, epoch 5, iter = 5600, loss = 1.747392491698265, 35.2460196018219 s per 100 iters\n","time = 284.0, epoch 5, iter = 5700, loss = 1.762812739610672, 35.21528196334839 s per 100 iters\n","time = 284.0, epoch 5, iter = 5800, loss = 1.7740760380029679, 34.196398973464966 s per 100 iters\n","time = 285.0, epoch 5, iter = 5900, loss = 1.768101251721382, 34.52172875404358 s per 100 iters\n","time = 285.0, epoch 5, iter = 6000, loss = 1.7719929647445678, 35.35425162315369 s per 100 iters\n","time = 286.0, epoch 5, iter = 6100, loss = 1.7735503786802291, 35.13883924484253 s per 100 iters\n","time = 287.0, epoch 5, iter = 6200, loss = 1.7403091609477996, 33.98075485229492 s per 100 iters\n","time = 287.0, epoch 5, iter = 6300, loss = 1.759737777709961, 35.20866680145264 s per 100 iters\n","time = 288.0, epoch 5, iter = 6400, loss = 1.7592233622074127, 34.809159994125366 s per 100 iters\n","time = 288.0, epoch 5, iter = 6500, loss = 1.752025448679924, 35.27868056297302 s per 100 iters\n","time = 289.0, epoch 5, iter = 6600, loss = 1.7596460449695588, 33.801377296447754 s per 100 iters\n","time = 290.0, epoch 5, iter = 6700, loss = 1.7730911844968795, 34.92515182495117 s per 100 iters\n","time = 290.0, epoch 5, iter = 6800, loss = 1.7733189010620116, 35.76437711715698 s per 100 iters\n","time = 291.0, epoch 5, iter = 6900, loss = 1.7634623855352403, 33.627928495407104 s per 100 iters\n","time = 291.0, epoch 5, iter = 7000, loss = 1.7643785166740418, 34.56609869003296 s per 100 iters\n","time = 292.0, epoch 5, iter = 7100, loss = 1.7655069327354431, 35.55741786956787 s per 100 iters\n","time = 292.0, epoch 5, iter = 7200, loss = 1.7739364051818847, 35.825329303741455 s per 100 iters\n","time = 293.0, epoch 5, iter = 7300, loss = 1.7727075773477554, 35.7322838306427 s per 100 iters\n","time = 294.0, epoch 5, iter = 7400, loss = 1.7541062730550765, 33.87858843803406 s per 100 iters\n","time = 294.0, epoch 5, iter = 7500, loss = 1.7879825222492218, 35.97502112388611 s per 100 iters\n","time = 295.0, epoch 5, iter = 7600, loss = 1.753425989151001, 35.960742235183716 s per 100 iters\n","time = 295.0, epoch 5, iter = 7700, loss = 1.7755108606815337, 34.088611125946045 s per 100 iters\n","time = 296.0, epoch 5, iter = 7800, loss = 1.740239697098732, 35.19309377670288 s per 100 iters\n","time = 297.0, epoch 5, iter = 7900, loss = 1.7793277472257614, 35.117058515548706 s per 100 iters\n","time = 297.0, epoch 5, iter = 8000, loss = 1.7655900955200194, 35.01025867462158 s per 100 iters\n","time = 298.0, epoch 5, iter = 8100, loss = 1.7570077443122865, 34.07327389717102 s per 100 iters\n","time = 298.0, epoch 5, iter = 8200, loss = 1.7796945172548293, 34.782586097717285 s per 100 iters\n","time = 299.0, epoch 5, iter = 8300, loss = 1.7690604782104493, 34.69892382621765 s per 100 iters\n","time = 299.0, epoch 5, iter = 8400, loss = 1.785380094051361, 34.977410078048706 s per 100 iters\n","time = 300.0, epoch 5, iter = 8500, loss = 1.7531236267089845, 35.39071178436279 s per 100 iters\n","time = 301.0, epoch 5, iter = 8600, loss = 1.7747856187820434, 35.25112843513489 s per 100 iters\n","time = 301.0, epoch 5, iter = 8700, loss = 1.759985738992691, 33.946698904037476 s per 100 iters\n","time = 302.0, epoch 5, iter = 8800, loss = 1.7377085447311402, 34.2704713344574 s per 100 iters\n","time = 302.0, epoch 5, iter = 8900, loss = 1.7665016037225723, 34.39042568206787 s per 100 iters\n","time = 303.0, epoch 5, iter = 9000, loss = 1.7496551483869554, 34.865636587142944 s per 100 iters\n","time = 304.0, epoch 5, iter = 9100, loss = 1.7568385410308838, 34.41537094116211 s per 100 iters\n","time = 304.0, epoch 5, iter = 9200, loss = 1.7873491585254668, 35.0109167098999 s per 100 iters\n","time = 305.0, epoch 5, iter = 9300, loss = 1.759527446627617, 33.949143409729004 s per 100 iters\n","time = 305.0, epoch 5, iter = 9400, loss = 1.7650117188692094, 34.11453938484192 s per 100 iters\n","time = 306.0, epoch 5, iter = 9500, loss = 1.7622161668539047, 35.96079182624817 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 306.0, epoch 5, iter = 9600, loss = 1.7672610968351363, 34.60404658317566 s per 100 iters\n","time = 307.0, epoch 5, iter = 9700, loss = 1.7429819077253341, 34.077306032180786 s per 100 iters\n","time = 308.0, epoch 5, iter = 9800, loss = 1.7580885654687881, 34.81805396080017 s per 100 iters\n","time = 308.0, epoch 5, iter = 9900, loss = 1.7827451688051223, 35.03988766670227 s per 100 iters\n","time = 309.0, epoch 5, iter = 10000, loss = 1.7629228127002716, 34.55487394332886 s per 100 iters\n","time = 309.0, epoch 5, iter = 10100, loss = 1.7746503221988679, 35.04403853416443 s per 100 iters\n","time = 310.0, epoch 5, iter = 10200, loss = 1.7597482097148895, 35.09441256523132 s per 100 iters\n","time = 310.0, epoch 5, iter = 10300, loss = 1.7537307733297347, 35.48316478729248 s per 100 iters\n","time = 311.0, epoch 5, iter = 10400, loss = 1.7570847779512406, 34.35973930358887 s per 100 iters\n","time = 312.0, epoch 5, iter = 10500, loss = 1.7408816987276077, 34.6630859375 s per 100 iters\n","time = 312.0, epoch 5, iter = 10600, loss = 1.7596608352661134, 34.13106346130371 s per 100 iters\n","time = 313.0, epoch 5, iter = 10700, loss = 1.772278106212616, 34.91034722328186 s per 100 iters\n","time = 313.0, epoch 5, iter = 10800, loss = 1.7705456227064134, 34.61917567253113 s per 100 iters\n","time = 314.0, epoch 5, iter = 10900, loss = 1.7644590669870377, 34.960413694381714 s per 100 iters\n","time = 314.0, epoch 5, iter = 11000, loss = 1.7580248212814331, 34.227362632751465 s per 100 iters\n","time = 315.0, epoch 5, iter = 11100, loss = 1.7449646002054215, 32.7216420173645 s per 100 iters\n","time = 316.0, epoch 5, iter = 11200, loss = 1.7713827335834502, 33.17709517478943 s per 100 iters\n","time = 316.0, epoch 5, iter = 11300, loss = 1.7666474032402038, 34.090792417526245 s per 100 iters\n","time = 317.0, epoch 5, iter = 11400, loss = 1.769501312971115, 34.36054587364197 s per 100 iters\n","time = 317.0, epoch 5, iter = 11500, loss = 1.766907849907875, 35.46258568763733 s per 100 iters\n","time = 318.0, epoch 5, iter = 11600, loss = 1.7556640386581421, 35.99253535270691 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 319.0, epoch 5, iter = 11700, loss = 1.7705995815992355, 34.65981674194336 s per 100 iters\n","time = 319.0, epoch 5, iter = 11800, loss = 1.7847006386518478, 35.15413475036621 s per 100 iters\n","time = 320.0, epoch 5, iter = 11900, loss = 1.7784780460596084, 35.80069708824158 s per 100 iters\n","time = 320.0, epoch 5, iter = 12000, loss = 1.7877033579349517, 35.77168917655945 s per 100 iters\n","time = 321.0, epoch 5, iter = 12100, loss = 1.754449532032013, 35.317131757736206 s per 100 iters\n","time = 321.0, epoch 5, iter = 12200, loss = 1.7527293092012406, 35.73853516578674 s per 100 iters\n","time = 322.0, epoch 5, iter = 12300, loss = 1.786639279127121, 35.24507665634155 s per 100 iters\n","time = 323.0, epoch 5, iter = 12400, loss = 1.7672060322761536, 34.76074242591858 s per 100 iters\n","time = 323.0, epoch 5, iter = 12500, loss = 1.7337718963623048, 34.29224419593811 s per 100 iters\n","time = 324.0, epoch 5, iter = 12600, loss = 1.777003400325775, 33.73635458946228 s per 100 iters\n","time = 324.0, epoch 5, iter = 12700, loss = 1.7613964009284973, 34.39525747299194 s per 100 iters\n","time = 325.0, epoch 5, iter = 12800, loss = 1.7590047895908356, 34.11304235458374 s per 100 iters\n","time = 326.0, epoch 5, iter = 12900, loss = 1.7874853003025055, 35.697181940078735 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 326.0, epoch 5, iter = 13000, loss = 1.7789455550909041, 35.04916310310364 s per 100 iters\n","time = 327.0, epoch 5, iter = 13100, loss = 1.7567314559221268, 35.3265495300293 s per 100 iters\n","time = 327.0, epoch 5, iter = 13200, loss = 1.7801639068126678, 34.86791658401489 s per 100 iters\n","time = 328.0, epoch 5, iter = 13300, loss = 1.7518789875507355, 34.954766273498535 s per 100 iters\n","time = 328.0, epoch 5, iter = 13400, loss = 1.767175374031067, 35.35575532913208 s per 100 iters\n","time = 329.0, epoch 5, iter = 13500, loss = 1.772502766251564, 35.53343844413757 s per 100 iters\n","time = 330.0, epoch 5, iter = 13600, loss = 1.7666484022140503, 33.64733266830444 s per 100 iters\n","time = 330.0, epoch 5, iter = 13700, loss = 1.7653049755096435, 35.01645231246948 s per 100 iters\n","time = 331.0, epoch 5, iter = 13800, loss = 1.7817061322927474, 34.15256333351135 s per 100 iters\n","time = 331.0, epoch 5, iter = 13900, loss = 1.7709448873996734, 34.62448596954346 s per 100 iters\n","time = 332.0, epoch 5, iter = 14000, loss = 1.7555836713314057, 34.940462589263916 s per 100 iters\n","time = 332.0, epoch 5, iter = 14100, loss = 1.761138100028038, 34.421751737594604 s per 100 iters\n","time = 333.0, epoch 5, iter = 14200, loss = 1.771083631515503, 34.54107117652893 s per 100 iters\n","time = 334.0, epoch 5, iter = 14300, loss = 1.7661566162109374, 36.133737564086914 s per 100 iters\n","--- Balidazioa ---\n","25.696045398712158 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '｟B rosanna spearman ｟E', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehenengoz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austertasuna eta ｟C don ｟C fabrizioren moduek konbentzitu zuten ｟C donnafugatako jauregia ez zela ｟C kapraro banderaren antroa ￭, eta seguru aski bizirik aterako zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta exekutiboko beste ofizialak ￭, berriz ￭, epailea eta exekutiboko beste funtzionarioak ￭, sari eta zigorra ￭, zeinetatik subiranotasunaren lokarri eta kide bakoitza bere eginkizuna betetzeko mugatzen diren ￭, nerbioak dira ￭, eta ondasun guztiak ￭, aberastasun partikularrak ￭, botere publikoak ￭, botere publikoak ￭, edo botere legegilearen boterea ￭, eta boterea ￭, horretarako ￭, gauza guztiak ￭, eta gauza guztiak ￭, eta gauza artifizialak ￭, berriz ￭, ｟C subiranotasunaren ｟C boterea ￭, ｟C jainkoaren ｟C jainkoaren ｟C boterea ￭, ｟C izpiritu ｟C izpirituan ￭, ｟C izpirituan ￭, ｟C izpirituan', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura ere beren ideala da ￭, eta agian beste inor ez ￭, gaur egun ￭, berek ere beren antzezpen izpiritualena dute ￭, bere talde aurreratua ￭, gerlari eta eskaargirik aurreratua ￭, bere erakarmenik finena ￭, liluratzeko forma sentibera ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C derwatten kasuan ￭, gutxienez ￭, eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 10.900145412918793\n","7.858502626419067 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu inporta ￭?', '｟C argazkia erakutsi nahi diot 1960an eta bere semea 1940ko uniformean ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 24.787642473302935\n","BLEU puntuazioa (biak): 14.095608227481925\n","time = 335.0, epoch 6, iter = 100, loss = 1.6386155325174332, 36.90094447135925 s per 100 iters\n","time = 336.0, epoch 6, iter = 200, loss = 1.6563751077651978, 35.52950191497803 s per 100 iters\n","time = 336.0, epoch 6, iter = 300, loss = 1.6371706795692444, 34.87119746208191 s per 100 iters\n","time = 337.0, epoch 6, iter = 400, loss = 1.6476971840858459, 34.74158453941345 s per 100 iters\n","time = 337.0, epoch 6, iter = 500, loss = 1.6353489315509797, 34.616899728775024 s per 100 iters\n","time = 338.0, epoch 6, iter = 600, loss = 1.628463174700737, 33.96655082702637 s per 100 iters\n","time = 339.0, epoch 6, iter = 700, loss = 1.6264838397502899, 34.89180254936218 s per 100 iters\n","time = 339.0, epoch 6, iter = 800, loss = 1.6601744163036347, 35.29896426200867 s per 100 iters\n","time = 340.0, epoch 6, iter = 900, loss = 1.6403120809793472, 33.97268199920654 s per 100 iters\n","time = 340.0, epoch 6, iter = 1000, loss = 1.6705689662694931, 35.717501401901245 s per 100 iters\n","time = 341.0, epoch 6, iter = 1100, loss = 1.6218831634521484, 33.69368815422058 s per 100 iters\n","time = 341.0, epoch 6, iter = 1200, loss = 1.6613627260923385, 35.97789239883423 s per 100 iters\n","time = 342.0, epoch 6, iter = 1300, loss = 1.660516358613968, 35.5655722618103 s per 100 iters\n","time = 343.0, epoch 6, iter = 1400, loss = 1.65840793967247, 35.011510610580444 s per 100 iters\n","time = 343.0, epoch 6, iter = 1500, loss = 1.652293426990509, 35.17246127128601 s per 100 iters\n","time = 344.0, epoch 6, iter = 1600, loss = 1.6751130616664887, 34.640300273895264 s per 100 iters\n","time = 344.0, epoch 6, iter = 1700, loss = 1.673867511153221, 36.59106111526489 s per 100 iters\n","time = 345.0, epoch 6, iter = 1800, loss = 1.6441339391469956, 34.87807893753052 s per 100 iters\n","time = 346.0, epoch 6, iter = 1900, loss = 1.6452140194177627, 34.775280714035034 s per 100 iters\n","time = 346.0, epoch 6, iter = 2000, loss = 1.6627061617374421, 35.24423694610596 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 347.0, epoch 6, iter = 2100, loss = 1.6564533734321594, 34.725276947021484 s per 100 iters\n","time = 347.0, epoch 6, iter = 2200, loss = 1.6586900663375854, 35.618165254592896 s per 100 iters\n","time = 348.0, epoch 6, iter = 2300, loss = 1.6658087545633316, 34.233819007873535 s per 100 iters\n","time = 348.0, epoch 6, iter = 2400, loss = 1.6912618035078049, 35.302531242370605 s per 100 iters\n","time = 349.0, epoch 6, iter = 2500, loss = 1.6599311876296996, 34.632251024246216 s per 100 iters\n","time = 350.0, epoch 6, iter = 2600, loss = 1.682620171904564, 34.48605012893677 s per 100 iters\n","time = 350.0, epoch 6, iter = 2700, loss = 1.655122802257538, 34.770524740219116 s per 100 iters\n","time = 351.0, epoch 6, iter = 2800, loss = 1.659425791501999, 34.22960042953491 s per 100 iters\n","time = 351.0, epoch 6, iter = 2900, loss = 1.6508684754371643, 35.341506004333496 s per 100 iters\n","time = 352.0, epoch 6, iter = 3000, loss = 1.6618580621480943, 34.50656485557556 s per 100 iters\n","time = 353.0, epoch 6, iter = 3100, loss = 1.6794972276687623, 33.74215626716614 s per 100 iters\n","time = 353.0, epoch 6, iter = 3200, loss = 1.6774667805433274, 34.2726194858551 s per 100 iters\n","time = 354.0, epoch 6, iter = 3300, loss = 1.6667701798677443, 34.753567934036255 s per 100 iters\n","time = 354.0, epoch 6, iter = 3400, loss = 1.6665405964851379, 34.91927146911621 s per 100 iters\n","time = 355.0, epoch 6, iter = 3500, loss = 1.6683283585309983, 34.88078451156616 s per 100 iters\n","time = 355.0, epoch 6, iter = 3600, loss = 1.6853306102752685, 34.66009330749512 s per 100 iters\n","time = 356.0, epoch 6, iter = 3700, loss = 1.6640736383199692, 34.93909931182861 s per 100 iters\n","time = 357.0, epoch 6, iter = 3800, loss = 1.671240535378456, 34.366344690322876 s per 100 iters\n","time = 357.0, epoch 6, iter = 3900, loss = 1.6921644365787507, 35.189069747924805 s per 100 iters\n","time = 358.0, epoch 6, iter = 4000, loss = 1.6861187148094177, 35.28542423248291 s per 100 iters\n","time = 358.0, epoch 6, iter = 4100, loss = 1.6727659732103348, 33.87112617492676 s per 100 iters\n","time = 359.0, epoch 6, iter = 4200, loss = 1.665975226163864, 34.18745803833008 s per 100 iters\n","time = 359.0, epoch 6, iter = 4300, loss = 1.6792180186510086, 35.13085627555847 s per 100 iters\n","time = 360.0, epoch 6, iter = 4400, loss = 1.6889525443315505, 35.48999309539795 s per 100 iters\n","time = 361.0, epoch 6, iter = 4500, loss = 1.684811760187149, 35.01786255836487 s per 100 iters\n","time = 361.0, epoch 6, iter = 4600, loss = 1.6803199750185014, 35.25991106033325 s per 100 iters\n","time = 362.0, epoch 6, iter = 4700, loss = 1.6772101461887359, 35.162800312042236 s per 100 iters\n","time = 362.0, epoch 6, iter = 4800, loss = 1.6810358864068986, 34.70943856239319 s per 100 iters\n","time = 364.0, epoch 6, iter = 5000, loss = 1.6924120944738388, 34.4516658782959 s per 100 iters\n","time = 364.0, epoch 6, iter = 5100, loss = 1.6827914309501648, 34.769556760787964 s per 100 iters\n","time = 365.0, epoch 6, iter = 5200, loss = 1.665525372028351, 34.176950454711914 s per 100 iters\n","time = 365.0, epoch 6, iter = 5300, loss = 1.6921888536214829, 34.814367055892944 s per 100 iters\n","time = 366.0, epoch 6, iter = 5400, loss = 1.6956270349025726, 34.78422713279724 s per 100 iters\n","time = 366.0, epoch 6, iter = 5500, loss = 1.687020468711853, 35.19076943397522 s per 100 iters\n","time = 367.0, epoch 6, iter = 5600, loss = 1.686949875354767, 34.24235010147095 s per 100 iters\n","time = 368.0, epoch 6, iter = 5700, loss = 1.6948210912942887, 35.146241426467896 s per 100 iters\n","time = 368.0, epoch 6, iter = 5800, loss = 1.6651071900129317, 34.0320143699646 s per 100 iters\n","time = 369.0, epoch 6, iter = 5900, loss = 1.6972946804761886, 34.472471952438354 s per 100 iters\n","time = 369.0, epoch 6, iter = 6000, loss = 1.6915555238723754, 35.30468392372131 s per 100 iters\n","time = 370.0, epoch 6, iter = 6100, loss = 1.7015647011995316, 34.89742684364319 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 370.0, epoch 6, iter = 6200, loss = 1.6893373346328735, 34.878628730773926 s per 100 iters\n","time = 371.0, epoch 6, iter = 6300, loss = 1.695062484741211, 34.64528226852417 s per 100 iters\n","time = 372.0, epoch 6, iter = 6400, loss = 1.6921031332015992, 35.118080615997314 s per 100 iters\n","time = 372.0, epoch 6, iter = 6500, loss = 1.6972735494375228, 34.71407866477966 s per 100 iters\n","time = 373.0, epoch 6, iter = 6600, loss = 1.6823274296522142, 35.34619879722595 s per 100 iters\n","time = 373.0, epoch 6, iter = 6700, loss = 1.7008248472213745, 35.28157663345337 s per 100 iters\n","time = 374.0, epoch 6, iter = 6800, loss = 1.6683287084102632, 34.49692463874817 s per 100 iters\n","time = 375.0, epoch 6, iter = 6900, loss = 1.6925794064998627, 35.314276456832886 s per 100 iters\n","time = 375.0, epoch 6, iter = 7000, loss = 1.6844909065961837, 35.19099712371826 s per 100 iters\n","time = 376.0, epoch 6, iter = 7100, loss = 1.7082727944850922, 35.646387815475464 s per 100 iters\n","time = 376.0, epoch 6, iter = 7200, loss = 1.6761465072631836, 34.3967227935791 s per 100 iters\n","time = 377.0, epoch 6, iter = 7300, loss = 1.6916520017385483, 34.34814190864563 s per 100 iters\n","time = 377.0, epoch 6, iter = 7400, loss = 1.6955874174833299, 34.83347702026367 s per 100 iters\n","time = 378.0, epoch 6, iter = 7500, loss = 1.686903228163719, 34.00454258918762 s per 100 iters\n","time = 379.0, epoch 6, iter = 7600, loss = 1.6682528603076934, 34.08872175216675 s per 100 iters\n","time = 379.0, epoch 6, iter = 7700, loss = 1.702438902258873, 34.49915647506714 s per 100 iters\n","time = 380.0, epoch 6, iter = 7800, loss = 1.670470159649849, 34.011242389678955 s per 100 iters\n","time = 380.0, epoch 6, iter = 7900, loss = 1.701725697517395, 34.321840047836304 s per 100 iters\n","time = 381.0, epoch 6, iter = 8000, loss = 1.6787138217687607, 35.256672382354736 s per 100 iters\n","time = 381.0, epoch 6, iter = 8100, loss = 1.7124127995967866, 34.26662039756775 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 382.0, epoch 6, iter = 8200, loss = 1.6933697879314422, 34.45389795303345 s per 100 iters\n","time = 383.0, epoch 6, iter = 8300, loss = 1.7054598891735078, 35.2104389667511 s per 100 iters\n","time = 383.0, epoch 6, iter = 8400, loss = 1.6798093187808991, 34.19996905326843 s per 100 iters\n","time = 384.0, epoch 6, iter = 8500, loss = 1.695442982316017, 34.81176137924194 s per 100 iters\n","time = 384.0, epoch 6, iter = 8600, loss = 1.6986171531677245, 35.57693672180176 s per 100 iters\n","time = 385.0, epoch 6, iter = 8700, loss = 1.7012200880050659, 34.705934047698975 s per 100 iters\n","time = 386.0, epoch 6, iter = 8800, loss = 1.6913252705335617, 34.871060371398926 s per 100 iters\n","time = 386.0, epoch 6, iter = 8900, loss = 1.7045496934652329, 35.0535991191864 s per 100 iters\n","time = 387.0, epoch 6, iter = 9000, loss = 1.7314513444900512, 35.47149658203125 s per 100 iters\n","time = 387.0, epoch 6, iter = 9100, loss = 1.7043834125995636, 33.84986662864685 s per 100 iters\n","time = 388.0, epoch 6, iter = 9200, loss = 1.689830545783043, 34.682677030563354 s per 100 iters\n","time = 388.0, epoch 6, iter = 9300, loss = 1.7125340062379837, 34.603832960128784 s per 100 iters\n","time = 389.0, epoch 6, iter = 9400, loss = 1.679378599524498, 34.03266382217407 s per 100 iters\n","time = 390.0, epoch 6, iter = 9500, loss = 1.6989995539188385, 35.15577530860901 s per 100 iters\n","time = 390.0, epoch 6, iter = 9600, loss = 1.706108357310295, 35.18784141540527 s per 100 iters\n","time = 391.0, epoch 6, iter = 9700, loss = 1.7023492389917374, 34.79080677032471 s per 100 iters\n","time = 391.0, epoch 6, iter = 9800, loss = 1.7291015446186067, 34.525719165802 s per 100 iters\n","time = 392.0, epoch 6, iter = 9900, loss = 1.7062872511148452, 34.1221137046814 s per 100 iters\n","time = 392.0, epoch 6, iter = 10000, loss = 1.6901772207021712, 34.84351205825806 s per 100 iters\n","time = 393.0, epoch 6, iter = 10100, loss = 1.7141562068462373, 34.17883229255676 s per 100 iters\n","time = 394.0, epoch 6, iter = 10200, loss = 1.7048363721370696, 35.597256660461426 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 394.0, epoch 6, iter = 10300, loss = 1.7228643155097962, 35.34978413581848 s per 100 iters\n","time = 395.0, epoch 6, iter = 10400, loss = 1.693348678946495, 34.69805312156677 s per 100 iters\n","time = 395.0, epoch 6, iter = 10500, loss = 1.7052900981903076, 35.273810148239136 s per 100 iters\n","time = 396.0, epoch 6, iter = 10600, loss = 1.7053229320049286, 35.275543451309204 s per 100 iters\n","time = 397.0, epoch 6, iter = 10700, loss = 1.7147815763950347, 35.2310585975647 s per 100 iters\n","time = 397.0, epoch 6, iter = 10800, loss = 1.706168697476387, 34.38934898376465 s per 100 iters\n","time = 398.0, epoch 6, iter = 10900, loss = 1.7084672164916992, 34.407047510147095 s per 100 iters\n","time = 398.0, epoch 6, iter = 11000, loss = 1.7108687108755112, 35.76340985298157 s per 100 iters\n","time = 399.0, epoch 6, iter = 11100, loss = 1.720249518752098, 35.240715980529785 s per 100 iters\n","time = 399.0, epoch 6, iter = 11200, loss = 1.7060550737380982, 34.951979637145996 s per 100 iters\n","time = 400.0, epoch 6, iter = 11300, loss = 1.710667046904564, 34.45830178260803 s per 100 iters\n","time = 401.0, epoch 6, iter = 11400, loss = 1.6953196924924852, 34.66396999359131 s per 100 iters\n","time = 401.0, epoch 6, iter = 11500, loss = 1.7133158367872239, 35.35352110862732 s per 100 iters\n","time = 402.0, epoch 6, iter = 11600, loss = 1.7256642603874206, 34.778361082077026 s per 100 iters\n","time = 402.0, epoch 6, iter = 11700, loss = 1.7052272433042526, 34.640610218048096 s per 100 iters\n","time = 403.0, epoch 6, iter = 11800, loss = 1.735312044620514, 35.151347637176514 s per 100 iters\n","time = 404.0, epoch 6, iter = 11900, loss = 1.710570337176323, 35.32760286331177 s per 100 iters\n","time = 404.0, epoch 6, iter = 12000, loss = 1.703780135512352, 35.42608857154846 s per 100 iters\n","time = 405.0, epoch 6, iter = 12100, loss = 1.6880331176519394, 34.350526571273804 s per 100 iters\n","time = 405.0, epoch 6, iter = 12200, loss = 1.6960251867771148, 33.997944593429565 s per 100 iters\n","time = 406.0, epoch 6, iter = 12300, loss = 1.7102223932743073, 34.60590052604675 s per 100 iters\n","time = 406.0, epoch 6, iter = 12400, loss = 1.6818859964609145, 34.871068477630615 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 407.0, epoch 6, iter = 12500, loss = 1.6779326683282851, 34.26308584213257 s per 100 iters\n","time = 408.0, epoch 6, iter = 12600, loss = 1.7054449474811555, 34.18311882019043 s per 100 iters\n","time = 408.0, epoch 6, iter = 12700, loss = 1.6957081705331802, 35.327019453048706 s per 100 iters\n","time = 409.0, epoch 6, iter = 12800, loss = 1.7076302021741867, 34.96158742904663 s per 100 iters\n","time = 409.0, epoch 6, iter = 12900, loss = 1.7177383035421372, 35.7688205242157 s per 100 iters\n","time = 410.0, epoch 6, iter = 13000, loss = 1.7104192543029786, 35.17564940452576 s per 100 iters\n","time = 411.0, epoch 6, iter = 13100, loss = 1.6894836699962616, 33.68390512466431 s per 100 iters\n","time = 411.0, epoch 6, iter = 13200, loss = 1.7095331662893296, 34.56461548805237 s per 100 iters\n","time = 412.0, epoch 6, iter = 13300, loss = 1.6972552305459976, 33.7276930809021 s per 100 iters\n","time = 412.0, epoch 6, iter = 13400, loss = 1.7029968827962876, 34.177295207977295 s per 100 iters\n","time = 413.0, epoch 6, iter = 13500, loss = 1.7019226318597793, 34.595407009124756 s per 100 iters\n","time = 413.0, epoch 6, iter = 13600, loss = 1.7066720581054688, 35.4637725353241 s per 100 iters\n","time = 414.0, epoch 6, iter = 13700, loss = 1.7099460208415984, 34.89422821998596 s per 100 iters\n","time = 415.0, epoch 6, iter = 13800, loss = 1.7173801988363266, 33.95077347755432 s per 100 iters\n","time = 415.0, epoch 6, iter = 13900, loss = 1.7016626852750778, 34.3112678527832 s per 100 iters\n","time = 416.0, epoch 6, iter = 14000, loss = 1.7031138402223587, 34.147867918014526 s per 100 iters\n","time = 416.0, epoch 6, iter = 14100, loss = 1.7063449972867966, 35.856921911239624 s per 100 iters\n","time = 417.0, epoch 6, iter = 14200, loss = 1.7064087724685668, 34.770916223526 s per 100 iters\n","time = 417.0, epoch 6, iter = 14300, loss = 1.7099690276384354, 35.27227973937988 s per 100 iters\n","--- Balidazioa ---\n","22.564692735671997 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina zer zen hura ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da arraroa ￭?', '｟C colin berriro geratu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehenbiziko aldiz ￭, ｟C siziliako bazterretan barneratu zenetik ￭, eta nesken xarma ￭, aita ｟C pirrone eta ｟C don ｟C fabrizioren portaerak konbentzitu zuten ｟C donnafugatako jauregia ez zela ｟C capraro bandiduaren antrotroa eta seguraski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza eta exekutiboaren beste ofizialak ￭, zigor eta zigor ￭, zeinetatik bakoitza eta subiranotasunaren sedeari dagozkionak ￭, bere eginkizuna betearazteko ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten duten nerbioak ￭; aberastasun guztiak ￭, aberatsen indarra ￭, herria ￭, edo boterea ￭, boterea ￭, boterea ￭, boterea ￭, gauza guztientzat ￭, boterea da ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura ￭, hain zuzen ere ￭, beren ideal ￭, eta agian beste inor ez ￭, gaur egun errepresentatzen dute ￭, berek dira haren sormen izpiritualuena ￭, bere gudari eta esploratzaileen tropa aurreratuenena ￭, bere sedukzio-forma ezin gozoago ￭, delikatua ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 11.114986535811779\n","7.877380847930908 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C oso musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvette istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendeku bila etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin hitz egin nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu inporta ￭?', '｟C eta argazkia erakutsi diot 1960an eta bere semea 1940ko uniformean ￭.', '｟C orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C zoaz lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C seguru ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.138659502955164\n","BLEU puntuazioa (biak): 14.599101777709302\n","time = 419.0, epoch 7, iter = 100, loss = 1.5762139940261841, 36.1911518573761 s per 100 iters\n","time = 419.0, epoch 7, iter = 200, loss = 1.5783833587169647, 34.89445972442627 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 420.0, epoch 7, iter = 300, loss = 1.5568665158748627, 34.64583706855774 s per 100 iters\n","time = 421.0, epoch 7, iter = 400, loss = 1.5749131566286088, 34.8409526348114 s per 100 iters\n","time = 421.0, epoch 7, iter = 500, loss = 1.5722003179788588, 35.00336480140686 s per 100 iters\n","time = 422.0, epoch 7, iter = 600, loss = 1.5818539142608643, 34.13525390625 s per 100 iters\n","time = 422.0, epoch 7, iter = 700, loss = 1.5821187311410905, 35.33500289916992 s per 100 iters\n","time = 423.0, epoch 7, iter = 800, loss = 1.578783051967621, 34.98002362251282 s per 100 iters\n","time = 423.0, epoch 7, iter = 900, loss = 1.59336432158947, 34.759215116500854 s per 100 iters\n","time = 424.0, epoch 7, iter = 1000, loss = 1.5992864954471588, 35.59387683868408 s per 100 iters\n","time = 425.0, epoch 7, iter = 1100, loss = 1.5893085610866546, 34.31023645401001 s per 100 iters\n","time = 425.0, epoch 7, iter = 1200, loss = 1.6101638942956924, 35.4621684551239 s per 100 iters\n","time = 426.0, epoch 7, iter = 1300, loss = 1.5760669946670531, 34.816879987716675 s per 100 iters\n","time = 426.0, epoch 7, iter = 1400, loss = 1.6014256221055985, 35.29767107963562 s per 100 iters\n","time = 427.0, epoch 7, iter = 1500, loss = 1.5834078884124756, 34.29673528671265 s per 100 iters\n","time = 428.0, epoch 7, iter = 1600, loss = 1.5711349320411683, 35.08376431465149 s per 100 iters\n","time = 428.0, epoch 7, iter = 1700, loss = 1.6091583222150803, 35.008944272994995 s per 100 iters\n","time = 429.0, epoch 7, iter = 1800, loss = 1.6171542030572892, 34.75564622879028 s per 100 iters\n","time = 429.0, epoch 7, iter = 1900, loss = 1.5937824958562852, 34.380353927612305 s per 100 iters\n","time = 430.0, epoch 7, iter = 2000, loss = 1.6226130026578902, 35.07631325721741 s per 100 iters\n","time = 430.0, epoch 7, iter = 2100, loss = 1.6113311266899109, 35.4698371887207 s per 100 iters\n","time = 431.0, epoch 7, iter = 2200, loss = 1.60422318816185, 35.2515709400177 s per 100 iters\n","time = 432.0, epoch 7, iter = 2300, loss = 1.5854791367053986, 34.58629751205444 s per 100 iters\n","time = 432.0, epoch 7, iter = 2400, loss = 1.6030299919843674, 35.09747624397278 s per 100 iters\n","time = 433.0, epoch 7, iter = 2500, loss = 1.6034287512302399, 34.439966917037964 s per 100 iters\n","time = 433.0, epoch 7, iter = 2600, loss = 1.61488112449646, 35.1629524230957 s per 100 iters\n","time = 434.0, epoch 7, iter = 2700, loss = 1.597054785490036, 35.79264712333679 s per 100 iters\n","time = 434.0, epoch 7, iter = 2800, loss = 1.5881999450922013, 34.06952619552612 s per 100 iters\n","time = 435.0, epoch 7, iter = 2900, loss = 1.5952415251731873, 34.6231951713562 s per 100 iters\n","time = 436.0, epoch 7, iter = 3000, loss = 1.6378270649909974, 34.93284726142883 s per 100 iters\n","time = 436.0, epoch 7, iter = 3100, loss = 1.6288018661737442, 36.02737736701965 s per 100 iters\n","time = 437.0, epoch 7, iter = 3200, loss = 1.621070802807808, 35.703675508499146 s per 100 iters\n","time = 437.0, epoch 7, iter = 3300, loss = 1.6114688265323638, 34.62669610977173 s per 100 iters\n","time = 438.0, epoch 7, iter = 3400, loss = 1.6216356498003006, 35.71443486213684 s per 100 iters\n","time = 439.0, epoch 7, iter = 3500, loss = 1.611481813788414, 35.30834174156189 s per 100 iters\n","time = 439.0, epoch 7, iter = 3600, loss = 1.6079823940992355, 35.523431062698364 s per 100 iters\n","time = 440.0, epoch 7, iter = 3700, loss = 1.5855047994852065, 35.06135296821594 s per 100 iters\n","time = 440.0, epoch 7, iter = 3800, loss = 1.6075652527809143, 34.5074508190155 s per 100 iters\n","time = 441.0, epoch 7, iter = 3900, loss = 1.6095557844638824, 34.602707862854004 s per 100 iters\n","time = 442.0, epoch 7, iter = 4000, loss = 1.627853155732155, 36.01144099235535 s per 100 iters\n","time = 442.0, epoch 7, iter = 4100, loss = 1.6261772269010544, 35.30348300933838 s per 100 iters\n","time = 443.0, epoch 7, iter = 4200, loss = 1.6372641849517822, 36.09125113487244 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 443.0, epoch 7, iter = 4300, loss = 1.6034220385551452, 35.394843101501465 s per 100 iters\n","time = 444.0, epoch 7, iter = 4400, loss = 1.6021547508239746, 34.3267183303833 s per 100 iters\n","time = 444.0, epoch 7, iter = 4500, loss = 1.6151589035987854, 35.52171564102173 s per 100 iters\n","time = 445.0, epoch 7, iter = 4600, loss = 1.6148670440912247, 34.089292764663696 s per 100 iters\n","time = 446.0, epoch 7, iter = 4700, loss = 1.625490050315857, 34.46748232841492 s per 100 iters\n","time = 446.0, epoch 7, iter = 4800, loss = 1.6101917576789857, 34.64367127418518 s per 100 iters\n","time = 447.0, epoch 7, iter = 4900, loss = 1.621584383249283, 35.0455846786499 s per 100 iters\n","time = 447.0, epoch 7, iter = 5000, loss = 1.6355183768272399, 35.46921992301941 s per 100 iters\n","time = 448.0, epoch 7, iter = 5100, loss = 1.6387819623947144, 34.84698438644409 s per 100 iters\n","time = 449.0, epoch 7, iter = 5200, loss = 1.620513123869896, 34.845354080200195 s per 100 iters\n","time = 449.0, epoch 7, iter = 5300, loss = 1.6166711163520813, 34.55797028541565 s per 100 iters\n","time = 450.0, epoch 7, iter = 5400, loss = 1.6485236781835555, 34.96162486076355 s per 100 iters\n","time = 450.0, epoch 7, iter = 5500, loss = 1.6234233689308166, 34.673663854599 s per 100 iters\n","time = 451.0, epoch 7, iter = 5600, loss = 1.6225930893421172, 34.53176689147949 s per 100 iters\n","time = 451.0, epoch 7, iter = 5700, loss = 1.629942524433136, 34.94766664505005 s per 100 iters\n","time = 452.0, epoch 7, iter = 5800, loss = 1.6259012132883073, 34.10610890388489 s per 100 iters\n","time = 453.0, epoch 7, iter = 5900, loss = 1.6338317155838014, 35.026296615600586 s per 100 iters\n","time = 453.0, epoch 7, iter = 6000, loss = 1.6059210550785066, 34.28517270088196 s per 100 iters\n","time = 454.0, epoch 7, iter = 6100, loss = 1.6450436896085738, 34.878645181655884 s per 100 iters\n","time = 454.0, epoch 7, iter = 6200, loss = 1.6522889471054076, 35.567476749420166 s per 100 iters\n","time = 455.0, epoch 7, iter = 6300, loss = 1.630858126282692, 35.02068066596985 s per 100 iters\n","time = 456.0, epoch 7, iter = 6400, loss = 1.6275574153661727, 36.053876876831055 s per 100 iters\n","time = 456.0, epoch 7, iter = 6500, loss = 1.6366492146253586, 34.09994196891785 s per 100 iters\n","time = 457.0, epoch 7, iter = 6600, loss = 1.6517665535211563, 34.829081773757935 s per 100 iters\n","time = 457.0, epoch 7, iter = 6700, loss = 1.6373562568426132, 36.129761934280396 s per 100 iters\n","time = 458.0, epoch 7, iter = 6800, loss = 1.630207249522209, 34.46666669845581 s per 100 iters\n","time = 458.0, epoch 7, iter = 6900, loss = 1.6314244270324707, 35.0047333240509 s per 100 iters\n","time = 459.0, epoch 7, iter = 7000, loss = 1.625398822426796, 34.38085961341858 s per 100 iters\n","time = 460.0, epoch 7, iter = 7100, loss = 1.615995621085167, 35.0282986164093 s per 100 iters\n","time = 460.0, epoch 7, iter = 7200, loss = 1.6395400315523148, 34.28100657463074 s per 100 iters\n","time = 461.0, epoch 7, iter = 7300, loss = 1.613109045624733, 35.40401864051819 s per 100 iters\n","time = 461.0, epoch 7, iter = 7400, loss = 1.6321056634187698, 34.85447025299072 s per 100 iters\n","time = 462.0, epoch 7, iter = 7500, loss = 1.6289513075351716, 35.039944648742676 s per 100 iters\n","time = 462.0, epoch 7, iter = 7600, loss = 1.6385645270347595, 34.902806520462036 s per 100 iters\n","time = 463.0, epoch 7, iter = 7700, loss = 1.6381531411409378, 34.169018268585205 s per 100 iters\n","time = 464.0, epoch 7, iter = 7800, loss = 1.6253573125600815, 34.59302473068237 s per 100 iters\n","time = 464.0, epoch 7, iter = 7900, loss = 1.6321258932352065, 34.691681146621704 s per 100 iters\n","time = 465.0, epoch 7, iter = 8000, loss = 1.6502581751346588, 35.137256145477295 s per 100 iters\n","time = 465.0, epoch 7, iter = 8100, loss = 1.6400906014442445, 33.546027421951294 s per 100 iters\n","time = 466.0, epoch 7, iter = 8200, loss = 1.622584453225136, 33.86010766029358 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 467.0, epoch 7, iter = 8300, loss = 1.6564751988649369, 34.92262530326843 s per 100 iters\n","time = 467.0, epoch 7, iter = 8400, loss = 1.6365334939956666, 34.74188280105591 s per 100 iters\n","time = 468.0, epoch 7, iter = 8500, loss = 1.6334492379426957, 34.297014474868774 s per 100 iters\n","time = 468.0, epoch 7, iter = 8600, loss = 1.662838683128357, 35.95288825035095 s per 100 iters\n","time = 469.0, epoch 7, iter = 8700, loss = 1.6370619815587997, 34.99741196632385 s per 100 iters\n","time = 469.0, epoch 7, iter = 8800, loss = 1.6448285418748856, 34.799203634262085 s per 100 iters\n","time = 470.0, epoch 7, iter = 8900, loss = 1.6502730929851532, 34.75486731529236 s per 100 iters\n","time = 471.0, epoch 7, iter = 9000, loss = 1.6358442962169648, 34.14252758026123 s per 100 iters\n","time = 471.0, epoch 7, iter = 9100, loss = 1.63395248234272, 33.77676558494568 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 472.0, epoch 7, iter = 9200, loss = 1.6413424855470657, 33.698763608932495 s per 100 iters\n","time = 472.0, epoch 7, iter = 9300, loss = 1.612993710041046, 35.217336893081665 s per 100 iters\n","time = 473.0, epoch 7, iter = 9400, loss = 1.6465898668766021, 34.296974182128906 s per 100 iters\n","time = 473.0, epoch 7, iter = 9500, loss = 1.6515374958515168, 35.060866832733154 s per 100 iters\n","time = 474.0, epoch 7, iter = 9600, loss = 1.6516611897945404, 34.31260347366333 s per 100 iters\n","time = 475.0, epoch 7, iter = 9700, loss = 1.6467458802461623, 35.29210615158081 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-70c91888ae3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mentrenatu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-3280eebef4ed>\u001b[0m in \u001b[0;36mentrenatu\u001b[0;34m(hasi_epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 818.00 MiB (GPU 0; 14.73 GiB total capacity; 11.32 GiB already allocated; 677.88 MiB free; 13.29 GiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f7bb55ec536 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1cf1e (0x7f7bb5835f1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1df9e (0x7f7bb5836f9e in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10_cuda.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x135 (0x7f7bb83dd475 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0xf8135b (0x7f7bb69c935b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xfcac47 (0x7f7bb6a12c47 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0x1073c49 (0x7f7bee571c49 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0x1073f87 (0x7f7bee571f87 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xe1ff1e (0x7f7bee31df1e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x9e0 (0x7f7bee324810 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1132be1 (0x7f7bee630be1 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1185ee3 (0x7f7bee683ee3 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x28c2f52 (0x7f7bb830af52 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #13: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xb9 (0x7f7bb831f969 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #14: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x99 (0x7f7bb830b6e9 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #15: <unknown function> + 0xf8bfe0 (0x7f7bb69d3fe0 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cuda.so)\nframe #16: <unknown function> + 0x10c4396 (0x7f7bee5c2396 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #17: <unknown function> + 0x2ca977c (0x7f7bf01a777c in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #18: <unknown function> + 0x10c4396 (0x7f7bee5c2396 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #19: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1c9 (0x7f7befda3859 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x2d89705 (0x7f7bf0287705 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #21: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f7bf0284a03 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f7bf02857e2 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #23: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f7bf027de59 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f7bfcbc5488 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\nframe #25: <unknown function> + 0xbd6df (0x7f7c20e766df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #26: <unknown function> + 0x76db (0x7f7c21f586db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #27: clone + 0x3f (0x7f7c2229188f in /lib/x86_64-linux-gnu/libc.so.6)\n"]}]},{"cell_type":"code","metadata":{"id":"nY-8OUAt35SJ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hB6-rIl235El","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ea9ec629-69bf-42d8-9a3c-24f3c1fedcc9"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/origetaos2-6.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu(7)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 7, iter = 100, loss = 1.5896439117193222, 34.18616533279419 s per 100 iters\n","time = 1.0, epoch 7, iter = 200, loss = 1.5699071455001832, 32.63543891906738 s per 100 iters\n","time = 1.0, epoch 7, iter = 300, loss = 1.5812548637390136, 35.069244384765625 s per 100 iters\n","time = 2.0, epoch 7, iter = 400, loss = 1.5856702357530594, 33.85111331939697 s per 100 iters\n","time = 2.0, epoch 7, iter = 500, loss = 1.5729769426584244, 34.79100060462952 s per 100 iters\n","time = 3.0, epoch 7, iter = 600, loss = 1.580143837928772, 35.35230541229248 s per 100 iters\n","time = 4.0, epoch 7, iter = 700, loss = 1.5842797529697419, 34.265310764312744 s per 100 iters\n","time = 4.0, epoch 7, iter = 800, loss = 1.5841820710897445, 33.82787203788757 s per 100 iters\n","time = 5.0, epoch 7, iter = 900, loss = 1.580748097896576, 34.228254079818726 s per 100 iters\n","time = 5.0, epoch 7, iter = 1000, loss = 1.5763005322217942, 34.44353413581848 s per 100 iters\n","time = 6.0, epoch 7, iter = 1100, loss = 1.597156919836998, 35.48771262168884 s per 100 iters\n","time = 6.0, epoch 7, iter = 1200, loss = 1.5993622082471848, 34.59531021118164 s per 100 iters\n","time = 7.0, epoch 7, iter = 1300, loss = 1.5847276324033737, 34.83439898490906 s per 100 iters\n","time = 8.0, epoch 7, iter = 1400, loss = 1.589492923617363, 33.726059675216675 s per 100 iters\n","time = 8.0, epoch 7, iter = 1500, loss = 1.582132774591446, 35.54016995429993 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 9.0, epoch 7, iter = 1600, loss = 1.589766519665718, 34.33907127380371 s per 100 iters\n","time = 9.0, epoch 7, iter = 1700, loss = 1.5925166356563567, 34.660335302352905 s per 100 iters\n","time = 10.0, epoch 7, iter = 1800, loss = 1.5936511105298996, 34.07561898231506 s per 100 iters\n","time = 10.0, epoch 7, iter = 1900, loss = 1.5782656794786454, 33.685805320739746 s per 100 iters\n","time = 11.0, epoch 7, iter = 2000, loss = 1.60765296459198, 34.8836624622345 s per 100 iters\n","time = 12.0, epoch 7, iter = 2100, loss = 1.605762094259262, 34.34974646568298 s per 100 iters\n","time = 12.0, epoch 7, iter = 2200, loss = 1.6114706307649613, 34.51733660697937 s per 100 iters\n","time = 13.0, epoch 7, iter = 2300, loss = 1.6137631726264954, 34.8283314704895 s per 100 iters\n","time = 13.0, epoch 7, iter = 2400, loss = 1.590831772685051, 34.076804637908936 s per 100 iters\n","time = 14.0, epoch 7, iter = 2500, loss = 1.6049418687820434, 34.367387771606445 s per 100 iters\n","time = 14.0, epoch 7, iter = 2600, loss = 1.6126190835237504, 34.2909574508667 s per 100 iters\n","time = 15.0, epoch 7, iter = 2700, loss = 1.6041372227668762, 34.48729157447815 s per 100 iters\n","time = 16.0, epoch 7, iter = 2800, loss = 1.6222354620695114, 34.41292715072632 s per 100 iters\n","time = 16.0, epoch 7, iter = 2900, loss = 1.6271204447746277, 33.60557413101196 s per 100 iters\n","time = 17.0, epoch 7, iter = 3000, loss = 1.6115819585323334, 34.59047174453735 s per 100 iters\n","time = 17.0, epoch 7, iter = 3100, loss = 1.5995176297426223, 35.454285621643066 s per 100 iters\n","time = 18.0, epoch 7, iter = 3200, loss = 1.6160141628980638, 35.20225667953491 s per 100 iters\n","time = 18.0, epoch 7, iter = 3300, loss = 1.6134106808900832, 34.72467374801636 s per 100 iters\n","time = 19.0, epoch 7, iter = 3400, loss = 1.6104025852680206, 34.56957268714905 s per 100 iters\n","time = 20.0, epoch 7, iter = 3500, loss = 1.6099096137285231, 34.242265462875366 s per 100 iters\n","time = 20.0, epoch 7, iter = 3600, loss = 1.6067590117454529, 34.93447685241699 s per 100 iters\n","time = 21.0, epoch 7, iter = 3700, loss = 1.6246119606494904, 33.9792697429657 s per 100 iters\n","time = 21.0, epoch 7, iter = 3800, loss = 1.626013017296791, 35.26363182067871 s per 100 iters\n","time = 22.0, epoch 7, iter = 3900, loss = 1.6074229741096497, 34.32154369354248 s per 100 iters\n","time = 23.0, epoch 7, iter = 4000, loss = 1.630789567232132, 35.51093888282776 s per 100 iters\n","time = 23.0, epoch 7, iter = 4100, loss = 1.6478958863019944, 34.62372064590454 s per 100 iters\n","time = 24.0, epoch 7, iter = 4200, loss = 1.620019502043724, 35.27462840080261 s per 100 iters\n","time = 24.0, epoch 7, iter = 4300, loss = 1.6097976207733153, 34.86395835876465 s per 100 iters\n","time = 25.0, epoch 7, iter = 4400, loss = 1.6426760536432266, 34.61250019073486 s per 100 iters\n","time = 25.0, epoch 7, iter = 4500, loss = 1.6419205683469773, 34.766037940979004 s per 100 iters\n","time = 26.0, epoch 7, iter = 4600, loss = 1.6437420505285263, 35.54607319831848 s per 100 iters\n","time = 27.0, epoch 7, iter = 4700, loss = 1.618413614630699, 35.24551272392273 s per 100 iters\n","time = 27.0, epoch 7, iter = 4800, loss = 1.625668762922287, 35.38991165161133 s per 100 iters\n","time = 28.0, epoch 7, iter = 4900, loss = 1.6372362911701202, 34.16427302360535 s per 100 iters\n","time = 28.0, epoch 7, iter = 5000, loss = 1.62569593667984, 34.72300457954407 s per 100 iters\n","time = 29.0, epoch 7, iter = 5100, loss = 1.6093837344646453, 35.83733081817627 s per 100 iters\n","time = 29.0, epoch 7, iter = 5200, loss = 1.6171935027837754, 34.45865082740784 s per 100 iters\n","time = 30.0, epoch 7, iter = 5300, loss = 1.616507324576378, 35.00062155723572 s per 100 iters\n","time = 31.0, epoch 7, iter = 5400, loss = 1.629300822019577, 34.724064111709595 s per 100 iters\n","time = 31.0, epoch 7, iter = 5500, loss = 1.6425230032205582, 34.97314238548279 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 32.0, epoch 7, iter = 5600, loss = 1.6067356723546982, 34.60753059387207 s per 100 iters\n","time = 32.0, epoch 7, iter = 5700, loss = 1.618637113571167, 34.64735960960388 s per 100 iters\n","time = 33.0, epoch 7, iter = 5800, loss = 1.6518992453813552, 35.42124819755554 s per 100 iters\n","time = 34.0, epoch 7, iter = 5900, loss = 1.6246114993095397, 35.18285512924194 s per 100 iters\n","time = 34.0, epoch 7, iter = 6000, loss = 1.6247782498598098, 35.989181995391846 s per 100 iters\n","time = 35.0, epoch 7, iter = 6100, loss = 1.632343538403511, 35.292083978652954 s per 100 iters\n","time = 35.0, epoch 7, iter = 6200, loss = 1.6563820141553878, 35.666000843048096 s per 100 iters\n","time = 36.0, epoch 7, iter = 6300, loss = 1.6401485925912858, 34.03538966178894 s per 100 iters\n","time = 36.0, epoch 7, iter = 6400, loss = 1.6146752375364304, 34.265743017196655 s per 100 iters\n","time = 37.0, epoch 7, iter = 6500, loss = 1.6197040086984635, 34.62656784057617 s per 100 iters\n","time = 38.0, epoch 7, iter = 6600, loss = 1.6036050510406494, 34.75694417953491 s per 100 iters\n","time = 38.0, epoch 7, iter = 6700, loss = 1.6079571568965911, 33.783844232559204 s per 100 iters\n","time = 39.0, epoch 7, iter = 6800, loss = 1.6478191089630128, 33.786574840545654 s per 100 iters\n","time = 39.0, epoch 7, iter = 6900, loss = 1.6424853587150574, 34.474205493927 s per 100 iters\n","time = 40.0, epoch 7, iter = 7000, loss = 1.6699946761131286, 34.608885288238525 s per 100 iters\n","time = 40.0, epoch 7, iter = 7100, loss = 1.6319063758850099, 33.925753355026245 s per 100 iters\n","time = 41.0, epoch 7, iter = 7200, loss = 1.6282433676719665, 34.122074365615845 s per 100 iters\n","time = 42.0, epoch 7, iter = 7300, loss = 1.6378432154655456, 34.452627420425415 s per 100 iters\n","time = 42.0, epoch 7, iter = 7400, loss = 1.6542384546995164, 35.02193593978882 s per 100 iters\n","time = 43.0, epoch 7, iter = 7500, loss = 1.6437897372245789, 34.29507780075073 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 43.0, epoch 7, iter = 7600, loss = 1.6501828628778457, 34.93613004684448 s per 100 iters\n","time = 44.0, epoch 7, iter = 7700, loss = 1.6344372308254242, 34.53049182891846 s per 100 iters\n","time = 45.0, epoch 7, iter = 7800, loss = 1.6300733429193497, 35.086650371551514 s per 100 iters\n","time = 45.0, epoch 7, iter = 7900, loss = 1.6387951290607452, 35.984485387802124 s per 100 iters\n","time = 46.0, epoch 7, iter = 8000, loss = 1.64935671210289, 34.13794660568237 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 46.0, epoch 7, iter = 8100, loss = 1.651286039352417, 35.26141142845154 s per 100 iters\n","time = 47.0, epoch 7, iter = 8200, loss = 1.626950092315674, 34.382601499557495 s per 100 iters\n","time = 47.0, epoch 7, iter = 8300, loss = 1.6474127250909805, 35.45753026008606 s per 100 iters\n","time = 48.0, epoch 7, iter = 8400, loss = 1.6531818145513535, 35.154950857162476 s per 100 iters\n","time = 49.0, epoch 7, iter = 8500, loss = 1.634046585559845, 34.18175435066223 s per 100 iters\n","time = 49.0, epoch 7, iter = 8600, loss = 1.6465915995836258, 34.65725898742676 s per 100 iters\n","time = 50.0, epoch 7, iter = 8700, loss = 1.6501585286855698, 35.65308856964111 s per 100 iters\n","time = 50.0, epoch 7, iter = 8800, loss = 1.6640275168418883, 35.63756966590881 s per 100 iters\n","time = 51.0, epoch 7, iter = 8900, loss = 1.6404218620061874, 35.66457200050354 s per 100 iters\n","time = 52.0, epoch 7, iter = 9000, loss = 1.6360041117668152, 33.77250647544861 s per 100 iters\n","time = 52.0, epoch 7, iter = 9100, loss = 1.6549116778373718, 34.740214824676514 s per 100 iters\n","time = 53.0, epoch 7, iter = 9200, loss = 1.6424371069669723, 33.810826539993286 s per 100 iters\n","time = 53.0, epoch 7, iter = 9300, loss = 1.656403613090515, 35.83375549316406 s per 100 iters\n","time = 54.0, epoch 7, iter = 9400, loss = 1.6651746016740798, 35.12509059906006 s per 100 iters\n","time = 54.0, epoch 7, iter = 9500, loss = 1.6517005097866058, 34.78918099403381 s per 100 iters\n","time = 55.0, epoch 7, iter = 9600, loss = 1.6392214280366897, 34.66527223587036 s per 100 iters\n","time = 56.0, epoch 7, iter = 9700, loss = 1.6571822035312653, 33.96379041671753 s per 100 iters\n","time = 56.0, epoch 7, iter = 9800, loss = 1.6512098079919815, 34.982030391693115 s per 100 iters\n","time = 57.0, epoch 7, iter = 9900, loss = 1.6333623790740968, 33.910528898239136 s per 100 iters\n","time = 57.0, epoch 7, iter = 10000, loss = 1.6333373445272446, 33.437878370285034 s per 100 iters\n","time = 58.0, epoch 7, iter = 10100, loss = 1.6632565546035767, 34.41094636917114 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 58.0, epoch 7, iter = 10200, loss = 1.6698244547843932, 35.22474527359009 s per 100 iters\n","time = 59.0, epoch 7, iter = 10300, loss = 1.6389672058820723, 34.33539819717407 s per 100 iters\n","time = 60.0, epoch 7, iter = 10400, loss = 1.647861903309822, 34.99190044403076 s per 100 iters\n","time = 60.0, epoch 7, iter = 10500, loss = 1.641916822195053, 34.85127902030945 s per 100 iters\n","time = 61.0, epoch 7, iter = 10600, loss = 1.662343407869339, 34.51447081565857 s per 100 iters\n","time = 61.0, epoch 7, iter = 10700, loss = 1.6379432666301728, 34.58437418937683 s per 100 iters\n","time = 62.0, epoch 7, iter = 10800, loss = 1.6559299045801164, 34.89566969871521 s per 100 iters\n","time = 62.0, epoch 7, iter = 10900, loss = 1.625282194018364, 33.94036626815796 s per 100 iters\n","time = 63.0, epoch 7, iter = 11000, loss = 1.6521946740150453, 35.45424222946167 s per 100 iters\n","time = 64.0, epoch 7, iter = 11100, loss = 1.6492707437276841, 34.70100498199463 s per 100 iters\n","time = 64.0, epoch 7, iter = 11200, loss = 1.6541275435686111, 34.03075098991394 s per 100 iters\n","time = 65.0, epoch 7, iter = 11300, loss = 1.6492114835977554, 35.13651990890503 s per 100 iters\n","time = 65.0, epoch 7, iter = 11400, loss = 1.6465826731920243, 33.75596570968628 s per 100 iters\n","time = 66.0, epoch 7, iter = 11500, loss = 1.6415280520915985, 34.323593854904175 s per 100 iters\n","time = 67.0, epoch 7, iter = 11600, loss = 1.6446237117052078, 34.199742794036865 s per 100 iters\n","time = 67.0, epoch 7, iter = 11700, loss = 1.66942872941494, 34.990453481674194 s per 100 iters\n","time = 68.0, epoch 7, iter = 11800, loss = 1.6552412581443787, 35.041001319885254 s per 100 iters\n","time = 68.0, epoch 7, iter = 11900, loss = 1.6659352296590806, 35.86516451835632 s per 100 iters\n","time = 69.0, epoch 7, iter = 12000, loss = 1.6434925174713135, 35.39293098449707 s per 100 iters\n","time = 69.0, epoch 7, iter = 12100, loss = 1.6322507417201997, 34.448182106018066 s per 100 iters\n","time = 70.0, epoch 7, iter = 12200, loss = 1.6487951093912125, 34.71450471878052 s per 100 iters\n","time = 71.0, epoch 7, iter = 12300, loss = 1.6576286417245865, 34.870773792266846 s per 100 iters\n","time = 71.0, epoch 7, iter = 12400, loss = 1.6259592539072036, 34.17531681060791 s per 100 iters\n","time = 72.0, epoch 7, iter = 12500, loss = 1.6478195387125014, 33.80292105674744 s per 100 iters\n","time = 72.0, epoch 7, iter = 12600, loss = 1.6640763199329376, 34.63220429420471 s per 100 iters\n","time = 73.0, epoch 7, iter = 12700, loss = 1.6465394926071166, 34.126805782318115 s per 100 iters\n","time = 73.0, epoch 7, iter = 12800, loss = 1.6382932418584824, 35.15297055244446 s per 100 iters\n","time = 74.0, epoch 7, iter = 12900, loss = 1.6665940421819687, 34.67790246009827 s per 100 iters\n","time = 75.0, epoch 7, iter = 13000, loss = 1.6663058257102967, 35.03539776802063 s per 100 iters\n","time = 75.0, epoch 7, iter = 13100, loss = 1.6426054072380065, 33.89684319496155 s per 100 iters\n","time = 76.0, epoch 7, iter = 13200, loss = 1.6597666591405869, 33.553343296051025 s per 100 iters\n","time = 76.0, epoch 7, iter = 13300, loss = 1.6586699438095094, 34.64743185043335 s per 100 iters\n","time = 77.0, epoch 7, iter = 13400, loss = 1.674662465453148, 35.575138330459595 s per 100 iters\n","time = 77.0, epoch 7, iter = 13500, loss = 1.658648246526718, 33.927398920059204 s per 100 iters\n","time = 78.0, epoch 7, iter = 13600, loss = 1.6696021604537963, 34.94161248207092 s per 100 iters\n","time = 79.0, epoch 7, iter = 13700, loss = 1.6552356988191606, 34.2481644153595 s per 100 iters\n","time = 79.0, epoch 7, iter = 13800, loss = 1.6651576846837997, 35.06333351135254 s per 100 iters\n","time = 80.0, epoch 7, iter = 13900, loss = 1.6695261693000794, 34.32850980758667 s per 100 iters\n","time = 80.0, epoch 7, iter = 14000, loss = 1.657189571261406, 34.563873291015625 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 81.0, epoch 7, iter = 14100, loss = 1.672288365960121, 35.411985874176025 s per 100 iters\n","time = 82.0, epoch 7, iter = 14200, loss = 1.6865043169260026, 35.50089716911316 s per 100 iters\n","time = 82.0, epoch 7, iter = 14300, loss = 1.6603157365322112, 34.82333850860596 s per 100 iters\n","--- Balidazioa ---\n","26.182192087173462 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C beranduegi da ordea ￭:', '｟C baina zer zen hura ￭?', '｟B rosanna spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colin berriro gelditu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ￭, ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirrone ￭, eta ｟C don ｟C fabriziok egindako portaerak komentzitu zuen ｟C donnafugatako jauregia ez zela ｟C capraro bandidoaren antroa ￭, eta seguraski bizirik irtengo zenetik ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi dauzkat ￭.', 'magistratuak eta epailearen beste ofizialak ￭, eta exekutatiboak ￭, zigor artifizialak ￭; sariketa eta zigorra ￭, zeinen bidez subiranotasunaren eserleku eta kide bakoitza bere eginkizuna betetzeko mugitzen diren ￭, nerbioak dira gorputz naturalean gauza bera egiten duten nerbioak ￭; diru partikularrak eta aberastasun partikularrak ￭, populusen indarra ￭, herria ￭, herria ￭, edo xede artifizialak ￭, gauza horiek guztiak dira ￭.', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideala da ￭, eta agian beste inor ere ez ￭, gaur bertan irudikatzen dute ￭, berek ere bere burua ￭, bere sortzetiko izpiritualena ￭, bere gudari eta eskaeratan aurreratuenak ￭, bere erakarmenik fin eta liluragarriena ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C derwatt-en kasuan eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 11.894317942110014\n","7.942505359649658 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvette istorio hori ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku hartzeko etorria zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C argazkia erakutsi diot ￭, 1960an eta bere semea 1940ko uniformean ￭.', '｟C eta orduan dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C seguru ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.931736250880036\n","BLEU puntuazioa (biak): 15.364405061741056\n","time = 84.0, epoch 8, iter = 100, loss = 1.5379789274930955, 36.43964147567749 s per 100 iters\n","time = 84.0, epoch 8, iter = 200, loss = 1.5236474800109863, 34.25505971908569 s per 100 iters\n","time = 85.0, epoch 8, iter = 300, loss = 1.5196330267190934, 34.03429365158081 s per 100 iters\n","time = 85.0, epoch 8, iter = 400, loss = 1.5073046350479127, 34.22359609603882 s per 100 iters\n","time = 86.0, epoch 8, iter = 500, loss = 1.5136580526828767, 35.617106676101685 s per 100 iters\n","time = 86.0, epoch 8, iter = 600, loss = 1.5563226813077926, 36.16641426086426 s per 100 iters\n","time = 87.0, epoch 8, iter = 700, loss = 1.5357156819105149, 35.22159028053284 s per 100 iters\n","time = 88.0, epoch 8, iter = 800, loss = 1.524981968998909, 35.33491492271423 s per 100 iters\n","time = 88.0, epoch 8, iter = 900, loss = 1.5372937196493148, 35.48481607437134 s per 100 iters\n","time = 89.0, epoch 8, iter = 1000, loss = 1.5268672049045562, 34.68401026725769 s per 100 iters\n","time = 89.0, epoch 8, iter = 1100, loss = 1.524932193160057, 34.63075017929077 s per 100 iters\n","time = 90.0, epoch 8, iter = 1200, loss = 1.5311578530073167, 35.45651698112488 s per 100 iters\n","time = 91.0, epoch 8, iter = 1300, loss = 1.5205175495147705, 35.12230205535889 s per 100 iters\n","time = 91.0, epoch 8, iter = 1400, loss = 1.530673126578331, 34.81637787818909 s per 100 iters\n","time = 92.0, epoch 8, iter = 1500, loss = 1.5535032099485397, 35.342023611068726 s per 100 iters\n","time = 92.0, epoch 8, iter = 1600, loss = 1.5502792835235595, 34.92900371551514 s per 100 iters\n","time = 93.0, epoch 8, iter = 1700, loss = 1.5474586647748947, 35.085756063461304 s per 100 iters\n","time = 93.0, epoch 8, iter = 1800, loss = 1.538587394952774, 34.706645250320435 s per 100 iters\n","time = 94.0, epoch 8, iter = 1900, loss = 1.5199673283100128, 33.66189908981323 s per 100 iters\n","time = 95.0, epoch 8, iter = 2000, loss = 1.5756305748224257, 34.712756633758545 s per 100 iters\n","time = 95.0, epoch 8, iter = 2100, loss = 1.5385932874679566, 34.914129972457886 s per 100 iters\n","time = 96.0, epoch 8, iter = 2200, loss = 1.5295154237747193, 34.33102250099182 s per 100 iters\n","time = 96.0, epoch 8, iter = 2300, loss = 1.5570023953914642, 34.873517990112305 s per 100 iters\n","time = 97.0, epoch 8, iter = 2400, loss = 1.5421820622682572, 33.75197434425354 s per 100 iters\n","time = 98.0, epoch 8, iter = 2500, loss = 1.5448406159877777, 36.04446816444397 s per 100 iters\n","time = 98.0, epoch 8, iter = 2600, loss = 1.5544720584154128, 34.39480996131897 s per 100 iters\n","time = 99.0, epoch 8, iter = 2700, loss = 1.5462076860666274, 34.57020139694214 s per 100 iters\n","time = 99.0, epoch 8, iter = 2800, loss = 1.5416651433706283, 34.674834966659546 s per 100 iters\n","time = 100.0, epoch 8, iter = 2900, loss = 1.548962436914444, 34.503071308135986 s per 100 iters\n","time = 100.0, epoch 8, iter = 3000, loss = 1.5606801277399063, 34.84351396560669 s per 100 iters\n","time = 101.0, epoch 8, iter = 3100, loss = 1.5560117655992507, 34.4750440120697 s per 100 iters\n","time = 102.0, epoch 8, iter = 3200, loss = 1.5497958213090897, 34.072709798812866 s per 100 iters\n","time = 102.0, epoch 8, iter = 3300, loss = 1.5498988538980485, 34.485156536102295 s per 100 iters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sb6TvjfZiNJT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iN1ywwxi5QfK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594250103729,"user_tz":-120,"elapsed":9892772,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"f87f9376-4b96-431c-86a0-13976fa0548d"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/origetaos2-7.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu(8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 8, iter = 100, loss = 1.5246928930282593, 34.451682329177856 s per 100 iters\n","time = 1.0, epoch 8, iter = 200, loss = 1.5088815903663635, 34.192556381225586 s per 100 iters\n","time = 1.0, epoch 8, iter = 300, loss = 1.532218310236931, 32.31767678260803 s per 100 iters\n","time = 2.0, epoch 8, iter = 400, loss = 1.5259188783168793, 32.709121227264404 s per 100 iters\n","time = 2.0, epoch 8, iter = 500, loss = 1.5340817111730576, 33.95073485374451 s per 100 iters\n","time = 3.0, epoch 8, iter = 600, loss = 1.5181268578767777, 34.10865545272827 s per 100 iters\n","time = 3.0, epoch 8, iter = 700, loss = 1.5337137830257417, 34.63194918632507 s per 100 iters\n","time = 4.0, epoch 8, iter = 800, loss = 1.5453230381011962, 33.63463234901428 s per 100 iters\n","time = 5.0, epoch 8, iter = 900, loss = 1.5722149103879928, 34.28828191757202 s per 100 iters\n","time = 5.0, epoch 8, iter = 1000, loss = 1.534862477183342, 33.48111701011658 s per 100 iters\n","time = 6.0, epoch 8, iter = 1100, loss = 1.541333515048027, 33.46427583694458 s per 100 iters\n","time = 6.0, epoch 8, iter = 1200, loss = 1.5568287593126298, 34.84832501411438 s per 100 iters\n","time = 7.0, epoch 8, iter = 1300, loss = 1.5242599660158158, 32.67833352088928 s per 100 iters\n","time = 7.0, epoch 8, iter = 1400, loss = 1.5321448969841003, 32.943649768829346 s per 100 iters\n","time = 8.0, epoch 8, iter = 1500, loss = 1.5328924936056136, 33.71431064605713 s per 100 iters\n","time = 8.0, epoch 8, iter = 1600, loss = 1.53151517868042, 34.18658423423767 s per 100 iters\n","time = 9.0, epoch 8, iter = 1700, loss = 1.5715527147054673, 34.065836668014526 s per 100 iters\n","time = 10.0, epoch 8, iter = 1800, loss = 1.5413297021389007, 34.94762849807739 s per 100 iters\n","time = 10.0, epoch 8, iter = 1900, loss = 1.5440402334928514, 33.822542667388916 s per 100 iters\n","time = 11.0, epoch 8, iter = 2000, loss = 1.529773787856102, 33.16113567352295 s per 100 iters\n","time = 11.0, epoch 8, iter = 2100, loss = 1.536149383187294, 33.44083595275879 s per 100 iters\n","time = 12.0, epoch 8, iter = 2200, loss = 1.5460978055000305, 34.1634886264801 s per 100 iters\n","time = 12.0, epoch 8, iter = 2300, loss = 1.539184374809265, 33.09671092033386 s per 100 iters\n","time = 13.0, epoch 8, iter = 2400, loss = 1.5654671221971512, 33.67892575263977 s per 100 iters\n","time = 14.0, epoch 8, iter = 2500, loss = 1.5701777213811874, 34.365681409835815 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 14.0, epoch 8, iter = 2600, loss = 1.5544510906934739, 33.68340277671814 s per 100 iters\n","time = 15.0, epoch 8, iter = 2700, loss = 1.5425844341516495, 33.498342514038086 s per 100 iters\n","time = 15.0, epoch 8, iter = 2800, loss = 1.5717571818828582, 35.043859243392944 s per 100 iters\n","time = 16.0, epoch 8, iter = 2900, loss = 1.556890001296997, 33.04978966712952 s per 100 iters\n","time = 16.0, epoch 8, iter = 3000, loss = 1.5685312414169312, 33.44797396659851 s per 100 iters\n","time = 17.0, epoch 8, iter = 3100, loss = 1.5634654062986373, 33.512694358825684 s per 100 iters\n","time = 18.0, epoch 8, iter = 3200, loss = 1.57743332862854, 34.53558921813965 s per 100 iters\n","time = 18.0, epoch 8, iter = 3300, loss = 1.5810651475191115, 33.917269229888916 s per 100 iters\n","time = 19.0, epoch 8, iter = 3400, loss = 1.5565073436498642, 33.06680488586426 s per 100 iters\n","time = 19.0, epoch 8, iter = 3500, loss = 1.5576112651824952, 33.03165793418884 s per 100 iters\n","time = 20.0, epoch 8, iter = 3600, loss = 1.5319174987077713, 33.293673276901245 s per 100 iters\n","time = 20.0, epoch 8, iter = 3700, loss = 1.5688572043180466, 33.690547466278076 s per 100 iters\n","time = 21.0, epoch 8, iter = 3800, loss = 1.5847547483444213, 33.62843441963196 s per 100 iters\n","time = 21.0, epoch 8, iter = 3900, loss = 1.5681931364536286, 33.56657648086548 s per 100 iters\n","time = 22.0, epoch 8, iter = 4000, loss = 1.5557080179452896, 33.65641927719116 s per 100 iters\n","time = 23.0, epoch 8, iter = 4100, loss = 1.5807916027307511, 34.19571924209595 s per 100 iters\n","time = 23.0, epoch 8, iter = 4200, loss = 1.5614045429229737, 33.75653600692749 s per 100 iters\n","time = 24.0, epoch 8, iter = 4300, loss = 1.59186537027359, 34.550527572631836 s per 100 iters\n","time = 24.0, epoch 8, iter = 4400, loss = 1.5722389030456543, 33.53635358810425 s per 100 iters\n","time = 25.0, epoch 8, iter = 4500, loss = 1.5417395776510239, 32.81642770767212 s per 100 iters\n","time = 25.0, epoch 8, iter = 4600, loss = 1.5648308342695236, 34.57024431228638 s per 100 iters\n","time = 26.0, epoch 8, iter = 4700, loss = 1.5779632067680358, 34.17837405204773 s per 100 iters\n","time = 27.0, epoch 8, iter = 4800, loss = 1.5651229649782181, 34.326627254486084 s per 100 iters\n","time = 27.0, epoch 8, iter = 4900, loss = 1.581821727156639, 33.513864278793335 s per 100 iters\n","time = 28.0, epoch 8, iter = 5000, loss = 1.585076506137848, 33.95617318153381 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 28.0, epoch 8, iter = 5100, loss = 1.6104202747344971, 33.339335680007935 s per 100 iters\n","time = 29.0, epoch 8, iter = 5200, loss = 1.589170933365822, 33.62758994102478 s per 100 iters\n","time = 29.0, epoch 8, iter = 5300, loss = 1.6005841702222825, 34.759811878204346 s per 100 iters\n","time = 30.0, epoch 8, iter = 5400, loss = 1.5410129857063293, 34.11129355430603 s per 100 iters\n","time = 30.0, epoch 8, iter = 5500, loss = 1.5829297715425492, 34.365506410598755 s per 100 iters\n","time = 31.0, epoch 8, iter = 5600, loss = 1.5884981971979142, 34.17446517944336 s per 100 iters\n","time = 32.0, epoch 8, iter = 5700, loss = 1.5614206010103227, 33.2616708278656 s per 100 iters\n","time = 32.0, epoch 8, iter = 5800, loss = 1.5823377066850661, 32.565356492996216 s per 100 iters\n","time = 33.0, epoch 8, iter = 5900, loss = 1.5891415548324586, 34.3625602722168 s per 100 iters\n","time = 33.0, epoch 8, iter = 6000, loss = 1.5958457452058792, 33.7254798412323 s per 100 iters\n","time = 34.0, epoch 8, iter = 6100, loss = 1.5799861162900926, 33.57471990585327 s per 100 iters\n","time = 34.0, epoch 8, iter = 6200, loss = 1.5432894444465637, 34.17819857597351 s per 100 iters\n","time = 35.0, epoch 8, iter = 6300, loss = 1.5856472647190094, 33.46072959899902 s per 100 iters\n","time = 36.0, epoch 8, iter = 6400, loss = 1.60633336186409, 34.09055757522583 s per 100 iters\n","time = 36.0, epoch 8, iter = 6500, loss = 1.5882111263275147, 33.789337396621704 s per 100 iters\n","time = 37.0, epoch 8, iter = 6600, loss = 1.5698880463838578, 33.86648726463318 s per 100 iters\n","time = 37.0, epoch 8, iter = 6700, loss = 1.5926505130529405, 34.56050133705139 s per 100 iters\n","time = 38.0, epoch 8, iter = 6800, loss = 1.5938162088394165, 33.70723557472229 s per 100 iters\n","time = 38.0, epoch 8, iter = 6900, loss = 1.5846148473024368, 33.61814260482788 s per 100 iters\n","time = 39.0, epoch 8, iter = 7000, loss = 1.5641567313671112, 33.74614334106445 s per 100 iters\n","time = 39.0, epoch 8, iter = 7100, loss = 1.5913624995946885, 34.356497049331665 s per 100 iters\n","time = 40.0, epoch 8, iter = 7200, loss = 1.6050689601898194, 34.091002225875854 s per 100 iters\n","time = 41.0, epoch 8, iter = 7300, loss = 1.5926925736665725, 33.95689129829407 s per 100 iters\n","time = 41.0, epoch 8, iter = 7400, loss = 1.5872014892101287, 33.90989708900452 s per 100 iters\n","time = 42.0, epoch 8, iter = 7500, loss = 1.5990109556913377, 33.893221378326416 s per 100 iters\n","time = 42.0, epoch 8, iter = 7600, loss = 1.5750233554840087, 33.94044256210327 s per 100 iters\n","time = 43.0, epoch 8, iter = 7700, loss = 1.5870587635040283, 33.60905694961548 s per 100 iters\n","time = 43.0, epoch 8, iter = 7800, loss = 1.594931753873825, 34.15800619125366 s per 100 iters\n","time = 44.0, epoch 8, iter = 7900, loss = 1.6181533741950989, 34.589832067489624 s per 100 iters\n","time = 45.0, epoch 8, iter = 8000, loss = 1.5798827254772185, 32.721752643585205 s per 100 iters\n","time = 45.0, epoch 8, iter = 8100, loss = 1.6112508100271226, 34.17652606964111 s per 100 iters\n","time = 46.0, epoch 8, iter = 8200, loss = 1.5846854662895202, 34.4838764667511 s per 100 iters\n","time = 46.0, epoch 8, iter = 8300, loss = 1.6148536628484726, 33.50152850151062 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 47.0, epoch 8, iter = 8400, loss = 1.5820945024490356, 33.81815028190613 s per 100 iters\n","time = 47.0, epoch 8, iter = 8500, loss = 1.5915385806560516, 33.42444205284119 s per 100 iters\n","time = 48.0, epoch 8, iter = 8600, loss = 1.581003105044365, 33.984333992004395 s per 100 iters\n","time = 49.0, epoch 8, iter = 8700, loss = 1.5829879128932953, 33.39609336853027 s per 100 iters\n","time = 49.0, epoch 8, iter = 8800, loss = 1.5966835337877274, 33.10642457008362 s per 100 iters\n","time = 50.0, epoch 8, iter = 8900, loss = 1.5933024877309798, 34.11773681640625 s per 100 iters\n","time = 50.0, epoch 8, iter = 9000, loss = 1.5878177303075791, 33.724833488464355 s per 100 iters\n","time = 51.0, epoch 8, iter = 9100, loss = 1.5844780778884888, 34.431710720062256 s per 100 iters\n","time = 51.0, epoch 8, iter = 9200, loss = 1.602811103463173, 33.42056894302368 s per 100 iters\n","time = 52.0, epoch 8, iter = 9300, loss = 1.5994883644580842, 33.52955746650696 s per 100 iters\n","time = 52.0, epoch 8, iter = 9400, loss = 1.596348986029625, 34.21348428726196 s per 100 iters\n","time = 53.0, epoch 8, iter = 9500, loss = 1.629261936545372, 34.222084045410156 s per 100 iters\n","time = 54.0, epoch 8, iter = 9600, loss = 1.6040377485752106, 33.7095091342926 s per 100 iters\n","time = 54.0, epoch 8, iter = 9700, loss = 1.615096024274826, 33.10436654090881 s per 100 iters\n","time = 55.0, epoch 8, iter = 9800, loss = 1.5915325605869293, 32.87721300125122 s per 100 iters\n","time = 55.0, epoch 8, iter = 9900, loss = 1.6055939990282058, 33.65313410758972 s per 100 iters\n","time = 56.0, epoch 8, iter = 10000, loss = 1.5867419564723968, 33.17712044715881 s per 100 iters\n","time = 56.0, epoch 8, iter = 10100, loss = 1.6034902143478393, 33.653505086898804 s per 100 iters\n","time = 57.0, epoch 8, iter = 10200, loss = 1.5991402161121369, 33.607173204422 s per 100 iters\n","time = 58.0, epoch 8, iter = 10300, loss = 1.602004571557045, 34.23712086677551 s per 100 iters\n","time = 58.0, epoch 8, iter = 10400, loss = 1.6116514432430267, 32.99346995353699 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 59.0, epoch 8, iter = 10500, loss = 1.5758817929029465, 32.87379789352417 s per 100 iters\n","time = 59.0, epoch 8, iter = 10600, loss = 1.5825522714853286, 33.396750688552856 s per 100 iters\n","time = 60.0, epoch 8, iter = 10700, loss = 1.6037220788002013, 34.00084328651428 s per 100 iters\n","time = 60.0, epoch 8, iter = 10800, loss = 1.6207652401924133, 33.63132381439209 s per 100 iters\n","time = 61.0, epoch 8, iter = 10900, loss = 1.6109563952684403, 34.491015911102295 s per 100 iters\n","time = 61.0, epoch 8, iter = 11000, loss = 1.6109158474206924, 34.524051904678345 s per 100 iters\n","time = 62.0, epoch 8, iter = 11100, loss = 1.5924239373207092, 34.0931556224823 s per 100 iters\n","time = 63.0, epoch 8, iter = 11200, loss = 1.622338024377823, 34.71687364578247 s per 100 iters\n","time = 63.0, epoch 8, iter = 11300, loss = 1.6101477092504501, 33.304166316986084 s per 100 iters\n","time = 64.0, epoch 8, iter = 11400, loss = 1.5992567151784898, 33.2487359046936 s per 100 iters\n","time = 64.0, epoch 8, iter = 11500, loss = 1.605516945719719, 34.071892976760864 s per 100 iters\n","time = 65.0, epoch 8, iter = 11600, loss = 1.605013189315796, 33.62898373603821 s per 100 iters\n","time = 65.0, epoch 8, iter = 11700, loss = 1.6106408530473708, 33.74199724197388 s per 100 iters\n","time = 66.0, epoch 8, iter = 11800, loss = 1.5799631011486053, 34.26518630981445 s per 100 iters\n","time = 67.0, epoch 8, iter = 11900, loss = 1.6014106464385987, 33.44843006134033 s per 100 iters\n","time = 67.0, epoch 8, iter = 12000, loss = 1.610114330649376, 32.50340557098389 s per 100 iters\n","time = 68.0, epoch 8, iter = 12100, loss = 1.592570237517357, 33.074477434158325 s per 100 iters\n","time = 68.0, epoch 8, iter = 12200, loss = 1.5971346658468246, 33.646475076675415 s per 100 iters\n","time = 69.0, epoch 8, iter = 12300, loss = 1.604388608932495, 33.379127740859985 s per 100 iters\n","time = 69.0, epoch 8, iter = 12400, loss = 1.6062327253818511, 33.831974267959595 s per 100 iters\n","time = 70.0, epoch 8, iter = 12500, loss = 1.60287613093853, 34.93913698196411 s per 100 iters\n","time = 70.0, epoch 8, iter = 12600, loss = 1.616363333463669, 33.66225266456604 s per 100 iters\n","time = 71.0, epoch 8, iter = 12700, loss = 1.5941357380151748, 33.323370933532715 s per 100 iters\n","time = 72.0, epoch 8, iter = 12800, loss = 1.6123001968860626, 33.157036781311035 s per 100 iters\n","time = 72.0, epoch 8, iter = 12900, loss = 1.6256499707698822, 34.01337671279907 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 73.0, epoch 8, iter = 13000, loss = 1.6111840265989303, 33.61236023902893 s per 100 iters\n","time = 73.0, epoch 8, iter = 13100, loss = 1.6064980137348175, 34.606014251708984 s per 100 iters\n","time = 74.0, epoch 8, iter = 13200, loss = 1.5830843967199326, 33.024505853652954 s per 100 iters\n","time = 74.0, epoch 8, iter = 13300, loss = 1.620798226594925, 33.14897871017456 s per 100 iters\n","time = 75.0, epoch 8, iter = 13400, loss = 1.6223914784193039, 33.89796590805054 s per 100 iters\n","time = 75.0, epoch 8, iter = 13500, loss = 1.6122939544916153, 34.17105197906494 s per 100 iters\n","time = 76.0, epoch 8, iter = 13600, loss = 1.6220855164527892, 34.76876640319824 s per 100 iters\n","time = 77.0, epoch 8, iter = 13700, loss = 1.6204332745075225, 34.360841035842896 s per 100 iters\n","time = 77.0, epoch 8, iter = 13800, loss = 1.6195356208086014, 34.6898672580719 s per 100 iters\n","time = 78.0, epoch 8, iter = 13900, loss = 1.610760468840599, 33.6581552028656 s per 100 iters\n","time = 78.0, epoch 8, iter = 14000, loss = 1.5953126335144043, 32.38690710067749 s per 100 iters\n","time = 79.0, epoch 8, iter = 14100, loss = 1.6355493742227554, 33.53704762458801 s per 100 iters\n","time = 79.0, epoch 8, iter = 14200, loss = 1.6235618364810944, 33.53236675262451 s per 100 iters\n","time = 80.0, epoch 8, iter = 14300, loss = 1.6042062520980835, 35.10091853141785 s per 100 iters\n","--- Balidazioa ---\n","27.267204523086548 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure adiskidea ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hura ￭?', '｟B rosanna ｟C spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colin berriro geratu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen ￭, lehen aldiz ￭, ｟C siziliako bazterretan barneratu zenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirrone eta ｟C don ｟C fabrizioren portaerak konbentzitu zuten ｟C donnafugatako jauregia ez zela ｟C capraro bandiduaren antroa ￭, eta seguraski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailearen beste ofizialak ￭, berriz ￭, hizpide artifizialak ￭, saria eta zigorra ￭, subiranotasunaren jarleku eta kide bakoitza bere zeregina betetzeko mugatzen deneko ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭; dirua eta aberastasun partikularren indarra ￭, herria ￭, herria ￭, boterea edo herria ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, gauza guztientzat ￭, gauza guztiak ￭, alegia ￭, biltzeko ￭.', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori bera ere beren ideala da ￭, eta agian beste inor ez ￭, gaur egun irudikatzen dute ￭, beraiek dira beren burua ￭, bere elikagai eta eskaaratzailerik aurreratuenena ￭, bere erarik finena ￭, sedukzio forma sentigarriena ￭.', '｟C hegoaldean ez dago esklaborik esklaborik ez duten familiarik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 11.63307753937641\n","7.246167898178101 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ere ikusten ditugu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzeko etorria zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu inporta ￭?', '｟C eta argazkia erakutsi diot 1960ean eta bere semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C segi lotan ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.840513478355494\n","BLEU puntuazioa (biak): 15.158623147173511\n","time = 81.0, epoch 9, iter = 100, loss = 1.4635737532377242, 35.671226501464844 s per 100 iters\n","time = 82.0, epoch 9, iter = 200, loss = 1.4643604624271394, 34.14714217185974 s per 100 iters\n","time = 83.0, epoch 9, iter = 300, loss = 1.453091448545456, 33.760706424713135 s per 100 iters\n","time = 83.0, epoch 9, iter = 400, loss = 1.4545326101779938, 33.676756381988525 s per 100 iters\n","time = 84.0, epoch 9, iter = 500, loss = 1.4782744181156158, 33.74389052391052 s per 100 iters\n","time = 84.0, epoch 9, iter = 600, loss = 1.4906074452400206, 35.05551099777222 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 85.0, epoch 9, iter = 700, loss = 1.4764561289548874, 34.0972204208374 s per 100 iters\n","time = 85.0, epoch 9, iter = 800, loss = 1.4785232192277908, 34.5894455909729 s per 100 iters\n","time = 86.0, epoch 9, iter = 900, loss = 1.4679794591665267, 34.15133619308472 s per 100 iters\n","time = 87.0, epoch 9, iter = 1000, loss = 1.4864267760515213, 34.29174256324768 s per 100 iters\n","time = 87.0, epoch 9, iter = 1100, loss = 1.4849440747499465, 33.94673538208008 s per 100 iters\n","time = 88.0, epoch 9, iter = 1200, loss = 1.5035848551988602, 34.481255769729614 s per 100 iters\n","time = 88.0, epoch 9, iter = 1300, loss = 1.4745806622505189, 33.64487957954407 s per 100 iters\n","time = 89.0, epoch 9, iter = 1400, loss = 1.4805404698848725, 34.334094285964966 s per 100 iters\n","time = 89.0, epoch 9, iter = 1500, loss = 1.4978074026107788, 34.364179611206055 s per 100 iters\n","time = 90.0, epoch 9, iter = 1600, loss = 1.5054692828655243, 34.03187274932861 s per 100 iters\n","time = 91.0, epoch 9, iter = 1700, loss = 1.50055593252182, 34.24824666976929 s per 100 iters\n","time = 91.0, epoch 9, iter = 1800, loss = 1.4742458778619767, 33.585366010665894 s per 100 iters\n","time = 92.0, epoch 9, iter = 1900, loss = 1.496880533695221, 33.58360767364502 s per 100 iters\n","time = 92.0, epoch 9, iter = 2000, loss = 1.5051439261436463, 33.08365345001221 s per 100 iters\n","time = 93.0, epoch 9, iter = 2100, loss = 1.5067870086431503, 34.160093784332275 s per 100 iters\n","time = 93.0, epoch 9, iter = 2200, loss = 1.5043035113811494, 34.55743861198425 s per 100 iters\n","time = 94.0, epoch 9, iter = 2300, loss = 1.501648304462433, 33.859954595565796 s per 100 iters\n","time = 94.0, epoch 9, iter = 2400, loss = 1.499132780432701, 33.571311473846436 s per 100 iters\n","time = 95.0, epoch 9, iter = 2500, loss = 1.499170150756836, 32.64825367927551 s per 100 iters\n","time = 96.0, epoch 9, iter = 2600, loss = 1.5090886968374253, 33.75536108016968 s per 100 iters\n","time = 96.0, epoch 9, iter = 2700, loss = 1.4820905417203902, 33.2780396938324 s per 100 iters\n","time = 97.0, epoch 9, iter = 2800, loss = 1.5115951067209243, 34.550759077072144 s per 100 iters\n","time = 97.0, epoch 9, iter = 2900, loss = 1.5074442994594575, 35.0158486366272 s per 100 iters\n","time = 98.0, epoch 9, iter = 3000, loss = 1.5021971720457077, 33.40751385688782 s per 100 iters\n","time = 98.0, epoch 9, iter = 3100, loss = 1.4875759202241898, 33.325769901275635 s per 100 iters\n","time = 99.0, epoch 9, iter = 3200, loss = 1.5113069033622741, 34.36982035636902 s per 100 iters\n","time = 100.0, epoch 9, iter = 3300, loss = 1.5046186083555222, 33.57891654968262 s per 100 iters\n","time = 100.0, epoch 9, iter = 3400, loss = 1.5236424905061723, 34.551321268081665 s per 100 iters\n","time = 101.0, epoch 9, iter = 3500, loss = 1.5121350026130675, 33.942448139190674 s per 100 iters\n","time = 101.0, epoch 9, iter = 3600, loss = 1.5188018012046813, 33.77666640281677 s per 100 iters\n","time = 102.0, epoch 9, iter = 3700, loss = 1.490121635198593, 33.76099395751953 s per 100 iters\n","time = 102.0, epoch 9, iter = 3800, loss = 1.5059528052806854, 34.309767723083496 s per 100 iters\n","time = 103.0, epoch 9, iter = 3900, loss = 1.534686045050621, 34.17516779899597 s per 100 iters\n","time = 104.0, epoch 9, iter = 4000, loss = 1.517924702167511, 34.574546337127686 s per 100 iters\n","time = 104.0, epoch 9, iter = 4100, loss = 1.5370289653539657, 34.51875591278076 s per 100 iters\n","time = 105.0, epoch 9, iter = 4200, loss = 1.5190737456083299, 34.1235716342926 s per 100 iters\n","time = 105.0, epoch 9, iter = 4300, loss = 1.524813027381897, 33.916003465652466 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 106.0, epoch 9, iter = 4400, loss = 1.5199347460269927, 34.74071264266968 s per 100 iters\n","time = 106.0, epoch 9, iter = 4500, loss = 1.535774937272072, 33.590571880340576 s per 100 iters\n","time = 107.0, epoch 9, iter = 4600, loss = 1.5402655977010726, 34.739996671676636 s per 100 iters\n","time = 108.0, epoch 9, iter = 4700, loss = 1.5182799178361892, 33.69621300697327 s per 100 iters\n","time = 108.0, epoch 9, iter = 4800, loss = 1.5318714982271195, 33.98525261878967 s per 100 iters\n","time = 109.0, epoch 9, iter = 4900, loss = 1.514367991089821, 33.62053632736206 s per 100 iters\n","time = 109.0, epoch 9, iter = 5000, loss = 1.5182014912366868, 34.02933049201965 s per 100 iters\n","time = 110.0, epoch 9, iter = 5100, loss = 1.5286091727018356, 34.46220397949219 s per 100 iters\n","time = 110.0, epoch 9, iter = 5200, loss = 1.5208698159456253, 33.32775330543518 s per 100 iters\n","time = 111.0, epoch 9, iter = 5300, loss = 1.5300903910398482, 34.041999101638794 s per 100 iters\n","time = 111.0, epoch 9, iter = 5400, loss = 1.5404871600866317, 34.190184593200684 s per 100 iters\n","time = 112.0, epoch 9, iter = 5500, loss = 1.5121941167116164, 33.906659841537476 s per 100 iters\n","time = 113.0, epoch 9, iter = 5600, loss = 1.5399123740196228, 34.51934599876404 s per 100 iters\n","time = 113.0, epoch 9, iter = 5700, loss = 1.5158802074193956, 34.378982067108154 s per 100 iters\n","time = 114.0, epoch 9, iter = 5800, loss = 1.5383023035526275, 34.919883728027344 s per 100 iters\n","time = 114.0, epoch 9, iter = 5900, loss = 1.532414140701294, 34.17929553985596 s per 100 iters\n","time = 115.0, epoch 9, iter = 6000, loss = 1.5231707829236985, 33.68054413795471 s per 100 iters\n","time = 115.0, epoch 9, iter = 6100, loss = 1.5323467302322387, 34.82954931259155 s per 100 iters\n","time = 116.0, epoch 9, iter = 6200, loss = 1.5207416701316834, 35.457913637161255 s per 100 iters\n","time = 117.0, epoch 9, iter = 6300, loss = 1.5282692885398865, 34.9495964050293 s per 100 iters\n","time = 117.0, epoch 9, iter = 6400, loss = 1.5467574679851532, 34.77572703361511 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 118.0, epoch 9, iter = 6500, loss = 1.5424733293056487, 34.77214741706848 s per 100 iters\n","time = 118.0, epoch 9, iter = 6600, loss = 1.5424583488702774, 34.31983160972595 s per 100 iters\n","time = 119.0, epoch 9, iter = 6700, loss = 1.5408405667543412, 33.86090111732483 s per 100 iters\n","time = 120.0, epoch 9, iter = 6800, loss = 1.5496025854349136, 34.0481960773468 s per 100 iters\n","time = 120.0, epoch 9, iter = 6900, loss = 1.5411928290128707, 34.173566579818726 s per 100 iters\n","time = 121.0, epoch 9, iter = 7000, loss = 1.5560828065872192, 33.674580335617065 s per 100 iters\n","time = 121.0, epoch 9, iter = 7100, loss = 1.5732937145233155, 34.52688670158386 s per 100 iters\n","time = 122.0, epoch 9, iter = 7200, loss = 1.5385957652330398, 34.24186611175537 s per 100 iters\n","time = 122.0, epoch 9, iter = 7300, loss = 1.5462189078330995, 34.32205152511597 s per 100 iters\n","time = 123.0, epoch 9, iter = 7400, loss = 1.5369464355707168, 33.642767667770386 s per 100 iters\n","time = 124.0, epoch 9, iter = 7500, loss = 1.5410823976993562, 35.200815200805664 s per 100 iters\n","time = 124.0, epoch 9, iter = 7600, loss = 1.5476444554328919, 34.41417741775513 s per 100 iters\n","time = 125.0, epoch 9, iter = 7700, loss = 1.5548693746328355, 34.78188872337341 s per 100 iters\n","time = 125.0, epoch 9, iter = 7800, loss = 1.5392893570661546, 33.9752459526062 s per 100 iters\n","time = 126.0, epoch 9, iter = 7900, loss = 1.5506803500652313, 34.66655659675598 s per 100 iters\n","time = 126.0, epoch 9, iter = 8000, loss = 1.549608657360077, 34.6454119682312 s per 100 iters\n","time = 127.0, epoch 9, iter = 8100, loss = 1.559511998295784, 34.56030511856079 s per 100 iters\n","time = 128.0, epoch 9, iter = 8200, loss = 1.539407104253769, 34.37644028663635 s per 100 iters\n","time = 128.0, epoch 9, iter = 8300, loss = 1.5340573716163635, 32.532509326934814 s per 100 iters\n","time = 129.0, epoch 9, iter = 8400, loss = 1.5445336890220642, 33.37627911567688 s per 100 iters\n","time = 129.0, epoch 9, iter = 8500, loss = 1.5471238887310028, 33.04682946205139 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 130.0, epoch 9, iter = 8600, loss = 1.552003434896469, 33.73529291152954 s per 100 iters\n","time = 130.0, epoch 9, iter = 8700, loss = 1.556082090139389, 33.61869812011719 s per 100 iters\n","time = 131.0, epoch 9, iter = 8800, loss = 1.5629014283418656, 34.28114724159241 s per 100 iters\n","time = 131.0, epoch 9, iter = 8900, loss = 1.5468192839622497, 34.39823627471924 s per 100 iters\n","time = 132.0, epoch 9, iter = 9000, loss = 1.5579851913452147, 34.15044903755188 s per 100 iters\n","time = 133.0, epoch 9, iter = 9100, loss = 1.549691246151924, 34.67117929458618 s per 100 iters\n","time = 133.0, epoch 9, iter = 9200, loss = 1.5518867766857147, 34.92175054550171 s per 100 iters\n","time = 134.0, epoch 9, iter = 9300, loss = 1.5466630804538726, 34.14421629905701 s per 100 iters\n","time = 134.0, epoch 9, iter = 9400, loss = 1.5324202269315719, 33.60863661766052 s per 100 iters\n","time = 135.0, epoch 9, iter = 9500, loss = 1.5680295991897584, 34.61778211593628 s per 100 iters\n","time = 135.0, epoch 9, iter = 9600, loss = 1.5625763368606567, 33.68125128746033 s per 100 iters\n","time = 136.0, epoch 9, iter = 9700, loss = 1.5455161571502685, 33.58109498023987 s per 100 iters\n","time = 137.0, epoch 9, iter = 9800, loss = 1.5746239203214645, 33.86354160308838 s per 100 iters\n","time = 137.0, epoch 9, iter = 9900, loss = 1.5583094131946564, 34.04517221450806 s per 100 iters\n","time = 138.0, epoch 9, iter = 10000, loss = 1.5531269061565398, 34.266642570495605 s per 100 iters\n","time = 138.0, epoch 9, iter = 10100, loss = 1.540612360239029, 33.36573147773743 s per 100 iters\n","time = 139.0, epoch 9, iter = 10200, loss = 1.5555591642856599, 34.01227784156799 s per 100 iters\n","time = 139.0, epoch 9, iter = 10300, loss = 1.5677601397037506, 34.78000617027283 s per 100 iters\n","time = 140.0, epoch 9, iter = 10400, loss = 1.5605373495817185, 34.0291588306427 s per 100 iters\n","time = 141.0, epoch 9, iter = 10500, loss = 1.5661099553108215, 34.552905321121216 s per 100 iters\n","time = 141.0, epoch 9, iter = 10600, loss = 1.560622307062149, 34.48354434967041 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 142.0, epoch 9, iter = 10700, loss = 1.575291479229927, 33.374920129776 s per 100 iters\n","time = 142.0, epoch 9, iter = 10800, loss = 1.5762397521734237, 33.1193163394928 s per 100 iters\n","time = 143.0, epoch 9, iter = 10900, loss = 1.5685725897550582, 34.11957097053528 s per 100 iters\n","time = 143.0, epoch 9, iter = 11000, loss = 1.5529520833492279, 33.1335506439209 s per 100 iters\n","time = 144.0, epoch 9, iter = 11100, loss = 1.5617174005508423, 33.67435908317566 s per 100 iters\n","time = 144.0, epoch 9, iter = 11200, loss = 1.5797424352169036, 33.20124864578247 s per 100 iters\n","time = 145.0, epoch 9, iter = 11300, loss = 1.5224547588825226, 33.41460061073303 s per 100 iters\n","time = 146.0, epoch 9, iter = 11400, loss = 1.5645360201597214, 32.94803714752197 s per 100 iters\n","time = 146.0, epoch 9, iter = 11500, loss = 1.5592480611801147, 34.27419376373291 s per 100 iters\n","time = 147.0, epoch 9, iter = 11600, loss = 1.5413766759634018, 33.09737730026245 s per 100 iters\n","time = 147.0, epoch 9, iter = 11700, loss = 1.5715553319454194, 34.107882261276245 s per 100 iters\n","time = 148.0, epoch 9, iter = 11800, loss = 1.5560199385881424, 33.469319581985474 s per 100 iters\n","time = 148.0, epoch 9, iter = 11900, loss = 1.563815490603447, 33.311585664749146 s per 100 iters\n","time = 149.0, epoch 9, iter = 12000, loss = 1.5547901725769042, 33.616833209991455 s per 100 iters\n","time = 150.0, epoch 9, iter = 12100, loss = 1.5903593766689301, 34.10545229911804 s per 100 iters\n","time = 150.0, epoch 9, iter = 12200, loss = 1.5639472097158431, 33.26881790161133 s per 100 iters\n","time = 151.0, epoch 9, iter = 12300, loss = 1.5810379868745803, 34.288161277770996 s per 100 iters\n","time = 151.0, epoch 9, iter = 12400, loss = 1.5606789523363114, 33.73170256614685 s per 100 iters\n","time = 152.0, epoch 9, iter = 12500, loss = 1.5740343898534774, 33.951504707336426 s per 100 iters\n","time = 152.0, epoch 9, iter = 12600, loss = 1.583452863097191, 34.26037573814392 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 153.0, epoch 9, iter = 12700, loss = 1.564578999876976, 33.892765522003174 s per 100 iters\n","time = 153.0, epoch 9, iter = 12800, loss = 1.5658559560775758, 33.46313786506653 s per 100 iters\n","time = 154.0, epoch 9, iter = 12900, loss = 1.5493651568889617, 33.28408646583557 s per 100 iters\n","time = 155.0, epoch 9, iter = 13000, loss = 1.5569223326444626, 33.06601119041443 s per 100 iters\n","time = 155.0, epoch 9, iter = 13100, loss = 1.5642793798446655, 33.361392974853516 s per 100 iters\n","time = 156.0, epoch 9, iter = 13200, loss = 1.5616954171657562, 33.64554738998413 s per 100 iters\n","time = 156.0, epoch 9, iter = 13300, loss = 1.5752775651216506, 34.47837519645691 s per 100 iters\n","time = 157.0, epoch 9, iter = 13400, loss = 1.556614151597023, 33.83477330207825 s per 100 iters\n","time = 157.0, epoch 9, iter = 13500, loss = 1.5722707617282867, 34.346009254455566 s per 100 iters\n","time = 158.0, epoch 9, iter = 13600, loss = 1.558380852341652, 34.078030586242676 s per 100 iters\n","time = 159.0, epoch 9, iter = 13700, loss = 1.5596952641010284, 34.00390100479126 s per 100 iters\n","time = 159.0, epoch 9, iter = 13800, loss = 1.5799248349666595, 33.7066969871521 s per 100 iters\n","time = 160.0, epoch 9, iter = 13900, loss = 1.5542337596416473, 33.09526968002319 s per 100 iters\n","time = 160.0, epoch 9, iter = 14000, loss = 1.5775421768426896, 33.319188356399536 s per 100 iters\n","time = 161.0, epoch 9, iter = 14100, loss = 1.5831810057163238, 34.981125831604004 s per 100 iters\n","time = 161.0, epoch 9, iter = 14200, loss = 1.569607018828392, 32.86539912223816 s per 100 iters\n","time = 162.0, epoch 9, iter = 14300, loss = 1.558373646736145, 33.39914870262146 s per 100 iters\n","--- Balidazioa ---\n","25.698262214660645 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hura ￭?', '｟B rosanna spearman ｟E', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan oinez hasi zenetik ￭, eta nesken xarmaz ￭, ｟C pirroneren austeritateaz eta ｟C don ｟C fabrizioren moderazioak konbentzitu zuten ｟C donnafugatako jauregia ez zela ｟C capraro bandidoaren antroa ￭, eta seguraski bizirik irtengo zela bertatik ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C aaaaaaaaaaaaaaaaaaa ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza exekutatzeko beste ofizialak ￭, sari eta zigorrak ￭, zeinen bidez subiranotasunaren jarlekura eta kide bakoitza bere zeregina betetzeko mugatzen baitira ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭; dirua eta aberastasun partikularra ￭, botere legegilearen indarra edo oparotasuna dira ￭, eta hau da ￭, gauza artifizialen ardura ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideala da ￭, eta agian beste inork ez dute irudikatzen ￭, gaur egun berek dira beren izpiritualizatuenak ￭, bere gaitasun izpiritualena ￭, gerlari eta eskautaldi aurreratuenak ￭, haren gaitasunik fin eta liluragarriena ￭, ulertezina ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 11.992090235647794\n","6.916595220565796 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, oso musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosiko al duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia erakusten diot 1960ean eta bere semea 1940ko uniformean ￭.', '｟C eta orduan ￭, dena aldatu zen ￭.', '- ｟C ze txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C seguru ｟C delphinek dakiela ￭?']\n","BLEU puntuazioa (2): 27.35812514353964\n","BLEU puntuazioa (biak): 15.553462140303253\n","time = 163.0, epoch 10, iter = 100, loss = 1.4237454396486282, 35.847928524017334 s per 100 iters\n","time = 164.0, epoch 10, iter = 200, loss = 1.4274270749092102, 33.52838110923767 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-e31fcfc4adc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mentrenatu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-3280eebef4ed>\u001b[0m in \u001b[0;36mentrenatu\u001b[0;34m(hasi_epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ina4Jr6aBwFi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7dcFMaVBwkh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594322166799,"user_tz":-120,"elapsed":9772076,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ab59ac0b-7d69-4aad-d69a-c82a3ead1a24"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/origetaos2-9.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu(10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 10, iter = 100, loss = 1.4374516487121582, 39.05898308753967 s per 100 iters\n","time = 1.0, epoch 10, iter = 200, loss = 1.4282585489749908, 37.986351013183594 s per 100 iters\n","time = 1.0, epoch 10, iter = 300, loss = 1.4346407687664031, 37.94548940658569 s per 100 iters\n","time = 2.0, epoch 10, iter = 400, loss = 1.4207569700479508, 36.82137489318848 s per 100 iters\n","time = 3.0, epoch 10, iter = 500, loss = 1.4225375312566757, 38.22032332420349 s per 100 iters\n","time = 3.0, epoch 10, iter = 600, loss = 1.4145608282089233, 38.47470688819885 s per 100 iters\n","time = 4.0, epoch 10, iter = 700, loss = 1.437300933599472, 38.698312759399414 s per 100 iters\n","time = 5.0, epoch 10, iter = 800, loss = 1.4575019478797913, 37.75700283050537 s per 100 iters\n","time = 5.0, epoch 10, iter = 900, loss = 1.4413196182250976, 38.504703760147095 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 6.0, epoch 10, iter = 1000, loss = 1.4622584193944932, 37.874409437179565 s per 100 iters\n","time = 6.0, epoch 10, iter = 1100, loss = 1.4286431443691254, 37.51617479324341 s per 100 iters\n","time = 7.0, epoch 10, iter = 1200, loss = 1.4359986370801925, 38.12455940246582 s per 100 iters\n","time = 8.0, epoch 10, iter = 1300, loss = 1.4427260857820512, 37.3789279460907 s per 100 iters\n","time = 8.0, epoch 10, iter = 1400, loss = 1.4424093574285508, 37.516984939575195 s per 100 iters\n","time = 9.0, epoch 10, iter = 1500, loss = 1.4688697016239167, 39.128047704696655 s per 100 iters\n","time = 10.0, epoch 10, iter = 1600, loss = 1.4571265983581543, 37.85273313522339 s per 100 iters\n","time = 10.0, epoch 10, iter = 1700, loss = 1.4574845254421234, 36.93590712547302 s per 100 iters\n","time = 11.0, epoch 10, iter = 1800, loss = 1.4390651541948318, 37.77796912193298 s per 100 iters\n","time = 12.0, epoch 10, iter = 1900, loss = 1.4622533488273621, 37.59098768234253 s per 100 iters\n","time = 12.0, epoch 10, iter = 2000, loss = 1.4776083970069884, 38.458879709243774 s per 100 iters\n","time = 13.0, epoch 10, iter = 2100, loss = 1.4397310626506805, 37.51433801651001 s per 100 iters\n","time = 13.0, epoch 10, iter = 2200, loss = 1.461404517889023, 38.02607607841492 s per 100 iters\n","time = 14.0, epoch 10, iter = 2300, loss = 1.4700852352380753, 38.718498945236206 s per 100 iters\n","time = 15.0, epoch 10, iter = 2400, loss = 1.4631798243522645, 37.9669463634491 s per 100 iters\n","time = 15.0, epoch 10, iter = 2500, loss = 1.4589235591888428, 37.9597065448761 s per 100 iters\n","time = 16.0, epoch 10, iter = 2600, loss = 1.4724126052856445, 37.773396492004395 s per 100 iters\n","time = 17.0, epoch 10, iter = 2700, loss = 1.4637099063396455, 37.58364748954773 s per 100 iters\n","time = 17.0, epoch 10, iter = 2800, loss = 1.4706681090593339, 37.81397461891174 s per 100 iters\n","time = 18.0, epoch 10, iter = 2900, loss = 1.46886645257473, 37.83177947998047 s per 100 iters\n","time = 18.0, epoch 10, iter = 3000, loss = 1.4742436504364014, 38.392048358917236 s per 100 iters\n","time = 19.0, epoch 10, iter = 3100, loss = 1.4572886997461318, 37.705172538757324 s per 100 iters\n","time = 20.0, epoch 10, iter = 3200, loss = 1.4829436820745467, 38.77059555053711 s per 100 iters\n","time = 20.0, epoch 10, iter = 3300, loss = 1.4774604111909866, 37.65070080757141 s per 100 iters\n","time = 21.0, epoch 10, iter = 3400, loss = 1.470848051905632, 37.85184335708618 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 22.0, epoch 10, iter = 3500, loss = 1.4785442715883255, 37.79799270629883 s per 100 iters\n","time = 22.0, epoch 10, iter = 3600, loss = 1.4905662423372268, 38.633718967437744 s per 100 iters\n","time = 23.0, epoch 10, iter = 3700, loss = 1.4858540266752243, 37.59022283554077 s per 100 iters\n","time = 24.0, epoch 10, iter = 3800, loss = 1.4637141388654709, 38.03357410430908 s per 100 iters\n","time = 24.0, epoch 10, iter = 3900, loss = 1.4796928137540817, 39.38360953330994 s per 100 iters\n","time = 25.0, epoch 10, iter = 4000, loss = 1.4775014716386794, 38.724618434906006 s per 100 iters\n","time = 25.0, epoch 10, iter = 4100, loss = 1.4745546001195908, 37.69847369194031 s per 100 iters\n","time = 26.0, epoch 10, iter = 4200, loss = 1.4815189212560653, 38.50041103363037 s per 100 iters\n","time = 27.0, epoch 10, iter = 4300, loss = 1.4714901679754258, 37.52684569358826 s per 100 iters\n","time = 27.0, epoch 10, iter = 4400, loss = 1.5008715343475343, 39.0396409034729 s per 100 iters\n","time = 28.0, epoch 10, iter = 4500, loss = 1.484224853515625, 38.08079195022583 s per 100 iters\n","time = 29.0, epoch 10, iter = 4600, loss = 1.5017725682258607, 38.01514172554016 s per 100 iters\n","time = 29.0, epoch 10, iter = 4700, loss = 1.477787097096443, 38.23520350456238 s per 100 iters\n","time = 30.0, epoch 10, iter = 4800, loss = 1.4821832692623138, 37.29605221748352 s per 100 iters\n","time = 31.0, epoch 10, iter = 4900, loss = 1.4825740319490432, 37.99824333190918 s per 100 iters\n","time = 31.0, epoch 10, iter = 5000, loss = 1.4854464811086654, 38.42305850982666 s per 100 iters\n","time = 32.0, epoch 10, iter = 5100, loss = 1.4833383923768997, 39.30659604072571 s per 100 iters\n","time = 32.0, epoch 10, iter = 5200, loss = 1.492234154343605, 38.489497423172 s per 100 iters\n","time = 33.0, epoch 10, iter = 5300, loss = 1.4876262760162353, 38.394083738327026 s per 100 iters\n","time = 34.0, epoch 10, iter = 5400, loss = 1.4801662904024124, 37.63169884681702 s per 100 iters\n","time = 34.0, epoch 10, iter = 5500, loss = 1.49898431122303, 39.14997720718384 s per 100 iters\n","time = 35.0, epoch 10, iter = 5600, loss = 1.505672624707222, 38.98678541183472 s per 100 iters\n","time = 36.0, epoch 10, iter = 5700, loss = 1.485741994380951, 38.3118052482605 s per 100 iters\n","time = 36.0, epoch 10, iter = 5800, loss = 1.4924706542491912, 38.53727841377258 s per 100 iters\n","time = 37.0, epoch 10, iter = 5900, loss = 1.4718624186515807, 37.29812407493591 s per 100 iters\n","time = 38.0, epoch 10, iter = 6000, loss = 1.492256909608841, 37.87159872055054 s per 100 iters\n","time = 38.0, epoch 10, iter = 6100, loss = 1.4908761191368103, 37.62811326980591 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 39.0, epoch 10, iter = 6200, loss = 1.4917907232046128, 38.14283227920532 s per 100 iters\n","time = 40.0, epoch 10, iter = 6300, loss = 1.4982903987169265, 38.13951659202576 s per 100 iters\n","time = 40.0, epoch 10, iter = 6400, loss = 1.4972753363847733, 39.025864362716675 s per 100 iters\n","time = 41.0, epoch 10, iter = 6500, loss = 1.5050677955150604, 39.139816761016846 s per 100 iters\n","time = 41.0, epoch 10, iter = 6600, loss = 1.496522706747055, 38.38954305648804 s per 100 iters\n","time = 42.0, epoch 10, iter = 6700, loss = 1.4964366286993027, 38.77418112754822 s per 100 iters\n","time = 43.0, epoch 10, iter = 6800, loss = 1.5064382928609847, 38.695024251937866 s per 100 iters\n","time = 43.0, epoch 10, iter = 6900, loss = 1.4825477492809296, 37.98041272163391 s per 100 iters\n","time = 44.0, epoch 10, iter = 7000, loss = 1.4853641033172607, 38.95013761520386 s per 100 iters\n","time = 45.0, epoch 10, iter = 7100, loss = 1.5141948890686034, 38.430620431900024 s per 100 iters\n","time = 45.0, epoch 10, iter = 7200, loss = 1.506115300655365, 38.35538458824158 s per 100 iters\n","time = 46.0, epoch 10, iter = 7300, loss = 1.5057203131914139, 37.61274337768555 s per 100 iters\n","time = 47.0, epoch 10, iter = 7400, loss = 1.4958854615688324, 38.90671491622925 s per 100 iters\n","time = 47.0, epoch 10, iter = 7500, loss = 1.5162215995788575, 38.06881785392761 s per 100 iters\n","time = 48.0, epoch 10, iter = 7600, loss = 1.503694593310356, 38.75697731971741 s per 100 iters\n","time = 48.0, epoch 10, iter = 7700, loss = 1.5173669159412384, 38.76939582824707 s per 100 iters\n","time = 49.0, epoch 10, iter = 7800, loss = 1.487290688753128, 37.974907636642456 s per 100 iters\n","time = 50.0, epoch 10, iter = 7900, loss = 1.5225229477882385, 38.52760696411133 s per 100 iters\n","time = 50.0, epoch 10, iter = 8000, loss = 1.5149335199594498, 38.43689942359924 s per 100 iters\n","time = 51.0, epoch 10, iter = 8100, loss = 1.503681645989418, 38.22750473022461 s per 100 iters\n","time = 52.0, epoch 10, iter = 8200, loss = 1.5146055299043655, 38.84507465362549 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 52.0, epoch 10, iter = 8300, loss = 1.5365351009368897, 39.23346996307373 s per 100 iters\n","time = 53.0, epoch 10, iter = 8400, loss = 1.503663147687912, 38.07276654243469 s per 100 iters\n","time = 54.0, epoch 10, iter = 8500, loss = 1.5238822430372239, 38.56618142127991 s per 100 iters\n","time = 54.0, epoch 10, iter = 8600, loss = 1.510938707590103, 38.09479069709778 s per 100 iters\n","time = 55.0, epoch 10, iter = 8700, loss = 1.487962571978569, 38.11447834968567 s per 100 iters\n","time = 56.0, epoch 10, iter = 8800, loss = 1.5173335433006288, 38.47584867477417 s per 100 iters\n","time = 56.0, epoch 10, iter = 8900, loss = 1.531651764512062, 39.771748542785645 s per 100 iters\n","time = 57.0, epoch 10, iter = 9000, loss = 1.5006649523973465, 37.85067319869995 s per 100 iters\n","time = 57.0, epoch 10, iter = 9100, loss = 1.5045001935958862, 37.82341194152832 s per 100 iters\n","time = 58.0, epoch 10, iter = 9200, loss = 1.5058090388774872, 39.02683115005493 s per 100 iters\n","time = 59.0, epoch 10, iter = 9300, loss = 1.5170365858078003, 38.50385618209839 s per 100 iters\n","time = 59.0, epoch 10, iter = 9400, loss = 1.5080344313383103, 37.62984347343445 s per 100 iters\n","time = 60.0, epoch 10, iter = 9500, loss = 1.510670212507248, 37.91996908187866 s per 100 iters\n","time = 61.0, epoch 10, iter = 9600, loss = 1.5063108950853348, 38.219483375549316 s per 100 iters\n","time = 61.0, epoch 10, iter = 9700, loss = 1.5082830059528352, 37.91882348060608 s per 100 iters\n","time = 62.0, epoch 10, iter = 9800, loss = 1.5234131562709807, 38.55861735343933 s per 100 iters\n","time = 63.0, epoch 10, iter = 9900, loss = 1.513275267481804, 38.200056314468384 s per 100 iters\n","time = 63.0, epoch 10, iter = 10000, loss = 1.5115673053264618, 39.38928008079529 s per 100 iters\n","time = 64.0, epoch 10, iter = 10100, loss = 1.5173630094528199, 38.46039319038391 s per 100 iters\n","time = 65.0, epoch 10, iter = 10200, loss = 1.5147635942697526, 38.430230140686035 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 65.0, epoch 10, iter = 10300, loss = 1.5250319236516952, 37.79317092895508 s per 100 iters\n","time = 66.0, epoch 10, iter = 10400, loss = 1.5129758816957475, 37.55377531051636 s per 100 iters\n","time = 66.0, epoch 10, iter = 10500, loss = 1.530130934715271, 38.51477885246277 s per 100 iters\n","time = 67.0, epoch 10, iter = 10600, loss = 1.5232777392864227, 39.42309927940369 s per 100 iters\n","time = 68.0, epoch 10, iter = 10700, loss = 1.519776862859726, 37.48532199859619 s per 100 iters\n","time = 68.0, epoch 10, iter = 10800, loss = 1.5366879057884217, 38.362679958343506 s per 100 iters\n","time = 69.0, epoch 10, iter = 10900, loss = 1.4945799809694291, 37.58652663230896 s per 100 iters\n","time = 70.0, epoch 10, iter = 11000, loss = 1.5303625786304473, 37.905014991760254 s per 100 iters\n","time = 70.0, epoch 10, iter = 11100, loss = 1.4846209233999252, 38.22673559188843 s per 100 iters\n","time = 71.0, epoch 10, iter = 11200, loss = 1.5435682100057602, 37.94452691078186 s per 100 iters\n","time = 71.0, epoch 10, iter = 11300, loss = 1.536629050374031, 38.87484335899353 s per 100 iters\n","time = 72.0, epoch 10, iter = 11400, loss = 1.532451656460762, 38.08653998374939 s per 100 iters\n","time = 73.0, epoch 10, iter = 11500, loss = 1.5219292211532593, 38.84161567687988 s per 100 iters\n","time = 73.0, epoch 10, iter = 11600, loss = 1.4991194701194763, 37.91792559623718 s per 100 iters\n","time = 74.0, epoch 10, iter = 11700, loss = 1.5145834010839463, 37.94153308868408 s per 100 iters\n","time = 75.0, epoch 10, iter = 11800, loss = 1.532447464466095, 38.206562519073486 s per 100 iters\n","time = 75.0, epoch 10, iter = 11900, loss = 1.5160220521688461, 38.02509331703186 s per 100 iters\n","time = 76.0, epoch 10, iter = 12000, loss = 1.5491070544719696, 38.97316527366638 s per 100 iters\n","time = 77.0, epoch 10, iter = 12100, loss = 1.513777915239334, 38.58935618400574 s per 100 iters\n","time = 77.0, epoch 10, iter = 12200, loss = 1.5159399616718292, 38.38138794898987 s per 100 iters\n","time = 78.0, epoch 10, iter = 12300, loss = 1.542003583908081, 38.35545516014099 s per 100 iters\n","time = 79.0, epoch 10, iter = 12400, loss = 1.5296460169553756, 37.63308906555176 s per 100 iters\n","time = 79.0, epoch 10, iter = 12500, loss = 1.525431563258171, 37.58419418334961 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 80.0, epoch 10, iter = 12600, loss = 1.5421653789281846, 38.78899312019348 s per 100 iters\n","time = 80.0, epoch 10, iter = 12700, loss = 1.5412361603975295, 38.04820919036865 s per 100 iters\n","time = 81.0, epoch 10, iter = 12800, loss = 1.5208425480127334, 37.833704471588135 s per 100 iters\n","time = 82.0, epoch 10, iter = 12900, loss = 1.5389672112464905, 38.44281268119812 s per 100 iters\n","time = 82.0, epoch 10, iter = 13000, loss = 1.54256886780262, 38.35325384140015 s per 100 iters\n","time = 83.0, epoch 10, iter = 13100, loss = 1.5316280227899552, 38.42932462692261 s per 100 iters\n","time = 84.0, epoch 10, iter = 13200, loss = 1.5281006228923797, 38.1124484539032 s per 100 iters\n","time = 84.0, epoch 10, iter = 13300, loss = 1.511557452082634, 37.22665071487427 s per 100 iters\n","time = 85.0, epoch 10, iter = 13400, loss = 1.524961529970169, 38.36539602279663 s per 100 iters\n","time = 86.0, epoch 10, iter = 13500, loss = 1.5191677606105805, 38.177107095718384 s per 100 iters\n","time = 86.0, epoch 10, iter = 13600, loss = 1.5277661633491517, 37.95333290100098 s per 100 iters\n","time = 87.0, epoch 10, iter = 13700, loss = 1.5356278550624847, 37.48600959777832 s per 100 iters\n","time = 87.0, epoch 10, iter = 13800, loss = 1.5181034690141677, 38.13150978088379 s per 100 iters\n","time = 88.0, epoch 10, iter = 13900, loss = 1.5355787879228593, 38.27983069419861 s per 100 iters\n","time = 89.0, epoch 10, iter = 14000, loss = 1.5352211534976958, 37.811763286590576 s per 100 iters\n","time = 89.0, epoch 10, iter = 14100, loss = 1.5430230402946472, 38.1539363861084 s per 100 iters\n","time = 90.0, epoch 10, iter = 14200, loss = 1.5365406775474548, 37.40834403038025 s per 100 iters\n","time = 91.0, epoch 10, iter = 14300, loss = 1.5455647832155228, 38.39191913604736 s per 100 iters\n","--- Balidazioa ---\n","36.47039723396301 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hura ￭?', '｟B rosanna ｟C spearman ｟E', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen ￭, lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirrone eta ｟C don ｟C fabrizioren portaera handiek eta ｟C donnafugatako jauregia ez zela ｟C kapraro bandidoaren antroa ￭, eta seguraski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C aaaaaaaaaaaaaaaaaaaa ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza eta exekutatzeko beste ofizialak ￭, iruzkin artifizialak dira ￭; sarigarriak eta zigorrak ￭, zeintzuen bidez subiranotasunaren jarleku eta kide bakoitza bere eginkizuna betetzeko mugatzen baitira ￭, nerbioak baitira ￭, gorputz naturalean gauza bera egiten duten nerbioak ￭; aberastasun partikularren aberastasunak eta aberastasun partikularren indarra ￭, herria ￭, herria ￭, herria ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, hau da ￭, gauza guztien boterea ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideal bera da ￭, eta agian beste inor ez ￭, gaur egun irudikatzen dute ￭, beraiek dira beren buruargitasun izpiritualena ￭, gerlarien eta eskaerien tropa aurreratua ￭, bere sentibera sentibera ￭, sedukzio-forma ezin ukaezinagoa ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 11.88731112515488\n","7.7640838623046875 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaks-era iritsi zenean mendeku bila etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia erakutsi nahi diot 1960ean eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.215678422579092\n","BLEU puntuazioa (biak): 15.182541492495277\n","time = 92.0, epoch 11, iter = 100, loss = 1.3835033303499222, 39.44082164764404 s per 100 iters\n","time = 93.0, epoch 11, iter = 200, loss = 1.3832992225885392, 38.33367347717285 s per 100 iters\n","time = 93.0, epoch 11, iter = 300, loss = 1.3727047806978225, 37.63501310348511 s per 100 iters\n","time = 94.0, epoch 11, iter = 400, loss = 1.3729130673408507, 36.55231499671936 s per 100 iters\n","time = 95.0, epoch 11, iter = 500, loss = 1.3875698661804199, 38.264121532440186 s per 100 iters\n","time = 95.0, epoch 11, iter = 600, loss = 1.3902797901630402, 38.38292598724365 s per 100 iters\n","time = 96.0, epoch 11, iter = 700, loss = 1.37836749792099, 37.09296894073486 s per 100 iters\n","time = 97.0, epoch 11, iter = 800, loss = 1.3862761795520782, 38.000941038131714 s per 100 iters\n","time = 97.0, epoch 11, iter = 900, loss = 1.414718707203865, 38.180826902389526 s per 100 iters\n","time = 98.0, epoch 11, iter = 1000, loss = 1.4194407123327255, 37.839728116989136 s per 100 iters\n","time = 99.0, epoch 11, iter = 1100, loss = 1.399014475941658, 38.13654065132141 s per 100 iters\n","time = 99.0, epoch 11, iter = 1200, loss = 1.4001871591806412, 37.649232149124146 s per 100 iters\n","time = 100.0, epoch 11, iter = 1300, loss = 1.3987999457120894, 37.64229154586792 s per 100 iters\n","time = 100.0, epoch 11, iter = 1400, loss = 1.405565277338028, 37.67729878425598 s per 100 iters\n","time = 101.0, epoch 11, iter = 1500, loss = 1.4042121362686157, 37.69549512863159 s per 100 iters\n","time = 102.0, epoch 11, iter = 1600, loss = 1.4074192386865616, 38.4250431060791 s per 100 iters\n","time = 102.0, epoch 11, iter = 1700, loss = 1.4120045989751815, 37.938029050827026 s per 100 iters\n","time = 103.0, epoch 11, iter = 1800, loss = 1.4166454595327378, 37.53358173370361 s per 100 iters\n","time = 104.0, epoch 11, iter = 1900, loss = 1.409117048382759, 38.53688192367554 s per 100 iters\n","time = 104.0, epoch 11, iter = 2000, loss = 1.4163840705156325, 38.414761781692505 s per 100 iters\n","time = 105.0, epoch 11, iter = 2100, loss = 1.4089103668928147, 38.31656885147095 s per 100 iters\n","time = 105.0, epoch 11, iter = 2200, loss = 1.4325174582004547, 38.077757835388184 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n","time = 106.0, epoch 11, iter = 2300, loss = 1.4312009996175765, 38.70329236984253 s per 100 iters\n","time = 107.0, epoch 11, iter = 2400, loss = 1.4083861935138702, 38.014748096466064 s per 100 iters\n","time = 107.0, epoch 11, iter = 2500, loss = 1.431266257762909, 38.11479735374451 s per 100 iters\n","time = 108.0, epoch 11, iter = 2600, loss = 1.4558466857671737, 39.36334490776062 s per 100 iters\n","time = 109.0, epoch 11, iter = 2700, loss = 1.4157241398096085, 37.17301821708679 s per 100 iters\n","time = 109.0, epoch 11, iter = 2800, loss = 1.4261172705888747, 38.37777495384216 s per 100 iters\n","time = 110.0, epoch 11, iter = 2900, loss = 1.424519031047821, 38.10736536979675 s per 100 iters\n","time = 111.0, epoch 11, iter = 3000, loss = 1.4162493842840194, 38.31196093559265 s per 100 iters\n","time = 111.0, epoch 11, iter = 3100, loss = 1.4227482867240906, 38.45001006126404 s per 100 iters\n","time = 112.0, epoch 11, iter = 3200, loss = 1.408403718471527, 37.82252073287964 s per 100 iters\n","time = 112.0, epoch 11, iter = 3300, loss = 1.4492102563381195, 37.86392068862915 s per 100 iters\n","time = 113.0, epoch 11, iter = 3400, loss = 1.4356438314914703, 37.768630266189575 s per 100 iters\n","time = 114.0, epoch 11, iter = 3500, loss = 1.4479367107152938, 38.673738956451416 s per 100 iters\n","time = 114.0, epoch 11, iter = 3600, loss = 1.424425590634346, 37.774686336517334 s per 100 iters\n","time = 115.0, epoch 11, iter = 3700, loss = 1.4291503036022186, 38.158984422683716 s per 100 iters\n","time = 116.0, epoch 11, iter = 3800, loss = 1.4327056938409806, 38.555766105651855 s per 100 iters\n","time = 116.0, epoch 11, iter = 3900, loss = 1.4533059138059616, 38.42199349403381 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 117.0, epoch 11, iter = 4000, loss = 1.4432735270261765, 38.49599814414978 s per 100 iters\n","time = 118.0, epoch 11, iter = 4100, loss = 1.4420810395479202, 38.599162578582764 s per 100 iters\n","time = 118.0, epoch 11, iter = 4200, loss = 1.4598363852500915, 38.47018909454346 s per 100 iters\n","time = 119.0, epoch 11, iter = 4300, loss = 1.4359277951717377, 38.15315771102905 s per 100 iters\n","time = 120.0, epoch 11, iter = 4400, loss = 1.454687124490738, 38.296547412872314 s per 100 iters\n","time = 120.0, epoch 11, iter = 4500, loss = 1.423556690812111, 38.50224232673645 s per 100 iters\n","time = 121.0, epoch 11, iter = 4600, loss = 1.4332106989622115, 38.13356804847717 s per 100 iters\n","time = 121.0, epoch 11, iter = 4700, loss = 1.4561215400695802, 37.71097660064697 s per 100 iters\n","time = 122.0, epoch 11, iter = 4800, loss = 1.436828474998474, 38.37573313713074 s per 100 iters\n","time = 123.0, epoch 11, iter = 4900, loss = 1.4411941516399382, 37.32085680961609 s per 100 iters\n","time = 123.0, epoch 11, iter = 5000, loss = 1.4486186200380324, 38.78293228149414 s per 100 iters\n","time = 124.0, epoch 11, iter = 5100, loss = 1.4270410138368606, 37.37997579574585 s per 100 iters\n","time = 125.0, epoch 11, iter = 5200, loss = 1.4459239202737808, 37.554022789001465 s per 100 iters\n","time = 125.0, epoch 11, iter = 5300, loss = 1.4567457449436187, 37.77261924743652 s per 100 iters\n","time = 126.0, epoch 11, iter = 5400, loss = 1.44687959253788, 37.4251024723053 s per 100 iters\n","time = 126.0, epoch 11, iter = 5500, loss = 1.4455039995908736, 37.80452036857605 s per 100 iters\n","time = 127.0, epoch 11, iter = 5600, loss = 1.4475933676958084, 37.4544517993927 s per 100 iters\n","time = 128.0, epoch 11, iter = 5700, loss = 1.4711841493844986, 38.740822553634644 s per 100 iters\n","time = 128.0, epoch 11, iter = 5800, loss = 1.4593475884199143, 38.04586434364319 s per 100 iters\n","time = 129.0, epoch 11, iter = 5900, loss = 1.464769448041916, 38.03512525558472 s per 100 iters\n","time = 130.0, epoch 11, iter = 6000, loss = 1.4388889414072037, 37.5462908744812 s per 100 iters\n","time = 130.0, epoch 11, iter = 6100, loss = 1.461192935705185, 37.94658589363098 s per 100 iters\n","time = 131.0, epoch 11, iter = 6200, loss = 1.4680492115020751, 38.60905909538269 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 132.0, epoch 11, iter = 6300, loss = 1.4560992377996445, 38.5787239074707 s per 100 iters\n","time = 132.0, epoch 11, iter = 6400, loss = 1.4584352016448974, 38.12964463233948 s per 100 iters\n","time = 133.0, epoch 11, iter = 6500, loss = 1.4565055871009827, 38.346689224243164 s per 100 iters\n","time = 133.0, epoch 11, iter = 6600, loss = 1.4672775238752365, 38.555519819259644 s per 100 iters\n","time = 134.0, epoch 11, iter = 6700, loss = 1.4554501861333846, 38.17044973373413 s per 100 iters\n","time = 135.0, epoch 11, iter = 6800, loss = 1.4552159625291825, 38.216991662979126 s per 100 iters\n","time = 135.0, epoch 11, iter = 6900, loss = 1.466028968691826, 39.04637265205383 s per 100 iters\n","time = 136.0, epoch 11, iter = 7000, loss = 1.4809567326307296, 38.809548139572144 s per 100 iters\n","time = 137.0, epoch 11, iter = 7100, loss = 1.4804595291614533, 38.36264610290527 s per 100 iters\n","time = 137.0, epoch 11, iter = 7200, loss = 1.452982952594757, 37.51815056800842 s per 100 iters\n","time = 138.0, epoch 11, iter = 7300, loss = 1.4603855019807817, 38.007121086120605 s per 100 iters\n","time = 139.0, epoch 11, iter = 7400, loss = 1.4703986740112305, 38.54028248786926 s per 100 iters\n","time = 139.0, epoch 11, iter = 7500, loss = 1.4649414324760437, 37.91530466079712 s per 100 iters\n","time = 140.0, epoch 11, iter = 7600, loss = 1.4714222729206086, 37.72567582130432 s per 100 iters\n","time = 140.0, epoch 11, iter = 7700, loss = 1.465432669520378, 37.59204411506653 s per 100 iters\n","time = 141.0, epoch 11, iter = 7800, loss = 1.4526430881023407, 37.79540729522705 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 142.0, epoch 11, iter = 7900, loss = 1.4782209539413451, 38.563618183135986 s per 100 iters\n","time = 142.0, epoch 11, iter = 8000, loss = 1.4852910649776458, 36.920385122299194 s per 100 iters\n","time = 143.0, epoch 11, iter = 8100, loss = 1.4807154911756515, 37.88989472389221 s per 100 iters\n","time = 144.0, epoch 11, iter = 8200, loss = 1.477653152346611, 38.22554636001587 s per 100 iters\n","time = 144.0, epoch 11, iter = 8300, loss = 1.4763628751039506, 37.687304973602295 s per 100 iters\n","time = 145.0, epoch 11, iter = 8400, loss = 1.4712759637832642, 37.54426193237305 s per 100 iters\n","time = 145.0, epoch 11, iter = 8500, loss = 1.4779996353387832, 36.91535711288452 s per 100 iters\n","time = 146.0, epoch 11, iter = 8600, loss = 1.4757365494966508, 37.36121225357056 s per 100 iters\n","time = 147.0, epoch 11, iter = 8700, loss = 1.457406478524208, 37.42432761192322 s per 100 iters\n","time = 147.0, epoch 11, iter = 8800, loss = 1.4838625705242157, 37.98188829421997 s per 100 iters\n","time = 148.0, epoch 11, iter = 8900, loss = 1.4582679164409638, 37.97636032104492 s per 100 iters\n","time = 149.0, epoch 11, iter = 9000, loss = 1.4707891565561295, 38.00385904312134 s per 100 iters\n","time = 149.0, epoch 11, iter = 9100, loss = 1.4692295223474503, 38.400803089141846 s per 100 iters\n","time = 150.0, epoch 11, iter = 9200, loss = 1.4745968091487884, 37.344907999038696 s per 100 iters\n","time = 151.0, epoch 11, iter = 9300, loss = 1.4643566083908082, 37.3305459022522 s per 100 iters\n","time = 151.0, epoch 11, iter = 9400, loss = 1.489834663271904, 38.11696124076843 s per 100 iters\n","time = 152.0, epoch 11, iter = 9500, loss = 1.4895247584581375, 38.01490116119385 s per 100 iters\n","time = 152.0, epoch 11, iter = 9600, loss = 1.4765435248613357, 37.70428991317749 s per 100 iters\n","time = 153.0, epoch 11, iter = 9700, loss = 1.4561165821552278, 37.116323709487915 s per 100 iters\n","time = 154.0, epoch 11, iter = 9800, loss = 1.4748130077123642, 38.173298358917236 s per 100 iters\n","time = 154.0, epoch 11, iter = 9900, loss = 1.4944002598524093, 38.31653141975403 s per 100 iters\n","time = 155.0, epoch 11, iter = 10000, loss = 1.467276378273964, 37.426613569259644 s per 100 iters\n","time = 156.0, epoch 11, iter = 10100, loss = 1.467197871208191, 38.33096885681152 s per 100 iters\n","time = 156.0, epoch 11, iter = 10200, loss = 1.4674400573968887, 37.303192377090454 s per 100 iters\n","time = 157.0, epoch 11, iter = 10300, loss = 1.4707304775714873, 37.54685688018799 s per 100 iters\n","time = 157.0, epoch 11, iter = 10400, loss = 1.4626964390277863, 38.477309226989746 s per 100 iters\n","time = 158.0, epoch 11, iter = 10500, loss = 1.4870330059528352, 38.457818031311035 s per 100 iters\n","time = 159.0, epoch 11, iter = 10600, loss = 1.4979590660333633, 38.608811140060425 s per 100 iters\n","time = 159.0, epoch 11, iter = 10700, loss = 1.4909636235237123, 38.60409355163574 s per 100 iters\n","time = 160.0, epoch 11, iter = 10800, loss = 1.48670345723629, 38.175246238708496 s per 100 iters\n","time = 161.0, epoch 11, iter = 10900, loss = 1.4811208158731461, 37.59905409812927 s per 100 iters\n","time = 161.0, epoch 11, iter = 11000, loss = 1.477892642021179, 37.919686794281006 s per 100 iters\n","time = 162.0, epoch 11, iter = 11100, loss = 1.494162569642067, 37.724297523498535 s per 100 iters\n","time = 163.0, epoch 11, iter = 11200, loss = 1.4818613106012344, 37.77112078666687 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 163.0, epoch 11, iter = 11300, loss = 1.4833331525325775, 37.561981201171875 s per 100 iters\n","time = 164.0, epoch 11, iter = 11400, loss = 1.4874040025472641, 38.22494602203369 s per 100 iters\n","time = 164.0, epoch 11, iter = 11500, loss = 1.5037028819322587, 38.82905626296997 s per 100 iters\n","time = 165.0, epoch 11, iter = 11600, loss = 1.4668024802207946, 37.49151062965393 s per 100 iters\n","time = 166.0, epoch 11, iter = 11700, loss = 1.5052462351322173, 37.73667097091675 s per 100 iters\n","time = 166.0, epoch 11, iter = 11800, loss = 1.48101023375988, 38.16902804374695 s per 100 iters\n","time = 167.0, epoch 11, iter = 11900, loss = 1.5016711097955704, 37.44663953781128 s per 100 iters\n","time = 168.0, epoch 11, iter = 12000, loss = 1.5151043450832367, 39.185131549835205 s per 100 iters\n","time = 168.0, epoch 11, iter = 12100, loss = 1.4890193730592727, 37.55423140525818 s per 100 iters\n","time = 169.0, epoch 11, iter = 12200, loss = 1.4705401986837388, 37.72795534133911 s per 100 iters\n","time = 170.0, epoch 11, iter = 12300, loss = 1.5037747824192047, 38.102763175964355 s per 100 iters\n","time = 170.0, epoch 11, iter = 12400, loss = 1.4832297575473785, 38.001954555511475 s per 100 iters\n","time = 171.0, epoch 11, iter = 12500, loss = 1.5124551248550415, 38.60589933395386 s per 100 iters\n","time = 171.0, epoch 11, iter = 12600, loss = 1.5055773770809173, 38.291011333465576 s per 100 iters\n","time = 172.0, epoch 11, iter = 12700, loss = 1.4711192524433137, 36.90809416770935 s per 100 iters\n","time = 173.0, epoch 11, iter = 12800, loss = 1.5005119240283966, 38.04389309883118 s per 100 iters\n","time = 173.0, epoch 11, iter = 12900, loss = 1.490966619849205, 38.53612399101257 s per 100 iters\n","time = 174.0, epoch 11, iter = 13000, loss = 1.489214334487915, 38.29983830451965 s per 100 iters\n","time = 175.0, epoch 11, iter = 13100, loss = 1.4823002636432647, 37.623960733413696 s per 100 iters\n","time = 175.0, epoch 11, iter = 13200, loss = 1.4643970984220505, 38.34011793136597 s per 100 iters\n","time = 176.0, epoch 11, iter = 13300, loss = 1.4986894935369492, 38.37769103050232 s per 100 iters\n","time = 176.0, epoch 11, iter = 13400, loss = 1.493322518467903, 37.23848748207092 s per 100 iters\n","time = 177.0, epoch 11, iter = 13500, loss = 1.5136602008342743, 39.6540207862854 s per 100 iters\n","time = 178.0, epoch 11, iter = 13600, loss = 1.5118991488218307, 38.291281938552856 s per 100 iters\n","time = 178.0, epoch 11, iter = 13700, loss = 1.486025121808052, 38.208885192871094 s per 100 iters\n","time = 179.0, epoch 11, iter = 13800, loss = 1.4891383337974549, 37.591214656829834 s per 100 iters\n","time = 180.0, epoch 11, iter = 13900, loss = 1.517368016242981, 39.48906660079956 s per 100 iters\n","time = 180.0, epoch 11, iter = 14000, loss = 1.502911577820778, 38.17834687232971 s per 100 iters\n","time = 181.0, epoch 11, iter = 14100, loss = 1.4774135750532151, 37.83780884742737 s per 100 iters\n","time = 182.0, epoch 11, iter = 14200, loss = 1.477778396010399, 38.45743989944458 s per 100 iters\n","time = 182.0, epoch 11, iter = 14300, loss = 1.4976917260885239, 37.91374206542969 s per 100 iters\n","--- Balidazioa ---\n","32.919236183166504 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina zer zen hura ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da arraroa ￭?', '｟C colinek berriro gelditu zuen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ongi jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, ｟C pirrone aitaren austeritatea eta ｟C don ｟C fabrizioren moduek ｟C donnafugatako jauregia ez zela ｟C capraro bandiduaren antroa ￭, eta seguraski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', 'magistratuek eta epailetza eta exekuzioetako beste ofizialek ￭, iruzkin artifizialak ￭, sarien eta zigorrak ￭, subiranotasunaren aldeko iskanbila eta kidea bere eginkizuna betetzeko mugitzen direnen truke ￭, nerbioak dira gorputz naturalean gauza bera egiten dutenak ￭; aberastasun partikularrak eta aberastasun partikularrak ￭, berriz ￭, botere legegileak ￭, herria ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, eta boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea ￭, boterea', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideala da ￭, eta agian beste inor ez ￭, gaur egun irudikatzen dute ￭, beraiek dira beren burugogorenak ￭, beren buruak ￭, gudari eta eskalari tropa aurreratuenak ￭, bere gaitasunik ezgaiena ￭, sedukzio-formarik delikatu eta desegokiena ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 12.169789349937043\n","8.727905750274658 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika oso interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C ezagutzen dugu ｟C corvettearen historia ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earl ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko al duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia erakusten ari diot 1960an eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C ze txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur al zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.9928334015519\n","BLEU puntuazioa (biak): 15.591363565697861\n","time = 184.0, epoch 12, iter = 100, loss = 1.3649175459146499, 39.458043813705444 s per 100 iters\n","time = 185.0, epoch 12, iter = 200, loss = 1.3431032282114028, 38.097670555114746 s per 100 iters\n","time = 185.0, epoch 12, iter = 300, loss = 1.3609942924976348, 38.35435128211975 s per 100 iters\n","time = 186.0, epoch 12, iter = 400, loss = 1.3783941888809204, 38.23116683959961 s per 100 iters\n","time = 186.0, epoch 12, iter = 500, loss = 1.3482322031259537, 37.82537913322449 s per 100 iters\n","time = 187.0, epoch 12, iter = 600, loss = 1.353544723391533, 38.23816275596619 s per 100 iters\n","time = 188.0, epoch 12, iter = 700, loss = 1.3680423980951308, 38.572696924209595 s per 100 iters\n","time = 188.0, epoch 12, iter = 800, loss = 1.3457579976320266, 37.36439108848572 s per 100 iters\n","time = 189.0, epoch 12, iter = 900, loss = 1.3608707332611083, 38.869701623916626 s per 100 iters\n","time = 190.0, epoch 12, iter = 1000, loss = 1.3469884669780732, 38.314619302749634 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 190.0, epoch 12, iter = 1100, loss = 1.3586564463377, 38.07439470291138 s per 100 iters\n","time = 191.0, epoch 12, iter = 1200, loss = 1.3654293471574783, 38.32462000846863 s per 100 iters\n","time = 192.0, epoch 12, iter = 1300, loss = 1.3731178921461105, 38.07117581367493 s per 100 iters\n","time = 192.0, epoch 12, iter = 1400, loss = 1.3645723658800124, 37.70051574707031 s per 100 iters\n","time = 193.0, epoch 12, iter = 1500, loss = 1.3761616122722626, 38.38824963569641 s per 100 iters\n","time = 193.0, epoch 12, iter = 1600, loss = 1.3694626367092133, 38.574164152145386 s per 100 iters\n","time = 194.0, epoch 12, iter = 1700, loss = 1.372444331049919, 38.96983551979065 s per 100 iters\n","time = 195.0, epoch 12, iter = 1800, loss = 1.3889873778820039, 38.244776248931885 s per 100 iters\n","time = 195.0, epoch 12, iter = 1900, loss = 1.3663693434000015, 38.36324334144592 s per 100 iters\n","time = 196.0, epoch 12, iter = 2000, loss = 1.378091983795166, 38.388792991638184 s per 100 iters\n","time = 197.0, epoch 12, iter = 2100, loss = 1.3844393277168274, 38.7740912437439 s per 100 iters\n","time = 197.0, epoch 12, iter = 2200, loss = 1.378328986763954, 38.3299503326416 s per 100 iters\n","time = 198.0, epoch 12, iter = 2300, loss = 1.3814492577314377, 37.82952356338501 s per 100 iters\n","time = 199.0, epoch 12, iter = 2400, loss = 1.3897772413492202, 38.65198230743408 s per 100 iters\n","time = 199.0, epoch 12, iter = 2500, loss = 1.3893392890691758, 38.20705318450928 s per 100 iters\n","time = 200.0, epoch 12, iter = 2600, loss = 1.3800066268444062, 38.983051776885986 s per 100 iters\n","time = 200.0, epoch 12, iter = 2700, loss = 1.3835683435201644, 38.98658633232117 s per 100 iters\n","time = 201.0, epoch 12, iter = 2800, loss = 1.3948823148012162, 38.762460708618164 s per 100 iters\n","time = 202.0, epoch 12, iter = 2900, loss = 1.4089557313919068, 38.31811237335205 s per 100 iters\n","time = 202.0, epoch 12, iter = 3000, loss = 1.38563338637352, 37.85737895965576 s per 100 iters\n","time = 203.0, epoch 12, iter = 3100, loss = 1.3835481709241868, 38.01366114616394 s per 100 iters\n","time = 204.0, epoch 12, iter = 3200, loss = 1.4045472186803818, 39.056856632232666 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 204.0, epoch 12, iter = 3300, loss = 1.4076048892736435, 37.74830389022827 s per 100 iters\n","time = 205.0, epoch 12, iter = 3400, loss = 1.410338585972786, 38.92722821235657 s per 100 iters\n","time = 206.0, epoch 12, iter = 3500, loss = 1.4024049574136734, 38.6429660320282 s per 100 iters\n","time = 206.0, epoch 12, iter = 3600, loss = 1.3982479286193847, 38.348644495010376 s per 100 iters\n","time = 207.0, epoch 12, iter = 3700, loss = 1.397677294611931, 37.751116037368774 s per 100 iters\n","time = 208.0, epoch 12, iter = 3800, loss = 1.3885071527957917, 38.72883224487305 s per 100 iters\n","time = 208.0, epoch 12, iter = 3900, loss = 1.4004879450798036, 38.07764768600464 s per 100 iters\n","time = 209.0, epoch 12, iter = 4000, loss = 1.4145831841230392, 38.28752827644348 s per 100 iters\n","time = 209.0, epoch 12, iter = 4100, loss = 1.4043274819850922, 38.646528482437134 s per 100 iters\n","time = 210.0, epoch 12, iter = 4200, loss = 1.4164906018972396, 37.96499180793762 s per 100 iters\n","time = 211.0, epoch 12, iter = 4300, loss = 1.4108530926704406, 38.78433918952942 s per 100 iters\n","time = 211.0, epoch 12, iter = 4400, loss = 1.394952540397644, 39.13862991333008 s per 100 iters\n","time = 212.0, epoch 12, iter = 4500, loss = 1.412459253668785, 38.4633092880249 s per 100 iters\n","time = 213.0, epoch 12, iter = 4600, loss = 1.399550304412842, 38.07961392402649 s per 100 iters\n","time = 213.0, epoch 12, iter = 4700, loss = 1.3942641115188599, 38.10434579849243 s per 100 iters\n","time = 214.0, epoch 12, iter = 4800, loss = 1.430907034277916, 39.14687395095825 s per 100 iters\n","time = 215.0, epoch 12, iter = 4900, loss = 1.4383645093441009, 38.849358558654785 s per 100 iters\n","time = 215.0, epoch 12, iter = 5000, loss = 1.411412245631218, 38.57011604309082 s per 100 iters\n","time = 216.0, epoch 12, iter = 5100, loss = 1.4246335291862489, 38.522249937057495 s per 100 iters\n","time = 216.0, epoch 12, iter = 5200, loss = 1.4052468836307526, 37.790369510650635 s per 100 iters\n","time = 217.0, epoch 12, iter = 5300, loss = 1.4177856516838074, 38.3689501285553 s per 100 iters\n","time = 218.0, epoch 12, iter = 5400, loss = 1.4159002542495727, 39.43202066421509 s per 100 iters\n","time = 218.0, epoch 12, iter = 5500, loss = 1.4059169882535933, 38.48544216156006 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 219.0, epoch 12, iter = 5600, loss = 1.407064825296402, 37.57808828353882 s per 100 iters\n","time = 220.0, epoch 12, iter = 5700, loss = 1.410577866435051, 38.612677335739136 s per 100 iters\n","time = 220.0, epoch 12, iter = 5800, loss = 1.4247220993041991, 37.84365439414978 s per 100 iters\n","time = 221.0, epoch 12, iter = 5900, loss = 1.424434158205986, 38.43617844581604 s per 100 iters\n","time = 222.0, epoch 12, iter = 6000, loss = 1.3930611276626588, 38.212955713272095 s per 100 iters\n","time = 222.0, epoch 12, iter = 6100, loss = 1.412343229651451, 38.1475465297699 s per 100 iters\n","time = 223.0, epoch 12, iter = 6200, loss = 1.416876620054245, 38.69074249267578 s per 100 iters\n","time = 224.0, epoch 12, iter = 6300, loss = 1.3971023219823837, 38.2197904586792 s per 100 iters\n","time = 224.0, epoch 12, iter = 6400, loss = 1.42732696890831, 38.737921953201294 s per 100 iters\n","time = 225.0, epoch 12, iter = 6500, loss = 1.4294585412740708, 38.640467405319214 s per 100 iters\n","time = 225.0, epoch 12, iter = 6600, loss = 1.4203709292411804, 38.09679102897644 s per 100 iters\n","time = 226.0, epoch 12, iter = 6700, loss = 1.4310804885625839, 38.697611808776855 s per 100 iters\n","time = 227.0, epoch 12, iter = 6800, loss = 1.4301032739877702, 38.60847282409668 s per 100 iters\n","time = 227.0, epoch 12, iter = 6900, loss = 1.4133149141073227, 37.71206450462341 s per 100 iters\n","time = 228.0, epoch 12, iter = 7000, loss = 1.4253546178340912, 37.835779905319214 s per 100 iters\n","time = 229.0, epoch 12, iter = 7100, loss = 1.4260330724716186, 38.93722748756409 s per 100 iters\n","time = 229.0, epoch 12, iter = 7200, loss = 1.4335297048091888, 38.79874849319458 s per 100 iters\n","time = 230.0, epoch 12, iter = 7300, loss = 1.4130190587043763, 38.826414585113525 s per 100 iters\n","time = 231.0, epoch 12, iter = 7400, loss = 1.4364361983537675, 38.11688423156738 s per 100 iters\n","time = 231.0, epoch 12, iter = 7500, loss = 1.434814733862877, 38.536240339279175 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 232.0, epoch 12, iter = 7600, loss = 1.444132615327835, 38.35153532028198 s per 100 iters\n","time = 232.0, epoch 12, iter = 7700, loss = 1.4133833891153336, 37.810224533081055 s per 100 iters\n","time = 233.0, epoch 12, iter = 7800, loss = 1.4162306761741639, 38.706408739089966 s per 100 iters\n","time = 234.0, epoch 12, iter = 7900, loss = 1.4413093799352645, 38.47204113006592 s per 100 iters\n","time = 234.0, epoch 12, iter = 8000, loss = 1.4260814255475998, 38.460856914520264 s per 100 iters\n","time = 235.0, epoch 12, iter = 8100, loss = 1.4524002182483673, 38.70648431777954 s per 100 iters\n","time = 236.0, epoch 12, iter = 8200, loss = 1.4291360366344452, 38.26108694076538 s per 100 iters\n","time = 236.0, epoch 12, iter = 8300, loss = 1.436457825899124, 38.68900418281555 s per 100 iters\n","time = 237.0, epoch 12, iter = 8400, loss = 1.4592533946037292, 38.490479946136475 s per 100 iters\n","time = 238.0, epoch 12, iter = 8500, loss = 1.425889778137207, 37.35045647621155 s per 100 iters\n","time = 238.0, epoch 12, iter = 8600, loss = 1.4412136560678481, 37.8669855594635 s per 100 iters\n","time = 239.0, epoch 12, iter = 8700, loss = 1.4362583476305009, 37.97045612335205 s per 100 iters\n","time = 240.0, epoch 12, iter = 8800, loss = 1.4273858541250228, 37.68695259094238 s per 100 iters\n","time = 240.0, epoch 12, iter = 8900, loss = 1.444252142906189, 38.57203912734985 s per 100 iters\n","time = 241.0, epoch 12, iter = 9000, loss = 1.422646746635437, 37.3823926448822 s per 100 iters\n","time = 241.0, epoch 12, iter = 9100, loss = 1.4476881462335587, 38.037208795547485 s per 100 iters\n","time = 242.0, epoch 12, iter = 9200, loss = 1.4546239364147187, 38.46128845214844 s per 100 iters\n","time = 243.0, epoch 12, iter = 9300, loss = 1.4390386700630189, 37.16883826255798 s per 100 iters\n","time = 243.0, epoch 12, iter = 9400, loss = 1.4434501713514327, 38.4512574672699 s per 100 iters\n","time = 244.0, epoch 12, iter = 9500, loss = 1.4484887492656708, 37.8442120552063 s per 100 iters\n","time = 245.0, epoch 12, iter = 9600, loss = 1.426544274687767, 38.02381348609924 s per 100 iters\n","time = 245.0, epoch 12, iter = 9700, loss = 1.453698189854622, 38.89973163604736 s per 100 iters\n","time = 246.0, epoch 12, iter = 9800, loss = 1.4398462557792664, 38.18183493614197 s per 100 iters\n","time = 246.0, epoch 12, iter = 9900, loss = 1.4480343180894852, 38.463964223861694 s per 100 iters\n","time = 247.0, epoch 12, iter = 10000, loss = 1.4654527199268341, 39.277000427246094 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 248.0, epoch 12, iter = 10100, loss = 1.4518647873401642, 38.66794991493225 s per 100 iters\n","time = 248.0, epoch 12, iter = 10200, loss = 1.4415370726585388, 37.824745416641235 s per 100 iters\n","time = 249.0, epoch 12, iter = 10300, loss = 1.449947277903557, 38.21548128128052 s per 100 iters\n","time = 250.0, epoch 12, iter = 10400, loss = 1.4470753931999207, 37.792661905288696 s per 100 iters\n","time = 250.0, epoch 12, iter = 10500, loss = 1.455451198220253, 38.23248767852783 s per 100 iters\n","time = 251.0, epoch 12, iter = 10600, loss = 1.4589444291591644, 38.09715032577515 s per 100 iters\n","time = 252.0, epoch 12, iter = 10700, loss = 1.4469645220041274, 38.165751934051514 s per 100 iters\n","time = 252.0, epoch 12, iter = 10800, loss = 1.4458884525299072, 37.890511989593506 s per 100 iters\n","time = 253.0, epoch 12, iter = 10900, loss = 1.4418989181518556, 38.06793761253357 s per 100 iters\n","time = 253.0, epoch 12, iter = 11000, loss = 1.4382084047794341, 37.625423192977905 s per 100 iters\n","time = 254.0, epoch 12, iter = 11100, loss = 1.4501427483558655, 38.43988561630249 s per 100 iters\n","time = 255.0, epoch 12, iter = 11200, loss = 1.4736827689409255, 38.59810447692871 s per 100 iters\n","time = 255.0, epoch 12, iter = 11300, loss = 1.4443840366601943, 38.36171817779541 s per 100 iters\n","time = 256.0, epoch 12, iter = 11400, loss = 1.4717637741565703, 38.98659348487854 s per 100 iters\n","time = 257.0, epoch 12, iter = 11500, loss = 1.4472959733009338, 38.30298733711243 s per 100 iters\n","time = 257.0, epoch 12, iter = 11600, loss = 1.4665982669591904, 38.643917083740234 s per 100 iters\n","time = 258.0, epoch 12, iter = 11700, loss = 1.4525823658704757, 37.641645193099976 s per 100 iters\n","time = 259.0, epoch 12, iter = 11800, loss = 1.4510850083827973, 38.60369277000427 s per 100 iters\n","time = 259.0, epoch 12, iter = 11900, loss = 1.4407965409755707, 37.558013916015625 s per 100 iters\n","time = 260.0, epoch 12, iter = 12000, loss = 1.456210137605667, 37.40170359611511 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 261.0, epoch 12, iter = 12100, loss = 1.462372623682022, 38.08239984512329 s per 100 iters\n","time = 261.0, epoch 12, iter = 12200, loss = 1.4342609280347824, 37.229520320892334 s per 100 iters\n","time = 262.0, epoch 12, iter = 12300, loss = 1.4604036420583726, 38.0162079334259 s per 100 iters\n","time = 262.0, epoch 12, iter = 12400, loss = 1.4672074949741363, 38.14313721656799 s per 100 iters\n","time = 263.0, epoch 12, iter = 12500, loss = 1.4488635325431825, 37.72716283798218 s per 100 iters\n","time = 264.0, epoch 12, iter = 12600, loss = 1.4592142152786254, 38.6808762550354 s per 100 iters\n","time = 264.0, epoch 12, iter = 12700, loss = 1.446286626458168, 38.670074462890625 s per 100 iters\n","time = 265.0, epoch 12, iter = 12800, loss = 1.4307554823160171, 36.984715938568115 s per 100 iters\n","time = 266.0, epoch 12, iter = 12900, loss = 1.441831620335579, 38.38296818733215 s per 100 iters\n","time = 266.0, epoch 12, iter = 13000, loss = 1.4692646610736846, 38.401463985443115 s per 100 iters\n","time = 267.0, epoch 12, iter = 13100, loss = 1.4523223340511322, 38.18276023864746 s per 100 iters\n","time = 267.0, epoch 12, iter = 13200, loss = 1.454105675816536, 37.57159972190857 s per 100 iters\n","time = 268.0, epoch 12, iter = 13300, loss = 1.453497539162636, 38.64696669578552 s per 100 iters\n","time = 269.0, epoch 12, iter = 13400, loss = 1.456529843211174, 38.43574500083923 s per 100 iters\n","time = 269.0, epoch 12, iter = 13500, loss = 1.4579165935516358, 38.330403327941895 s per 100 iters\n","time = 270.0, epoch 12, iter = 13600, loss = 1.4491510665416718, 38.921419858932495 s per 100 iters\n","time = 271.0, epoch 12, iter = 13700, loss = 1.4940587109327317, 39.74459528923035 s per 100 iters\n","time = 271.0, epoch 12, iter = 13800, loss = 1.4583525443077088, 38.57630634307861 s per 100 iters\n","time = 272.0, epoch 12, iter = 13900, loss = 1.4645865952968598, 38.16044235229492 s per 100 iters\n","time = 273.0, epoch 12, iter = 14000, loss = 1.462292588353157, 38.42843294143677 s per 100 iters\n","time = 273.0, epoch 12, iter = 14100, loss = 1.4561730074882506, 38.40298533439636 s per 100 iters\n","time = 274.0, epoch 12, iter = 14200, loss = 1.439769828915596, 37.81998133659363 s per 100 iters\n","time = 275.0, epoch 12, iter = 14300, loss = 1.4847512972354888, 38.43889904022217 s per 100 iters\n","--- Balidazioa ---\n","32.299798011779785 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C beranduegi da ordea ￭:', '｟C baina zer zen hura ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen ￭, lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, aita ｟C pirrone eta ｟C don ｟C fabrizioren portaera ￭, ｟C donnafugatako jauregia ez zela ｟C kapraro bandiduaren antroa ￭, eta seguraski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C aa ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta exekuzio-taldeko beste ofizialak ￭, argigarriak dira ￭; sarigarriak eta zigorrak ￭, subiranotasunaren egarri diren atal guztiak bere eginkizunaren betetzeko mugatzen baitira ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten duten nerbioak ￭; aberastasun partikularren indarra eta aberastasuna ￭, herri osasunaren edo segurtasunaren indarra dira ￭, hau guztia ordezkatzen dutenak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideal ￭, berek ￭, agian beste inork ez ￭, gaur egun irudikatzen dute ￭, berek berek ere beren sortzapen izpiritualena ￭, bere gerlari eta eskaaritza-talde aurreratua ￭, bere delikatuena ￭, sedukzio-forma sentibera eta desinteresgarria ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C derwatt-en kasuan eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 11.953223003487235\n","7.718055725097656 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C oso musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C korvetteren istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin hitz egin nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazki bat erakusten ari diot 1960an eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C ze txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaks-era dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.662068141190698\n","BLEU puntuazioa (biak): 15.348635278052575\n","time = 276.0, epoch 13, iter = 100, loss = 1.3143600857257842, 39.463809967041016 s per 100 iters\n","time = 277.0, epoch 13, iter = 200, loss = 1.3125199788808823, 38.90254783630371 s per 100 iters\n","time = 277.0, epoch 13, iter = 300, loss = 1.307298823595047, 38.41379499435425 s per 100 iters\n","time = 278.0, epoch 13, iter = 400, loss = 1.3320260566473008, 38.55266785621643 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 279.0, epoch 13, iter = 500, loss = 1.3176793098449706, 37.81329560279846 s per 100 iters\n","time = 279.0, epoch 13, iter = 600, loss = 1.3391965174674987, 39.20718955993652 s per 100 iters\n","time = 280.0, epoch 13, iter = 700, loss = 1.2920571404695511, 37.13713884353638 s per 100 iters\n","time = 281.0, epoch 13, iter = 800, loss = 1.3143660920858382, 37.70143675804138 s per 100 iters\n","time = 281.0, epoch 13, iter = 900, loss = 1.3229237329959869, 38.1387836933136 s per 100 iters\n","time = 282.0, epoch 13, iter = 1000, loss = 1.3162522101402283, 37.907657861709595 s per 100 iters\n","time = 283.0, epoch 13, iter = 1100, loss = 1.3361460745334626, 38.75386571884155 s per 100 iters\n","time = 283.0, epoch 13, iter = 1200, loss = 1.3282382738590242, 37.13585638999939 s per 100 iters\n","time = 284.0, epoch 13, iter = 1300, loss = 1.3209376239776611, 38.493499517440796 s per 100 iters\n","time = 284.0, epoch 13, iter = 1400, loss = 1.342412343621254, 38.420167207717896 s per 100 iters\n","time = 285.0, epoch 13, iter = 1500, loss = 1.3370441722869872, 38.70536923408508 s per 100 iters\n","time = 286.0, epoch 13, iter = 1600, loss = 1.3295945197343826, 39.04256272315979 s per 100 iters\n","time = 286.0, epoch 13, iter = 1700, loss = 1.3411060231924057, 37.76393508911133 s per 100 iters\n","time = 287.0, epoch 13, iter = 1800, loss = 1.3519643419981002, 38.56400775909424 s per 100 iters\n","time = 288.0, epoch 13, iter = 1900, loss = 1.3483911871910095, 38.701164960861206 s per 100 iters\n","time = 288.0, epoch 13, iter = 2000, loss = 1.3317476427555084, 37.61457443237305 s per 100 iters\n","time = 289.0, epoch 13, iter = 2100, loss = 1.3425441414117814, 39.135748863220215 s per 100 iters\n","time = 290.0, epoch 13, iter = 2200, loss = 1.3636627036333084, 38.26052188873291 s per 100 iters\n","time = 290.0, epoch 13, iter = 2300, loss = 1.3630328786373138, 38.34141755104065 s per 100 iters\n","time = 291.0, epoch 13, iter = 2400, loss = 1.366983967423439, 38.47395157814026 s per 100 iters\n","time = 291.0, epoch 13, iter = 2500, loss = 1.3452363044023514, 38.64246439933777 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 292.0, epoch 13, iter = 2600, loss = 1.353784791827202, 38.52742600440979 s per 100 iters\n","time = 293.0, epoch 13, iter = 2700, loss = 1.3489390885829926, 38.15044283866882 s per 100 iters\n","time = 293.0, epoch 13, iter = 2800, loss = 1.363083052635193, 38.10497856140137 s per 100 iters\n","time = 294.0, epoch 13, iter = 2900, loss = 1.3616668385267259, 37.935527086257935 s per 100 iters\n","time = 295.0, epoch 13, iter = 3000, loss = 1.3563737148046493, 37.629340410232544 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 295.0, epoch 13, iter = 3100, loss = 1.3567115157842635, 38.96010112762451 s per 100 iters\n","time = 296.0, epoch 13, iter = 3200, loss = 1.3543217879533769, 37.97096538543701 s per 100 iters\n","time = 297.0, epoch 13, iter = 3300, loss = 1.352515124976635, 39.25297808647156 s per 100 iters\n","time = 297.0, epoch 13, iter = 3400, loss = 1.3680916678905488, 38.605613470077515 s per 100 iters\n","time = 298.0, epoch 13, iter = 3500, loss = 1.3481228572130204, 36.97845458984375 s per 100 iters\n","time = 298.0, epoch 13, iter = 3600, loss = 1.3796215188503265, 39.383365869522095 s per 100 iters\n","time = 299.0, epoch 13, iter = 3700, loss = 1.3718194442987441, 38.95246171951294 s per 100 iters\n","time = 300.0, epoch 13, iter = 3800, loss = 1.3684931945800782, 38.978715896606445 s per 100 iters\n","time = 300.0, epoch 13, iter = 3900, loss = 1.3499568837881089, 37.819129943847656 s per 100 iters\n","time = 301.0, epoch 13, iter = 4000, loss = 1.3815416806936265, 38.454394578933716 s per 100 iters\n","time = 302.0, epoch 13, iter = 4100, loss = 1.364186588525772, 38.40356636047363 s per 100 iters\n","time = 302.0, epoch 13, iter = 4200, loss = 1.3565843212604523, 37.17120361328125 s per 100 iters\n","time = 303.0, epoch 13, iter = 4300, loss = 1.380403510928154, 38.57216238975525 s per 100 iters\n","time = 304.0, epoch 13, iter = 4400, loss = 1.3719730120897293, 38.49758577346802 s per 100 iters\n","time = 304.0, epoch 13, iter = 4500, loss = 1.3796988940238952, 38.78474187850952 s per 100 iters\n","time = 305.0, epoch 13, iter = 4600, loss = 1.37052150785923, 38.58642554283142 s per 100 iters\n","time = 306.0, epoch 13, iter = 4700, loss = 1.3855389314889908, 38.89985108375549 s per 100 iters\n","time = 306.0, epoch 13, iter = 4800, loss = 1.3741765058040618, 38.7109956741333 s per 100 iters\n","time = 307.0, epoch 13, iter = 4900, loss = 1.353560511469841, 38.49210858345032 s per 100 iters\n","time = 307.0, epoch 13, iter = 5000, loss = 1.394914894104004, 39.00942873954773 s per 100 iters\n","time = 308.0, epoch 13, iter = 5100, loss = 1.3822005957365036, 38.43691897392273 s per 100 iters\n","time = 309.0, epoch 13, iter = 5200, loss = 1.385347265601158, 37.457552671432495 s per 100 iters\n","time = 309.0, epoch 13, iter = 5300, loss = 1.3730655372142793, 37.8983952999115 s per 100 iters\n","time = 310.0, epoch 13, iter = 5400, loss = 1.4044343906641006, 38.35271668434143 s per 100 iters\n","time = 311.0, epoch 13, iter = 5500, loss = 1.3805285876989364, 37.89003801345825 s per 100 iters\n","time = 311.0, epoch 13, iter = 5600, loss = 1.3596149915456772, 38.30898404121399 s per 100 iters\n","time = 312.0, epoch 13, iter = 5700, loss = 1.410549442768097, 38.79585814476013 s per 100 iters\n","time = 313.0, epoch 13, iter = 5800, loss = 1.3947413653135299, 38.03924894332886 s per 100 iters\n","time = 313.0, epoch 13, iter = 5900, loss = 1.385203206539154, 39.17674469947815 s per 100 iters\n","time = 314.0, epoch 13, iter = 6000, loss = 1.37840511739254, 37.704511880874634 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 314.0, epoch 13, iter = 6100, loss = 1.4054846346378327, 39.198768615722656 s per 100 iters\n","time = 315.0, epoch 13, iter = 6200, loss = 1.3647930401563644, 38.039626359939575 s per 100 iters\n","time = 316.0, epoch 13, iter = 6300, loss = 1.3857098889350892, 38.71189522743225 s per 100 iters\n","time = 316.0, epoch 13, iter = 6400, loss = 1.3795871919393539, 38.71565341949463 s per 100 iters\n","time = 317.0, epoch 13, iter = 6500, loss = 1.3777586257457732, 38.21063017845154 s per 100 iters\n","time = 318.0, epoch 13, iter = 6600, loss = 1.411296935081482, 38.84029698371887 s per 100 iters\n","time = 318.0, epoch 13, iter = 6700, loss = 1.3901543444395066, 37.43111872673035 s per 100 iters\n","time = 319.0, epoch 13, iter = 6800, loss = 1.3824354326725006, 38.33446645736694 s per 100 iters\n","time = 320.0, epoch 13, iter = 6900, loss = 1.3925874149799347, 37.94014763832092 s per 100 iters\n","time = 320.0, epoch 13, iter = 7000, loss = 1.4128845244646073, 38.314765214920044 s per 100 iters\n","time = 321.0, epoch 13, iter = 7100, loss = 1.3783860504627228, 37.93838953971863 s per 100 iters\n","time = 322.0, epoch 13, iter = 7200, loss = 1.412058275938034, 39.197333574295044 s per 100 iters\n","time = 322.0, epoch 13, iter = 7300, loss = 1.3993919920921325, 38.382970094680786 s per 100 iters\n","time = 323.0, epoch 13, iter = 7400, loss = 1.4006682431697846, 38.19632697105408 s per 100 iters\n","time = 323.0, epoch 13, iter = 7500, loss = 1.3879382938146592, 37.537840366363525 s per 100 iters\n","time = 324.0, epoch 13, iter = 7600, loss = 1.3867294156551362, 38.09422779083252 s per 100 iters\n","time = 325.0, epoch 13, iter = 7700, loss = 1.3883894181251526, 38.283798933029175 s per 100 iters\n","time = 325.0, epoch 13, iter = 7800, loss = 1.393821566104889, 38.88333821296692 s per 100 iters\n","time = 326.0, epoch 13, iter = 7900, loss = 1.398475387096405, 38.630281925201416 s per 100 iters\n","time = 327.0, epoch 13, iter = 8000, loss = 1.407953069806099, 37.46814441680908 s per 100 iters\n","time = 327.0, epoch 13, iter = 8100, loss = 1.424616552591324, 38.49919843673706 s per 100 iters\n","time = 328.0, epoch 13, iter = 8200, loss = 1.4217736321687697, 38.47963261604309 s per 100 iters\n","time = 329.0, epoch 13, iter = 8300, loss = 1.409523795247078, 38.195802211761475 s per 100 iters\n","time = 329.0, epoch 13, iter = 8400, loss = 1.4005002200603485, 37.71735143661499 s per 100 iters\n","time = 330.0, epoch 13, iter = 8500, loss = 1.3970544987916946, 38.264676332473755 s per 100 iters\n","time = 330.0, epoch 13, iter = 8600, loss = 1.413024855852127, 38.5783166885376 s per 100 iters\n","time = 331.0, epoch 13, iter = 8700, loss = 1.4246708506345749, 38.89447355270386 s per 100 iters\n","time = 332.0, epoch 13, iter = 8800, loss = 1.3880042040348053, 38.536519289016724 s per 100 iters\n","time = 332.0, epoch 13, iter = 8900, loss = 1.4063526213169097, 38.83937335014343 s per 100 iters\n","time = 333.0, epoch 13, iter = 9000, loss = 1.3957047468423844, 37.453453063964844 s per 100 iters\n","time = 334.0, epoch 13, iter = 9100, loss = 1.4003155106306076, 38.71020483970642 s per 100 iters\n","time = 334.0, epoch 13, iter = 9200, loss = 1.3977973955869674, 38.18833923339844 s per 100 iters\n","time = 335.0, epoch 13, iter = 9300, loss = 1.3988582730293273, 37.50692892074585 s per 100 iters\n","time = 336.0, epoch 13, iter = 9400, loss = 1.4062386959791184, 37.43044710159302 s per 100 iters\n","time = 336.0, epoch 13, iter = 9500, loss = 1.4123865395784378, 38.42718267440796 s per 100 iters\n","time = 337.0, epoch 13, iter = 9600, loss = 1.4136179679632186, 38.043864250183105 s per 100 iters\n","time = 337.0, epoch 13, iter = 9700, loss = 1.414124528169632, 38.38882255554199 s per 100 iters\n","time = 338.0, epoch 13, iter = 9800, loss = 1.4117599135637284, 37.853344440460205 s per 100 iters\n","time = 339.0, epoch 13, iter = 9900, loss = 1.4185870534181595, 38.66526412963867 s per 100 iters\n","time = 339.0, epoch 13, iter = 10000, loss = 1.4118645924329758, 37.64398741722107 s per 100 iters\n","time = 340.0, epoch 13, iter = 10100, loss = 1.407650311589241, 37.72864389419556 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 341.0, epoch 13, iter = 10200, loss = 1.4168542528152466, 37.02294898033142 s per 100 iters\n","time = 341.0, epoch 13, iter = 10300, loss = 1.4203114485740662, 38.457146644592285 s per 100 iters\n","time = 342.0, epoch 13, iter = 10400, loss = 1.4234854155778884, 38.45851945877075 s per 100 iters\n","time = 343.0, epoch 13, iter = 10500, loss = 1.4171878176927566, 38.83187961578369 s per 100 iters\n","time = 343.0, epoch 13, iter = 10600, loss = 1.409039604663849, 38.702017307281494 s per 100 iters\n","time = 344.0, epoch 13, iter = 10700, loss = 1.4302364337444304, 39.14207315444946 s per 100 iters\n","time = 344.0, epoch 13, iter = 10800, loss = 1.4056015455722808, 38.23176193237305 s per 100 iters\n","time = 345.0, epoch 13, iter = 10900, loss = 1.413850189447403, 38.218653440475464 s per 100 iters\n","time = 346.0, epoch 13, iter = 11000, loss = 1.4144391989707947, 37.93961143493652 s per 100 iters\n","time = 346.0, epoch 13, iter = 11100, loss = 1.4137674731016159, 37.893845319747925 s per 100 iters\n","time = 347.0, epoch 13, iter = 11200, loss = 1.427258980870247, 38.370720624923706 s per 100 iters\n","time = 348.0, epoch 13, iter = 11300, loss = 1.4268524330854415, 37.35844135284424 s per 100 iters\n","time = 348.0, epoch 13, iter = 11400, loss = 1.4247907894849776, 38.456340074539185 s per 100 iters\n","time = 349.0, epoch 13, iter = 11500, loss = 1.4173520070314407, 38.07946562767029 s per 100 iters\n","time = 350.0, epoch 13, iter = 11600, loss = 1.431529091000557, 38.03532338142395 s per 100 iters\n","time = 350.0, epoch 13, iter = 11700, loss = 1.4225019884109498, 38.05822277069092 s per 100 iters\n","time = 351.0, epoch 13, iter = 11800, loss = 1.3947542715072632, 36.82028913497925 s per 100 iters\n","time = 351.0, epoch 13, iter = 11900, loss = 1.4328173828125, 38.83594846725464 s per 100 iters\n","time = 352.0, epoch 13, iter = 12000, loss = 1.4195141673088074, 37.84420919418335 s per 100 iters\n","time = 353.0, epoch 13, iter = 12100, loss = 1.4168730372190474, 38.32603120803833 s per 100 iters\n","time = 353.0, epoch 13, iter = 12200, loss = 1.442839383482933, 37.8757119178772 s per 100 iters\n","time = 354.0, epoch 13, iter = 12300, loss = 1.4320149648189544, 37.97356724739075 s per 100 iters\n","time = 355.0, epoch 13, iter = 12400, loss = 1.4224993467330933, 37.9802041053772 s per 100 iters\n","time = 355.0, epoch 13, iter = 12500, loss = 1.4264960658550263, 38.03993344306946 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 356.0, epoch 13, iter = 12600, loss = 1.4130868017673492, 37.337788581848145 s per 100 iters\n","time = 356.0, epoch 13, iter = 12700, loss = 1.4389090299606324, 38.54497313499451 s per 100 iters\n","time = 357.0, epoch 13, iter = 12800, loss = 1.450784061551094, 38.444021463394165 s per 100 iters\n","time = 358.0, epoch 13, iter = 12900, loss = 1.4244374227523804, 37.61776089668274 s per 100 iters\n","time = 358.0, epoch 13, iter = 13000, loss = 1.4271586883068084, 37.937671184539795 s per 100 iters\n","time = 359.0, epoch 13, iter = 13100, loss = 1.4267751199007035, 38.26167273521423 s per 100 iters\n","time = 360.0, epoch 13, iter = 13200, loss = 1.415531298518181, 37.962562084198 s per 100 iters\n","time = 360.0, epoch 13, iter = 13300, loss = 1.4218915265798568, 38.035128355026245 s per 100 iters\n","time = 361.0, epoch 13, iter = 13400, loss = 1.4270739710330964, 37.951212644577026 s per 100 iters\n","time = 362.0, epoch 13, iter = 13500, loss = 1.428018235564232, 38.46618366241455 s per 100 iters\n","time = 362.0, epoch 13, iter = 13600, loss = 1.4413776397705078, 38.679147481918335 s per 100 iters\n","time = 363.0, epoch 13, iter = 13700, loss = 1.4212324649095536, 37.6965651512146 s per 100 iters\n","time = 363.0, epoch 13, iter = 13800, loss = 1.4104739993810653, 37.6890082359314 s per 100 iters\n","time = 364.0, epoch 13, iter = 13900, loss = 1.434455575942993, 37.469417572021484 s per 100 iters\n","time = 365.0, epoch 13, iter = 14000, loss = 1.4387191981077194, 38.70564150810242 s per 100 iters\n","time = 365.0, epoch 13, iter = 14100, loss = 1.458091294169426, 38.73688626289368 s per 100 iters\n","time = 366.0, epoch 13, iter = 14200, loss = 1.4517384272813798, 38.52135133743286 s per 100 iters\n","time = 367.0, epoch 13, iter = 14300, loss = 1.4377540290355681, 38.149880170822144 s per 100 iters\n","--- Balidazioa ---\n","31.75317645072937 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina zer zen hura ￭?', '｟B rosanna spearman ｟E', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ongi jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarmak ￭, aita ｟C pirrone eta ｟C don ｟C fabrizioren portaerak ￭, ｟C donnafugatako jauregia ez zela ｟C kapraro bandidoaren antroa ￭, eta seguraski bizirik irtengo zela segurutik ￭.', '｟C denek erosten zuten ￭.', '｟C ederra zen ￭.', '｟C aaaaa ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza eta exekuzioko beste ofizialak artifizialak dira ￭; saria eta zigorra ￭, subiranotasunaren aulkira eta kide bakoitza bere zereginari betetzeko mugitzen direnen truke ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭; botere partikularraren aberastasunak eta aberastasun guztiak ￭, herri populus edo populusaren segurtasuna dira ￭, hau da ￭, gauza guztien aholkularia ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideal ￭, beraiek ￭, agian beste inor ez ￭, gaur egun irudikatzen dute ￭, beraiek dira beren artean beren eragikorrik izpiritualena ￭, bere esploratzaile eta eskaaritza talde aurreratua ￭, bere sentikortasunik ezgaiena ￭, sedukzio-forma ulertezin eta desegokia ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 12.029533854574563\n","8.85862684249878 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria eskuratzen duela ￭?', '｟C ezagutzen dugu ｟C corvettearen istorioa ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendeku bila etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo al duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoen bat egongo da basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. bost axola zaizu ￭?', '｟C eta argazkia erakutsi nahi diot 1960an eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.730020547696263\n","BLEU puntuazioa (biak): 15.421018880238401\n","time = 368.0, epoch 14, iter = 100, loss = 1.2831331938505173, 38.97777533531189 s per 100 iters\n","time = 369.0, epoch 14, iter = 200, loss = 1.2896709883213042, 38.32078957557678 s per 100 iters\n","time = 370.0, epoch 14, iter = 300, loss = 1.2800350219011307, 38.475114822387695 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 370.0, epoch 14, iter = 400, loss = 1.2753979894518852, 37.87423014640808 s per 100 iters\n","time = 371.0, epoch 14, iter = 500, loss = 1.2984311610460282, 38.081392765045166 s per 100 iters\n","time = 371.0, epoch 14, iter = 600, loss = 1.2857072162628174, 38.286789894104004 s per 100 iters\n","time = 372.0, epoch 14, iter = 700, loss = 1.291777200102806, 38.283584117889404 s per 100 iters\n","time = 373.0, epoch 14, iter = 800, loss = 1.3071104151010513, 38.04159688949585 s per 100 iters\n","time = 373.0, epoch 14, iter = 900, loss = 1.2826813572645188, 37.93849182128906 s per 100 iters\n","time = 374.0, epoch 14, iter = 1000, loss = 1.3027811175584794, 38.10884404182434 s per 100 iters\n","time = 375.0, epoch 14, iter = 1100, loss = 1.296705271601677, 37.78608202934265 s per 100 iters\n","time = 375.0, epoch 14, iter = 1200, loss = 1.303277930021286, 37.812235832214355 s per 100 iters\n","time = 376.0, epoch 14, iter = 1300, loss = 1.3065451878309249, 38.34538769721985 s per 100 iters\n","time = 377.0, epoch 14, iter = 1400, loss = 1.3111088448762893, 38.03440761566162 s per 100 iters\n","time = 377.0, epoch 14, iter = 1500, loss = 1.2986756896972655, 38.862207889556885 s per 100 iters\n","time = 378.0, epoch 14, iter = 1600, loss = 1.2928736102581024, 38.34993648529053 s per 100 iters\n","time = 378.0, epoch 14, iter = 1700, loss = 1.2938947105407714, 38.69871187210083 s per 100 iters\n","time = 379.0, epoch 14, iter = 1800, loss = 1.3226348012685776, 39.007732629776 s per 100 iters\n","time = 380.0, epoch 14, iter = 1900, loss = 1.3137629103660584, 38.58716559410095 s per 100 iters\n","time = 380.0, epoch 14, iter = 2000, loss = 1.324101119041443, 38.71252369880676 s per 100 iters\n","time = 381.0, epoch 14, iter = 2100, loss = 1.3101807326078414, 38.169233560562134 s per 100 iters\n","time = 382.0, epoch 14, iter = 2200, loss = 1.308831530213356, 37.51095390319824 s per 100 iters\n","time = 382.0, epoch 14, iter = 2300, loss = 1.3168574595451354, 38.45163035392761 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 383.0, epoch 14, iter = 2400, loss = 1.3186586368083955, 39.14595103263855 s per 100 iters\n","time = 384.0, epoch 14, iter = 2500, loss = 1.3088934177160263, 38.514323234558105 s per 100 iters\n","time = 384.0, epoch 14, iter = 2600, loss = 1.3247390329837798, 37.99160814285278 s per 100 iters\n","time = 385.0, epoch 14, iter = 2700, loss = 1.3265073537826537, 37.567774057388306 s per 100 iters\n","time = 385.0, epoch 14, iter = 2800, loss = 1.3159766799211503, 37.669970750808716 s per 100 iters\n","time = 386.0, epoch 14, iter = 2900, loss = 1.3488908535242081, 38.691890716552734 s per 100 iters\n","time = 387.0, epoch 14, iter = 3000, loss = 1.3298665648698806, 38.16871356964111 s per 100 iters\n","time = 387.0, epoch 14, iter = 3100, loss = 1.3304899531602858, 38.15813755989075 s per 100 iters\n","time = 388.0, epoch 14, iter = 3200, loss = 1.3445100647211075, 39.209880113601685 s per 100 iters\n","time = 389.0, epoch 14, iter = 3300, loss = 1.3192444682121276, 37.868852615356445 s per 100 iters\n","time = 389.0, epoch 14, iter = 3400, loss = 1.3386217314004898, 37.2994384765625 s per 100 iters\n","time = 390.0, epoch 14, iter = 3500, loss = 1.3351711761951446, 38.66227841377258 s per 100 iters\n","time = 391.0, epoch 14, iter = 3600, loss = 1.3195313400030135, 37.30556082725525 s per 100 iters\n","time = 391.0, epoch 14, iter = 3700, loss = 1.339512187242508, 38.95976543426514 s per 100 iters\n","time = 392.0, epoch 14, iter = 3800, loss = 1.3353287202119828, 37.41647791862488 s per 100 iters\n","time = 392.0, epoch 14, iter = 3900, loss = 1.340058098435402, 37.622684478759766 s per 100 iters\n","time = 393.0, epoch 14, iter = 4000, loss = 1.3335708743333816, 37.93550729751587 s per 100 iters\n","time = 394.0, epoch 14, iter = 4100, loss = 1.3313953793048858, 38.26311445236206 s per 100 iters\n","time = 394.0, epoch 14, iter = 4200, loss = 1.3467224711179733, 38.40555810928345 s per 100 iters\n","time = 395.0, epoch 14, iter = 4300, loss = 1.3370856428146363, 38.6021363735199 s per 100 iters\n","time = 396.0, epoch 14, iter = 4400, loss = 1.3331468638777733, 38.516149282455444 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 396.0, epoch 14, iter = 4500, loss = 1.3488760340213775, 38.28857946395874 s per 100 iters\n","time = 397.0, epoch 14, iter = 4600, loss = 1.3420008224248887, 38.172964096069336 s per 100 iters\n","time = 398.0, epoch 14, iter = 4700, loss = 1.3355746394395829, 37.72324013710022 s per 100 iters\n","time = 398.0, epoch 14, iter = 4800, loss = 1.3558810150623322, 37.931782245635986 s per 100 iters\n","time = 399.0, epoch 14, iter = 4900, loss = 1.3452803540229796, 38.38482332229614 s per 100 iters\n","time = 399.0, epoch 14, iter = 5000, loss = 1.3607654821872712, 37.90396785736084 s per 100 iters\n","time = 400.0, epoch 14, iter = 5100, loss = 1.3445978665351868, 37.715944051742554 s per 100 iters\n","time = 401.0, epoch 14, iter = 5200, loss = 1.3480861884355546, 38.01604890823364 s per 100 iters\n","time = 401.0, epoch 14, iter = 5300, loss = 1.3487653201818466, 37.69283080101013 s per 100 iters\n","time = 402.0, epoch 14, iter = 5400, loss = 1.3574850779771805, 38.06251096725464 s per 100 iters\n","time = 403.0, epoch 14, iter = 5500, loss = 1.3568181788921356, 38.021360874176025 s per 100 iters\n","time = 403.0, epoch 14, iter = 5600, loss = 1.3617068201303482, 38.550896644592285 s per 100 iters\n","time = 404.0, epoch 14, iter = 5700, loss = 1.3349392533302307, 37.24335026741028 s per 100 iters\n","time = 405.0, epoch 14, iter = 5800, loss = 1.3847075563669204, 38.30491781234741 s per 100 iters\n","time = 405.0, epoch 14, iter = 5900, loss = 1.3787505519390106, 38.05694818496704 s per 100 iters\n","time = 406.0, epoch 14, iter = 6000, loss = 1.3512105119228364, 38.40738892555237 s per 100 iters\n","time = 406.0, epoch 14, iter = 6100, loss = 1.35282876431942, 38.180179595947266 s per 100 iters\n","time = 407.0, epoch 14, iter = 6200, loss = 1.3305074268579482, 37.69081425666809 s per 100 iters\n","time = 408.0, epoch 14, iter = 6300, loss = 1.3644524711370467, 38.36510872840881 s per 100 iters\n","time = 408.0, epoch 14, iter = 6400, loss = 1.363933853507042, 38.30239200592041 s per 100 iters\n","time = 409.0, epoch 14, iter = 6500, loss = 1.3536438584327697, 37.88996648788452 s per 100 iters\n","time = 410.0, epoch 14, iter = 6600, loss = 1.3662055492401124, 37.911153078079224 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 410.0, epoch 14, iter = 6700, loss = 1.358521655201912, 37.729711294174194 s per 100 iters\n","time = 411.0, epoch 14, iter = 6800, loss = 1.3610353398323058, 38.10585832595825 s per 100 iters\n","time = 412.0, epoch 14, iter = 6900, loss = 1.3486641097068786, 37.80177974700928 s per 100 iters\n","time = 412.0, epoch 14, iter = 7000, loss = 1.3837961488962174, 38.836307764053345 s per 100 iters\n","time = 413.0, epoch 14, iter = 7100, loss = 1.3623525083065033, 37.44847512245178 s per 100 iters\n","time = 413.0, epoch 14, iter = 7200, loss = 1.3854432874917983, 38.56298089027405 s per 100 iters\n","time = 414.0, epoch 14, iter = 7300, loss = 1.358260189294815, 37.80717444419861 s per 100 iters\n","time = 415.0, epoch 14, iter = 7400, loss = 1.3588708055019378, 38.047548055648804 s per 100 iters\n","time = 415.0, epoch 14, iter = 7500, loss = 1.3661141449213028, 37.93962097167969 s per 100 iters\n","time = 416.0, epoch 14, iter = 7600, loss = 1.3703702563047409, 37.811649560928345 s per 100 iters\n","time = 417.0, epoch 14, iter = 7700, loss = 1.3746168690919875, 38.453887939453125 s per 100 iters\n","time = 417.0, epoch 14, iter = 7800, loss = 1.371319019794464, 38.2486412525177 s per 100 iters\n","time = 418.0, epoch 14, iter = 7900, loss = 1.367464075088501, 37.590237617492676 s per 100 iters\n","time = 418.0, epoch 14, iter = 8000, loss = 1.3782670253515243, 37.26736116409302 s per 100 iters\n","time = 419.0, epoch 14, iter = 8100, loss = 1.3845929753780366, 38.34788250923157 s per 100 iters\n","time = 420.0, epoch 14, iter = 8200, loss = 1.369079201221466, 38.06019997596741 s per 100 iters\n","time = 420.0, epoch 14, iter = 8300, loss = 1.3737404054403306, 37.16356182098389 s per 100 iters\n","time = 421.0, epoch 14, iter = 8400, loss = 1.3900334680080413, 38.49100661277771 s per 100 iters\n","time = 422.0, epoch 14, iter = 8500, loss = 1.371034276485443, 38.41716694831848 s per 100 iters\n","time = 422.0, epoch 14, iter = 8600, loss = 1.3870449924468995, 37.67718720436096 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 423.0, epoch 14, iter = 8700, loss = 1.365699844956398, 36.71613311767578 s per 100 iters\n","time = 424.0, epoch 14, iter = 8800, loss = 1.3665804558992385, 37.38594460487366 s per 100 iters\n","time = 424.0, epoch 14, iter = 8900, loss = 1.3875695890188218, 38.60101008415222 s per 100 iters\n","time = 425.0, epoch 14, iter = 9000, loss = 1.3573319280147553, 37.36774444580078 s per 100 iters\n","time = 425.0, epoch 14, iter = 9100, loss = 1.3895590311288835, 37.91892623901367 s per 100 iters\n","time = 426.0, epoch 14, iter = 9200, loss = 1.3701658207178116, 37.9961884021759 s per 100 iters\n","time = 427.0, epoch 14, iter = 9300, loss = 1.3736710852384568, 37.371591567993164 s per 100 iters\n","time = 427.0, epoch 14, iter = 9400, loss = 1.3694281482696533, 38.70870327949524 s per 100 iters\n","time = 428.0, epoch 14, iter = 9500, loss = 1.4022231709957123, 38.04797148704529 s per 100 iters\n","time = 429.0, epoch 14, iter = 9600, loss = 1.3787760424613953, 38.352887868881226 s per 100 iters\n","time = 429.0, epoch 14, iter = 9700, loss = 1.3691948795318603, 38.0357940196991 s per 100 iters\n","time = 430.0, epoch 14, iter = 9800, loss = 1.392309329509735, 37.82836079597473 s per 100 iters\n","time = 430.0, epoch 14, iter = 9900, loss = 1.374450719356537, 37.86539959907532 s per 100 iters\n","time = 431.0, epoch 14, iter = 10000, loss = 1.375990654230118, 38.16168403625488 s per 100 iters\n","time = 432.0, epoch 14, iter = 10100, loss = 1.3741832172870636, 37.483322620391846 s per 100 iters\n","time = 432.0, epoch 14, iter = 10200, loss = 1.3686532807350158, 37.62288236618042 s per 100 iters\n","time = 433.0, epoch 14, iter = 10300, loss = 1.4063858383893966, 37.56137657165527 s per 100 iters\n","time = 434.0, epoch 14, iter = 10400, loss = 1.3942452865839003, 37.59981918334961 s per 100 iters\n","time = 434.0, epoch 14, iter = 10500, loss = 1.408330944776535, 38.17369270324707 s per 100 iters\n","time = 435.0, epoch 14, iter = 10600, loss = 1.3870436000823974, 37.3380606174469 s per 100 iters\n","time = 436.0, epoch 14, iter = 10700, loss = 1.3890778881311416, 37.317944049835205 s per 100 iters\n","time = 436.0, epoch 14, iter = 10800, loss = 1.388740069270134, 37.68862318992615 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 437.0, epoch 14, iter = 10900, loss = 1.3859387809038162, 37.168009996414185 s per 100 iters\n","time = 437.0, epoch 14, iter = 11000, loss = 1.3949893093109131, 38.51195454597473 s per 100 iters\n","time = 438.0, epoch 14, iter = 11100, loss = 1.3880210626125336, 37.64673972129822 s per 100 iters\n","time = 439.0, epoch 14, iter = 11200, loss = 1.37421071767807, 37.20110082626343 s per 100 iters\n","time = 439.0, epoch 14, iter = 11300, loss = 1.3903960573673249, 38.75643968582153 s per 100 iters\n","time = 440.0, epoch 14, iter = 11400, loss = 1.4033418965339661, 38.50416707992554 s per 100 iters\n","time = 441.0, epoch 14, iter = 11500, loss = 1.3970513767004014, 38.02132248878479 s per 100 iters\n","time = 441.0, epoch 14, iter = 11600, loss = 1.400856602191925, 38.101335763931274 s per 100 iters\n","time = 442.0, epoch 14, iter = 11700, loss = 1.3663199162483215, 38.3932888507843 s per 100 iters\n","time = 442.0, epoch 14, iter = 11800, loss = 1.4021998572349548, 38.18250751495361 s per 100 iters\n","time = 443.0, epoch 14, iter = 11900, loss = 1.4098916405439377, 38.160953521728516 s per 100 iters\n","time = 444.0, epoch 14, iter = 12000, loss = 1.3966134124994278, 37.55105113983154 s per 100 iters\n","time = 444.0, epoch 14, iter = 12100, loss = 1.3899014538526535, 37.786555767059326 s per 100 iters\n","time = 445.0, epoch 14, iter = 12200, loss = 1.395793341398239, 38.10513377189636 s per 100 iters\n","time = 446.0, epoch 14, iter = 12300, loss = 1.3869520604610444, 37.600430488586426 s per 100 iters\n","time = 446.0, epoch 14, iter = 12400, loss = 1.3849340403079986, 37.715768575668335 s per 100 iters\n","time = 447.0, epoch 14, iter = 12500, loss = 1.398620536327362, 38.092679262161255 s per 100 iters\n","time = 448.0, epoch 14, iter = 12600, loss = 1.3871020185947418, 37.14830493927002 s per 100 iters\n","time = 448.0, epoch 14, iter = 12700, loss = 1.4006480741500855, 37.70592451095581 s per 100 iters\n","time = 449.0, epoch 14, iter = 12800, loss = 1.38742631316185, 37.71129274368286 s per 100 iters\n","time = 449.0, epoch 14, iter = 12900, loss = 1.4028963261842728, 38.65260934829712 s per 100 iters\n","time = 450.0, epoch 14, iter = 13000, loss = 1.3890640860795975, 38.27656102180481 s per 100 iters\n","time = 451.0, epoch 14, iter = 13100, loss = 1.3921769416332246, 37.47143292427063 s per 100 iters\n","time = 451.0, epoch 14, iter = 13200, loss = 1.4117248457670213, 37.89690613746643 s per 100 iters\n","time = 452.0, epoch 14, iter = 13300, loss = 1.403141211271286, 38.12840676307678 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 453.0, epoch 14, iter = 13400, loss = 1.3957110875844956, 37.951467514038086 s per 100 iters\n","time = 453.0, epoch 14, iter = 13500, loss = 1.3941427457332611, 38.30192518234253 s per 100 iters\n","time = 454.0, epoch 14, iter = 13600, loss = 1.403767676949501, 37.39111375808716 s per 100 iters\n","time = 454.0, epoch 14, iter = 13700, loss = 1.42959712266922, 38.331050157547 s per 100 iters\n","time = 455.0, epoch 14, iter = 13800, loss = 1.4112456154823303, 37.862287521362305 s per 100 iters\n","time = 456.0, epoch 14, iter = 13900, loss = 1.4095631909370423, 37.87062978744507 s per 100 iters\n","time = 456.0, epoch 14, iter = 14000, loss = 1.3934158211946488, 37.513975620269775 s per 100 iters\n","time = 457.0, epoch 14, iter = 14100, loss = 1.391323782801628, 37.856035232543945 s per 100 iters\n","time = 458.0, epoch 14, iter = 14200, loss = 1.4143253618478775, 37.73420572280884 s per 100 iters\n","time = 458.0, epoch 14, iter = 14300, loss = 1.4052585417032242, 37.987245082855225 s per 100 iters\n","--- Balidazioa ---\n","31.787437915802002 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina zer zen hura ￭?', '｟C rosanna ｟C spearman ￭.', '｟C ez al da bitxia ￭?', '｟C colin berriro gelditu zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarmak ￭, aita ｟C pirrone-ren austeritateak eta ｟C don ｟C fabrizioren moduek ｟C donnafugatako jauregia ez zela ｟C kapraro bandidoaren antroa ￭, eta seguru aski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza eta exekuzioko beste ofizialak ￭, zigor eta zigorrak ￭, subiranotasunaren egoitzari dagozkion kide guztiak ￭, bere eginkizunari dagozkion zainak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭; gorputz bakoitzaren aberastasun eta aberastasun eta aberastasunek ￭, indar salulus edo aberastasunek ￭, herri honen helburua ￭, hau da ￭, gauza partikular guztien aholkuak ￭, aholkulariak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori bera ere beren ideala besterik ez da ￭, eta agian beste inor ez dute irudikatzen gaur egun ￭, beraiek dira beren sortzapen izpiritualizatuenak ￭, bere esploratzaile eta esploratzaileen talde aurreratuenak ￭, bere gaitasunik fin eta delikatuena ￭, sedukzio-forma sentigarriena ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C derwatt-en kasuan ￭, orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 12.126009945092303\n","8.05088472366333 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvettearen historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo al duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoen bat egongo da basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia erakusten diot 1960an eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C zoaz lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C merryk badakiela ￭?']\n","BLEU puntuazioa (2): 26.27327042965173\n","BLEU puntuazioa (biak): 15.385839559222244\n","time = 460.0, epoch 15, iter = 100, loss = 1.2603986430168153, 39.22779989242554 s per 100 iters\n","time = 460.0, epoch 15, iter = 200, loss = 1.2483293527364732, 37.90471315383911 s per 100 iters\n","time = 461.0, epoch 15, iter = 300, loss = 1.2660169172286988, 38.101557970047 s per 100 iters\n","time = 462.0, epoch 15, iter = 400, loss = 1.2482276970148087, 37.801103353500366 s per 100 iters\n","time = 462.0, epoch 15, iter = 500, loss = 1.2630797815322876, 37.845213890075684 s per 100 iters\n","time = 463.0, epoch 15, iter = 600, loss = 1.2606250113248825, 37.820934772491455 s per 100 iters\n","time = 464.0, epoch 15, iter = 700, loss = 1.2781261935830117, 38.06069564819336 s per 100 iters\n","time = 464.0, epoch 15, iter = 800, loss = 1.2510672229528428, 38.04331111907959 s per 100 iters\n","time = 465.0, epoch 15, iter = 900, loss = 1.2526783174276352, 38.210495948791504 s per 100 iters\n","time = 466.0, epoch 15, iter = 1000, loss = 1.2855623984336852, 38.25780367851257 s per 100 iters\n","time = 466.0, epoch 15, iter = 1100, loss = 1.2701405227184295, 37.40434908866882 s per 100 iters\n","time = 467.0, epoch 15, iter = 1200, loss = 1.285422443151474, 38.178550004959106 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 467.0, epoch 15, iter = 1300, loss = 1.2785775780677795, 37.910621881484985 s per 100 iters\n","time = 468.0, epoch 15, iter = 1400, loss = 1.2739216965436935, 37.39047908782959 s per 100 iters\n","time = 469.0, epoch 15, iter = 1500, loss = 1.2823191785812378, 38.07535934448242 s per 100 iters\n","time = 469.0, epoch 15, iter = 1600, loss = 1.2696394836902618, 37.954246044158936 s per 100 iters\n","time = 470.0, epoch 15, iter = 1700, loss = 1.283151723742485, 37.62858700752258 s per 100 iters\n","time = 471.0, epoch 15, iter = 1800, loss = 1.279751707315445, 37.7719624042511 s per 100 iters\n","time = 471.0, epoch 15, iter = 1900, loss = 1.2888272875547409, 38.87523436546326 s per 100 iters\n","time = 472.0, epoch 15, iter = 2000, loss = 1.2667223823070526, 37.998905658721924 s per 100 iters\n","time = 472.0, epoch 15, iter = 2100, loss = 1.2878700864315034, 37.433489084243774 s per 100 iters\n","time = 473.0, epoch 15, iter = 2200, loss = 1.2851552146673202, 37.94197058677673 s per 100 iters\n","time = 474.0, epoch 15, iter = 2300, loss = 1.299186242222786, 38.20959806442261 s per 100 iters\n","time = 474.0, epoch 15, iter = 2400, loss = 1.287031082510948, 37.846147537231445 s per 100 iters\n","time = 475.0, epoch 15, iter = 2500, loss = 1.2880784052610397, 37.8183069229126 s per 100 iters\n","time = 476.0, epoch 15, iter = 2600, loss = 1.3002275133132934, 39.09012699127197 s per 100 iters\n","time = 476.0, epoch 15, iter = 2700, loss = 1.291012041568756, 37.26312780380249 s per 100 iters\n","time = 477.0, epoch 15, iter = 2800, loss = 1.293624874353409, 38.06268382072449 s per 100 iters\n","time = 478.0, epoch 15, iter = 2900, loss = 1.3063320744037628, 37.24441075325012 s per 100 iters\n","time = 478.0, epoch 15, iter = 3000, loss = 1.3108286863565446, 38.34896969795227 s per 100 iters\n","time = 479.0, epoch 15, iter = 3100, loss = 1.2904152286052704, 37.397618532180786 s per 100 iters\n","time = 479.0, epoch 15, iter = 3200, loss = 1.2900371569395066, 37.26721477508545 s per 100 iters\n","time = 480.0, epoch 15, iter = 3300, loss = 1.3146557039022446, 37.77715039253235 s per 100 iters\n","time = 481.0, epoch 15, iter = 3400, loss = 1.2928342336416245, 38.23042273521423 s per 100 iters\n","time = 481.0, epoch 15, iter = 3500, loss = 1.2965929967164993, 38.3289315700531 s per 100 iters\n","time = 482.0, epoch 15, iter = 3600, loss = 1.3070575922727585, 37.36386156082153 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 483.0, epoch 15, iter = 3700, loss = 1.324790136218071, 37.25003933906555 s per 100 iters\n","time = 483.0, epoch 15, iter = 3800, loss = 1.307956456542015, 37.41789746284485 s per 100 iters\n","time = 484.0, epoch 15, iter = 3900, loss = 1.323642606139183, 37.93847632408142 s per 100 iters\n","time = 484.0, epoch 15, iter = 4000, loss = 1.3099359101057053, 38.48831796646118 s per 100 iters\n","time = 485.0, epoch 15, iter = 4100, loss = 1.3059333705902099, 37.665029764175415 s per 100 iters\n","time = 486.0, epoch 15, iter = 4200, loss = 1.2964679723978043, 37.23189973831177 s per 100 iters\n","time = 486.0, epoch 15, iter = 4300, loss = 1.3233254557847978, 38.69648051261902 s per 100 iters\n","time = 487.0, epoch 15, iter = 4400, loss = 1.3094774848222732, 37.84625434875488 s per 100 iters\n","time = 488.0, epoch 15, iter = 4500, loss = 1.3256253445148467, 37.94216585159302 s per 100 iters\n","time = 488.0, epoch 15, iter = 4600, loss = 1.3081802025437355, 37.430322885513306 s per 100 iters\n","time = 489.0, epoch 15, iter = 4700, loss = 1.3300842583179473, 37.97354292869568 s per 100 iters\n","time = 490.0, epoch 15, iter = 4800, loss = 1.3256674510240556, 37.87504196166992 s per 100 iters\n","time = 490.0, epoch 15, iter = 4900, loss = 1.3267443442344666, 38.22759032249451 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 491.0, epoch 15, iter = 5000, loss = 1.3247404330968857, 37.31839346885681 s per 100 iters\n","time = 491.0, epoch 15, iter = 5100, loss = 1.318857017159462, 38.11878490447998 s per 100 iters\n","time = 492.0, epoch 15, iter = 5200, loss = 1.327348724603653, 37.885266065597534 s per 100 iters\n","time = 493.0, epoch 15, iter = 5300, loss = 1.337286141514778, 38.03223371505737 s per 100 iters\n","time = 493.0, epoch 15, iter = 5400, loss = 1.318143305182457, 37.916171073913574 s per 100 iters\n","time = 494.0, epoch 15, iter = 5500, loss = 1.3277918362617493, 38.348745346069336 s per 100 iters\n","time = 495.0, epoch 15, iter = 5600, loss = 1.316394075155258, 38.752214431762695 s per 100 iters\n","time = 495.0, epoch 15, iter = 5700, loss = 1.3241005617380142, 38.0833683013916 s per 100 iters\n","time = 496.0, epoch 15, iter = 5800, loss = 1.3159581905603408, 37.57464241981506 s per 100 iters\n","time = 496.0, epoch 15, iter = 5900, loss = 1.3111851525306701, 37.40898656845093 s per 100 iters\n","time = 497.0, epoch 15, iter = 6000, loss = 1.3460982352495194, 38.038830280303955 s per 100 iters\n","time = 498.0, epoch 15, iter = 6100, loss = 1.3382041674852372, 37.64687490463257 s per 100 iters\n","time = 498.0, epoch 15, iter = 6200, loss = 1.3283748137950897, 37.51584219932556 s per 100 iters\n","time = 499.0, epoch 15, iter = 6300, loss = 1.327083973288536, 38.0841019153595 s per 100 iters\n","time = 500.0, epoch 15, iter = 6400, loss = 1.3530283945798873, 38.987910985946655 s per 100 iters\n","time = 500.0, epoch 15, iter = 6500, loss = 1.3359947091341018, 37.930460691452026 s per 100 iters\n","time = 501.0, epoch 15, iter = 6600, loss = 1.333802085518837, 37.93737864494324 s per 100 iters\n","time = 502.0, epoch 15, iter = 6700, loss = 1.3564511573314666, 37.45901703834534 s per 100 iters\n","time = 502.0, epoch 15, iter = 6800, loss = 1.3311455911397934, 38.05571794509888 s per 100 iters\n","time = 503.0, epoch 15, iter = 6900, loss = 1.3444416469335556, 38.74500870704651 s per 100 iters\n","time = 503.0, epoch 15, iter = 7000, loss = 1.3229832804203034, 37.74884915351868 s per 100 iters\n","time = 504.0, epoch 15, iter = 7100, loss = 1.3453804033994674, 37.77152395248413 s per 100 iters\n","time = 505.0, epoch 15, iter = 7200, loss = 1.3151765143871308, 37.44333076477051 s per 100 iters\n","time = 505.0, epoch 15, iter = 7300, loss = 1.3409012204408646, 37.74663591384888 s per 100 iters\n","time = 506.0, epoch 15, iter = 7400, loss = 1.3393786007165909, 38.13504695892334 s per 100 iters\n","time = 507.0, epoch 15, iter = 7500, loss = 1.3177824288606643, 37.58494567871094 s per 100 iters\n","time = 507.0, epoch 15, iter = 7600, loss = 1.3166263300180434, 36.5277738571167 s per 100 iters\n","time = 508.0, epoch 15, iter = 7700, loss = 1.3212239837646484, 37.48948431015015 s per 100 iters\n","time = 508.0, epoch 15, iter = 7800, loss = 1.3388398802280426, 37.88126802444458 s per 100 iters\n","time = 509.0, epoch 15, iter = 7900, loss = 1.334538345336914, 37.4453330039978 s per 100 iters\n","time = 510.0, epoch 15, iter = 8000, loss = 1.3437334883213043, 38.179829835891724 s per 100 iters\n","time = 510.0, epoch 15, iter = 8100, loss = 1.3593161976337433, 38.492480993270874 s per 100 iters\n","time = 511.0, epoch 15, iter = 8200, loss = 1.3568223237991333, 37.839465856552124 s per 100 iters\n","time = 512.0, epoch 15, iter = 8300, loss = 1.3287758374214171, 37.55129790306091 s per 100 iters\n","time = 512.0, epoch 15, iter = 8400, loss = 1.334945061802864, 37.515925884246826 s per 100 iters\n","time = 513.0, epoch 15, iter = 8500, loss = 1.3412460285425185, 38.41545081138611 s per 100 iters\n","time = 514.0, epoch 15, iter = 8600, loss = 1.3522201746702194, 38.28929281234741 s per 100 iters\n","time = 514.0, epoch 15, iter = 8700, loss = 1.361413325071335, 38.446165800094604 s per 100 iters\n","time = 515.0, epoch 15, iter = 8800, loss = 1.354456866979599, 37.98285746574402 s per 100 iters\n","time = 515.0, epoch 15, iter = 8900, loss = 1.364225600361824, 38.707404375076294 s per 100 iters\n","time = 516.0, epoch 15, iter = 9000, loss = 1.3544342195987702, 38.1308228969574 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 517.0, epoch 15, iter = 9100, loss = 1.3437699395418168, 38.30701756477356 s per 100 iters\n","time = 517.0, epoch 15, iter = 9200, loss = 1.3402446520328521, 38.00230598449707 s per 100 iters\n","time = 518.0, epoch 15, iter = 9300, loss = 1.3506219965219497, 38.555927753448486 s per 100 iters\n","time = 519.0, epoch 15, iter = 9400, loss = 1.3555092787742615, 37.70234131813049 s per 100 iters\n","time = 519.0, epoch 15, iter = 9500, loss = 1.3485956317186356, 37.99809527397156 s per 100 iters\n","time = 520.0, epoch 15, iter = 9600, loss = 1.3646827089786528, 38.5870258808136 s per 100 iters\n","time = 521.0, epoch 15, iter = 9700, loss = 1.3540365755558015, 37.44705247879028 s per 100 iters\n","time = 521.0, epoch 15, iter = 9800, loss = 1.3640840691328049, 38.522876024246216 s per 100 iters\n","time = 522.0, epoch 15, iter = 9900, loss = 1.3655735343694686, 37.72221851348877 s per 100 iters\n","time = 522.0, epoch 15, iter = 10000, loss = 1.349529748558998, 37.62436866760254 s per 100 iters\n","time = 523.0, epoch 15, iter = 10100, loss = 1.332388162612915, 37.52500104904175 s per 100 iters\n","time = 524.0, epoch 15, iter = 10200, loss = 1.3758258497714997, 37.994712352752686 s per 100 iters\n","time = 524.0, epoch 15, iter = 10300, loss = 1.3603807425498962, 37.82251858711243 s per 100 iters\n","time = 525.0, epoch 15, iter = 10400, loss = 1.345999653339386, 38.3917510509491 s per 100 iters\n","time = 526.0, epoch 15, iter = 10500, loss = 1.3729174894094467, 37.44902491569519 s per 100 iters\n","time = 526.0, epoch 15, iter = 10600, loss = 1.3501556026935577, 37.700114011764526 s per 100 iters\n","time = 527.0, epoch 15, iter = 10700, loss = 1.356129749417305, 37.285099267959595 s per 100 iters\n","time = 527.0, epoch 15, iter = 10800, loss = 1.362499731183052, 37.49974966049194 s per 100 iters\n","time = 528.0, epoch 15, iter = 10900, loss = 1.3602056694030762, 37.91203689575195 s per 100 iters\n","time = 529.0, epoch 15, iter = 11000, loss = 1.3668379032611846, 38.33369588851929 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 529.0, epoch 15, iter = 11100, loss = 1.3426228147745132, 37.33982038497925 s per 100 iters\n","time = 530.0, epoch 15, iter = 11200, loss = 1.3580055260658264, 37.49939823150635 s per 100 iters\n","time = 531.0, epoch 15, iter = 11300, loss = 1.3596842432022094, 37.805903911590576 s per 100 iters\n","time = 531.0, epoch 15, iter = 11400, loss = 1.3658514076471329, 37.35751008987427 s per 100 iters\n","time = 532.0, epoch 15, iter = 11500, loss = 1.3549680018424988, 37.95722246170044 s per 100 iters\n","time = 532.0, epoch 15, iter = 11600, loss = 1.3652222043275832, 38.64311480522156 s per 100 iters\n","time = 533.0, epoch 15, iter = 11700, loss = 1.3616091829538346, 38.54437518119812 s per 100 iters\n","time = 534.0, epoch 15, iter = 11800, loss = 1.3550585579872132, 37.70926332473755 s per 100 iters\n","time = 534.0, epoch 15, iter = 11900, loss = 1.3776192891597747, 38.8148729801178 s per 100 iters\n","time = 535.0, epoch 15, iter = 12000, loss = 1.3893172323703766, 39.1396324634552 s per 100 iters\n","time = 536.0, epoch 15, iter = 12100, loss = 1.3707512468099594, 38.02952432632446 s per 100 iters\n","time = 536.0, epoch 15, iter = 12200, loss = 1.348705712556839, 37.622621059417725 s per 100 iters\n","time = 537.0, epoch 15, iter = 12300, loss = 1.3811631351709366, 38.79186654090881 s per 100 iters\n","time = 538.0, epoch 15, iter = 12400, loss = 1.389544017314911, 39.1091890335083 s per 100 iters\n","time = 538.0, epoch 15, iter = 12500, loss = 1.36885273873806, 38.05739712715149 s per 100 iters\n","time = 539.0, epoch 15, iter = 12600, loss = 1.3620554715394975, 37.46468186378479 s per 100 iters\n","time = 540.0, epoch 15, iter = 12700, loss = 1.3690189802646637, 38.62031579017639 s per 100 iters\n","time = 540.0, epoch 15, iter = 12800, loss = 1.367355329990387, 37.71136522293091 s per 100 iters\n","time = 541.0, epoch 15, iter = 12900, loss = 1.3689449220895766, 37.57810354232788 s per 100 iters\n","time = 541.0, epoch 15, iter = 13000, loss = 1.3703080773353578, 37.69351625442505 s per 100 iters\n","time = 542.0, epoch 15, iter = 13100, loss = 1.3678023421764374, 37.63098478317261 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 543.0, epoch 15, iter = 13200, loss = 1.3702932405471802, 37.32361388206482 s per 100 iters\n","time = 543.0, epoch 15, iter = 13300, loss = 1.3661308401823045, 38.35186815261841 s per 100 iters\n","time = 544.0, epoch 15, iter = 13400, loss = 1.383279338479042, 38.26989006996155 s per 100 iters\n","time = 545.0, epoch 15, iter = 13500, loss = 1.3929150450229644, 38.5180778503418 s per 100 iters\n","time = 545.0, epoch 15, iter = 13600, loss = 1.3624357521533965, 38.14222002029419 s per 100 iters\n","time = 546.0, epoch 15, iter = 13700, loss = 1.3870473045110703, 38.27988147735596 s per 100 iters\n","time = 546.0, epoch 15, iter = 13800, loss = 1.3628841364383697, 37.52771258354187 s per 100 iters\n","time = 547.0, epoch 15, iter = 13900, loss = 1.3769357693195343, 37.9933922290802 s per 100 iters\n","time = 548.0, epoch 15, iter = 14000, loss = 1.370221951007843, 38.34829902648926 s per 100 iters\n","time = 548.0, epoch 15, iter = 14100, loss = 1.3748153477907181, 38.17300820350647 s per 100 iters\n","time = 549.0, epoch 15, iter = 14200, loss = 1.3811071145534515, 38.3631637096405 s per 100 iters\n","time = 550.0, epoch 15, iter = 14300, loss = 1.3636102783679962, 38.77472949028015 s per 100 iters\n","--- Balidazioa ---\n","42.94243144989014 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C beranduegi da ordea ￭:', '｟C baina zer zen hura ￭?', '｟B rosanna l spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan oinak jarri zituenetik ￭, eta nesken xarma ￭, aita ｟C pirroneen austertasuna eta ｟C don ｟C fabrizioren moduek konbentzitu zuten ｟C donnafugatako jauregia ez zela ｟C capraro bandidoaren antroa ￭, eta seguru aski bizirik irtengo zenetik ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza eta exekutiboko beste ofizialak ￭, iruzkin artifizialak dira ￭; sariketa eta zigorra ￭, zeinen bidez subiranotasunaren egoitza eta kide bakoitza bere eginkizunaren betetzeko mugitzen baita ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭; gorputzean gauza partikular bakoitzaren aberastasunak eta aberastasunak ￭, indar eta aberastasun guztiak ￭, herri dohainak ￭, boterea ￭, boterea ￭, herria ￭, boterea ￭, aholkulariak dira ￭, eta aholkuak ￭, hau da ￭, ｟C herria ￭, ｟C ahalguztiduntasuna ￭, ｟C herria ￭, ｟C kontseilariak ￭, ｟C estatuari guztiak ￭, ｟C kontseil', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura ￭, hain zuzen ￭, beren ideala da ￭, eta agian beste inor ez ￭, gaur egun irudikatzen dute ￭, berek dira bere izpiritualizatuenak ￭, bere esploratzaile eta esploratzaileen tropa aurreratuenak ￭, bere trauskiltasunik ezinago fin eta liluragarriz josia ￭.', '｟C hegoaldean ez dago esklaborik ez duten adina familia hain behartsu ￭.', '｟C duela gutxi ￭, ｟C derwatten kasuan ￭, eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 12.327325894061033\n","8.697256326675415 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteren istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosi egingo al duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu inporta ￭?', '｟C eta argazkia erakutsi nahi diot 1960ean eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 27.1370789831204\n","BLEU puntuazioa (biak): 15.75105569103469\n","time = 551.0, epoch 16, iter = 100, loss = 1.2215137568116188, 39.82803130149841 s per 100 iters\n","time = 552.0, epoch 16, iter = 200, loss = 1.2226650196313857, 39.067588567733765 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-ccfc2f12d8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mentrenatu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-63-3280eebef4ed>\u001b[0m in \u001b[0;36mentrenatu\u001b[0;34m(hasi_epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mnew_step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Currently, Amp does not support closure use with optimizers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFusedSGD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master_params_to_model_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"hTgg39CukOWc","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9t4hZTWkOFk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594387796280,"user_tz":-120,"elapsed":22582342,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"35250fef-e9ca-496b-dadc-9a79f3e5314d"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/origetaos2-15.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu(16)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 16, iter = 100, loss = 1.2227581399679184, 39.07497453689575 s per 100 iters\n","time = 1.0, epoch 16, iter = 200, loss = 1.2316978281736375, 38.21989917755127 s per 100 iters\n","time = 1.0, epoch 16, iter = 300, loss = 1.2318175041675568, 38.2343475818634 s per 100 iters\n","time = 2.0, epoch 16, iter = 400, loss = 1.2274018067121506, 38.01075267791748 s per 100 iters\n","time = 3.0, epoch 16, iter = 500, loss = 1.2465133476257324, 37.999144077301025 s per 100 iters\n","time = 3.0, epoch 16, iter = 600, loss = 1.2379872381687165, 38.16829562187195 s per 100 iters\n","time = 4.0, epoch 16, iter = 700, loss = 1.227624734044075, 38.155980825424194 s per 100 iters\n","time = 5.0, epoch 16, iter = 800, loss = 1.2423436272144317, 37.73416209220886 s per 100 iters\n","time = 5.0, epoch 16, iter = 900, loss = 1.2510554605722428, 37.82762312889099 s per 100 iters\n","time = 6.0, epoch 16, iter = 1000, loss = 1.2464825737476348, 38.131407260894775 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 7.0, epoch 16, iter = 1100, loss = 1.2626960209012033, 39.03036189079285 s per 100 iters\n","time = 7.0, epoch 16, iter = 1200, loss = 1.2374565833806992, 37.96846914291382 s per 100 iters\n","time = 8.0, epoch 16, iter = 1300, loss = 1.2493604290485383, 37.470375537872314 s per 100 iters\n","time = 8.0, epoch 16, iter = 1400, loss = 1.2519442695379257, 37.36133527755737 s per 100 iters\n","time = 9.0, epoch 16, iter = 1500, loss = 1.2636691397428512, 38.257996797561646 s per 100 iters\n","time = 10.0, epoch 16, iter = 1600, loss = 1.2699517267942428, 38.051804304122925 s per 100 iters\n","time = 10.0, epoch 16, iter = 1700, loss = 1.2426935970783233, 37.83859634399414 s per 100 iters\n","time = 11.0, epoch 16, iter = 1800, loss = 1.2457336696982384, 37.34086751937866 s per 100 iters\n","time = 12.0, epoch 16, iter = 1900, loss = 1.2679662835597991, 37.816463470458984 s per 100 iters\n","time = 12.0, epoch 16, iter = 2000, loss = 1.281223758459091, 38.57241463661194 s per 100 iters\n","time = 13.0, epoch 16, iter = 2100, loss = 1.260148020386696, 37.9323616027832 s per 100 iters\n","time = 13.0, epoch 16, iter = 2200, loss = 1.2719868886470795, 37.65870523452759 s per 100 iters\n","time = 14.0, epoch 16, iter = 2300, loss = 1.2483820742368699, 38.11814737319946 s per 100 iters\n","time = 15.0, epoch 16, iter = 2400, loss = 1.2683010643720627, 38.43108654022217 s per 100 iters\n","time = 15.0, epoch 16, iter = 2500, loss = 1.2826708877086639, 37.84750938415527 s per 100 iters\n","time = 16.0, epoch 16, iter = 2600, loss = 1.2758630639314652, 38.17359709739685 s per 100 iters\n","time = 17.0, epoch 16, iter = 2700, loss = 1.2857878470420838, 38.1772518157959 s per 100 iters\n","time = 17.0, epoch 16, iter = 2800, loss = 1.2827328512072562, 37.86772561073303 s per 100 iters\n","time = 18.0, epoch 16, iter = 2900, loss = 1.2776389497518539, 37.31781029701233 s per 100 iters\n","time = 19.0, epoch 16, iter = 3000, loss = 1.2827276968955994, 38.382299184799194 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 19.0, epoch 16, iter = 3100, loss = 1.269295206964016, 37.25894284248352 s per 100 iters\n","time = 20.0, epoch 16, iter = 3200, loss = 1.2816745162010192, 38.72658848762512 s per 100 iters\n","time = 20.0, epoch 16, iter = 3300, loss = 1.2882710051536561, 38.07640218734741 s per 100 iters\n","time = 21.0, epoch 16, iter = 3400, loss = 1.2813736855983735, 37.292999505996704 s per 100 iters\n","time = 22.0, epoch 16, iter = 3500, loss = 1.2907667565345764, 38.039894342422485 s per 100 iters\n","time = 22.0, epoch 16, iter = 3600, loss = 1.280596290230751, 37.93425703048706 s per 100 iters\n","time = 23.0, epoch 16, iter = 3700, loss = 1.2840478366613388, 38.26046013832092 s per 100 iters\n","time = 24.0, epoch 16, iter = 3800, loss = 1.3015416675806046, 38.037264823913574 s per 100 iters\n","time = 24.0, epoch 16, iter = 3900, loss = 1.3048877495527267, 38.30073881149292 s per 100 iters\n","time = 25.0, epoch 16, iter = 4000, loss = 1.290652317404747, 38.28725266456604 s per 100 iters\n","time = 25.0, epoch 16, iter = 4100, loss = 1.2855199486017228, 37.7853627204895 s per 100 iters\n","time = 26.0, epoch 16, iter = 4200, loss = 1.2960021191835402, 37.47628736495972 s per 100 iters\n","time = 27.0, epoch 16, iter = 4300, loss = 1.2742664822936058, 38.30707335472107 s per 100 iters\n","time = 27.0, epoch 16, iter = 4400, loss = 1.2881167834997178, 38.50791573524475 s per 100 iters\n","time = 28.0, epoch 16, iter = 4500, loss = 1.3004969722032547, 38.56055665016174 s per 100 iters\n","time = 29.0, epoch 16, iter = 4600, loss = 1.288680363893509, 38.04257154464722 s per 100 iters\n","time = 29.0, epoch 16, iter = 4700, loss = 1.2825341111421584, 37.825886487960815 s per 100 iters\n","time = 30.0, epoch 16, iter = 4800, loss = 1.3043616706132888, 38.38561749458313 s per 100 iters\n","time = 31.0, epoch 16, iter = 4900, loss = 1.2841906762123108, 37.53377819061279 s per 100 iters\n","time = 31.0, epoch 16, iter = 5000, loss = 1.2846228668093682, 37.162415981292725 s per 100 iters\n","time = 32.0, epoch 16, iter = 5100, loss = 1.3142831534147263, 37.887505292892456 s per 100 iters\n","time = 32.0, epoch 16, iter = 5200, loss = 1.3109030693769455, 37.84853219985962 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 33.0, epoch 16, iter = 5300, loss = 1.2940607118606566, 37.31469249725342 s per 100 iters\n","time = 34.0, epoch 16, iter = 5400, loss = 1.2827062475681306, 38.16583967208862 s per 100 iters\n","time = 34.0, epoch 16, iter = 5500, loss = 1.3071724849939346, 38.99047517776489 s per 100 iters\n","time = 35.0, epoch 16, iter = 5600, loss = 1.2911709320545197, 37.53154230117798 s per 100 iters\n","time = 36.0, epoch 16, iter = 5700, loss = 1.2960444790124894, 38.40248203277588 s per 100 iters\n","time = 36.0, epoch 16, iter = 5800, loss = 1.2876061102747918, 37.968138694763184 s per 100 iters\n","time = 37.0, epoch 16, iter = 5900, loss = 1.313891617655754, 38.071436166763306 s per 100 iters\n","time = 38.0, epoch 16, iter = 6000, loss = 1.292178988456726, 37.48754572868347 s per 100 iters\n","time = 38.0, epoch 16, iter = 6100, loss = 1.2906406086683273, 37.68890142440796 s per 100 iters\n","time = 39.0, epoch 16, iter = 6200, loss = 1.3030972802639007, 37.60958480834961 s per 100 iters\n","time = 39.0, epoch 16, iter = 6300, loss = 1.2938448816537857, 37.900694370269775 s per 100 iters\n","time = 40.0, epoch 16, iter = 6400, loss = 1.3172814732789992, 38.26963424682617 s per 100 iters\n","time = 41.0, epoch 16, iter = 6500, loss = 1.3113190186023713, 37.84811520576477 s per 100 iters\n","time = 41.0, epoch 16, iter = 6600, loss = 1.3074197870492936, 37.73535346984863 s per 100 iters\n","time = 42.0, epoch 16, iter = 6700, loss = 1.2971689814329148, 37.447558879852295 s per 100 iters\n","time = 43.0, epoch 16, iter = 6800, loss = 1.3128711223602294, 37.68609404563904 s per 100 iters\n","time = 43.0, epoch 16, iter = 6900, loss = 1.3170907235145568, 37.792293548583984 s per 100 iters\n","time = 44.0, epoch 16, iter = 7000, loss = 1.3156456166505814, 38.509217977523804 s per 100 iters\n","time = 44.0, epoch 16, iter = 7100, loss = 1.3234195607900618, 38.64379405975342 s per 100 iters\n","time = 45.0, epoch 16, iter = 7200, loss = 1.3104790323972701, 37.722012758255005 s per 100 iters\n","time = 46.0, epoch 16, iter = 7300, loss = 1.3059174358844756, 37.171852827072144 s per 100 iters\n","time = 46.0, epoch 16, iter = 7400, loss = 1.3035907900333406, 37.98775553703308 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 47.0, epoch 16, iter = 7500, loss = 1.3024864435195922, 38.34532809257507 s per 100 iters\n","time = 48.0, epoch 16, iter = 7600, loss = 1.3170458298921586, 37.469979763031006 s per 100 iters\n","time = 48.0, epoch 16, iter = 7700, loss = 1.3259784764051437, 38.76943230628967 s per 100 iters\n","time = 49.0, epoch 16, iter = 7800, loss = 1.3122529065608979, 37.5747184753418 s per 100 iters\n","time = 50.0, epoch 16, iter = 7900, loss = 1.3349754959344864, 38.473883390426636 s per 100 iters\n","time = 50.0, epoch 16, iter = 8000, loss = 1.3081143939495086, 38.11962389945984 s per 100 iters\n","time = 51.0, epoch 16, iter = 8100, loss = 1.326032127737999, 37.708845138549805 s per 100 iters\n","time = 51.0, epoch 16, iter = 8200, loss = 1.3230234789848327, 37.378047704696655 s per 100 iters\n","time = 52.0, epoch 16, iter = 8300, loss = 1.307739450931549, 37.65204358100891 s per 100 iters\n","time = 53.0, epoch 16, iter = 8400, loss = 1.3230708104372024, 38.00261831283569 s per 100 iters\n","time = 53.0, epoch 16, iter = 8500, loss = 1.3253239977359772, 38.412566900253296 s per 100 iters\n","time = 54.0, epoch 16, iter = 8600, loss = 1.3293965435028077, 37.67525243759155 s per 100 iters\n","time = 55.0, epoch 16, iter = 8700, loss = 1.3143751865625382, 37.73429083824158 s per 100 iters\n","time = 55.0, epoch 16, iter = 8800, loss = 1.3299817371368408, 38.25182271003723 s per 100 iters\n","time = 56.0, epoch 16, iter = 8900, loss = 1.3045631420612336, 38.003835916519165 s per 100 iters\n","time = 56.0, epoch 16, iter = 9000, loss = 1.3281600499153137, 37.7462432384491 s per 100 iters\n","time = 57.0, epoch 16, iter = 9100, loss = 1.3204094582796098, 38.183213233947754 s per 100 iters\n","time = 58.0, epoch 16, iter = 9200, loss = 1.335760579109192, 39.114699602127075 s per 100 iters\n","time = 58.0, epoch 16, iter = 9300, loss = 1.3370286309719086, 38.80483555793762 s per 100 iters\n","time = 59.0, epoch 16, iter = 9400, loss = 1.3343388545513153, 37.88395953178406 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 60.0, epoch 16, iter = 9500, loss = 1.3257693934440613, 37.455132246017456 s per 100 iters\n","time = 60.0, epoch 16, iter = 9600, loss = 1.319772140979767, 37.54450988769531 s per 100 iters\n","time = 61.0, epoch 16, iter = 9700, loss = 1.3399349600076675, 37.33854413032532 s per 100 iters\n","time = 62.0, epoch 16, iter = 9800, loss = 1.327565547823906, 37.42916679382324 s per 100 iters\n","time = 62.0, epoch 16, iter = 9900, loss = 1.3257137817144393, 38.29720067977905 s per 100 iters\n","time = 63.0, epoch 16, iter = 10000, loss = 1.3237371993064881, 37.51233673095703 s per 100 iters\n","time = 63.0, epoch 16, iter = 10100, loss = 1.3401648443937302, 37.43327569961548 s per 100 iters\n","time = 64.0, epoch 16, iter = 10200, loss = 1.3310365104675292, 38.70683145523071 s per 100 iters\n","time = 65.0, epoch 16, iter = 10300, loss = 1.331636928319931, 37.51935529708862 s per 100 iters\n","time = 65.0, epoch 16, iter = 10400, loss = 1.3387831646203994, 39.07972478866577 s per 100 iters\n","time = 66.0, epoch 16, iter = 10500, loss = 1.3309466278553008, 37.94922065734863 s per 100 iters\n","time = 67.0, epoch 16, iter = 10600, loss = 1.3559232866764068, 39.32224893569946 s per 100 iters\n","time = 67.0, epoch 16, iter = 10700, loss = 1.3345717120170593, 37.65733480453491 s per 100 iters\n","time = 68.0, epoch 16, iter = 10800, loss = 1.3254881501197815, 38.036301374435425 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 69.0, epoch 16, iter = 10900, loss = 1.3412784284353256, 38.3731894493103 s per 100 iters\n","time = 69.0, epoch 16, iter = 11000, loss = 1.3420874273777008, 37.7310688495636 s per 100 iters\n","time = 70.0, epoch 16, iter = 11100, loss = 1.34030916929245, 38.57305836677551 s per 100 iters\n","time = 70.0, epoch 16, iter = 11200, loss = 1.354621366262436, 38.08033490180969 s per 100 iters\n","time = 71.0, epoch 16, iter = 11300, loss = 1.3346119982004165, 37.474905490875244 s per 100 iters\n","time = 72.0, epoch 16, iter = 11400, loss = 1.338127224445343, 37.66889691352844 s per 100 iters\n","time = 72.0, epoch 16, iter = 11500, loss = 1.352021006345749, 37.62964344024658 s per 100 iters\n","time = 73.0, epoch 16, iter = 11600, loss = 1.3446668297052384, 38.31294560432434 s per 100 iters\n","time = 74.0, epoch 16, iter = 11700, loss = 1.3378056704998016, 37.90536642074585 s per 100 iters\n","time = 74.0, epoch 16, iter = 11800, loss = 1.334540753364563, 37.67381191253662 s per 100 iters\n","time = 75.0, epoch 16, iter = 11900, loss = 1.3069101387262345, 37.35235118865967 s per 100 iters\n","time = 75.0, epoch 16, iter = 12000, loss = 1.3500741231441498, 38.31678295135498 s per 100 iters\n","time = 76.0, epoch 16, iter = 12100, loss = 1.3456530332565309, 37.867302894592285 s per 100 iters\n","time = 77.0, epoch 16, iter = 12200, loss = 1.332718545794487, 38.40952658653259 s per 100 iters\n","time = 77.0, epoch 16, iter = 12300, loss = 1.3473843359947204, 37.78125858306885 s per 100 iters\n","time = 78.0, epoch 16, iter = 12400, loss = 1.3493812745809555, 38.37675094604492 s per 100 iters\n","time = 79.0, epoch 16, iter = 12500, loss = 1.3387536531686783, 38.02368092536926 s per 100 iters\n","time = 79.0, epoch 16, iter = 12600, loss = 1.375259811282158, 38.588576316833496 s per 100 iters\n","time = 80.0, epoch 16, iter = 12700, loss = 1.3544770032167435, 37.769522190093994 s per 100 iters\n","time = 81.0, epoch 16, iter = 12800, loss = 1.3457654970884323, 37.72776913642883 s per 100 iters\n","time = 81.0, epoch 16, iter = 12900, loss = 1.3666134667396546, 38.569210052490234 s per 100 iters\n","time = 82.0, epoch 16, iter = 13000, loss = 1.33003442466259, 37.27811050415039 s per 100 iters\n","time = 82.0, epoch 16, iter = 13100, loss = 1.3477699196338653, 38.07762360572815 s per 100 iters\n","time = 83.0, epoch 16, iter = 13200, loss = 1.3228935027122497, 37.228731870651245 s per 100 iters\n","time = 84.0, epoch 16, iter = 13300, loss = 1.3631738305091858, 38.65182137489319 s per 100 iters\n","time = 84.0, epoch 16, iter = 13400, loss = 1.3402152001857757, 37.48944044113159 s per 100 iters\n","time = 85.0, epoch 16, iter = 13500, loss = 1.3502696996927261, 37.607937812805176 s per 100 iters\n","time = 86.0, epoch 16, iter = 13600, loss = 1.3657015991210937, 38.55262899398804 s per 100 iters\n","time = 86.0, epoch 16, iter = 13700, loss = 1.3466350650787353, 38.28683352470398 s per 100 iters\n","time = 87.0, epoch 16, iter = 13800, loss = 1.3319613474607468, 37.84060072898865 s per 100 iters\n","time = 88.0, epoch 16, iter = 13900, loss = 1.345432897210121, 38.30236101150513 s per 100 iters\n","time = 88.0, epoch 16, iter = 14000, loss = 1.3592160469293595, 37.72647166252136 s per 100 iters\n","time = 89.0, epoch 16, iter = 14100, loss = 1.3519039261341095, 37.57714819908142 s per 100 iters\n","time = 89.0, epoch 16, iter = 14200, loss = 1.3637757700681687, 38.0900776386261 s per 100 iters\n","time = 90.0, epoch 16, iter = 14300, loss = 1.3324397444725036, 37.34631896018982 s per 100 iters\n","--- Balidazioa ---\n","34.447072982788086 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer zen hori ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain doinu eta betea da ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehenengo aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, aita ｟C pirrone eta ｟C don ｟C fabrizioren portaerak ｟C donnafugatako jauregia ez zela ｟C kapraro bandidoaren antroa ￭, eta ziur aski bizirik irtengo zela ￭.', '｟C erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C aaaaaaaaaaaaaaaaa ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza exekutikoaren beste ofizialak ￭, iruzkin artifizialak dira ￭; sariketa eta zigorra ￭, subiranotasunaren egarri eta kide bakoitza bere eginkizuna betetzeko mugituz mugitzen diren saltsari guztiak ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭; gorputz partikular bakoitzaren dirua eta aberastasunen indarra ￭, edo populus boterea ￭, herriak ￭, bere boterea ￭, aholkulariak ￭, gauza artifizialak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura ￭, hain zuzen ￭, beren ideala besterik ez da ￭, eta agian beste inor ez ￭, beraiek dira gaur egun ￭, beren berek dira gaur egun ￭, beren berek ￭, beren sortzetiko izpiritualik erotuena ￭, bere esploratzaile eta esploratzaileen tropa aurreratuenak ￭, bere liluramenduzko formarik delikatuena ￭, liluramenduzko formarik ezina ￭.', '｟C hegoaldean ez dago esklaborik ez duten familiarik ￭.', '｟C derwatt-en kasuan eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 12.250115264847308\n","8.50295376777649 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteko historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia dut ￭, 1960ean ￭, semea eta bere semea ￭. ￭. ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.841065159321452\n","BLEU puntuazioa (biak): 15.605005900549331\n","time = 92.0, epoch 17, iter = 100, loss = 1.2024164760112763, 38.769280433654785 s per 100 iters\n","time = 92.0, epoch 17, iter = 200, loss = 1.2065084886550903, 37.642104625701904 s per 100 iters\n","time = 93.0, epoch 17, iter = 300, loss = 1.2239532354474068, 38.17358064651489 s per 100 iters\n","time = 94.0, epoch 17, iter = 400, loss = 1.1969382625818252, 38.12469458580017 s per 100 iters\n","time = 94.0, epoch 17, iter = 500, loss = 1.2073691469430923, 38.02933144569397 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 95.0, epoch 17, iter = 600, loss = 1.2339124700427055, 38.430954456329346 s per 100 iters\n","time = 95.0, epoch 17, iter = 700, loss = 1.2288569286465645, 38.43308353424072 s per 100 iters\n","time = 96.0, epoch 17, iter = 800, loss = 1.202909253835678, 37.55442762374878 s per 100 iters\n","time = 97.0, epoch 17, iter = 900, loss = 1.2176985031366347, 38.23002552986145 s per 100 iters\n","time = 97.0, epoch 17, iter = 1000, loss = 1.2119850555062295, 38.281334400177 s per 100 iters\n","time = 98.0, epoch 17, iter = 1100, loss = 1.2280594915151597, 39.018765926361084 s per 100 iters\n","time = 99.0, epoch 17, iter = 1200, loss = 1.238364895582199, 38.00683307647705 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 99.0, epoch 17, iter = 1300, loss = 1.231112567782402, 37.95969772338867 s per 100 iters\n","time = 100.0, epoch 17, iter = 1400, loss = 1.2070505797863007, 37.26128315925598 s per 100 iters\n","time = 101.0, epoch 17, iter = 1500, loss = 1.2243406265974044, 38.04223871231079 s per 100 iters\n","time = 101.0, epoch 17, iter = 1600, loss = 1.2427220851182939, 37.280479192733765 s per 100 iters\n","time = 102.0, epoch 17, iter = 1700, loss = 1.2266723543405533, 38.84799337387085 s per 100 iters\n","time = 102.0, epoch 17, iter = 1800, loss = 1.2416821545362473, 38.28246545791626 s per 100 iters\n","time = 103.0, epoch 17, iter = 1900, loss = 1.21394098341465, 38.002914905548096 s per 100 iters\n","time = 104.0, epoch 17, iter = 2000, loss = 1.23153873026371, 37.41025495529175 s per 100 iters\n","time = 104.0, epoch 17, iter = 2100, loss = 1.232146347463131, 37.88176894187927 s per 100 iters\n","time = 105.0, epoch 17, iter = 2200, loss = 1.2480505686998367, 38.35706424713135 s per 100 iters\n","time = 106.0, epoch 17, iter = 2300, loss = 1.2383668059110642, 38.04627060890198 s per 100 iters\n","time = 106.0, epoch 17, iter = 2400, loss = 1.2315691721439361, 37.84594511985779 s per 100 iters\n","time = 107.0, epoch 17, iter = 2500, loss = 1.220076796412468, 37.75449252128601 s per 100 iters\n","time = 108.0, epoch 17, iter = 2600, loss = 1.2300268006324768, 38.930628299713135 s per 100 iters\n","time = 108.0, epoch 17, iter = 2700, loss = 1.2547545969486236, 38.705820083618164 s per 100 iters\n","time = 109.0, epoch 17, iter = 2800, loss = 1.2473467648029328, 38.695563316345215 s per 100 iters\n","time = 109.0, epoch 17, iter = 2900, loss = 1.2357778960466386, 37.77858352661133 s per 100 iters\n","time = 110.0, epoch 17, iter = 3000, loss = 1.2580172967910768, 38.40228343009949 s per 100 iters\n","time = 111.0, epoch 17, iter = 3100, loss = 1.2509652680158616, 37.563812255859375 s per 100 iters\n","time = 111.0, epoch 17, iter = 3200, loss = 1.2618575638532639, 37.77115797996521 s per 100 iters\n","time = 112.0, epoch 17, iter = 3300, loss = 1.2574875718355178, 38.342987298965454 s per 100 iters\n","time = 113.0, epoch 17, iter = 3400, loss = 1.2630415105819701, 37.629172563552856 s per 100 iters\n","time = 113.0, epoch 17, iter = 3500, loss = 1.264142758846283, 38.6220223903656 s per 100 iters\n","time = 114.0, epoch 17, iter = 3600, loss = 1.2507268750667573, 37.43827533721924 s per 100 iters\n","time = 115.0, epoch 17, iter = 3700, loss = 1.265303357243538, 38.30131196975708 s per 100 iters\n","time = 115.0, epoch 17, iter = 3800, loss = 1.2451575392484664, 37.989842653274536 s per 100 iters\n","time = 116.0, epoch 17, iter = 3900, loss = 1.2500284785032272, 37.90716075897217 s per 100 iters\n","time = 116.0, epoch 17, iter = 4000, loss = 1.2420248848199844, 37.57580089569092 s per 100 iters\n","time = 117.0, epoch 17, iter = 4100, loss = 1.2625667315721512, 38.25219368934631 s per 100 iters\n","time = 118.0, epoch 17, iter = 4200, loss = 1.2480587083101273, 37.826733350753784 s per 100 iters\n","time = 118.0, epoch 17, iter = 4300, loss = 1.2598861560225487, 37.861977100372314 s per 100 iters\n","time = 119.0, epoch 17, iter = 4400, loss = 1.252468651533127, 37.65245223045349 s per 100 iters\n","time = 120.0, epoch 17, iter = 4500, loss = 1.2619061771035194, 38.18923044204712 s per 100 iters\n","time = 120.0, epoch 17, iter = 4600, loss = 1.2800748145580292, 38.11546516418457 s per 100 iters\n","time = 121.0, epoch 17, iter = 4700, loss = 1.2645927411317825, 37.95696687698364 s per 100 iters\n","time = 121.0, epoch 17, iter = 4800, loss = 1.281278818845749, 37.81625699996948 s per 100 iters\n","time = 122.0, epoch 17, iter = 4900, loss = 1.2696237766742706, 38.18890190124512 s per 100 iters\n","time = 123.0, epoch 17, iter = 5000, loss = 1.2772337186336518, 38.400022983551025 s per 100 iters\n","time = 123.0, epoch 17, iter = 5100, loss = 1.2487014013528823, 37.309696674346924 s per 100 iters\n","time = 124.0, epoch 17, iter = 5200, loss = 1.2717922294139863, 38.1202917098999 s per 100 iters\n","time = 125.0, epoch 17, iter = 5300, loss = 1.263475807905197, 38.21063017845154 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 125.0, epoch 17, iter = 5400, loss = 1.2659965175390244, 37.59976148605347 s per 100 iters\n","time = 126.0, epoch 17, iter = 5500, loss = 1.2558446270227432, 37.9227409362793 s per 100 iters\n","time = 127.0, epoch 17, iter = 5600, loss = 1.2852791237831116, 37.916412353515625 s per 100 iters\n","time = 127.0, epoch 17, iter = 5700, loss = 1.2803260964155196, 38.1590461730957 s per 100 iters\n","time = 128.0, epoch 17, iter = 5800, loss = 1.2876251870393753, 38.619147539138794 s per 100 iters\n","time = 128.0, epoch 17, iter = 5900, loss = 1.2759583508968353, 38.42323303222656 s per 100 iters\n","time = 129.0, epoch 17, iter = 6000, loss = 1.2810493332147599, 37.599424839019775 s per 100 iters\n","time = 130.0, epoch 17, iter = 6100, loss = 1.263748704791069, 38.02406144142151 s per 100 iters\n","time = 130.0, epoch 17, iter = 6200, loss = 1.2802980691194534, 37.63242721557617 s per 100 iters\n","time = 131.0, epoch 17, iter = 6300, loss = 1.274867895245552, 37.86364459991455 s per 100 iters\n","time = 132.0, epoch 17, iter = 6400, loss = 1.2950552469491958, 37.8103551864624 s per 100 iters\n","time = 132.0, epoch 17, iter = 6500, loss = 1.2821137297153473, 38.16988682746887 s per 100 iters\n","time = 133.0, epoch 17, iter = 6600, loss = 1.2480837112665177, 38.523902893066406 s per 100 iters\n","time = 133.0, epoch 17, iter = 6700, loss = 1.271865565776825, 37.18303465843201 s per 100 iters\n","time = 134.0, epoch 17, iter = 6800, loss = 1.2764308208227158, 37.746400117874146 s per 100 iters\n","time = 135.0, epoch 17, iter = 6900, loss = 1.2878753435611725, 37.710697174072266 s per 100 iters\n","time = 135.0, epoch 17, iter = 7000, loss = 1.284915931224823, 38.673680782318115 s per 100 iters\n","time = 136.0, epoch 17, iter = 7100, loss = 1.2799589616060256, 37.58140850067139 s per 100 iters\n","time = 137.0, epoch 17, iter = 7200, loss = 1.2963910573720931, 38.76351571083069 s per 100 iters\n","time = 137.0, epoch 17, iter = 7300, loss = 1.2779972779750823, 38.027230978012085 s per 100 iters\n","time = 138.0, epoch 17, iter = 7400, loss = 1.279869299530983, 38.13257884979248 s per 100 iters\n","time = 139.0, epoch 17, iter = 7500, loss = 1.2823310708999633, 37.7650580406189 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 139.0, epoch 17, iter = 7600, loss = 1.2825309199094772, 38.21514964103699 s per 100 iters\n","time = 140.0, epoch 17, iter = 7700, loss = 1.302525408267975, 37.973400831222534 s per 100 iters\n","time = 140.0, epoch 17, iter = 7800, loss = 1.3025561022758483, 38.21015286445618 s per 100 iters\n","time = 141.0, epoch 17, iter = 7900, loss = 1.3040956300497055, 38.330230474472046 s per 100 iters\n","time = 142.0, epoch 17, iter = 8000, loss = 1.2866915422677994, 38.21228075027466 s per 100 iters\n","time = 142.0, epoch 17, iter = 8100, loss = 1.2891328501701356, 38.430070638656616 s per 100 iters\n","time = 143.0, epoch 17, iter = 8200, loss = 1.308635939359665, 37.71468114852905 s per 100 iters\n","time = 144.0, epoch 17, iter = 8300, loss = 1.2750196540355683, 37.69995999336243 s per 100 iters\n","time = 144.0, epoch 17, iter = 8400, loss = 1.3068686103820801, 38.01746129989624 s per 100 iters\n","time = 145.0, epoch 17, iter = 8500, loss = 1.2975881630182267, 37.73619103431702 s per 100 iters\n","time = 146.0, epoch 17, iter = 8600, loss = 1.304088950753212, 37.19511914253235 s per 100 iters\n","time = 146.0, epoch 17, iter = 8700, loss = 1.2931885594129562, 38.29230976104736 s per 100 iters\n","time = 147.0, epoch 17, iter = 8800, loss = 1.309601138830185, 38.93773555755615 s per 100 iters\n","time = 147.0, epoch 17, iter = 8900, loss = 1.29032075047493, 37.51202654838562 s per 100 iters\n","time = 148.0, epoch 17, iter = 9000, loss = 1.3132578700780868, 38.410014390945435 s per 100 iters\n","time = 149.0, epoch 17, iter = 9100, loss = 1.305382410287857, 38.26184344291687 s per 100 iters\n","time = 149.0, epoch 17, iter = 9200, loss = 1.2948431813716887, 38.026947021484375 s per 100 iters\n","time = 150.0, epoch 17, iter = 9300, loss = 1.3049841296672822, 38.410446643829346 s per 100 iters\n","time = 151.0, epoch 17, iter = 9400, loss = 1.3098761188983916, 37.606508016586304 s per 100 iters\n","time = 151.0, epoch 17, iter = 9500, loss = 1.2928958386182785, 38.294278621673584 s per 100 iters\n","time = 152.0, epoch 17, iter = 9600, loss = 1.3080096060037614, 37.89722752571106 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 153.0, epoch 17, iter = 9700, loss = 1.3027836561203003, 38.59776210784912 s per 100 iters\n","time = 153.0, epoch 17, iter = 9800, loss = 1.314488888978958, 38.923393964767456 s per 100 iters\n","time = 154.0, epoch 17, iter = 9900, loss = 1.287133702635765, 37.71807384490967 s per 100 iters\n","time = 154.0, epoch 17, iter = 10000, loss = 1.3130700892210008, 37.66922664642334 s per 100 iters\n","time = 155.0, epoch 17, iter = 10100, loss = 1.3259260898828507, 38.82645845413208 s per 100 iters\n","time = 156.0, epoch 17, iter = 10200, loss = 1.3040710788965226, 37.78390598297119 s per 100 iters\n","time = 156.0, epoch 17, iter = 10300, loss = 1.3061321306228637, 37.87026643753052 s per 100 iters\n","time = 157.0, epoch 17, iter = 10400, loss = 1.308212980031967, 39.048442125320435 s per 100 iters\n","time = 158.0, epoch 17, iter = 10500, loss = 1.309250384569168, 37.26135182380676 s per 100 iters\n","time = 158.0, epoch 17, iter = 10600, loss = 1.3042594963312149, 38.188591718673706 s per 100 iters\n","time = 159.0, epoch 17, iter = 10700, loss = 1.3154095202684402, 38.63085055351257 s per 100 iters\n","time = 160.0, epoch 17, iter = 10800, loss = 1.3021180433034898, 37.9832878112793 s per 100 iters\n","time = 160.0, epoch 17, iter = 10900, loss = 1.3072705471515655, 38.15557050704956 s per 100 iters\n","time = 161.0, epoch 17, iter = 11000, loss = 1.32239589035511, 38.65663933753967 s per 100 iters\n","time = 161.0, epoch 17, iter = 11100, loss = 1.3219303977489472, 37.650734663009644 s per 100 iters\n","time = 162.0, epoch 17, iter = 11200, loss = 1.3073951244354247, 37.81913352012634 s per 100 iters\n","time = 163.0, epoch 17, iter = 11300, loss = 1.320933859348297, 37.67957806587219 s per 100 iters\n","time = 163.0, epoch 17, iter = 11400, loss = 1.3260930114984513, 38.18083381652832 s per 100 iters\n","time = 164.0, epoch 17, iter = 11500, loss = 1.341906822323799, 39.91967010498047 s per 100 iters\n","time = 165.0, epoch 17, iter = 11600, loss = 1.326394070982933, 38.1607301235199 s per 100 iters\n","time = 165.0, epoch 17, iter = 11700, loss = 1.3265552091598511, 38.285852909088135 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 166.0, epoch 17, iter = 11800, loss = 1.3234333169460297, 37.87372088432312 s per 100 iters\n","time = 167.0, epoch 17, iter = 11900, loss = 1.3249921530485154, 37.92431449890137 s per 100 iters\n","time = 167.0, epoch 17, iter = 12000, loss = 1.3149087929725647, 38.31658673286438 s per 100 iters\n","time = 168.0, epoch 17, iter = 12100, loss = 1.325762831568718, 38.1968138217926 s per 100 iters\n","time = 168.0, epoch 17, iter = 12200, loss = 1.32701624751091, 38.54088234901428 s per 100 iters\n","time = 169.0, epoch 17, iter = 12300, loss = 1.3306418031454086, 38.08571004867554 s per 100 iters\n","time = 170.0, epoch 17, iter = 12400, loss = 1.3110027176141739, 37.51670694351196 s per 100 iters\n","time = 170.0, epoch 17, iter = 12500, loss = 1.329418830871582, 38.49778151512146 s per 100 iters\n","time = 171.0, epoch 17, iter = 12600, loss = 1.3101353138685226, 38.084346771240234 s per 100 iters\n","time = 172.0, epoch 17, iter = 12700, loss = 1.3107794636487962, 38.224709272384644 s per 100 iters\n","time = 172.0, epoch 17, iter = 12800, loss = 1.3288403540849685, 38.144211769104004 s per 100 iters\n","time = 173.0, epoch 17, iter = 12900, loss = 1.3281891173124314, 38.07582235336304 s per 100 iters\n","time = 174.0, epoch 17, iter = 13000, loss = 1.3194208997488022, 38.28161120414734 s per 100 iters\n","time = 174.0, epoch 17, iter = 13100, loss = 1.3235961878299713, 37.680097818374634 s per 100 iters\n","time = 175.0, epoch 17, iter = 13200, loss = 1.3155658566951751, 38.02582240104675 s per 100 iters\n","time = 175.0, epoch 17, iter = 13300, loss = 1.3183713221549989, 38.06394648551941 s per 100 iters\n","time = 176.0, epoch 17, iter = 13400, loss = 1.325540714263916, 37.748475313186646 s per 100 iters\n","time = 177.0, epoch 17, iter = 13500, loss = 1.33135049700737, 37.811758041381836 s per 100 iters\n","time = 177.0, epoch 17, iter = 13600, loss = 1.309274399280548, 37.87009525299072 s per 100 iters\n","time = 178.0, epoch 17, iter = 13700, loss = 1.3148707485198974, 37.64095664024353 s per 100 iters\n","time = 179.0, epoch 17, iter = 13800, loss = 1.3155430144071578, 38.145171880722046 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 179.0, epoch 17, iter = 13900, loss = 1.3200852298736572, 37.812260389328 s per 100 iters\n","time = 180.0, epoch 17, iter = 14000, loss = 1.3411898058652878, 38.78227996826172 s per 100 iters\n","time = 180.0, epoch 17, iter = 14100, loss = 1.3206103891134262, 38.56545805931091 s per 100 iters\n","time = 181.0, epoch 17, iter = 14200, loss = 1.317772899866104, 37.74403762817383 s per 100 iters\n","time = 182.0, epoch 17, iter = 14300, loss = 1.3422763174772263, 38.89037823677063 s per 100 iters\n","--- Balidazioa ---\n","34.37451434135437 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C beranduegi da ordea ￭:', '｟C baina zer zen hura ￭?', '｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarmak ￭, ｟C aita ｟C pirroneren austeritasunak eta ｟C don ｟C fabrikako portaerek konbentzitu zuten ｟C donnafugatako jauregia ez zela ｟C capraro bandiduaren antroa ￭, eta seguraski bizirik irtengo zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza exekuzioaren beste ofizialak ￭, epaiketariko eta exekuzio-egileak ￭, sari eta zigorra ￭, zeinen bidez subiranotasunaren iturburu eta kide bakoitza bere eginkizunaren betetzeko mugatzen baita ￭, nerbioak baitira gorputz naturalean ￭, aberastasun eta aberastasun partikularren indarra ￭, indarra eta herria ￭, herria ￭, aholkulariak dira ￭, eta aholkuak eman behar zaizkio ￭.', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideal ￭, berek ￭, eta agian beste inork ere ez ￭, gaur egun irudikatzen dute ￭, berek dira bere izpiritualdukorrena ￭, bere gerlari eta esploratzaile talde aurreratuenak ￭, bere gaitasunik ezgaitzenak ￭, sedukzio-forma sentigaitza ￭, delikatu eta jasanezinena ￭.', '｟C hegoaldean ez dago esklaborik ez izateko bezain familia urrikalgarririk ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan ￭, eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 12.347756219465131\n","7.835370302200317 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C oso musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteren istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin da ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jauna zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. bost axola zaizu ￭?', '｟C eta argazkia erakutsi nahi diot 1960an eta semea 1940ko uniforme batean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 27.569530530585162\n","BLEU puntuazioa (biak): 15.875394073925994\n","time = 183.0, epoch 18, iter = 100, loss = 1.1949890065193176, 39.18995237350464 s per 100 iters\n","time = 184.0, epoch 18, iter = 200, loss = 1.1819043308496475, 38.37181210517883 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 185.0, epoch 18, iter = 300, loss = 1.1841240605711938, 38.79564166069031 s per 100 iters\n","time = 185.0, epoch 18, iter = 400, loss = 1.1846394035220147, 38.30056691169739 s per 100 iters\n","time = 186.0, epoch 18, iter = 500, loss = 1.1813903480768204, 38.42416834831238 s per 100 iters\n","time = 187.0, epoch 18, iter = 600, loss = 1.1697927623987199, 37.657105922698975 s per 100 iters\n","time = 187.0, epoch 18, iter = 700, loss = 1.184692851305008, 38.04315376281738 s per 100 iters\n","time = 188.0, epoch 18, iter = 800, loss = 1.1890435075759889, 38.605655908584595 s per 100 iters\n","time = 188.0, epoch 18, iter = 900, loss = 1.1995505368709565, 38.1567120552063 s per 100 iters\n","time = 189.0, epoch 18, iter = 1000, loss = 1.2005264085531235, 37.57604169845581 s per 100 iters\n","time = 190.0, epoch 18, iter = 1100, loss = 1.2021778947114945, 38.21447205543518 s per 100 iters\n","time = 190.0, epoch 18, iter = 1200, loss = 1.1813154029846191, 37.25770664215088 s per 100 iters\n","time = 191.0, epoch 18, iter = 1300, loss = 1.192133676111698, 37.33474946022034 s per 100 iters\n","time = 192.0, epoch 18, iter = 1400, loss = 1.208258725106716, 38.15235638618469 s per 100 iters\n","time = 192.0, epoch 18, iter = 1500, loss = 1.2118570578098298, 38.31985068321228 s per 100 iters\n","time = 193.0, epoch 18, iter = 1600, loss = 1.199980434179306, 38.954092502593994 s per 100 iters\n","time = 194.0, epoch 18, iter = 1700, loss = 1.2012877172231675, 38.21705961227417 s per 100 iters\n","time = 194.0, epoch 18, iter = 1800, loss = 1.2052089270949364, 38.11345839500427 s per 100 iters\n","time = 195.0, epoch 18, iter = 1900, loss = 1.2009686294198036, 38.157546520233154 s per 100 iters\n","time = 195.0, epoch 18, iter = 2000, loss = 1.1889316213130952, 38.084808588027954 s per 100 iters\n","time = 196.0, epoch 18, iter = 2100, loss = 1.22006214261055, 37.96316409111023 s per 100 iters\n","time = 197.0, epoch 18, iter = 2200, loss = 1.1988369315862655, 37.41122317314148 s per 100 iters\n","time = 197.0, epoch 18, iter = 2300, loss = 1.216200089454651, 38.60782599449158 s per 100 iters\n","time = 198.0, epoch 18, iter = 2400, loss = 1.2001073625683785, 38.033923625946045 s per 100 iters\n","time = 199.0, epoch 18, iter = 2500, loss = 1.225346696972847, 37.335206270217896 s per 100 iters\n","time = 199.0, epoch 18, iter = 2600, loss = 1.208195613026619, 37.874133586883545 s per 100 iters\n","time = 200.0, epoch 18, iter = 2700, loss = 1.215997383594513, 38.5739381313324 s per 100 iters\n","time = 201.0, epoch 18, iter = 2800, loss = 1.2283095413446425, 37.99672079086304 s per 100 iters\n","time = 201.0, epoch 18, iter = 2900, loss = 1.2220932728052138, 38.26269054412842 s per 100 iters\n","time = 202.0, epoch 18, iter = 3000, loss = 1.220696821808815, 37.96190404891968 s per 100 iters\n","time = 202.0, epoch 18, iter = 3100, loss = 1.2148737835884094, 37.50128769874573 s per 100 iters\n","time = 203.0, epoch 18, iter = 3200, loss = 1.2325750696659088, 38.71225929260254 s per 100 iters\n","time = 204.0, epoch 18, iter = 3300, loss = 1.2363570308685303, 38.1756489276886 s per 100 iters\n","time = 204.0, epoch 18, iter = 3400, loss = 1.2160370439291, 38.18891000747681 s per 100 iters\n","time = 205.0, epoch 18, iter = 3500, loss = 1.2364286094903947, 38.30171537399292 s per 100 iters\n","time = 206.0, epoch 18, iter = 3600, loss = 1.2269770818948746, 37.90600562095642 s per 100 iters\n","time = 206.0, epoch 18, iter = 3700, loss = 1.2326807588338853, 38.90216588973999 s per 100 iters\n","time = 207.0, epoch 18, iter = 3800, loss = 1.225840077996254, 37.93837022781372 s per 100 iters\n","time = 208.0, epoch 18, iter = 3900, loss = 1.240084899365902, 37.85718131065369 s per 100 iters\n","time = 208.0, epoch 18, iter = 4000, loss = 1.2357811188697816, 37.94291973114014 s per 100 iters\n","time = 209.0, epoch 18, iter = 4100, loss = 1.2309334695339202, 38.07324004173279 s per 100 iters\n","time = 209.0, epoch 18, iter = 4200, loss = 1.2437741687893868, 38.42313742637634 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 210.0, epoch 18, iter = 4300, loss = 1.2348213341832162, 37.723302602767944 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 211.0, epoch 18, iter = 4400, loss = 1.25474564909935, 38.22078824043274 s per 100 iters\n","time = 211.0, epoch 18, iter = 4500, loss = 1.2264696913957596, 38.065837144851685 s per 100 iters\n","time = 212.0, epoch 18, iter = 4600, loss = 1.243155135512352, 37.042054891586304 s per 100 iters\n","time = 213.0, epoch 18, iter = 4700, loss = 1.2445240712165833, 38.81117296218872 s per 100 iters\n","time = 213.0, epoch 18, iter = 4800, loss = 1.2280205684900283, 37.00878095626831 s per 100 iters\n","time = 214.0, epoch 18, iter = 4900, loss = 1.2341879349946976, 38.03969645500183 s per 100 iters\n","time = 214.0, epoch 18, iter = 5000, loss = 1.2380365443229675, 37.62704372406006 s per 100 iters\n","time = 215.0, epoch 18, iter = 5100, loss = 1.2418672037124634, 37.73847198486328 s per 100 iters\n","time = 216.0, epoch 18, iter = 5200, loss = 1.2413849437236786, 38.04822850227356 s per 100 iters\n","time = 216.0, epoch 18, iter = 5300, loss = 1.2636401563882829, 37.781615257263184 s per 100 iters\n","time = 217.0, epoch 18, iter = 5400, loss = 1.2536402571201324, 38.47057247161865 s per 100 iters\n","time = 218.0, epoch 18, iter = 5500, loss = 1.2402692174911498, 37.95862793922424 s per 100 iters\n","time = 218.0, epoch 18, iter = 5600, loss = 1.2547310423851012, 38.212942600250244 s per 100 iters\n","time = 219.0, epoch 18, iter = 5700, loss = 1.2360583820939064, 38.37818765640259 s per 100 iters\n","time = 220.0, epoch 18, iter = 5800, loss = 1.2433536207675935, 37.56884527206421 s per 100 iters\n","time = 220.0, epoch 18, iter = 5900, loss = 1.2462864685058594, 37.64416718482971 s per 100 iters\n","time = 221.0, epoch 18, iter = 6000, loss = 1.2628741091489792, 37.56622934341431 s per 100 iters\n","time = 221.0, epoch 18, iter = 6100, loss = 1.2742011052370072, 38.39772367477417 s per 100 iters\n","time = 222.0, epoch 18, iter = 6200, loss = 1.2700487470626831, 38.50805163383484 s per 100 iters\n","time = 223.0, epoch 18, iter = 6300, loss = 1.269645869731903, 38.28627371788025 s per 100 iters\n","time = 223.0, epoch 18, iter = 6400, loss = 1.2571548634767533, 38.19317889213562 s per 100 iters\n","time = 224.0, epoch 18, iter = 6500, loss = 1.2593780797719956, 38.503703355789185 s per 100 iters\n","time = 225.0, epoch 18, iter = 6600, loss = 1.2465602898597716, 37.63924050331116 s per 100 iters\n","time = 225.0, epoch 18, iter = 6700, loss = 1.263658954501152, 38.05868196487427 s per 100 iters\n","time = 226.0, epoch 18, iter = 6800, loss = 1.2736590617895127, 38.968998432159424 s per 100 iters\n","time = 227.0, epoch 18, iter = 6900, loss = 1.250765382349491, 37.70971608161926 s per 100 iters\n","time = 227.0, epoch 18, iter = 7000, loss = 1.2669574975967408, 38.03036713600159 s per 100 iters\n","time = 228.0, epoch 18, iter = 7100, loss = 1.258316701054573, 37.50593018531799 s per 100 iters\n","time = 228.0, epoch 18, iter = 7200, loss = 1.2771608126163483, 37.75188183784485 s per 100 iters\n","time = 229.0, epoch 18, iter = 7300, loss = 1.2761191686987876, 38.03045630455017 s per 100 iters\n","time = 230.0, epoch 18, iter = 7400, loss = 1.2707293331623077, 38.98349332809448 s per 100 iters\n","time = 230.0, epoch 18, iter = 7500, loss = 1.262740808725357, 38.09187030792236 s per 100 iters\n","time = 231.0, epoch 18, iter = 7600, loss = 1.2888223910331726, 39.179786682128906 s per 100 iters\n","time = 232.0, epoch 18, iter = 7700, loss = 1.2668994730710983, 38.15182018280029 s per 100 iters\n","time = 232.0, epoch 18, iter = 7800, loss = 1.26165097117424, 38.686723947525024 s per 100 iters\n","time = 233.0, epoch 18, iter = 7900, loss = 1.2849668335914612, 38.22531318664551 s per 100 iters\n","time = 234.0, epoch 18, iter = 8000, loss = 1.270299271941185, 37.80836510658264 s per 100 iters\n","time = 234.0, epoch 18, iter = 8100, loss = 1.279902149438858, 37.426088094711304 s per 100 iters\n","time = 235.0, epoch 18, iter = 8200, loss = 1.2646970176696777, 38.12845849990845 s per 100 iters\n","time = 235.0, epoch 18, iter = 8300, loss = 1.2855334609746933, 37.99916195869446 s per 100 iters\n","time = 236.0, epoch 18, iter = 8400, loss = 1.2702746987342834, 37.72964143753052 s per 100 iters\n","time = 237.0, epoch 18, iter = 8500, loss = 1.269681807756424, 37.94940519332886 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 237.0, epoch 18, iter = 8600, loss = 1.2898398065567016, 38.53203558921814 s per 100 iters\n","time = 238.0, epoch 18, iter = 8700, loss = 1.2712274551391602, 38.0809109210968 s per 100 iters\n","time = 239.0, epoch 18, iter = 8800, loss = 1.253738476037979, 37.62689924240112 s per 100 iters\n","time = 239.0, epoch 18, iter = 8900, loss = 1.269519322514534, 38.19954252243042 s per 100 iters\n","time = 240.0, epoch 18, iter = 9000, loss = 1.3003743225336075, 37.82342553138733 s per 100 iters\n","time = 240.0, epoch 18, iter = 9100, loss = 1.286134724020958, 37.52119326591492 s per 100 iters\n","time = 241.0, epoch 18, iter = 9200, loss = 1.2667062309384347, 38.01280951499939 s per 100 iters\n","time = 242.0, epoch 18, iter = 9300, loss = 1.2668667554855346, 37.70950388908386 s per 100 iters\n","time = 242.0, epoch 18, iter = 9400, loss = 1.2897082108259201, 38.673715591430664 s per 100 iters\n","time = 243.0, epoch 18, iter = 9500, loss = 1.267130805850029, 37.78590512275696 s per 100 iters\n","time = 244.0, epoch 18, iter = 9600, loss = 1.2912162780761718, 38.57135272026062 s per 100 iters\n","time = 244.0, epoch 18, iter = 9700, loss = 1.2729121860861778, 37.46655559539795 s per 100 iters\n","time = 245.0, epoch 18, iter = 9800, loss = 1.2775080960988998, 37.96790599822998 s per 100 iters\n","time = 246.0, epoch 18, iter = 9900, loss = 1.2826209551095962, 38.34238362312317 s per 100 iters\n","time = 246.0, epoch 18, iter = 10000, loss = 1.3149241769313813, 38.44087290763855 s per 100 iters\n","time = 247.0, epoch 18, iter = 10100, loss = 1.2815030151605606, 38.293182134628296 s per 100 iters\n","time = 247.0, epoch 18, iter = 10200, loss = 1.2790438789129257, 38.119141578674316 s per 100 iters\n","time = 248.0, epoch 18, iter = 10300, loss = 1.2922562658786774, 38.32154965400696 s per 100 iters\n","time = 249.0, epoch 18, iter = 10400, loss = 1.2884459048509598, 37.49107074737549 s per 100 iters\n","time = 249.0, epoch 18, iter = 10500, loss = 1.2922996360063552, 37.742350816726685 s per 100 iters\n","time = 250.0, epoch 18, iter = 10600, loss = 1.2992187696695328, 37.65042996406555 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 251.0, epoch 18, iter = 10700, loss = 1.2765704655647279, 38.15892481803894 s per 100 iters\n","time = 251.0, epoch 18, iter = 10800, loss = 1.2811952978372574, 38.00936198234558 s per 100 iters\n","time = 252.0, epoch 18, iter = 10900, loss = 1.273264861702919, 37.658965826034546 s per 100 iters\n","time = 253.0, epoch 18, iter = 11000, loss = 1.2871179670095443, 38.933725357055664 s per 100 iters\n","time = 253.0, epoch 18, iter = 11100, loss = 1.278217836022377, 38.156862020492554 s per 100 iters\n","time = 254.0, epoch 18, iter = 11200, loss = 1.2906677317619324, 37.42235827445984 s per 100 iters\n","time = 254.0, epoch 18, iter = 11300, loss = 1.3002484452724457, 38.028799533843994 s per 100 iters\n","time = 255.0, epoch 18, iter = 11400, loss = 1.3062051659822465, 38.20042061805725 s per 100 iters\n","time = 256.0, epoch 18, iter = 11500, loss = 1.2918850779533386, 37.79529070854187 s per 100 iters\n","time = 256.0, epoch 18, iter = 11600, loss = 1.284620051383972, 37.49112510681152 s per 100 iters\n","time = 257.0, epoch 18, iter = 11700, loss = 1.3103734487295151, 38.95685291290283 s per 100 iters\n","time = 258.0, epoch 18, iter = 11800, loss = 1.2924116843938827, 38.00210976600647 s per 100 iters\n","time = 258.0, epoch 18, iter = 11900, loss = 1.3031771409511566, 38.314218521118164 s per 100 iters\n","time = 259.0, epoch 18, iter = 12000, loss = 1.301280506849289, 37.33071565628052 s per 100 iters\n","time = 260.0, epoch 18, iter = 12100, loss = 1.3063095951080321, 37.76381874084473 s per 100 iters\n","time = 260.0, epoch 18, iter = 12200, loss = 1.302435907125473, 37.899699687957764 s per 100 iters\n","time = 261.0, epoch 18, iter = 12300, loss = 1.2952480292320252, 38.486255168914795 s per 100 iters\n","time = 261.0, epoch 18, iter = 12400, loss = 1.3089961636066436, 37.34222197532654 s per 100 iters\n","time = 262.0, epoch 18, iter = 12500, loss = 1.2799488890171051, 38.417245864868164 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 263.0, epoch 18, iter = 12600, loss = 1.3184863537549973, 38.46964955329895 s per 100 iters\n","time = 263.0, epoch 18, iter = 12700, loss = 1.2891065680980682, 38.267051696777344 s per 100 iters\n","time = 264.0, epoch 18, iter = 12800, loss = 1.2941086983680725, 37.09540939331055 s per 100 iters\n","time = 265.0, epoch 18, iter = 12900, loss = 1.3053939533233643, 38.46632790565491 s per 100 iters\n","time = 265.0, epoch 18, iter = 13000, loss = 1.312166782617569, 39.49952244758606 s per 100 iters\n","time = 266.0, epoch 18, iter = 13100, loss = 1.3060223841667176, 38.31743502616882 s per 100 iters\n","time = 267.0, epoch 18, iter = 13200, loss = 1.277005254626274, 37.78161811828613 s per 100 iters\n","time = 267.0, epoch 18, iter = 13300, loss = 1.2875425899028778, 37.13788819313049 s per 100 iters\n","time = 268.0, epoch 18, iter = 13400, loss = 1.303690430521965, 37.871466398239136 s per 100 iters\n","time = 268.0, epoch 18, iter = 13500, loss = 1.3048926055431367, 38.71407604217529 s per 100 iters\n","time = 269.0, epoch 18, iter = 13600, loss = 1.3195581901073457, 38.682228803634644 s per 100 iters\n","time = 270.0, epoch 18, iter = 13700, loss = 1.298169237971306, 38.33249282836914 s per 100 iters\n","time = 270.0, epoch 18, iter = 13800, loss = 1.2997722059488297, 38.76020359992981 s per 100 iters\n","time = 271.0, epoch 18, iter = 13900, loss = 1.3017144346237182, 38.37587356567383 s per 100 iters\n","time = 272.0, epoch 18, iter = 14000, loss = 1.2871991568803787, 38.016947746276855 s per 100 iters\n","time = 272.0, epoch 18, iter = 14100, loss = 1.3056959795951844, 38.01324439048767 s per 100 iters\n","time = 273.0, epoch 18, iter = 14200, loss = 1.3000782078504562, 37.46455192565918 s per 100 iters\n","time = 273.0, epoch 18, iter = 14300, loss = 1.322934883236885, 37.508899450302124 s per 100 iters\n","--- Balidazioa ---\n","36.97749471664429 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C beranduegi da ￭, ordea ￭:', '｟C baina zer zen hura ￭?', '｟C rosanna ｟C spearman', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da kantaria eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan oinak erori zirenetik ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneen austertasuna eta ｟C don ｟C fabrizioren portaerak ｟C donnafugatako jauregia ez zela ｟C kapraro bandidoaren antroa ￭, eta bertan bizirik irtengo zela seguru asko ￭.', '｟C erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza eta exekuzioaren beste ofizialak ￭, arinkeriak ￭; saria eta zigorra ￭, subiranotasunaren eserleku bakoitza eta kide bakoitza bere eginkizunaren betetzeko mugatzen direnen arabera ￭, gorputzean gauza bera egiten duten nerbioak dira ￭; gorputz naturalean ￭, aberastasun eta aberastasun partikularren indarra ￭, edo populi boterea ￭, edo populi herria ￭, aholkulariak ￭, guztiak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideal soilki da ￭, beraiek ￭, eta agian beste inor ez dute irudikatzen gaur egun ￭, beraiek dira horien izpiritualizatuen ekoizle ￭, bere esploratzaile eta esploratzaile talde aurreratuenak ￭, bere gaitasunik ezgaienak ￭, liluramenezko formarik ezgaiena ￭,', '｟C hegoaldean ez dago esklaborik ez duten hain familia pobreik ￭.', '｟C duela gutxi ￭, ｟C derwatten kasuan eta orain ｟C mafiaren madarikazioarekin ￭?']\n","BLEU puntuazioa (1): 12.207135429664541\n","8.639094352722168 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteren istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin hitz egin nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia erakutsi nahi diot 1960an eta semea 1940ko uniformean ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotan ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.819807535028417\n","BLEU puntuazioa (biak): 15.577257422138388\n","time = 275.0, epoch 19, iter = 100, loss = 1.15685427069664, 38.74629545211792 s per 100 iters\n","time = 276.0, epoch 19, iter = 200, loss = 1.1383276590704918, 37.991454124450684 s per 100 iters\n","time = 276.0, epoch 19, iter = 300, loss = 1.1647015103697778, 38.593029737472534 s per 100 iters\n","time = 277.0, epoch 19, iter = 400, loss = 1.1531197667121886, 37.621957302093506 s per 100 iters\n","time = 278.0, epoch 19, iter = 500, loss = 1.1671382975578308, 37.894814252853394 s per 100 iters\n","time = 278.0, epoch 19, iter = 600, loss = 1.1673374018073082, 38.29774880409241 s per 100 iters\n","time = 279.0, epoch 19, iter = 700, loss = 1.1670274513959884, 37.98877787590027 s per 100 iters\n","time = 280.0, epoch 19, iter = 800, loss = 1.166255922615528, 38.01525330543518 s per 100 iters\n","time = 280.0, epoch 19, iter = 900, loss = 1.1780880141258239, 37.80004286766052 s per 100 iters\n","time = 281.0, epoch 19, iter = 1000, loss = 1.1610872876644134, 37.8498113155365 s per 100 iters\n","time = 281.0, epoch 19, iter = 1100, loss = 1.157181413769722, 37.543559551239014 s per 100 iters\n","time = 282.0, epoch 19, iter = 1200, loss = 1.1769250756502152, 38.86268734931946 s per 100 iters\n","time = 283.0, epoch 19, iter = 1300, loss = 1.1755930951237679, 37.76630210876465 s per 100 iters\n","time = 283.0, epoch 19, iter = 1400, loss = 1.190161401927471, 38.02964663505554 s per 100 iters\n","time = 284.0, epoch 19, iter = 1500, loss = 1.1712401315569878, 39.126476764678955 s per 100 iters\n","time = 285.0, epoch 19, iter = 1600, loss = 1.1679757133126258, 37.63624334335327 s per 100 iters\n","time = 285.0, epoch 19, iter = 1700, loss = 1.1809657403826714, 38.358949422836304 s per 100 iters\n","time = 286.0, epoch 19, iter = 1800, loss = 1.192644864320755, 38.483712673187256 s per 100 iters\n","time = 287.0, epoch 19, iter = 1900, loss = 1.17890227496624, 37.95106863975525 s per 100 iters\n","time = 287.0, epoch 19, iter = 2000, loss = 1.1873405826091767, 37.77394247055054 s per 100 iters\n","time = 288.0, epoch 19, iter = 2100, loss = 1.196880278289318, 38.542075872421265 s per 100 iters\n","time = 288.0, epoch 19, iter = 2200, loss = 1.1908864933252334, 37.705599784851074 s per 100 iters\n","time = 289.0, epoch 19, iter = 2300, loss = 1.1929783192276955, 37.625733375549316 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 290.0, epoch 19, iter = 2400, loss = 1.1913875764608384, 37.58189129829407 s per 100 iters\n","time = 290.0, epoch 19, iter = 2500, loss = 1.212279511988163, 38.61926579475403 s per 100 iters\n","time = 291.0, epoch 19, iter = 2600, loss = 1.1916615125536918, 38.121416091918945 s per 100 iters\n","time = 292.0, epoch 19, iter = 2700, loss = 1.1924152234196663, 37.58941674232483 s per 100 iters\n","time = 292.0, epoch 19, iter = 2800, loss = 1.2023492860794067, 38.595911741256714 s per 100 iters\n","time = 293.0, epoch 19, iter = 2900, loss = 1.2116570621728897, 37.52234649658203 s per 100 iters\n","time = 294.0, epoch 19, iter = 3000, loss = 1.2023023134469986, 38.46192526817322 s per 100 iters\n","time = 294.0, epoch 19, iter = 3100, loss = 1.2146411821246148, 39.01915621757507 s per 100 iters\n","time = 295.0, epoch 19, iter = 3200, loss = 1.1978252577781676, 38.23177456855774 s per 100 iters\n","time = 295.0, epoch 19, iter = 3300, loss = 1.1836120727658273, 37.31133818626404 s per 100 iters\n","time = 296.0, epoch 19, iter = 3400, loss = 1.2105793756246568, 38.16206908226013 s per 100 iters\n","time = 297.0, epoch 19, iter = 3500, loss = 1.1949276906251907, 37.627564907073975 s per 100 iters\n","time = 297.0, epoch 19, iter = 3600, loss = 1.2123232311010361, 38.24028015136719 s per 100 iters\n","time = 298.0, epoch 19, iter = 3700, loss = 1.1991352778673172, 38.18302035331726 s per 100 iters\n","time = 299.0, epoch 19, iter = 3800, loss = 1.2142814493179321, 38.445054054260254 s per 100 iters\n","time = 299.0, epoch 19, iter = 3900, loss = 1.213041773736477, 37.78201985359192 s per 100 iters\n","time = 300.0, epoch 19, iter = 4000, loss = 1.2254233348369599, 38.263258934020996 s per 100 iters\n","time = 301.0, epoch 19, iter = 4100, loss = 1.230823388695717, 37.847294092178345 s per 100 iters\n","time = 301.0, epoch 19, iter = 4200, loss = 1.2057608264684676, 38.425432443618774 s per 100 iters\n","time = 302.0, epoch 19, iter = 4300, loss = 1.2364697340130806, 38.567143201828 s per 100 iters\n","time = 302.0, epoch 19, iter = 4400, loss = 1.2157502210140227, 37.5457284450531 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 303.0, epoch 19, iter = 4500, loss = 1.223318082690239, 38.16148328781128 s per 100 iters\n","time = 304.0, epoch 19, iter = 4600, loss = 1.2278568255901336, 38.501988887786865 s per 100 iters\n","time = 304.0, epoch 19, iter = 4700, loss = 1.2210212844610213, 37.730448961257935 s per 100 iters\n","time = 305.0, epoch 19, iter = 4800, loss = 1.2210917747020722, 38.27196788787842 s per 100 iters\n","time = 306.0, epoch 19, iter = 4900, loss = 1.2183314460515975, 37.78621029853821 s per 100 iters\n","time = 306.0, epoch 19, iter = 5000, loss = 1.2188204631209374, 38.64135813713074 s per 100 iters\n","time = 307.0, epoch 19, iter = 5100, loss = 1.2239611178636551, 37.84174418449402 s per 100 iters\n","time = 308.0, epoch 19, iter = 5200, loss = 1.2219755658507347, 37.834362745285034 s per 100 iters\n","time = 308.0, epoch 19, iter = 5300, loss = 1.2227078849077224, 37.345009088516235 s per 100 iters\n","time = 309.0, epoch 19, iter = 5400, loss = 1.2214613521099091, 37.83527088165283 s per 100 iters\n","time = 309.0, epoch 19, iter = 5500, loss = 1.2218996107578277, 37.897074937820435 s per 100 iters\n","time = 310.0, epoch 19, iter = 5600, loss = 1.2294038119912147, 38.64978241920471 s per 100 iters\n","time = 311.0, epoch 19, iter = 5700, loss = 1.2348946702480317, 38.24972081184387 s per 100 iters\n","time = 311.0, epoch 19, iter = 5800, loss = 1.2312140321731568, 38.47636818885803 s per 100 iters\n","time = 312.0, epoch 19, iter = 5900, loss = 1.2169119644165038, 38.192954301834106 s per 100 iters\n","time = 313.0, epoch 19, iter = 6000, loss = 1.2260969680547715, 37.71696329116821 s per 100 iters\n","time = 313.0, epoch 19, iter = 6100, loss = 1.225665068626404, 37.21786117553711 s per 100 iters\n","time = 314.0, epoch 19, iter = 6200, loss = 1.237164153456688, 37.827911615371704 s per 100 iters\n","time = 314.0, epoch 19, iter = 6300, loss = 1.2256335538625718, 38.00403046607971 s per 100 iters\n","time = 315.0, epoch 19, iter = 6400, loss = 1.236456306576729, 38.89005184173584 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 316.0, epoch 19, iter = 6500, loss = 1.2638309758901596, 38.35901880264282 s per 100 iters\n","time = 316.0, epoch 19, iter = 6600, loss = 1.2323748862743378, 37.772072553634644 s per 100 iters\n","time = 317.0, epoch 19, iter = 6700, loss = 1.2228233593702316, 37.60903811454773 s per 100 iters\n","time = 318.0, epoch 19, iter = 6800, loss = 1.247535413503647, 38.46419835090637 s per 100 iters\n","time = 318.0, epoch 19, iter = 6900, loss = 1.2579376059770584, 37.609363317489624 s per 100 iters\n","time = 319.0, epoch 19, iter = 7000, loss = 1.2213613802194596, 37.478604793548584 s per 100 iters\n","time = 320.0, epoch 19, iter = 7100, loss = 1.2266257154941558, 37.79623079299927 s per 100 iters\n","time = 320.0, epoch 19, iter = 7200, loss = 1.2202175390720367, 38.106053590774536 s per 100 iters\n","time = 321.0, epoch 19, iter = 7300, loss = 1.2471832185983658, 37.9900164604187 s per 100 iters\n","time = 321.0, epoch 19, iter = 7400, loss = 1.2331390649080276, 37.77766513824463 s per 100 iters\n","time = 322.0, epoch 19, iter = 7500, loss = 1.241072409749031, 37.31446385383606 s per 100 iters\n","time = 323.0, epoch 19, iter = 7600, loss = 1.244287716448307, 38.0899760723114 s per 100 iters\n","time = 323.0, epoch 19, iter = 7700, loss = 1.2451046964526176, 37.91451859474182 s per 100 iters\n","time = 324.0, epoch 19, iter = 7800, loss = 1.241010563969612, 38.171061277389526 s per 100 iters\n","time = 325.0, epoch 19, iter = 7900, loss = 1.233212772011757, 37.804309129714966 s per 100 iters\n","time = 325.0, epoch 19, iter = 8000, loss = 1.2345175683498382, 38.28115105628967 s per 100 iters\n","time = 326.0, epoch 19, iter = 8100, loss = 1.2357820338010788, 38.04956769943237 s per 100 iters\n","time = 327.0, epoch 19, iter = 8200, loss = 1.2700816041231155, 38.6933798789978 s per 100 iters\n","time = 327.0, epoch 19, iter = 8300, loss = 1.2348462641239166, 38.392359018325806 s per 100 iters\n","time = 328.0, epoch 19, iter = 8400, loss = 1.2523184716701508, 38.26800274848938 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 328.0, epoch 19, iter = 8500, loss = 1.2394029933214188, 38.2793915271759 s per 100 iters\n","time = 329.0, epoch 19, iter = 8600, loss = 1.2808051538467407, 37.94634199142456 s per 100 iters\n","time = 330.0, epoch 19, iter = 8700, loss = 1.2524198377132416, 37.5900092124939 s per 100 iters\n","time = 330.0, epoch 19, iter = 8800, loss = 1.253262767791748, 37.78804039955139 s per 100 iters\n","time = 331.0, epoch 19, iter = 8900, loss = 1.255162655711174, 37.992143869400024 s per 100 iters\n","time = 332.0, epoch 19, iter = 9000, loss = 1.2542697602510453, 38.28059411048889 s per 100 iters\n","time = 332.0, epoch 19, iter = 9100, loss = 1.2629580646753311, 37.95804572105408 s per 100 iters\n","time = 333.0, epoch 19, iter = 9200, loss = 1.2729850220680237, 38.659125328063965 s per 100 iters\n","time = 334.0, epoch 19, iter = 9300, loss = 1.2619453758001327, 37.4270179271698 s per 100 iters\n","time = 334.0, epoch 19, iter = 9400, loss = 1.2624610269069672, 37.52566313743591 s per 100 iters\n","time = 335.0, epoch 19, iter = 9500, loss = 1.2642967814207078, 38.95980668067932 s per 100 iters\n","time = 335.0, epoch 19, iter = 9600, loss = 1.2632289606332778, 38.73100280761719 s per 100 iters\n","time = 336.0, epoch 19, iter = 9700, loss = 1.263537304997444, 38.24079895019531 s per 100 iters\n","time = 337.0, epoch 19, iter = 9800, loss = 1.2738942992687226, 38.257442235946655 s per 100 iters\n","time = 337.0, epoch 19, iter = 9900, loss = 1.2459827905893326, 38.73705554008484 s per 100 iters\n","time = 338.0, epoch 19, iter = 10000, loss = 1.2386113786697388, 38.229166984558105 s per 100 iters\n","time = 339.0, epoch 19, iter = 10100, loss = 1.2591862246394157, 38.11570763587952 s per 100 iters\n","time = 339.0, epoch 19, iter = 10200, loss = 1.2617093914747237, 37.91100835800171 s per 100 iters\n","time = 340.0, epoch 19, iter = 10300, loss = 1.2564323163032531, 37.939733028411865 s per 100 iters\n","time = 341.0, epoch 19, iter = 10400, loss = 1.2508066481351852, 37.35868453979492 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 341.0, epoch 19, iter = 10500, loss = 1.2795434373617172, 38.98849177360535 s per 100 iters\n","time = 342.0, epoch 19, iter = 10600, loss = 1.2608216381072999, 38.058204650878906 s per 100 iters\n","time = 342.0, epoch 19, iter = 10700, loss = 1.26390881896019, 38.09150290489197 s per 100 iters\n","time = 343.0, epoch 19, iter = 10800, loss = 1.2726489120721818, 38.317275524139404 s per 100 iters\n","time = 344.0, epoch 19, iter = 10900, loss = 1.2799631851911544, 38.11933207511902 s per 100 iters\n","time = 344.0, epoch 19, iter = 11000, loss = 1.257676780819893, 37.60358428955078 s per 100 iters\n","time = 345.0, epoch 19, iter = 11100, loss = 1.2631365156173706, 37.9678897857666 s per 100 iters\n","time = 346.0, epoch 19, iter = 11200, loss = 1.2803299474716185, 37.719927072525024 s per 100 iters\n","time = 346.0, epoch 19, iter = 11300, loss = 1.2712845712900163, 37.31983947753906 s per 100 iters\n","time = 347.0, epoch 19, iter = 11400, loss = 1.276586385369301, 37.73125982284546 s per 100 iters\n","time = 347.0, epoch 19, iter = 11500, loss = 1.2813353449106217, 37.56129479408264 s per 100 iters\n","time = 348.0, epoch 19, iter = 11600, loss = 1.277019156217575, 37.80774974822998 s per 100 iters\n","time = 349.0, epoch 19, iter = 11700, loss = 1.2852774339914321, 38.224079847335815 s per 100 iters\n","time = 349.0, epoch 19, iter = 11800, loss = 1.277771180868149, 37.90189814567566 s per 100 iters\n","time = 350.0, epoch 19, iter = 11900, loss = 1.2952957463264465, 37.777135133743286 s per 100 iters\n","time = 351.0, epoch 19, iter = 12000, loss = 1.2590425074100495, 37.496631383895874 s per 100 iters\n","time = 351.0, epoch 19, iter = 12100, loss = 1.2756647658348084, 37.86859941482544 s per 100 iters\n","time = 352.0, epoch 19, iter = 12200, loss = 1.2607061439752578, 38.26613426208496 s per 100 iters\n","time = 353.0, epoch 19, iter = 12300, loss = 1.298431847691536, 38.13255023956299 s per 100 iters\n","time = 353.0, epoch 19, iter = 12400, loss = 1.2806161612272262, 37.466965675354004 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 354.0, epoch 19, iter = 12500, loss = 1.2785936605930328, 37.759273529052734 s per 100 iters\n","time = 354.0, epoch 19, iter = 12600, loss = 1.2592793905735016, 38.17289900779724 s per 100 iters\n","time = 355.0, epoch 19, iter = 12700, loss = 1.2895706713199615, 37.88162136077881 s per 100 iters\n","time = 356.0, epoch 19, iter = 12800, loss = 1.3013576340675355, 38.298946142196655 s per 100 iters\n","time = 356.0, epoch 19, iter = 12900, loss = 1.2836301040649414, 37.60999345779419 s per 100 iters\n","time = 357.0, epoch 19, iter = 13000, loss = 1.2916931879520417, 38.64971041679382 s per 100 iters\n","time = 358.0, epoch 19, iter = 13100, loss = 1.265460215806961, 37.90258169174194 s per 100 iters\n","time = 358.0, epoch 19, iter = 13200, loss = 1.287195433974266, 38.24666619300842 s per 100 iters\n","time = 359.0, epoch 19, iter = 13300, loss = 1.2912825793027878, 36.92925977706909 s per 100 iters\n","time = 359.0, epoch 19, iter = 13400, loss = 1.283377050757408, 38.248236417770386 s per 100 iters\n","time = 360.0, epoch 19, iter = 13500, loss = 1.2747366613149642, 37.79621696472168 s per 100 iters\n","time = 361.0, epoch 19, iter = 13600, loss = 1.2798765325546264, 38.08736872673035 s per 100 iters\n","time = 361.0, epoch 19, iter = 13700, loss = 1.2769212639331817, 37.73077440261841 s per 100 iters\n","time = 362.0, epoch 19, iter = 13800, loss = 1.2682615864276885, 38.12612795829773 s per 100 iters\n","time = 363.0, epoch 19, iter = 13900, loss = 1.28428562104702, 37.80923128128052 s per 100 iters\n","time = 363.0, epoch 19, iter = 14000, loss = 1.2960831314325332, 38.050227880477905 s per 100 iters\n","time = 364.0, epoch 19, iter = 14100, loss = 1.2910155099630356, 38.08471751213074 s per 100 iters\n","time = 365.0, epoch 19, iter = 14200, loss = 1.2866736322641372, 39.019782304763794 s per 100 iters\n","time = 365.0, epoch 19, iter = 14300, loss = 1.2730027848482133, 37.550785779953 s per 100 iters\n","--- Balidazioa ---\n","35.314960956573486 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭\" ￭.', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hura ￭?', '｟B rosanna spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da kantaria eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ondo jan zuen lehen aldiz ￭, ｟C siziliako bazterretan lehorreratu zenetik ￭, eta nesken xarma ￭, aita ｟C pirroneren austertasuna eta ｟C don ｟C fabrizioren moduek komentzitu zuten ｟C donnafugatako jauregia ez zela ｟C capraro bandidoaren antroa ￭, eta bertan seguru asko bizirik irtengo zela ￭.', '｟C erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C aaaaa ￭!', '｟C orain bi ditut ￭.', 'magistratuak eta epailetza-graduko beste ofizial batzuk ￭, jukutria artifizialak dira ￭; saria eta zigorra ￭, zeinen bidez subiranotasunaren egoitza eta kide bakoitza bere eginkizunaren betetzeko mugatzen baitira ￭, gorputzean gauza bera egiten duten nerbioak dira ￭; gorputzean gauza bera egiten dute ￭, eta kide partikular bakoitzaren aberastasunak eta aberastasun guztiak ￭, herria ￭, herria ￭, herria ￭, aholkulariak dira ￭, eta horien helburua ￭, hau da ￭, hau da ￭, ｟C estatuaren administrazioan ￭, gauza guztiei ematea ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hura bera ere beren ideala besterik ez da ￭, eta agian beste inor ez dute irudikatzen gaur egun ￭, beraiek dira beren izpiritualizatuen ekoizlea ￭, bere gudari eta esploratzaileen tropa aurreratuena ￭, bere jostaketa-forma fin eta sedukigarriena ￭.', '｟C hegoaldean ez dago esklaborik ez edukitzearren adina familia pobre ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kasuan eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 12.013797105673316\n","8.147238492965698 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika oso interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvette istorioari buruz hitz egiten dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosi egingo al duzu ￭, ｟C john ￭?', '｟C horra hor arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin hitz egin nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia dut ￭, 1960an eta semea 1940ko uniformean erakusteko ￭.', '｟C orduan ￭, dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotan ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.6297914024585\n","BLEU puntuazioa (biak): 15.39397671143517\n","time = 367.0, epoch 20, iter = 100, loss = 1.1541757571697235, 39.74796509742737 s per 100 iters\n","time = 367.0, epoch 20, iter = 200, loss = 1.1629197934269906, 38.392298460006714 s per 100 iters\n","time = 368.0, epoch 20, iter = 300, loss = 1.1362998047471047, 37.70439147949219 s per 100 iters\n","time = 369.0, epoch 20, iter = 400, loss = 1.1560449063777924, 38.32970690727234 s per 100 iters\n","time = 369.0, epoch 20, iter = 500, loss = 1.1304150664806365, 38.23959541320801 s per 100 iters\n","time = 370.0, epoch 20, iter = 600, loss = 1.1467117962241173, 37.12632393836975 s per 100 iters\n","time = 371.0, epoch 20, iter = 700, loss = 1.137830457687378, 37.16930413246155 s per 100 iters\n","time = 371.0, epoch 20, iter = 800, loss = 1.1561900153756142, 38.353153228759766 s per 100 iters\n","time = 372.0, epoch 20, iter = 900, loss = 1.1415219208598137, 37.82143545150757 s per 100 iters\n","time = 373.0, epoch 20, iter = 1000, loss = 1.1410726010799408, 38.061532497406006 s per 100 iters\n","time = 373.0, epoch 20, iter = 1100, loss = 1.1497024261951447, 37.8973069190979 s per 100 iters\n","time = 374.0, epoch 20, iter = 1200, loss = 1.1571217149496078, 37.36237621307373 s per 100 iters\n","time = 374.0, epoch 20, iter = 1300, loss = 1.1744467091560364, 39.118773460388184 s per 100 iters\n","time = 375.0, epoch 20, iter = 1400, loss = 1.15763833463192, 38.35293197631836 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-c56c98f41c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mentrenatu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-47-3280eebef4ed>\u001b[0m in \u001b[0;36mentrenatu\u001b[0;34m(hasi_epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_with_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mnew_fp32_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             models_are_masters=False)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp16_grads_needing_unscale_with_stash\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale\u001b[0;34m(self, model_grads, master_grads, unused_scale, models_are_masters, scale_override)\u001b[0m\n\u001b[1;32m    117\u001b[0m                                  1./scale)\n\u001b[1;32m    118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# Defer to update_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_python\u001b[0;34m(self, model_grads, master_grads, scale)\u001b[0m\n\u001b[1;32m     87\u001b[0m                                                                  \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                                                  \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                                                                  self.dynamic)\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36mscale_check_overflow_python\u001b[0;34m(model_grad, master_grad, scale, check_overflow)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"zcV1v1W1rpqo","colab_type":"text"},"source":["# Bakarrarekin checkpointetik entrenatzeko"]},{"cell_type":"code","metadata":{"id":"Dj69my9Drt-n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f3e91497-a2fa-4bf2-8b33-865a155e60e7"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/enbakarrik-8.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu_bakarra(lang=1, hasi_epoch=9)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 9, iter = 100, loss = 1.8229245960712432, 24.16276264190674 s per 100 iters\n","time = 0.0, epoch 9, iter = 200, loss = 1.8201310795545578, 22.809789896011353 s per 100 iters\n","time = 1.0, epoch 9, iter = 300, loss = 1.8307104712724687, 22.444570541381836 s per 100 iters\n","time = 1.0, epoch 9, iter = 400, loss = 1.7842485058307647, 22.610954999923706 s per 100 iters\n","time = 1.0, epoch 9, iter = 500, loss = 1.8178571599721909, 24.29111123085022 s per 100 iters\n","time = 2.0, epoch 9, iter = 600, loss = 1.8252231115102768, 23.267595291137695 s per 100 iters\n","time = 2.0, epoch 9, iter = 700, loss = 1.8044104993343353, 23.12816071510315 s per 100 iters\n","time = 3.0, epoch 9, iter = 800, loss = 1.8333674776554107, 24.192705392837524 s per 100 iters\n","time = 3.0, epoch 9, iter = 900, loss = 1.8118944323062898, 22.71843934059143 s per 100 iters\n","time = 3.0, epoch 9, iter = 1000, loss = 1.7925221705436707, 24.204169750213623 s per 100 iters\n","time = 4.0, epoch 9, iter = 1100, loss = 1.8440751856565476, 23.847012519836426 s per 100 iters\n","time = 4.0, epoch 9, iter = 1200, loss = 1.8167098987102508, 24.197312116622925 s per 100 iters\n","time = 5.0, epoch 9, iter = 1300, loss = 1.8269119846820832, 24.22587823867798 s per 100 iters\n","time = 5.0, epoch 9, iter = 1400, loss = 1.7989369928836823, 24.262415885925293 s per 100 iters\n","time = 5.0, epoch 9, iter = 1500, loss = 1.839189196228981, 23.89439034461975 s per 100 iters\n","time = 6.0, epoch 9, iter = 1600, loss = 1.808085298538208, 23.194773197174072 s per 100 iters\n","time = 6.0, epoch 9, iter = 1700, loss = 1.8187624877691269, 22.95605492591858 s per 100 iters\n","time = 7.0, epoch 9, iter = 1800, loss = 1.8260991632938386, 23.729583024978638 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 7.0, epoch 9, iter = 1900, loss = 1.8359648591279984, 23.96052575111389 s per 100 iters\n","time = 7.0, epoch 9, iter = 2000, loss = 1.8205766701698303, 22.567856550216675 s per 100 iters\n","time = 8.0, epoch 9, iter = 2100, loss = 1.8219614732265472, 22.761680126190186 s per 100 iters\n","time = 8.0, epoch 9, iter = 2200, loss = 1.8300171625614166, 23.149534702301025 s per 100 iters\n","time = 9.0, epoch 9, iter = 2300, loss = 1.839652922153473, 24.573368549346924 s per 100 iters\n","time = 9.0, epoch 9, iter = 2400, loss = 1.8580636274814606, 24.18024230003357 s per 100 iters\n","time = 9.0, epoch 9, iter = 2500, loss = 1.8698539501428604, 24.348728895187378 s per 100 iters\n","time = 10.0, epoch 9, iter = 2600, loss = 1.8460514235496521, 23.11587691307068 s per 100 iters\n","time = 10.0, epoch 9, iter = 2700, loss = 1.8453752636909484, 23.858912229537964 s per 100 iters\n","time = 11.0, epoch 9, iter = 2800, loss = 1.8286541736125945, 23.35808539390564 s per 100 iters\n","time = 11.0, epoch 9, iter = 2900, loss = 1.8359088188409804, 23.028186082839966 s per 100 iters\n","time = 11.0, epoch 9, iter = 3000, loss = 1.8246792048215865, 24.04102349281311 s per 100 iters\n","time = 12.0, epoch 9, iter = 3100, loss = 1.8266392016410828, 23.049724578857422 s per 100 iters\n","time = 12.0, epoch 9, iter = 3200, loss = 1.8507722878456117, 23.896114349365234 s per 100 iters\n","time = 12.0, epoch 9, iter = 3300, loss = 1.8383740919828415, 23.200981378555298 s per 100 iters\n","time = 13.0, epoch 9, iter = 3400, loss = 1.8355406057834625, 23.593193292617798 s per 100 iters\n","time = 13.0, epoch 9, iter = 3500, loss = 1.8536394184827805, 23.244659423828125 s per 100 iters\n","time = 14.0, epoch 9, iter = 3600, loss = 1.83325563788414, 22.62389302253723 s per 100 iters\n","time = 14.0, epoch 9, iter = 3700, loss = 1.8455687510967254, 23.148008823394775 s per 100 iters\n","time = 14.0, epoch 9, iter = 3800, loss = 1.8375180220603944, 23.58047342300415 s per 100 iters\n","time = 15.0, epoch 9, iter = 3900, loss = 1.838480805158615, 22.653895139694214 s per 100 iters\n","time = 15.0, epoch 9, iter = 4000, loss = 1.8522464787960053, 23.37420105934143 s per 100 iters\n","time = 16.0, epoch 9, iter = 4100, loss = 1.8557044440507888, 23.927043437957764 s per 100 iters\n","time = 16.0, epoch 9, iter = 4200, loss = 1.8488442879915237, 23.484704732894897 s per 100 iters\n","time = 16.0, epoch 9, iter = 4300, loss = 1.862260788679123, 23.5378999710083 s per 100 iters\n","time = 17.0, epoch 9, iter = 4400, loss = 1.870804557800293, 23.659977674484253 s per 100 iters\n","time = 17.0, epoch 9, iter = 4500, loss = 1.844505836367607, 23.35285186767578 s per 100 iters\n","time = 18.0, epoch 9, iter = 4600, loss = 1.8683185172080994, 23.87099575996399 s per 100 iters\n","time = 18.0, epoch 9, iter = 4700, loss = 1.8680815196037293, 23.260014295578003 s per 100 iters\n","time = 18.0, epoch 9, iter = 4800, loss = 1.8759913074970245, 23.539469242095947 s per 100 iters\n","time = 19.0, epoch 9, iter = 4900, loss = 1.8639774763584136, 23.512295961380005 s per 100 iters\n","time = 19.0, epoch 9, iter = 5000, loss = 1.8616249752044678, 24.219778776168823 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 19.0, epoch 9, iter = 5100, loss = 1.866775892972946, 23.618258714675903 s per 100 iters\n","time = 20.0, epoch 9, iter = 5200, loss = 1.8628431469202043, 23.79279923439026 s per 100 iters\n","time = 20.0, epoch 9, iter = 5300, loss = 1.8699832785129546, 24.436599731445312 s per 100 iters\n","time = 21.0, epoch 9, iter = 5400, loss = 1.8841767609119415, 23.215649604797363 s per 100 iters\n","time = 21.0, epoch 9, iter = 5500, loss = 1.8718482375144958, 23.635928630828857 s per 100 iters\n","time = 21.0, epoch 9, iter = 5600, loss = 1.8583191156387329, 23.58749747276306 s per 100 iters\n","time = 22.0, epoch 9, iter = 5700, loss = 1.8535959643125535, 23.222853422164917 s per 100 iters\n","time = 22.0, epoch 9, iter = 5800, loss = 1.8529630142450333, 23.797749757766724 s per 100 iters\n","time = 23.0, epoch 9, iter = 5900, loss = 1.854531980752945, 22.952564477920532 s per 100 iters\n","time = 23.0, epoch 9, iter = 6000, loss = 1.8678463149070739, 23.780938386917114 s per 100 iters\n","time = 23.0, epoch 9, iter = 6100, loss = 1.8546729665994643, 23.56341004371643 s per 100 iters\n","time = 24.0, epoch 9, iter = 6200, loss = 1.8730480182170868, 23.85627007484436 s per 100 iters\n","time = 24.0, epoch 9, iter = 6300, loss = 1.8693891316652298, 23.926204681396484 s per 100 iters\n","time = 25.0, epoch 9, iter = 6400, loss = 1.8574785375595093, 24.038387060165405 s per 100 iters\n","time = 25.0, epoch 9, iter = 6500, loss = 1.8714981001615525, 23.452748775482178 s per 100 iters\n","time = 25.0, epoch 9, iter = 6600, loss = 1.8480488699674607, 23.31122136116028 s per 100 iters\n","time = 26.0, epoch 9, iter = 6700, loss = 1.8827798414230346, 24.127968072891235 s per 100 iters\n","time = 26.0, epoch 9, iter = 6800, loss = 1.873550066947937, 24.02930212020874 s per 100 iters\n","time = 27.0, epoch 9, iter = 6900, loss = 1.8707196700572968, 23.376925230026245 s per 100 iters\n","time = 27.0, epoch 9, iter = 7000, loss = 1.8721649181842803, 23.71091604232788 s per 100 iters\n","time = 27.0, epoch 9, iter = 7100, loss = 1.868555125594139, 23.42063617706299 s per 100 iters\n","time = 28.0, epoch 9, iter = 7200, loss = 1.8730399292707443, 24.101291179656982 s per 100 iters\n","time = 28.0, epoch 9, iter = 7300, loss = 1.881515828371048, 23.266573429107666 s per 100 iters\n","time = 29.0, epoch 9, iter = 7400, loss = 1.875824669599533, 23.833143711090088 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 29.0, epoch 9, iter = 7500, loss = 1.8562666416168212, 23.088472604751587 s per 100 iters\n","time = 29.0, epoch 9, iter = 7600, loss = 1.8648649859428406, 23.275971174240112 s per 100 iters\n","time = 30.0, epoch 9, iter = 7700, loss = 1.8678271293640136, 23.859098196029663 s per 100 iters\n","time = 30.0, epoch 9, iter = 7800, loss = 1.8803431898355485, 23.345447063446045 s per 100 iters\n","time = 31.0, epoch 9, iter = 7900, loss = 1.8647193700075149, 23.370397329330444 s per 100 iters\n","time = 31.0, epoch 9, iter = 8000, loss = 1.8773606777191163, 23.64894986152649 s per 100 iters\n","time = 31.0, epoch 9, iter = 8100, loss = 1.8781117188930512, 23.51408362388611 s per 100 iters\n","time = 32.0, epoch 9, iter = 8200, loss = 1.8640117537975311, 23.425657510757446 s per 100 iters\n","time = 32.0, epoch 9, iter = 8300, loss = 1.8762841898202895, 23.577499628067017 s per 100 iters\n","time = 32.0, epoch 9, iter = 8400, loss = 1.8857262754440307, 23.627338647842407 s per 100 iters\n","time = 33.0, epoch 9, iter = 8500, loss = 1.8767508554458618, 23.71412754058838 s per 100 iters\n","time = 33.0, epoch 9, iter = 8600, loss = 1.8642897713184357, 23.213696479797363 s per 100 iters\n","time = 34.0, epoch 9, iter = 8700, loss = 1.8964490711688995, 24.17287850379944 s per 100 iters\n","time = 34.0, epoch 9, iter = 8800, loss = 1.872754293680191, 23.952924966812134 s per 100 iters\n","time = 34.0, epoch 9, iter = 8900, loss = 1.8979520225524902, 24.271775484085083 s per 100 iters\n","time = 35.0, epoch 9, iter = 9000, loss = 1.895551437139511, 24.227274417877197 s per 100 iters\n","time = 35.0, epoch 9, iter = 9100, loss = 1.882782508134842, 24.076982498168945 s per 100 iters\n","time = 36.0, epoch 9, iter = 9200, loss = 1.870962107181549, 23.354215145111084 s per 100 iters\n","time = 36.0, epoch 9, iter = 9300, loss = 1.8894400417804718, 23.1784451007843 s per 100 iters\n","time = 36.0, epoch 9, iter = 9400, loss = 1.8805750477313996, 23.338601112365723 s per 100 iters\n","time = 37.0, epoch 9, iter = 9500, loss = 1.8738786840438844, 23.677438735961914 s per 100 iters\n","time = 37.0, epoch 9, iter = 9600, loss = 1.9050969326496123, 24.50587010383606 s per 100 iters\n","time = 38.0, epoch 9, iter = 9700, loss = 1.8725174236297608, 24.3495512008667 s per 100 iters\n","time = 38.0, epoch 9, iter = 9800, loss = 1.8733364140987396, 23.72476863861084 s per 100 iters\n","time = 38.0, epoch 9, iter = 9900, loss = 1.8926203501224519, 24.083393812179565 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 39.0, epoch 9, iter = 10000, loss = 1.8697915589809417, 22.78597617149353 s per 100 iters\n","time = 39.0, epoch 9, iter = 10100, loss = 1.879156917333603, 23.447373390197754 s per 100 iters\n","time = 40.0, epoch 9, iter = 10200, loss = 1.8946832525730133, 23.553924560546875 s per 100 iters\n","time = 40.0, epoch 9, iter = 10300, loss = 1.9131302511692048, 23.178365230560303 s per 100 iters\n","time = 40.0, epoch 9, iter = 10400, loss = 1.8854118001461029, 23.18057155609131 s per 100 iters\n","time = 41.0, epoch 9, iter = 10500, loss = 1.8731984055042268, 23.29578447341919 s per 100 iters\n","time = 41.0, epoch 9, iter = 10600, loss = 1.899636937379837, 24.184484720230103 s per 100 iters\n","time = 42.0, epoch 9, iter = 10700, loss = 1.8600354552268983, 23.162989139556885 s per 100 iters\n","time = 42.0, epoch 9, iter = 10800, loss = 1.9059167742729186, 23.49034881591797 s per 100 iters\n","time = 42.0, epoch 9, iter = 10900, loss = 1.8782198131084442, 23.731664657592773 s per 100 iters\n","time = 43.0, epoch 9, iter = 11000, loss = 1.8861927407979966, 23.66316866874695 s per 100 iters\n","time = 43.0, epoch 9, iter = 11100, loss = 1.8926284563541413, 24.15145754814148 s per 100 iters\n","time = 44.0, epoch 9, iter = 11200, loss = 1.8731623089313507, 23.037880659103394 s per 100 iters\n","time = 44.0, epoch 9, iter = 11300, loss = 1.887367478609085, 24.207563877105713 s per 100 iters\n","time = 44.0, epoch 9, iter = 11400, loss = 1.8857717871665955, 23.76578140258789 s per 100 iters\n","time = 45.0, epoch 9, iter = 11500, loss = 1.8819652950763703, 23.406646013259888 s per 100 iters\n","time = 45.0, epoch 9, iter = 11600, loss = 1.8809716963768006, 23.360172986984253 s per 100 iters\n","time = 45.0, epoch 9, iter = 11700, loss = 1.898997745513916, 23.48452115058899 s per 100 iters\n","time = 46.0, epoch 9, iter = 11800, loss = 1.885458618402481, 23.360796213150024 s per 100 iters\n","time = 46.0, epoch 9, iter = 11900, loss = 1.8901776897907256, 23.38829755783081 s per 100 iters\n","time = 47.0, epoch 9, iter = 12000, loss = 1.8948317933082581, 23.282214641571045 s per 100 iters\n","time = 47.0, epoch 9, iter = 12100, loss = 1.8883554422855378, 23.89721918106079 s per 100 iters\n","time = 47.0, epoch 9, iter = 12200, loss = 1.9024893271923065, 23.51470160484314 s per 100 iters\n","time = 48.0, epoch 9, iter = 12300, loss = 1.8960849821567536, 23.992595672607422 s per 100 iters\n","time = 48.0, epoch 9, iter = 12400, loss = 1.8934375429153443, 23.57783079147339 s per 100 iters\n","time = 49.0, epoch 9, iter = 12500, loss = 1.8944007873535156, 22.895883560180664 s per 100 iters\n","time = 49.0, epoch 9, iter = 12600, loss = 1.8959611874818803, 24.467833042144775 s per 100 iters\n","time = 49.0, epoch 9, iter = 12700, loss = 1.8930532133579254, 22.751119375228882 s per 100 iters\n","time = 50.0, epoch 9, iter = 12800, loss = 1.9058699464797975, 23.27310562133789 s per 100 iters\n","time = 50.0, epoch 9, iter = 12900, loss = 1.909098653793335, 24.019846439361572 s per 100 iters\n","time = 51.0, epoch 9, iter = 13000, loss = 1.878246567249298, 23.28481888771057 s per 100 iters\n","time = 51.0, epoch 9, iter = 13100, loss = 1.9307759749889373, 24.34411072731018 s per 100 iters\n","time = 51.0, epoch 9, iter = 13200, loss = 1.8913689744472504, 22.623393774032593 s per 100 iters\n","time = 52.0, epoch 9, iter = 13300, loss = 1.8908813798427582, 22.959028959274292 s per 100 iters\n","time = 52.0, epoch 9, iter = 13400, loss = 1.8762888526916504, 23.464688301086426 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 53.0, epoch 9, iter = 13500, loss = 1.8908651143312454, 23.666220664978027 s per 100 iters\n","time = 53.0, epoch 9, iter = 13600, loss = 1.8889837837219239, 23.27511692047119 s per 100 iters\n","time = 53.0, epoch 9, iter = 13700, loss = 1.8934712648391723, 23.917290687561035 s per 100 iters\n","time = 54.0, epoch 9, iter = 13800, loss = 1.8941465371847153, 23.396312475204468 s per 100 iters\n","time = 54.0, epoch 9, iter = 13900, loss = 1.89538272023201, 23.488009691238403 s per 100 iters\n","time = 55.0, epoch 9, iter = 14000, loss = 1.899746023416519, 23.83206009864807 s per 100 iters\n","time = 55.0, epoch 9, iter = 14100, loss = 1.8982827281951904, 22.98197102546692 s per 100 iters\n","time = 55.0, epoch 9, iter = 14200, loss = 1.926061898469925, 23.432748079299927 s per 100 iters\n","time = 56.0, epoch 9, iter = 14300, loss = 1.880172302722931, 22.92384099960327 s per 100 iters\n","--- Balidazioa ---\n","26.578368425369263 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '｟B rosanna spearman ｟E', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afaritan ￭, ｟C siziliako itsasertzean lehenengo aldiz oina jarri zuen ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneen austeritatea ￭, eta ｟C don ｟C fabriziori zegokion moduan ￭, ｟C donnafugatarren jauregia ez zela ｟C capraroko ezkongaia ￭, eta bizirik irtengo zela seguru aski ￭.', '｟C denek erosten zuten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaileak eta exekuzio-eginkizunak ￭, ｟C joynes artisauak ￭, ｟C auzitegiari dagokiona ￭, subiranotasunarekin batera ￭, dintulu eta kide bakoitza bere betebeharraren arabera jokatzera doan zigorra ￭, gorputz naturalean dauden nerbio guztiak ￭, botereak eta aberastasunak ￭, ｟C salboak ￭, ｟C popularrak (￭ ｟C popularrak ￭) dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau haien ideala besterik ez da ￭, gaur egun eta agian beste inorena ere ordezkatzen dute ￭, beren ekoizpen izpiritualik handiena ￭, bere borrokalariak eta eskautarik aurreratuenak ￭, bere sedukzioaren forma delikatuena eta erokorena ￭.', '｟C hegoaldean ez dago esklaboak ez edukitzeko bezain familia pobreik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en gauza horrekin ￭, eta orain ｟C mafiaren akusazioa ￭?']\n","BLEU puntuazioa (1): 8.955477858174874\n","5.35071587562561 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C musika interesgarria zen ￭, ｟C marty ￭.', '｟C eta ｟C nick zaharrak janaria ekarriko digula uste duzu ￭?', '- ｟C ezagutzen dugu ｟C corvette ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorri zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C basoan otsoak egongo dira ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ｟C berdin zaizu ￭?', '｟C argazki bat atera dut 1960an eta semea 1940ko uniformearekin ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C seguru zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.50863551180328\n","BLEU puntuazioa (biak): 12.109327069801958\n","time = 57.0, epoch 10, iter = 100, loss = 1.7528099977970124, 24.05571484565735 s per 100 iters\n","time = 57.0, epoch 10, iter = 200, loss = 1.7494138902425767, 23.925714254379272 s per 100 iters\n","time = 58.0, epoch 10, iter = 300, loss = 1.7670801109075547, 23.59413433074951 s per 100 iters\n","time = 58.0, epoch 10, iter = 400, loss = 1.7637732255458831, 23.865673780441284 s per 100 iters\n","time = 58.0, epoch 10, iter = 500, loss = 1.7662375700473785, 23.662480115890503 s per 100 iters\n","time = 59.0, epoch 10, iter = 600, loss = 1.780102134346962, 24.051348209381104 s per 100 iters\n","time = 59.0, epoch 10, iter = 700, loss = 1.7577476924657822, 23.164122581481934 s per 100 iters\n","time = 60.0, epoch 10, iter = 800, loss = 1.7721680283546448, 23.633602142333984 s per 100 iters\n","time = 60.0, epoch 10, iter = 900, loss = 1.7518810957670212, 23.097002506256104 s per 100 iters\n","time = 60.0, epoch 10, iter = 1000, loss = 1.777789580821991, 23.606261491775513 s per 100 iters\n","time = 61.0, epoch 10, iter = 1100, loss = 1.7970933145284653, 23.2945613861084 s per 100 iters\n","time = 61.0, epoch 10, iter = 1200, loss = 1.780618770122528, 24.35931634902954 s per 100 iters\n","time = 61.0, epoch 10, iter = 1300, loss = 1.749437604546547, 23.21176314353943 s per 100 iters\n","time = 62.0, epoch 10, iter = 1400, loss = 1.7750050377845765, 23.080539226531982 s per 100 iters\n","time = 62.0, epoch 10, iter = 1500, loss = 1.782413985133171, 23.952085733413696 s per 100 iters\n","time = 63.0, epoch 10, iter = 1600, loss = 1.7787357914447783, 24.635344982147217 s per 100 iters\n","time = 63.0, epoch 10, iter = 1700, loss = 1.7706596922874451, 24.049907684326172 s per 100 iters\n","time = 63.0, epoch 10, iter = 1800, loss = 1.799680483341217, 24.136003017425537 s per 100 iters\n","time = 64.0, epoch 10, iter = 1900, loss = 1.7753261810541152, 24.720662593841553 s per 100 iters\n","time = 64.0, epoch 10, iter = 2000, loss = 1.7770787101984025, 24.185821771621704 s per 100 iters\n","time = 65.0, epoch 10, iter = 2100, loss = 1.7857406717538833, 22.96182084083557 s per 100 iters\n","time = 65.0, epoch 10, iter = 2200, loss = 1.7830487209558488, 22.845417261123657 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 65.0, epoch 10, iter = 2300, loss = 1.786049326658249, 23.938823223114014 s per 100 iters\n","time = 66.0, epoch 10, iter = 2400, loss = 1.7872986954450607, 22.94848871231079 s per 100 iters\n","time = 66.0, epoch 10, iter = 2500, loss = 1.784559227824211, 23.63101100921631 s per 100 iters\n","time = 67.0, epoch 10, iter = 2600, loss = 1.81120814204216, 23.657926082611084 s per 100 iters\n","time = 67.0, epoch 10, iter = 2700, loss = 1.8085188525915146, 24.019288301467896 s per 100 iters\n","time = 67.0, epoch 10, iter = 2800, loss = 1.7969815808534622, 24.425884246826172 s per 100 iters\n","time = 68.0, epoch 10, iter = 2900, loss = 1.7611720532178878, 23.15347671508789 s per 100 iters\n","time = 68.0, epoch 10, iter = 3000, loss = 1.812512766122818, 23.847652435302734 s per 100 iters\n","time = 69.0, epoch 10, iter = 3100, loss = 1.8046038681268692, 22.930925369262695 s per 100 iters\n","time = 69.0, epoch 10, iter = 3200, loss = 1.7921689450740814, 23.767651319503784 s per 100 iters\n","time = 69.0, epoch 10, iter = 3300, loss = 1.7994295066595078, 24.01143455505371 s per 100 iters\n","time = 70.0, epoch 10, iter = 3400, loss = 1.7829202699661255, 23.49449920654297 s per 100 iters\n","time = 70.0, epoch 10, iter = 3500, loss = 1.814469826221466, 23.65508794784546 s per 100 iters\n","time = 71.0, epoch 10, iter = 3600, loss = 1.8221428847312928, 23.231447219848633 s per 100 iters\n","time = 71.0, epoch 10, iter = 3700, loss = 1.7991857349872589, 23.792423248291016 s per 100 iters\n","time = 71.0, epoch 10, iter = 3800, loss = 1.7949109327793122, 22.726993560791016 s per 100 iters\n","time = 72.0, epoch 10, iter = 3900, loss = 1.8150011789798737, 23.36753559112549 s per 100 iters\n","time = 72.0, epoch 10, iter = 4000, loss = 1.8074854350090026, 22.8174045085907 s per 100 iters\n","time = 73.0, epoch 10, iter = 4100, loss = 1.8122559440135957, 23.615388870239258 s per 100 iters\n","time = 73.0, epoch 10, iter = 4200, loss = 1.8169931077957153, 23.63327383995056 s per 100 iters\n","time = 73.0, epoch 10, iter = 4300, loss = 1.8315931218862533, 23.417802333831787 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 74.0, epoch 10, iter = 4400, loss = 1.809745963215828, 23.881367444992065 s per 100 iters\n","time = 74.0, epoch 10, iter = 4500, loss = 1.7877060794830322, 22.295156478881836 s per 100 iters\n","time = 74.0, epoch 10, iter = 4600, loss = 1.8153702241182328, 23.65318775177002 s per 100 iters\n","time = 75.0, epoch 10, iter = 4700, loss = 1.810593727827072, 23.378379106521606 s per 100 iters\n","time = 75.0, epoch 10, iter = 4800, loss = 1.8063378703594208, 24.02576184272766 s per 100 iters\n","time = 76.0, epoch 10, iter = 4900, loss = 1.8213636291027069, 23.92992115020752 s per 100 iters\n","time = 76.0, epoch 10, iter = 5000, loss = 1.8224733412265777, 23.66648244857788 s per 100 iters\n","time = 76.0, epoch 10, iter = 5100, loss = 1.8252493911981582, 23.41786289215088 s per 100 iters\n","time = 77.0, epoch 10, iter = 5200, loss = 1.824937447309494, 23.421644687652588 s per 100 iters\n","time = 77.0, epoch 10, iter = 5300, loss = 1.8342680954933166, 23.387741327285767 s per 100 iters\n","time = 78.0, epoch 10, iter = 5400, loss = 1.8316690546274186, 23.75542140007019 s per 100 iters\n","time = 78.0, epoch 10, iter = 5500, loss = 1.8350229394435882, 23.315821886062622 s per 100 iters\n","time = 78.0, epoch 10, iter = 5600, loss = 1.8276254910230636, 24.553855657577515 s per 100 iters\n","time = 79.0, epoch 10, iter = 5700, loss = 1.817976372241974, 23.422964572906494 s per 100 iters\n","time = 79.0, epoch 10, iter = 5800, loss = 1.8346607542037965, 23.034661531448364 s per 100 iters\n","time = 80.0, epoch 10, iter = 5900, loss = 1.8219462305307388, 23.935710668563843 s per 100 iters\n","time = 80.0, epoch 10, iter = 6000, loss = 1.8112392330169678, 23.78312635421753 s per 100 iters\n","time = 80.0, epoch 10, iter = 6100, loss = 1.8342102974653245, 23.560982704162598 s per 100 iters\n","time = 81.0, epoch 10, iter = 6200, loss = 1.8139576560258865, 22.939669847488403 s per 100 iters\n","time = 81.0, epoch 10, iter = 6300, loss = 1.84787695646286, 23.821985483169556 s per 100 iters\n","time = 82.0, epoch 10, iter = 6400, loss = 1.8503466111421585, 24.483778953552246 s per 100 iters\n","time = 82.0, epoch 10, iter = 6500, loss = 1.8421173310279846, 23.021066427230835 s per 100 iters\n","time = 82.0, epoch 10, iter = 6600, loss = 1.79986159324646, 22.441227674484253 s per 100 iters\n","time = 83.0, epoch 10, iter = 6700, loss = 1.8430753457546234, 22.763569355010986 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 83.0, epoch 10, iter = 6800, loss = 1.8413854002952577, 24.53596067428589 s per 100 iters\n","time = 83.0, epoch 10, iter = 6900, loss = 1.8344381940364838, 23.459058046340942 s per 100 iters\n","time = 84.0, epoch 10, iter = 7000, loss = 1.816947772502899, 23.238439321517944 s per 100 iters\n","time = 84.0, epoch 10, iter = 7100, loss = 1.8268053078651427, 22.97952175140381 s per 100 iters\n","time = 85.0, epoch 10, iter = 7200, loss = 1.8122108709812164, 23.1063814163208 s per 100 iters\n","time = 85.0, epoch 10, iter = 7300, loss = 1.8270032596588135, 23.961101055145264 s per 100 iters\n","time = 85.0, epoch 10, iter = 7400, loss = 1.8353694027662277, 23.970147848129272 s per 100 iters\n","time = 86.0, epoch 10, iter = 7500, loss = 1.8468401569128037, 23.616191625595093 s per 100 iters\n","time = 86.0, epoch 10, iter = 7600, loss = 1.8420232445001603, 23.484692096710205 s per 100 iters\n","time = 87.0, epoch 10, iter = 7700, loss = 1.8434188568592071, 23.423686504364014 s per 100 iters\n","time = 87.0, epoch 10, iter = 7800, loss = 1.8461954998970032, 23.800115823745728 s per 100 iters\n","time = 87.0, epoch 10, iter = 7900, loss = 1.8386023712158204, 23.725571632385254 s per 100 iters\n","time = 88.0, epoch 10, iter = 8000, loss = 1.8329363179206848, 22.811721563339233 s per 100 iters\n","time = 88.0, epoch 10, iter = 8100, loss = 1.8157764607667923, 23.075818300247192 s per 100 iters\n","time = 89.0, epoch 10, iter = 8200, loss = 1.8416134369373323, 24.09526753425598 s per 100 iters\n","time = 89.0, epoch 10, iter = 8300, loss = 1.8336635059118271, 23.709948301315308 s per 100 iters\n","time = 89.0, epoch 10, iter = 8400, loss = 1.849509288072586, 23.779696226119995 s per 100 iters\n","time = 90.0, epoch 10, iter = 8500, loss = 1.8523879605531692, 23.798794984817505 s per 100 iters\n","time = 90.0, epoch 10, iter = 8600, loss = 1.815993488430977, 23.323745012283325 s per 100 iters\n","time = 91.0, epoch 10, iter = 8700, loss = 1.822209114432335, 23.1152925491333 s per 100 iters\n","time = 91.0, epoch 10, iter = 8800, loss = 1.8490689259767532, 23.715681314468384 s per 100 iters\n","time = 91.0, epoch 10, iter = 8900, loss = 1.8348352748155594, 23.41654634475708 s per 100 iters\n","time = 92.0, epoch 10, iter = 9000, loss = 1.859154549241066, 23.655035972595215 s per 100 iters\n","time = 92.0, epoch 10, iter = 9100, loss = 1.8514499735832215, 24.097864389419556 s per 100 iters\n","time = 93.0, epoch 10, iter = 9200, loss = 1.8551242136955262, 23.82466435432434 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 93.0, epoch 10, iter = 9300, loss = 1.8319448387622834, 23.53442144393921 s per 100 iters\n","time = 93.0, epoch 10, iter = 9400, loss = 1.8421278792619704, 23.810179948806763 s per 100 iters\n","time = 94.0, epoch 10, iter = 9500, loss = 1.8214369356632232, 23.869385957717896 s per 100 iters\n","time = 94.0, epoch 10, iter = 9600, loss = 1.8396973115205766, 22.88054394721985 s per 100 iters\n","time = 94.0, epoch 10, iter = 9700, loss = 1.830005749464035, 23.2355215549469 s per 100 iters\n","time = 95.0, epoch 10, iter = 9800, loss = 1.8207628321647644, 23.305662393569946 s per 100 iters\n","time = 95.0, epoch 10, iter = 9900, loss = 1.8360280323028564, 23.57694435119629 s per 100 iters\n","time = 96.0, epoch 10, iter = 10000, loss = 1.8407101368904113, 23.911322355270386 s per 100 iters\n","time = 96.0, epoch 10, iter = 10100, loss = 1.840567632317543, 23.558269739151 s per 100 iters\n","time = 96.0, epoch 10, iter = 10200, loss = 1.8338399320840835, 22.97747230529785 s per 100 iters\n","time = 97.0, epoch 10, iter = 10300, loss = 1.8419910538196564, 23.305609464645386 s per 100 iters\n","time = 97.0, epoch 10, iter = 10400, loss = 1.8446159529685975, 23.631215810775757 s per 100 iters\n","time = 98.0, epoch 10, iter = 10500, loss = 1.822679186463356, 22.94250988960266 s per 100 iters\n","time = 98.0, epoch 10, iter = 10600, loss = 1.8637810015678407, 24.07340145111084 s per 100 iters\n","time = 98.0, epoch 10, iter = 10700, loss = 1.855511051416397, 23.237521648406982 s per 100 iters\n","time = 99.0, epoch 10, iter = 10800, loss = 1.8512157058715821, 23.133113622665405 s per 100 iters\n","time = 99.0, epoch 10, iter = 10900, loss = 1.8409931403398514, 23.47066307067871 s per 100 iters\n","time = 100.0, epoch 10, iter = 11000, loss = 1.8565613996982575, 23.816879749298096 s per 100 iters\n","time = 100.0, epoch 10, iter = 11100, loss = 1.8670458352565766, 23.981767654418945 s per 100 iters\n","time = 100.0, epoch 10, iter = 11200, loss = 1.852703481912613, 23.489039659500122 s per 100 iters\n","time = 101.0, epoch 10, iter = 11300, loss = 1.8420468556880951, 23.388806581497192 s per 100 iters\n","time = 101.0, epoch 10, iter = 11400, loss = 1.8355940574407577, 23.090241193771362 s per 100 iters\n","time = 102.0, epoch 10, iter = 11500, loss = 1.8548998433351516, 23.48018527030945 s per 100 iters\n","time = 102.0, epoch 10, iter = 11600, loss = 1.8653722566366195, 24.326749801635742 s per 100 iters\n","time = 102.0, epoch 10, iter = 11700, loss = 1.8385250294208526, 24.41510820388794 s per 100 iters\n","time = 103.0, epoch 10, iter = 11800, loss = 1.855616887807846, 22.990886449813843 s per 100 iters\n","time = 103.0, epoch 10, iter = 11900, loss = 1.8611507272720338, 23.235065460205078 s per 100 iters\n","time = 103.0, epoch 10, iter = 12000, loss = 1.8420073568820954, 23.77337884902954 s per 100 iters\n","time = 104.0, epoch 10, iter = 12100, loss = 1.8426147723197936, 23.49123501777649 s per 100 iters\n","time = 104.0, epoch 10, iter = 12200, loss = 1.8602156615257264, 23.811661958694458 s per 100 iters\n","time = 105.0, epoch 10, iter = 12300, loss = 1.842045087814331, 23.56373429298401 s per 100 iters\n","time = 105.0, epoch 10, iter = 12400, loss = 1.8385657888650895, 23.216086864471436 s per 100 iters\n","time = 105.0, epoch 10, iter = 12500, loss = 1.8509447860717774, 23.750197172164917 s per 100 iters\n","time = 106.0, epoch 10, iter = 12600, loss = 1.8867392432689667, 23.699360609054565 s per 100 iters\n","time = 106.0, epoch 10, iter = 12700, loss = 1.8586433243751526, 23.68136477470398 s per 100 iters\n","time = 107.0, epoch 10, iter = 12800, loss = 1.8352885413169862, 23.250414848327637 s per 100 iters\n","time = 107.0, epoch 10, iter = 12900, loss = 1.8428100061416626, 23.63344407081604 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 107.0, epoch 10, iter = 13000, loss = 1.8607190585136413, 23.662708282470703 s per 100 iters\n","time = 108.0, epoch 10, iter = 13100, loss = 1.8569549000263215, 24.112624883651733 s per 100 iters\n","time = 108.0, epoch 10, iter = 13200, loss = 1.8605883479118348, 23.57590675354004 s per 100 iters\n","time = 109.0, epoch 10, iter = 13300, loss = 1.8611686933040619, 24.305346727371216 s per 100 iters\n","time = 109.0, epoch 10, iter = 13400, loss = 1.8480115008354188, 23.490850925445557 s per 100 iters\n","time = 109.0, epoch 10, iter = 13500, loss = 1.850122531056404, 24.18778347969055 s per 100 iters\n","time = 110.0, epoch 10, iter = 13600, loss = 1.847946537733078, 22.76211905479431 s per 100 iters\n","time = 110.0, epoch 10, iter = 13700, loss = 1.8611957824230194, 23.740662813186646 s per 100 iters\n","time = 111.0, epoch 10, iter = 13800, loss = 1.864111213684082, 23.367684364318848 s per 100 iters\n","time = 111.0, epoch 10, iter = 13900, loss = 1.8676853144168855, 23.03632164001465 s per 100 iters\n","time = 111.0, epoch 10, iter = 14000, loss = 1.8524532026052476, 23.463038682937622 s per 100 iters\n","time = 112.0, epoch 10, iter = 14100, loss = 1.8781976115703582, 24.222678184509277 s per 100 iters\n","time = 112.0, epoch 10, iter = 14200, loss = 1.851466497182846, 22.773929595947266 s per 100 iters\n","time = 113.0, epoch 10, iter = 14300, loss = 1.8517701482772828, 23.133064031600952 s per 100 iters\n","--- Balidazioa ---\n","28.88461399078369 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina ￭, zer zen hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da dotorea eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ￭, ｟C siziliako itsasertzean oinatzez eta nesken xarma ￭, ｟C aita ｟C pirrone-ren austeritatea eta ｟C don ｟C fabriziok argi eta garbi adierazi zion ｟C donnafugatako jauregia ez zela ｟C capraroko antxea ￭, eta seguru aski bizirik utziko zuen ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C epaile eta exekuzio-egileen ordezkariak ￭, egintza artifizialak ￭, sarien eta zigorraren (￭ subiranotasunaren jarlekura baraurik daudenak ￭, eta kide bakoitza bere eginbeharra betetzera mugatzen da ￭) ￭, nerbioak dira gorputz naturalean gauza bera egiten dutenak ￭, aberastasun eta ondasun partikularrak ￭, herrien indar guztiak ￭, ｟C salulen ｟C errepublika dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau haien ideala da ￭, gaur egun irudikatzen dute ￭, eta agian beste inor ez ￭, bera dira ￭, bere produkturik izpiritualenak ￭, bere borrokalariak eta eskueranzko borrokalariak ￭, bere delikatuen eta lirainaren formarik zorrotzenak ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez edukitzeko bezain pobrea ￭.', '｟C duela gutxi ￭, ｟C derwatt-en gauzarekin ￭, eta orain ｟C mafiari leporatu zion ￭?']\n","BLEU puntuazioa (1): 9.390184278433072\n","5.600547790527344 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak janaria jasotzen duela ￭?', '- ｟C ezagutzen dugu ｟C corvetteko istorioa ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earl ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorria zela uste nuen ￭.', '｟C du ｟C pont jaunaren ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ez zaizu axola ￭?', '｟C argazki bat daukat 1960an eta bere semea 60ko uniforme batean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C lo egizu berriro ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 21.61099931439565\n","BLEU puntuazioa (biak): 12.208581793428012\n","time = 114.0, epoch 11, iter = 100, loss = 1.7372025847434998, 25.101770639419556 s per 100 iters\n","time = 114.0, epoch 11, iter = 200, loss = 1.7147421407699586, 23.42081904411316 s per 100 iters\n","time = 114.0, epoch 11, iter = 300, loss = 1.6874965500831605, 23.40941309928894 s per 100 iters\n","time = 115.0, epoch 11, iter = 400, loss = 1.7249764281511306, 23.40467643737793 s per 100 iters\n","time = 115.0, epoch 11, iter = 500, loss = 1.7260594362020492, 23.66686511039734 s per 100 iters\n","time = 116.0, epoch 11, iter = 600, loss = 1.734830265045166, 23.9886314868927 s per 100 iters\n","time = 116.0, epoch 11, iter = 700, loss = 1.739881192445755, 23.5943386554718 s per 100 iters\n","time = 116.0, epoch 11, iter = 800, loss = 1.721013440489769, 23.347126960754395 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 117.0, epoch 11, iter = 900, loss = 1.7323612385988236, 24.005319356918335 s per 100 iters\n","time = 117.0, epoch 11, iter = 1000, loss = 1.7405097782611847, 22.64080286026001 s per 100 iters\n","time = 118.0, epoch 11, iter = 1100, loss = 1.7593180543184281, 23.89775061607361 s per 100 iters\n","time = 118.0, epoch 11, iter = 1200, loss = 1.746343693137169, 24.893235683441162 s per 100 iters\n","time = 118.0, epoch 11, iter = 1300, loss = 1.726583893299103, 23.39454698562622 s per 100 iters\n","time = 119.0, epoch 11, iter = 1400, loss = 1.74329099714756, 24.21682357788086 s per 100 iters\n","time = 119.0, epoch 11, iter = 1500, loss = 1.7286305278539658, 23.58730173110962 s per 100 iters\n","time = 120.0, epoch 11, iter = 1600, loss = 1.7474626076221467, 23.397868156433105 s per 100 iters\n","time = 120.0, epoch 11, iter = 1700, loss = 1.7373852616548537, 23.738638639450073 s per 100 iters\n","time = 120.0, epoch 11, iter = 1800, loss = 1.7545426696538926, 23.57979965209961 s per 100 iters\n","time = 121.0, epoch 11, iter = 1900, loss = 1.7653953069448471, 24.101359605789185 s per 100 iters\n","time = 121.0, epoch 11, iter = 2000, loss = 1.759364394545555, 24.616602659225464 s per 100 iters\n","time = 122.0, epoch 11, iter = 2100, loss = 1.762163843512535, 24.355947256088257 s per 100 iters\n","time = 122.0, epoch 11, iter = 2200, loss = 1.7396514111757277, 22.590383529663086 s per 100 iters\n","time = 122.0, epoch 11, iter = 2300, loss = 1.7411019629240037, 23.4620258808136 s per 100 iters\n","time = 123.0, epoch 11, iter = 2400, loss = 1.7434284955263137, 23.65168571472168 s per 100 iters\n","time = 123.0, epoch 11, iter = 2500, loss = 1.7600437647104263, 23.61486005783081 s per 100 iters\n","time = 124.0, epoch 11, iter = 2600, loss = 1.7503095543384553, 23.14331316947937 s per 100 iters\n","time = 124.0, epoch 11, iter = 2700, loss = 1.7406805831193923, 23.46454668045044 s per 100 iters\n","time = 124.0, epoch 11, iter = 2800, loss = 1.7651056444644928, 23.890748977661133 s per 100 iters\n","time = 125.0, epoch 11, iter = 2900, loss = 1.7520760828256607, 23.51791548728943 s per 100 iters\n","time = 125.0, epoch 11, iter = 3000, loss = 1.752809013724327, 23.840958833694458 s per 100 iters\n","time = 126.0, epoch 11, iter = 3100, loss = 1.7763522309064865, 23.340174674987793 s per 100 iters\n","time = 126.0, epoch 11, iter = 3200, loss = 1.7636526453495025, 23.660101175308228 s per 100 iters\n","time = 126.0, epoch 11, iter = 3300, loss = 1.7796337795257569, 23.986161708831787 s per 100 iters\n","time = 127.0, epoch 11, iter = 3400, loss = 1.770548067688942, 23.82939100265503 s per 100 iters\n","time = 127.0, epoch 11, iter = 3500, loss = 1.7812934547662735, 24.514668464660645 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 128.0, epoch 11, iter = 3600, loss = 1.7447480231523513, 22.894713163375854 s per 100 iters\n","time = 128.0, epoch 11, iter = 3700, loss = 1.7711727541685105, 23.528642892837524 s per 100 iters\n","time = 128.0, epoch 11, iter = 3800, loss = 1.7578045547008514, 23.15408158302307 s per 100 iters\n","time = 129.0, epoch 11, iter = 3900, loss = 1.7670624679327012, 23.403427362442017 s per 100 iters\n","time = 129.0, epoch 11, iter = 4000, loss = 1.7520548731088639, 22.281323432922363 s per 100 iters\n","time = 129.0, epoch 11, iter = 4100, loss = 1.774604499936104, 23.186742782592773 s per 100 iters\n","time = 130.0, epoch 11, iter = 4200, loss = 1.7565562236309051, 22.76481795310974 s per 100 iters\n","time = 130.0, epoch 11, iter = 4300, loss = 1.7953266847133635, 22.973080158233643 s per 100 iters\n","time = 131.0, epoch 11, iter = 4400, loss = 1.7810790866613389, 23.328196048736572 s per 100 iters\n","time = 131.0, epoch 11, iter = 4500, loss = 1.7667004042863845, 23.066750288009644 s per 100 iters\n","time = 131.0, epoch 11, iter = 4600, loss = 1.795505759716034, 23.73590111732483 s per 100 iters\n","time = 132.0, epoch 11, iter = 4700, loss = 1.7602495992183684, 23.177572011947632 s per 100 iters\n","time = 132.0, epoch 11, iter = 4800, loss = 1.7762554311752319, 22.842041969299316 s per 100 iters\n","time = 133.0, epoch 11, iter = 4900, loss = 1.7753306686878205, 23.592294216156006 s per 100 iters\n","time = 133.0, epoch 11, iter = 5000, loss = 1.7652113133668899, 23.23327946662903 s per 100 iters\n","time = 133.0, epoch 11, iter = 5100, loss = 1.7872235399484635, 23.491646766662598 s per 100 iters\n","time = 134.0, epoch 11, iter = 5200, loss = 1.7650825476646423, 23.275537490844727 s per 100 iters\n","time = 134.0, epoch 11, iter = 5300, loss = 1.7750621783733367, 23.746989250183105 s per 100 iters\n","time = 134.0, epoch 11, iter = 5400, loss = 1.7897171235084535, 24.064512252807617 s per 100 iters\n","time = 135.0, epoch 11, iter = 5500, loss = 1.779775253534317, 23.520042657852173 s per 100 iters\n","time = 135.0, epoch 11, iter = 5600, loss = 1.7739720678329467, 23.28526520729065 s per 100 iters\n","time = 136.0, epoch 11, iter = 5700, loss = 1.7752565348148346, 23.24807095527649 s per 100 iters\n","time = 136.0, epoch 11, iter = 5800, loss = 1.7957066464424134, 23.86260414123535 s per 100 iters\n","time = 136.0, epoch 11, iter = 5900, loss = 1.789435665011406, 22.649057388305664 s per 100 iters\n","time = 137.0, epoch 11, iter = 6000, loss = 1.7706899964809417, 23.866886615753174 s per 100 iters\n","time = 137.0, epoch 11, iter = 6100, loss = 1.7673270201683045, 23.890265941619873 s per 100 iters\n","time = 138.0, epoch 11, iter = 6200, loss = 1.7941873222589493, 23.528265714645386 s per 100 iters\n","time = 138.0, epoch 11, iter = 6300, loss = 1.7793407702445985, 23.01040506362915 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 138.0, epoch 11, iter = 6400, loss = 1.7550655138492584, 23.095184803009033 s per 100 iters\n","time = 139.0, epoch 11, iter = 6500, loss = 1.8064598149061204, 23.53618884086609 s per 100 iters\n","time = 139.0, epoch 11, iter = 6600, loss = 1.7926542663574219, 24.33930468559265 s per 100 iters\n","time = 140.0, epoch 11, iter = 6700, loss = 1.7898655974864959, 23.07463049888611 s per 100 iters\n","time = 140.0, epoch 11, iter = 6800, loss = 1.7926526856422424, 23.34325671195984 s per 100 iters\n","time = 140.0, epoch 11, iter = 6900, loss = 1.7996708345413208, 23.295554161071777 s per 100 iters\n","time = 141.0, epoch 11, iter = 7000, loss = 1.7900450348854064, 23.623716592788696 s per 100 iters\n","time = 141.0, epoch 11, iter = 7100, loss = 1.7841249120235443, 23.680651426315308 s per 100 iters\n","time = 142.0, epoch 11, iter = 7200, loss = 1.8019663351774216, 23.45695662498474 s per 100 iters\n","time = 142.0, epoch 11, iter = 7300, loss = 1.799968108534813, 23.270630359649658 s per 100 iters\n","time = 142.0, epoch 11, iter = 7400, loss = 1.8115138232707977, 24.341240406036377 s per 100 iters\n","time = 143.0, epoch 11, iter = 7500, loss = 1.828207279443741, 24.02109146118164 s per 100 iters\n","time = 143.0, epoch 11, iter = 7600, loss = 1.8146115517616273, 23.897703647613525 s per 100 iters\n","time = 144.0, epoch 11, iter = 7700, loss = 1.8028996217250823, 23.21597194671631 s per 100 iters\n","time = 144.0, epoch 11, iter = 7800, loss = 1.8071416318416595, 24.558531045913696 s per 100 iters\n","time = 144.0, epoch 11, iter = 7900, loss = 1.8067851597070694, 23.55275535583496 s per 100 iters\n","time = 145.0, epoch 11, iter = 8000, loss = 1.7917432117462158, 23.837934255599976 s per 100 iters\n","time = 145.0, epoch 11, iter = 8100, loss = 1.780445391535759, 23.09329867362976 s per 100 iters\n","time = 145.0, epoch 11, iter = 8200, loss = 1.7846025234460832, 23.43791913986206 s per 100 iters\n","time = 146.0, epoch 11, iter = 8300, loss = 1.8072008448839187, 23.58430528640747 s per 100 iters\n","time = 146.0, epoch 11, iter = 8400, loss = 1.8022000497579576, 22.732273817062378 s per 100 iters\n","time = 147.0, epoch 11, iter = 8500, loss = 1.8012700003385544, 23.945233821868896 s per 100 iters\n","time = 147.0, epoch 11, iter = 8600, loss = 1.8123914152383804, 24.58042597770691 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 147.0, epoch 11, iter = 8700, loss = 1.810644050836563, 23.986544132232666 s per 100 iters\n","time = 148.0, epoch 11, iter = 8800, loss = 1.8053676944971084, 23.359992504119873 s per 100 iters\n","time = 148.0, epoch 11, iter = 8900, loss = 1.800963261127472, 24.306426763534546 s per 100 iters\n","time = 149.0, epoch 11, iter = 9000, loss = 1.790938760638237, 23.327714443206787 s per 100 iters\n","time = 149.0, epoch 11, iter = 9100, loss = 1.8000838959217071, 24.015129327774048 s per 100 iters\n","time = 149.0, epoch 11, iter = 9200, loss = 1.8336841589212418, 23.917343139648438 s per 100 iters\n","time = 150.0, epoch 11, iter = 9300, loss = 1.7971039283275605, 23.24621820449829 s per 100 iters\n","time = 150.0, epoch 11, iter = 9400, loss = 1.8043032443523408, 23.250899076461792 s per 100 iters\n","time = 151.0, epoch 11, iter = 9500, loss = 1.8137777256965637, 23.522571802139282 s per 100 iters\n","time = 151.0, epoch 11, iter = 9600, loss = 1.772926189303398, 23.291990280151367 s per 100 iters\n","time = 151.0, epoch 11, iter = 9700, loss = 1.8133798718452454, 23.075353860855103 s per 100 iters\n","time = 152.0, epoch 11, iter = 9800, loss = 1.8059886664152145, 23.20654273033142 s per 100 iters\n","time = 152.0, epoch 11, iter = 9900, loss = 1.7982070285081864, 22.77558922767639 s per 100 iters\n","time = 153.0, epoch 11, iter = 10000, loss = 1.8001371455192565, 23.824111461639404 s per 100 iters\n","time = 153.0, epoch 11, iter = 10100, loss = 1.8185119706392288, 23.22227168083191 s per 100 iters\n","time = 153.0, epoch 11, iter = 10200, loss = 1.794628529548645, 22.92526340484619 s per 100 iters\n","time = 154.0, epoch 11, iter = 10300, loss = 1.8067452961206436, 23.724853515625 s per 100 iters\n","time = 154.0, epoch 11, iter = 10400, loss = 1.8135218739509582, 23.478090047836304 s per 100 iters\n","time = 154.0, epoch 11, iter = 10500, loss = 1.8090379214286805, 22.976808547973633 s per 100 iters\n","time = 155.0, epoch 11, iter = 10600, loss = 1.7894239628314972, 22.738247394561768 s per 100 iters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FpreMmC3MuMv","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6Mf1KTPkX5R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594852803077,"user_tz":-120,"elapsed":17837537,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"3a1854a3-ecb0-445e-91e5-d3979da1c4cb"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/enbakarrik-10.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu_bakarra(lang=1, hasi_epoch=11)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 11, iter = 100, loss = 1.7250559163093566, 24.351999282836914 s per 100 iters\n","time = 0.0, epoch 11, iter = 200, loss = 1.7205950433015824, 22.025792360305786 s per 100 iters\n","time = 1.0, epoch 11, iter = 300, loss = 1.7414143669605255, 22.93526530265808 s per 100 iters\n","time = 1.0, epoch 11, iter = 400, loss = 1.7445437514781952, 22.964322090148926 s per 100 iters\n","time = 1.0, epoch 11, iter = 500, loss = 1.7339388859272002, 24.15777349472046 s per 100 iters\n","time = 2.0, epoch 11, iter = 600, loss = 1.7049851137399674, 22.68667507171631 s per 100 iters\n","time = 2.0, epoch 11, iter = 700, loss = 1.7338815444707871, 23.17574405670166 s per 100 iters\n","time = 3.0, epoch 11, iter = 800, loss = 1.7444952684640884, 23.742818355560303 s per 100 iters\n","time = 3.0, epoch 11, iter = 900, loss = 1.7499950784444809, 24.520209789276123 s per 100 iters\n","time = 3.0, epoch 11, iter = 1000, loss = 1.7253870540857315, 23.794600009918213 s per 100 iters\n","time = 4.0, epoch 11, iter = 1100, loss = 1.741518228650093, 23.420180082321167 s per 100 iters\n","time = 4.0, epoch 11, iter = 1200, loss = 1.7531581258773803, 24.033796548843384 s per 100 iters\n","time = 5.0, epoch 11, iter = 1300, loss = 1.747235888838768, 24.003376722335815 s per 100 iters\n","time = 5.0, epoch 11, iter = 1400, loss = 1.7398409003019333, 23.273921728134155 s per 100 iters\n","time = 5.0, epoch 11, iter = 1500, loss = 1.7500216817855836, 24.383110284805298 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 6.0, epoch 11, iter = 1600, loss = 1.733354340195656, 23.620484352111816 s per 100 iters\n","time = 6.0, epoch 11, iter = 1700, loss = 1.7343994849920272, 24.502256155014038 s per 100 iters\n","time = 7.0, epoch 11, iter = 1800, loss = 1.7690713745355606, 24.018929719924927 s per 100 iters\n","time = 7.0, epoch 11, iter = 1900, loss = 1.7467205071449279, 23.432130336761475 s per 100 iters\n","time = 7.0, epoch 11, iter = 2000, loss = 1.7464082056283952, 23.059749841690063 s per 100 iters\n","time = 8.0, epoch 11, iter = 2100, loss = 1.7569989639520645, 23.967554092407227 s per 100 iters\n","time = 8.0, epoch 11, iter = 2200, loss = 1.7874191355705262, 23.752850770950317 s per 100 iters\n","time = 9.0, epoch 11, iter = 2300, loss = 1.7518671584129333, 23.419002294540405 s per 100 iters\n","time = 9.0, epoch 11, iter = 2400, loss = 1.7671986865997313, 23.60797119140625 s per 100 iters\n","time = 9.0, epoch 11, iter = 2500, loss = 1.767173963189125, 23.70183539390564 s per 100 iters\n","time = 10.0, epoch 11, iter = 2600, loss = 1.7646198785305023, 23.968116283416748 s per 100 iters\n","time = 10.0, epoch 11, iter = 2700, loss = 1.7575037306547165, 23.18511199951172 s per 100 iters\n","time = 11.0, epoch 11, iter = 2800, loss = 1.7482122039794923, 23.415034770965576 s per 100 iters\n","time = 11.0, epoch 11, iter = 2900, loss = 1.765334364771843, 23.32039189338684 s per 100 iters\n","time = 11.0, epoch 11, iter = 3000, loss = 1.7834527808427811, 23.040539741516113 s per 100 iters\n","time = 12.0, epoch 11, iter = 3100, loss = 1.7675347048044205, 23.42672109603882 s per 100 iters\n","time = 12.0, epoch 11, iter = 3200, loss = 1.7509637504816056, 24.174869298934937 s per 100 iters\n","time = 12.0, epoch 11, iter = 3300, loss = 1.7725063365697862, 23.697769165039062 s per 100 iters\n","time = 13.0, epoch 11, iter = 3400, loss = 1.7614968329668046, 23.34710144996643 s per 100 iters\n","time = 13.0, epoch 11, iter = 3500, loss = 1.7734903705120086, 22.951224327087402 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 14.0, epoch 11, iter = 3600, loss = 1.7701710885763169, 23.018646955490112 s per 100 iters\n","time = 14.0, epoch 11, iter = 3700, loss = 1.772804251909256, 23.490543842315674 s per 100 iters\n","time = 14.0, epoch 11, iter = 3800, loss = 1.759406228661537, 23.536337852478027 s per 100 iters\n","time = 15.0, epoch 11, iter = 3900, loss = 1.7675648564100266, 23.526355266571045 s per 100 iters\n","time = 15.0, epoch 11, iter = 4000, loss = 1.7703032839298247, 23.361729621887207 s per 100 iters\n","time = 16.0, epoch 11, iter = 4100, loss = 1.7704618430137635, 23.407835006713867 s per 100 iters\n","time = 16.0, epoch 11, iter = 4200, loss = 1.785364676117897, 23.992175579071045 s per 100 iters\n","time = 16.0, epoch 11, iter = 4300, loss = 1.7807366800308229, 22.662283897399902 s per 100 iters\n","time = 17.0, epoch 11, iter = 4400, loss = 1.7648494219779969, 23.819722890853882 s per 100 iters\n","time = 17.0, epoch 11, iter = 4500, loss = 1.7653173196315766, 23.2308509349823 s per 100 iters\n","time = 18.0, epoch 11, iter = 4600, loss = 1.7878188979625702, 24.061327695846558 s per 100 iters\n","time = 18.0, epoch 11, iter = 4700, loss = 1.7748826456069946, 23.59718894958496 s per 100 iters\n","time = 18.0, epoch 11, iter = 4800, loss = 1.7839905893802643, 23.63347887992859 s per 100 iters\n","time = 19.0, epoch 11, iter = 4900, loss = 1.7813475900888442, 23.707547664642334 s per 100 iters\n","time = 19.0, epoch 11, iter = 5000, loss = 1.7815247511863708, 23.366766929626465 s per 100 iters\n","time = 20.0, epoch 11, iter = 5100, loss = 1.7795611548423766, 23.81631374359131 s per 100 iters\n","time = 20.0, epoch 11, iter = 5200, loss = 1.7879013085365296, 23.814244270324707 s per 100 iters\n","time = 20.0, epoch 11, iter = 5300, loss = 1.772234202027321, 23.530006647109985 s per 100 iters\n","time = 21.0, epoch 11, iter = 5400, loss = 1.7873818808794022, 24.013524532318115 s per 100 iters\n","time = 21.0, epoch 11, iter = 5500, loss = 1.7833255183696748, 23.35935926437378 s per 100 iters\n","time = 21.0, epoch 11, iter = 5600, loss = 1.7991398203372955, 22.80722188949585 s per 100 iters\n","time = 22.0, epoch 11, iter = 5700, loss = 1.792121458053589, 23.935426950454712 s per 100 iters\n","time = 22.0, epoch 11, iter = 5800, loss = 1.7585753214359283, 23.720859050750732 s per 100 iters\n","time = 23.0, epoch 11, iter = 5900, loss = 1.762151336669922, 23.095092058181763 s per 100 iters\n","time = 23.0, epoch 11, iter = 6000, loss = 1.7999843907356263, 23.495713472366333 s per 100 iters\n","time = 23.0, epoch 11, iter = 6100, loss = 1.7973749750852586, 23.086156845092773 s per 100 iters\n","time = 24.0, epoch 11, iter = 6200, loss = 1.770038468837738, 23.682355642318726 s per 100 iters\n","time = 24.0, epoch 11, iter = 6300, loss = 1.7779391711950303, 23.32739496231079 s per 100 iters\n","time = 25.0, epoch 11, iter = 6400, loss = 1.793635516166687, 23.166790008544922 s per 100 iters\n","time = 25.0, epoch 11, iter = 6500, loss = 1.790979164838791, 23.365103483200073 s per 100 iters\n","time = 25.0, epoch 11, iter = 6600, loss = 1.7798602801561356, 23.702014207839966 s per 100 iters\n","time = 26.0, epoch 11, iter = 6700, loss = 1.7654131203889847, 23.79054045677185 s per 100 iters\n","time = 26.0, epoch 11, iter = 6800, loss = 1.79482142329216, 23.3089280128479 s per 100 iters\n","time = 27.0, epoch 11, iter = 6900, loss = 1.7973020869493483, 23.371689796447754 s per 100 iters\n","time = 27.0, epoch 11, iter = 7000, loss = 1.81319406747818, 23.22275686264038 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 27.0, epoch 11, iter = 7100, loss = 1.8014497685432433, 23.024614334106445 s per 100 iters\n","time = 28.0, epoch 11, iter = 7200, loss = 1.7927782368659972, 22.75414514541626 s per 100 iters\n","time = 28.0, epoch 11, iter = 7300, loss = 1.7648000878095627, 22.99711775779724 s per 100 iters\n","time = 28.0, epoch 11, iter = 7400, loss = 1.8049164098501205, 23.39424228668213 s per 100 iters\n","time = 29.0, epoch 11, iter = 7500, loss = 1.8057292968034744, 23.430901765823364 s per 100 iters\n","time = 29.0, epoch 11, iter = 7600, loss = 1.7855785977840424, 23.12080430984497 s per 100 iters\n","time = 30.0, epoch 11, iter = 7700, loss = 1.7905980610847474, 23.604580879211426 s per 100 iters\n","time = 30.0, epoch 11, iter = 7800, loss = 1.7824944418668747, 23.07041645050049 s per 100 iters\n","time = 30.0, epoch 11, iter = 7900, loss = 1.7946607559919356, 22.908945560455322 s per 100 iters\n","time = 31.0, epoch 11, iter = 8000, loss = 1.8131073027849198, 24.303189754486084 s per 100 iters\n","time = 31.0, epoch 11, iter = 8100, loss = 1.7913356554508209, 23.123781204223633 s per 100 iters\n","time = 32.0, epoch 11, iter = 8200, loss = 1.7989235788583755, 23.0236976146698 s per 100 iters\n","time = 32.0, epoch 11, iter = 8300, loss = 1.7901897019147872, 23.160600423812866 s per 100 iters\n","time = 32.0, epoch 11, iter = 8400, loss = 1.7874563241004944, 22.216647386550903 s per 100 iters\n","time = 33.0, epoch 11, iter = 8500, loss = 1.7933861166238785, 22.77562665939331 s per 100 iters\n","time = 33.0, epoch 11, iter = 8600, loss = 1.8016453289985657, 23.926804542541504 s per 100 iters\n","time = 34.0, epoch 11, iter = 8700, loss = 1.7969918245077132, 22.946924209594727 s per 100 iters\n","time = 34.0, epoch 11, iter = 8800, loss = 1.823289994597435, 23.07213282585144 s per 100 iters\n","time = 34.0, epoch 11, iter = 8900, loss = 1.8086579519510269, 22.83795690536499 s per 100 iters\n","time = 35.0, epoch 11, iter = 9000, loss = 1.7959275043010712, 23.545204162597656 s per 100 iters\n","time = 35.0, epoch 11, iter = 9100, loss = 1.808929967880249, 23.541956186294556 s per 100 iters\n","time = 35.0, epoch 11, iter = 9200, loss = 1.7999937844276428, 23.77521848678589 s per 100 iters\n","time = 36.0, epoch 11, iter = 9300, loss = 1.8103607767820358, 23.537826776504517 s per 100 iters\n","time = 36.0, epoch 11, iter = 9400, loss = 1.8099074363708496, 23.442116737365723 s per 100 iters\n","time = 37.0, epoch 11, iter = 9500, loss = 1.811407257914543, 23.190627813339233 s per 100 iters\n","time = 37.0, epoch 11, iter = 9600, loss = 1.8098200285434722, 23.26334500312805 s per 100 iters\n","time = 37.0, epoch 11, iter = 9700, loss = 1.8102507829666137, 23.440720796585083 s per 100 iters\n","time = 38.0, epoch 11, iter = 9800, loss = 1.8282053416967392, 23.19989538192749 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 38.0, epoch 11, iter = 9900, loss = 1.836831384897232, 23.753171682357788 s per 100 iters\n","time = 39.0, epoch 11, iter = 10000, loss = 1.8120342534780502, 23.652018070220947 s per 100 iters\n","time = 39.0, epoch 11, iter = 10100, loss = 1.8189608454704285, 23.59892964363098 s per 100 iters\n","time = 39.0, epoch 11, iter = 10200, loss = 1.8118152141571044, 22.90256929397583 s per 100 iters\n","time = 40.0, epoch 11, iter = 10300, loss = 1.8280761444568634, 24.30212712287903 s per 100 iters\n","time = 40.0, epoch 11, iter = 10400, loss = 1.815143517255783, 23.428488969802856 s per 100 iters\n","time = 41.0, epoch 11, iter = 10500, loss = 1.8145720744132996, 23.240429878234863 s per 100 iters\n","time = 41.0, epoch 11, iter = 10600, loss = 1.8191028130054474, 23.659871101379395 s per 100 iters\n","time = 41.0, epoch 11, iter = 10700, loss = 1.8166438126564026, 22.933961868286133 s per 100 iters\n","time = 42.0, epoch 11, iter = 10800, loss = 1.8186789786815643, 22.60458755493164 s per 100 iters\n","time = 42.0, epoch 11, iter = 10900, loss = 1.800008836388588, 22.85262393951416 s per 100 iters\n","time = 42.0, epoch 11, iter = 11000, loss = 1.8114095813035964, 23.932247638702393 s per 100 iters\n","time = 43.0, epoch 11, iter = 11100, loss = 1.8149313127994537, 23.48267388343811 s per 100 iters\n","time = 43.0, epoch 11, iter = 11200, loss = 1.8053883785009384, 22.92658233642578 s per 100 iters\n","time = 44.0, epoch 11, iter = 11300, loss = 1.807981607913971, 23.613192558288574 s per 100 iters\n","time = 44.0, epoch 11, iter = 11400, loss = 1.8279129147529602, 24.088738679885864 s per 100 iters\n","time = 44.0, epoch 11, iter = 11500, loss = 1.8294263023138047, 23.210383653640747 s per 100 iters\n","time = 45.0, epoch 11, iter = 11600, loss = 1.8290495812892913, 23.5455002784729 s per 100 iters\n","time = 45.0, epoch 11, iter = 11700, loss = 1.810836554169655, 22.973390102386475 s per 100 iters\n","time = 46.0, epoch 11, iter = 11800, loss = 1.8058894395828247, 24.32558846473694 s per 100 iters\n","time = 46.0, epoch 11, iter = 11900, loss = 1.8287549793720246, 22.803139209747314 s per 100 iters\n","time = 46.0, epoch 11, iter = 12000, loss = 1.8123054844141007, 23.42179560661316 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 47.0, epoch 11, iter = 12100, loss = 1.8256961488723755, 23.756535053253174 s per 100 iters\n","time = 47.0, epoch 11, iter = 12200, loss = 1.7914402437210084, 23.281959772109985 s per 100 iters\n","time = 48.0, epoch 11, iter = 12300, loss = 1.8094468080997468, 22.464722633361816 s per 100 iters\n","time = 48.0, epoch 11, iter = 12400, loss = 1.8140029311180115, 23.593754053115845 s per 100 iters\n","time = 48.0, epoch 11, iter = 12500, loss = 1.824656487107277, 23.067713260650635 s per 100 iters\n","time = 49.0, epoch 11, iter = 12600, loss = 1.8325699800252915, 22.31537103652954 s per 100 iters\n","time = 49.0, epoch 11, iter = 12700, loss = 1.8020263159275054, 23.573446035385132 s per 100 iters\n","time = 49.0, epoch 11, iter = 12800, loss = 1.833031752705574, 23.524033069610596 s per 100 iters\n","time = 50.0, epoch 11, iter = 12900, loss = 1.8233731013536454, 23.158977270126343 s per 100 iters\n","time = 50.0, epoch 11, iter = 13000, loss = 1.822870157957077, 22.74310064315796 s per 100 iters\n","time = 51.0, epoch 11, iter = 13100, loss = 1.8231177473068236, 23.21515679359436 s per 100 iters\n","time = 51.0, epoch 11, iter = 13200, loss = 1.8284963756799697, 23.500834703445435 s per 100 iters\n","time = 51.0, epoch 11, iter = 13300, loss = 1.8223972606658936, 23.116893529891968 s per 100 iters\n","time = 52.0, epoch 11, iter = 13400, loss = 1.8150729095935823, 24.163542985916138 s per 100 iters\n","time = 52.0, epoch 11, iter = 13500, loss = 1.8321890926361084, 23.34184217453003 s per 100 iters\n","time = 53.0, epoch 11, iter = 13600, loss = 1.8077297341823577, 22.855283737182617 s per 100 iters\n","time = 53.0, epoch 11, iter = 13700, loss = 1.8361155289411544, 22.906452655792236 s per 100 iters\n","time = 53.0, epoch 11, iter = 13800, loss = 1.8171614837646484, 22.99052357673645 s per 100 iters\n","time = 54.0, epoch 11, iter = 13900, loss = 1.834020681977272, 23.828473806381226 s per 100 iters\n","time = 54.0, epoch 11, iter = 14000, loss = 1.7930453431606292, 22.93864893913269 s per 100 iters\n","time = 55.0, epoch 11, iter = 14100, loss = 1.8233477652072907, 23.891996145248413 s per 100 iters\n","time = 55.0, epoch 11, iter = 14200, loss = 1.827474635243416, 22.79453992843628 s per 100 iters\n","time = 55.0, epoch 11, iter = 14300, loss = 1.8344617611169816, 23.301509380340576 s per 100 iters\n","--- Balidazioa ---\n","24.40566658973694 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da gozoa eta betea ￭.', '｟C eta ｟C dulcinea ￭?', '｟C afaldu zuenean ￭, ｟C siziliako itsasertzean oinatzik jarri gabe ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok ｟C donnafugatako jauregia ez zela ｟C capraroko anbarea ￭, eta seguru asko bizirik irtengo zela ￭.', '｟C denek erosten zuten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaile eta exekuzio-egileek ￭, joynziar artifizialek ￭, sarien eta zigorrak (￭ subiranoaren jarlekura bizkor eramanez ￭, bakoitzak bere eginbeharra betetzera mugatzen duelarik ￭) ￭, nerbioek gorputz naturalean egiten dute ￭, aberastasunak eta aberastasunak ￭, herri guztiak dira ￭, eta herri guztiak ￭, beren indarra ￭, herri-botereak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori ￭, ordea ￭, haien ideala besterik ez da ￭, eta agian beste inor ez ￭, eurak ere dira ￭, bere sorkari izpiritualenak ￭, bere garaikide eta iruzurgileen alderik aurreratuenak ￭, bere sedukzioaren forma delikal eta malenkoniatsuena ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain behartsu ￭.', '｟C duela gutxi ￭, ｟C derwatt-en zera horrekin ￭, eta orain ｟C mafiako madarikazioa ￭?']\n","BLEU puntuazioa (1): 9.495138200736413\n","5.3401148319244385 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C musika interesgarria izan da ￭.', '｟C eta ｟C nick zaharrak janaria ekartzen digula uste duzu ￭?', '- ｟C corvettek esandakoa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earl ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorria zela uste izan nuen ￭.', '｟C du ｟C ponten ama hil zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez dizu axola ￭?', '｟C argazki bat daukat 1960an eta bere semea 650 uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C seguru zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 21.636444310235728\n","BLEU puntuazioa (biak): 12.300670973745074\n","time = 56.0, epoch 12, iter = 100, loss = 1.6945721739530564, 25.252424240112305 s per 100 iters\n","time = 57.0, epoch 12, iter = 200, loss = 1.6919102174043656, 23.093372344970703 s per 100 iters\n","time = 57.0, epoch 12, iter = 300, loss = 1.6790245872735978, 23.413075923919678 s per 100 iters\n","time = 58.0, epoch 12, iter = 400, loss = 1.6969982498884202, 23.760409116744995 s per 100 iters\n","time = 58.0, epoch 12, iter = 500, loss = 1.6943935203552245, 23.712533950805664 s per 100 iters\n","time = 58.0, epoch 12, iter = 600, loss = 1.679201779961586, 23.472663640975952 s per 100 iters\n","time = 59.0, epoch 12, iter = 700, loss = 1.6930078744888306, 23.303160667419434 s per 100 iters\n","time = 59.0, epoch 12, iter = 800, loss = 1.708863296508789, 23.81188178062439 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 60.0, epoch 12, iter = 900, loss = 1.70980872631073, 23.1645987033844 s per 100 iters\n","time = 60.0, epoch 12, iter = 1000, loss = 1.6944234085083008, 23.139549016952515 s per 100 iters\n","time = 60.0, epoch 12, iter = 1100, loss = 1.706269484758377, 23.335265398025513 s per 100 iters\n","time = 61.0, epoch 12, iter = 1200, loss = 1.6852774065732956, 22.66526985168457 s per 100 iters\n","time = 61.0, epoch 12, iter = 1300, loss = 1.7092482447624207, 23.0253849029541 s per 100 iters\n","time = 61.0, epoch 12, iter = 1400, loss = 1.7075244480371474, 22.89033532142639 s per 100 iters\n","time = 62.0, epoch 12, iter = 1500, loss = 1.703092219233513, 23.39609980583191 s per 100 iters\n","time = 62.0, epoch 12, iter = 1600, loss = 1.7052518153190612, 22.95235848426819 s per 100 iters\n","time = 63.0, epoch 12, iter = 1700, loss = 1.7164716464281082, 23.777737379074097 s per 100 iters\n","time = 63.0, epoch 12, iter = 1800, loss = 1.7223453843593597, 22.726717710494995 s per 100 iters\n","time = 63.0, epoch 12, iter = 1900, loss = 1.6964540457725525, 23.599642515182495 s per 100 iters\n","time = 64.0, epoch 12, iter = 2000, loss = 1.7183746302127838, 22.713749885559082 s per 100 iters\n","time = 64.0, epoch 12, iter = 2100, loss = 1.7310823893547058, 23.595636129379272 s per 100 iters\n","time = 65.0, epoch 12, iter = 2200, loss = 1.6973088711500168, 24.110182762145996 s per 100 iters\n","time = 65.0, epoch 12, iter = 2300, loss = 1.7170221382379531, 24.00714373588562 s per 100 iters\n","time = 65.0, epoch 12, iter = 2400, loss = 1.7172758287191392, 23.28082275390625 s per 100 iters\n","time = 66.0, epoch 12, iter = 2500, loss = 1.721743676662445, 23.75439167022705 s per 100 iters\n","time = 66.0, epoch 12, iter = 2600, loss = 1.7094525837898253, 23.551753520965576 s per 100 iters\n","time = 66.0, epoch 12, iter = 2700, loss = 1.7293531787395477, 22.83993172645569 s per 100 iters\n","time = 67.0, epoch 12, iter = 2800, loss = 1.745697450041771, 23.379539966583252 s per 100 iters\n","time = 67.0, epoch 12, iter = 2900, loss = 1.7181860280036927, 23.410271644592285 s per 100 iters\n","time = 68.0, epoch 12, iter = 3000, loss = 1.724602651000023, 23.853561401367188 s per 100 iters\n","time = 68.0, epoch 12, iter = 3100, loss = 1.7272276610136033, 23.364237546920776 s per 100 iters\n","time = 68.0, epoch 12, iter = 3200, loss = 1.7031576174497605, 23.026048183441162 s per 100 iters\n","time = 69.0, epoch 12, iter = 3300, loss = 1.7509523218870162, 23.16210150718689 s per 100 iters\n","time = 69.0, epoch 12, iter = 3400, loss = 1.7172335177659988, 23.59516215324402 s per 100 iters\n","time = 70.0, epoch 12, iter = 3500, loss = 1.7207277667522431, 23.281754970550537 s per 100 iters\n","time = 70.0, epoch 12, iter = 3600, loss = 1.7359388077259064, 23.46029257774353 s per 100 iters\n","time = 70.0, epoch 12, iter = 3700, loss = 1.7470125949382782, 23.63328266143799 s per 100 iters\n","time = 71.0, epoch 12, iter = 3800, loss = 1.7332173383235931, 23.722631692886353 s per 100 iters\n","time = 71.0, epoch 12, iter = 3900, loss = 1.744444134235382, 23.755868911743164 s per 100 iters\n","time = 72.0, epoch 12, iter = 4000, loss = 1.736673462986946, 23.815741062164307 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 72.0, epoch 12, iter = 4100, loss = 1.7472415870428086, 24.027695178985596 s per 100 iters\n","time = 72.0, epoch 12, iter = 4200, loss = 1.7335647398233414, 22.79664421081543 s per 100 iters\n","time = 73.0, epoch 12, iter = 4300, loss = 1.7560000586509705, 23.985822677612305 s per 100 iters\n","time = 73.0, epoch 12, iter = 4400, loss = 1.7412451070547104, 23.632608652114868 s per 100 iters\n","time = 74.0, epoch 12, iter = 4500, loss = 1.756678382754326, 24.34228229522705 s per 100 iters\n","time = 74.0, epoch 12, iter = 4600, loss = 1.7592771369218827, 23.121585845947266 s per 100 iters\n","time = 74.0, epoch 12, iter = 4700, loss = 1.7642877352237702, 24.161083221435547 s per 100 iters\n","time = 75.0, epoch 12, iter = 4800, loss = 1.7482221722602844, 22.930877208709717 s per 100 iters\n","time = 75.0, epoch 12, iter = 4900, loss = 1.749301065802574, 23.79445791244507 s per 100 iters\n","time = 76.0, epoch 12, iter = 5000, loss = 1.7296546417474747, 22.615365266799927 s per 100 iters\n","time = 76.0, epoch 12, iter = 5100, loss = 1.7470101749897002, 24.14525318145752 s per 100 iters\n","time = 76.0, epoch 12, iter = 5200, loss = 1.7597207123041152, 23.40907382965088 s per 100 iters\n","time = 77.0, epoch 12, iter = 5300, loss = 1.7550639921426774, 23.863582134246826 s per 100 iters\n","time = 77.0, epoch 12, iter = 5400, loss = 1.7372857081890105, 22.930805683135986 s per 100 iters\n","time = 77.0, epoch 12, iter = 5500, loss = 1.7494697803258896, 23.174993753433228 s per 100 iters\n","time = 78.0, epoch 12, iter = 5600, loss = 1.74687116086483, 23.34567427635193 s per 100 iters\n","time = 78.0, epoch 12, iter = 5700, loss = 1.7460278064012527, 23.364261388778687 s per 100 iters\n","time = 79.0, epoch 12, iter = 5800, loss = 1.7385196828842162, 23.366524934768677 s per 100 iters\n","time = 79.0, epoch 12, iter = 5900, loss = 1.7363234513998032, 24.029356956481934 s per 100 iters\n","time = 79.0, epoch 12, iter = 6000, loss = 1.7381763076782226, 22.693918466567993 s per 100 iters\n","time = 80.0, epoch 12, iter = 6100, loss = 1.7414663064479827, 22.593640089035034 s per 100 iters\n","time = 80.0, epoch 12, iter = 6200, loss = 1.7618873631954193, 23.048043727874756 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 81.0, epoch 12, iter = 6300, loss = 1.7720843696594237, 23.028663873672485 s per 100 iters\n","time = 81.0, epoch 12, iter = 6400, loss = 1.7655743551254273, 23.73751425743103 s per 100 iters\n","time = 81.0, epoch 12, iter = 6500, loss = 1.761650162935257, 23.65017294883728 s per 100 iters\n","time = 82.0, epoch 12, iter = 6600, loss = 1.7644435453414917, 23.788966178894043 s per 100 iters\n","time = 82.0, epoch 12, iter = 6700, loss = 1.7676292616128921, 24.044872283935547 s per 100 iters\n","time = 83.0, epoch 12, iter = 6800, loss = 1.766951928138733, 23.837517738342285 s per 100 iters\n","time = 83.0, epoch 12, iter = 6900, loss = 1.7523840618133546, 24.146992444992065 s per 100 iters\n","time = 83.0, epoch 12, iter = 7000, loss = 1.743579608798027, 23.41815423965454 s per 100 iters\n","time = 84.0, epoch 12, iter = 7100, loss = 1.760054983496666, 23.358411073684692 s per 100 iters\n","time = 84.0, epoch 12, iter = 7200, loss = 1.7504092663526536, 23.75017476081848 s per 100 iters\n","time = 85.0, epoch 12, iter = 7300, loss = 1.7484427773952484, 23.13078999519348 s per 100 iters\n","time = 85.0, epoch 12, iter = 7400, loss = 1.767772690653801, 23.63696551322937 s per 100 iters\n","time = 85.0, epoch 12, iter = 7500, loss = 1.7685206711292267, 23.058647394180298 s per 100 iters\n","time = 86.0, epoch 12, iter = 7600, loss = 1.754434496164322, 22.90614104270935 s per 100 iters\n","time = 86.0, epoch 12, iter = 7700, loss = 1.7522644311189652, 23.61015295982361 s per 100 iters\n","time = 86.0, epoch 12, iter = 7800, loss = 1.7931560480594635, 23.466705799102783 s per 100 iters\n","time = 87.0, epoch 12, iter = 7900, loss = 1.762926954627037, 23.292860507965088 s per 100 iters\n","time = 87.0, epoch 12, iter = 8000, loss = 1.7738686466217042, 22.99874973297119 s per 100 iters\n","time = 88.0, epoch 12, iter = 8100, loss = 1.7700669687986375, 23.563721895217896 s per 100 iters\n","time = 88.0, epoch 12, iter = 8200, loss = 1.7499407291412354, 23.25638246536255 s per 100 iters\n","time = 88.0, epoch 12, iter = 8300, loss = 1.7569725704193115, 23.92747688293457 s per 100 iters\n","time = 89.0, epoch 12, iter = 8400, loss = 1.7840723621845245, 24.033239364624023 s per 100 iters\n","time = 89.0, epoch 12, iter = 8500, loss = 1.7877462357282639, 23.61685800552368 s per 100 iters\n","time = 90.0, epoch 12, iter = 8600, loss = 1.7701328766345978, 23.27042269706726 s per 100 iters\n","time = 90.0, epoch 12, iter = 8700, loss = 1.7474475222826005, 22.50153660774231 s per 100 iters\n","time = 90.0, epoch 12, iter = 8800, loss = 1.7870484727621079, 24.303893089294434 s per 100 iters\n","time = 91.0, epoch 12, iter = 8900, loss = 1.7792866843938828, 22.922991275787354 s per 100 iters\n","time = 91.0, epoch 12, iter = 9000, loss = 1.76191657602787, 23.03694438934326 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 92.0, epoch 12, iter = 9100, loss = 1.7587342274188995, 23.695492029190063 s per 100 iters\n","time = 92.0, epoch 12, iter = 9200, loss = 1.7735475933551788, 23.550309896469116 s per 100 iters\n","time = 92.0, epoch 12, iter = 9300, loss = 1.7653341299295426, 24.007667064666748 s per 100 iters\n","time = 93.0, epoch 12, iter = 9400, loss = 1.7867591458559036, 24.057855367660522 s per 100 iters\n","time = 93.0, epoch 12, iter = 9500, loss = 1.7922363996505737, 24.767667531967163 s per 100 iters\n","time = 94.0, epoch 12, iter = 9600, loss = 1.7855356162786484, 23.243798971176147 s per 100 iters\n","time = 94.0, epoch 12, iter = 9700, loss = 1.7813804441690444, 23.049938678741455 s per 100 iters\n","time = 94.0, epoch 12, iter = 9800, loss = 1.749666976928711, 24.26588797569275 s per 100 iters\n","time = 95.0, epoch 12, iter = 9900, loss = 1.7824603402614594, 23.0267174243927 s per 100 iters\n","time = 95.0, epoch 12, iter = 10000, loss = 1.7971923351287842, 23.691486358642578 s per 100 iters\n","time = 95.0, epoch 12, iter = 10100, loss = 1.765633294582367, 23.184510946273804 s per 100 iters\n","time = 96.0, epoch 12, iter = 10200, loss = 1.7760744470357894, 23.655112981796265 s per 100 iters\n","time = 96.0, epoch 12, iter = 10300, loss = 1.7794178354740142, 24.36757493019104 s per 100 iters\n","time = 97.0, epoch 12, iter = 10400, loss = 1.7785979491472244, 23.164737939834595 s per 100 iters\n","time = 97.0, epoch 12, iter = 10500, loss = 1.773757136464119, 23.17790198326111 s per 100 iters\n","time = 97.0, epoch 12, iter = 10600, loss = 1.7613970857858658, 22.834208488464355 s per 100 iters\n","time = 98.0, epoch 12, iter = 10700, loss = 1.787097454071045, 23.31932497024536 s per 100 iters\n","time = 98.0, epoch 12, iter = 10800, loss = 1.740255014896393, 23.216265201568604 s per 100 iters\n","time = 99.0, epoch 12, iter = 10900, loss = 1.7985008096694945, 24.0994815826416 s per 100 iters\n","time = 99.0, epoch 12, iter = 11000, loss = 1.7793825024366379, 23.133853673934937 s per 100 iters\n","time = 99.0, epoch 12, iter = 11100, loss = 1.7716597074270248, 23.611786603927612 s per 100 iters\n","time = 100.0, epoch 12, iter = 11200, loss = 1.766823135614395, 22.66966414451599 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 100.0, epoch 12, iter = 11300, loss = 1.8015383887290954, 23.14813470840454 s per 100 iters\n","time = 101.0, epoch 12, iter = 11400, loss = 1.7919907408952713, 24.005935192108154 s per 100 iters\n","time = 101.0, epoch 12, iter = 11500, loss = 1.8009849894046783, 23.338680028915405 s per 100 iters\n","time = 101.0, epoch 12, iter = 11600, loss = 1.8016089743375778, 23.58229899406433 s per 100 iters\n","time = 102.0, epoch 12, iter = 11700, loss = 1.7696349549293517, 22.998087167739868 s per 100 iters\n","time = 102.0, epoch 12, iter = 11800, loss = 1.8075066804885864, 23.96035933494568 s per 100 iters\n","time = 102.0, epoch 12, iter = 11900, loss = 1.7779110819101334, 23.269143104553223 s per 100 iters\n","time = 103.0, epoch 12, iter = 12000, loss = 1.7823679745197296, 23.518319368362427 s per 100 iters\n","time = 103.0, epoch 12, iter = 12100, loss = 1.7801346975564956, 23.68855357170105 s per 100 iters\n","time = 104.0, epoch 12, iter = 12200, loss = 1.7952410078048706, 23.84885263442993 s per 100 iters\n","time = 104.0, epoch 12, iter = 12300, loss = 1.7765992283821106, 23.327451705932617 s per 100 iters\n","time = 104.0, epoch 12, iter = 12400, loss = 1.7806105071306229, 22.516956090927124 s per 100 iters\n","time = 105.0, epoch 12, iter = 12500, loss = 1.7973006212711333, 23.37691354751587 s per 100 iters\n","time = 105.0, epoch 12, iter = 12600, loss = 1.7739365196228027, 23.3791081905365 s per 100 iters\n","time = 106.0, epoch 12, iter = 12700, loss = 1.7811896634101867, 23.56199860572815 s per 100 iters\n","time = 106.0, epoch 12, iter = 12800, loss = 1.7930972075462341, 23.276655435562134 s per 100 iters\n","time = 106.0, epoch 12, iter = 12900, loss = 1.7847651034593581, 22.777467966079712 s per 100 iters\n","time = 107.0, epoch 12, iter = 13000, loss = 1.7979195857048034, 23.753997564315796 s per 100 iters\n","time = 107.0, epoch 12, iter = 13100, loss = 1.7899762105941772, 22.702576398849487 s per 100 iters\n","time = 108.0, epoch 12, iter = 13200, loss = 1.7830748176574707, 23.770061492919922 s per 100 iters\n","time = 108.0, epoch 12, iter = 13300, loss = 1.7919467884302138, 23.34705376625061 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 108.0, epoch 12, iter = 13400, loss = 1.7870093482732772, 23.34162425994873 s per 100 iters\n","time = 109.0, epoch 12, iter = 13500, loss = 1.7850887674093245, 23.777523517608643 s per 100 iters\n","time = 109.0, epoch 12, iter = 13600, loss = 1.7630719816684723, 22.903973817825317 s per 100 iters\n","time = 110.0, epoch 12, iter = 13700, loss = 1.8007401072978972, 23.599020957946777 s per 100 iters\n","time = 110.0, epoch 12, iter = 13800, loss = 1.7912014997005463, 23.267296075820923 s per 100 iters\n","time = 110.0, epoch 12, iter = 13900, loss = 1.787540609240532, 23.510173320770264 s per 100 iters\n","time = 111.0, epoch 12, iter = 14000, loss = 1.7912066918611527, 23.12983775138855 s per 100 iters\n","time = 111.0, epoch 12, iter = 14100, loss = 1.7897760051488876, 22.340961456298828 s per 100 iters\n","time = 111.0, epoch 12, iter = 14200, loss = 1.771580775976181, 23.304956912994385 s per 100 iters\n","time = 112.0, epoch 12, iter = 14300, loss = 1.7918936657905578, 23.491934537887573 s per 100 iters\n","--- Balidazioa ---\n","24.420511484146118 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '｟B rosanna spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta bere dulcinea ￭?', '｟C afaritan ￭, ｟C siziliako itsasertzean oinatzik jarri gabe jan zuen ￭, eta nesken xarma ￭, ｟C aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok ｟C donnafugatako jauregia ez zela ｟C capraroko anbargoa ￭, eta hantxe bertan biziko zela seguru asko ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaileak eta beste funtzionario batzuk ￭, epailariak ￭, ｟C joyni artifizialak ￭, sariz eta zigorrak (￭ subiranoaren jarlekura azkar mugatzen baita ￭, bakoitza bere betebeharraren betetzeko ￭) ￭, nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭, aberastasun eta ondasun partikularren kideak ￭, indar guztiak ￭, herrien indar guztiak ￭, herrien segurtasuna baitira ￭) ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau haien ideala besterik ez da ￭, gaur egun eta agian beste inor ez ￭, horiek dira ￭, beren ekoizpen izpiritualizatuena ￭, haren borrokalaririk aurreratuenak ￭, haren sedukzioaren forma delikatuena eta elikrikoa ￭.', '｟C hegoaldean ez dago familia txiroagorik esklabuak ez izateko ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kontuarekin ￭, eta orain ｟C mafiaren akusazioa ￭?']\n","BLEU puntuazioa (1): 9.915402782906083\n","5.499986886978149 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C musika interesgarria izan da ￭, ｟C marty ￭.', '｟C non uste duzu ｟C nick zaharrak janaria jasotzen duela ￭?', '- ｟C corvette-aren istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartu zuela uste nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez dizu axola ￭?', '｟C argazki bat daukat 1960an eta bere semea 650ko uniforme batean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C lotara ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C seguru zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.501327396704973\n","BLEU puntuazioa (biak): 12.81581341943384\n","time = 113.0, epoch 13, iter = 100, loss = 1.6595154237747192, 24.347142696380615 s per 100 iters\n","time = 113.0, epoch 13, iter = 200, loss = 1.6632906675338746, 23.996835708618164 s per 100 iters\n","time = 114.0, epoch 13, iter = 300, loss = 1.6586287462711333, 22.799286127090454 s per 100 iters\n","time = 114.0, epoch 13, iter = 400, loss = 1.6595357769727708, 23.445569038391113 s per 100 iters\n","time = 114.0, epoch 13, iter = 500, loss = 1.6631763237714767, 23.019545078277588 s per 100 iters\n","time = 115.0, epoch 13, iter = 600, loss = 1.6480710178613662, 23.056127309799194 s per 100 iters\n","time = 115.0, epoch 13, iter = 700, loss = 1.6567576575279235, 22.993223428726196 s per 100 iters\n","time = 116.0, epoch 13, iter = 800, loss = 1.6646995890140532, 24.17278218269348 s per 100 iters\n","time = 116.0, epoch 13, iter = 900, loss = 1.6513526713848115, 23.550814151763916 s per 100 iters\n","time = 116.0, epoch 13, iter = 1000, loss = 1.6632636618614196, 23.08221983909607 s per 100 iters\n","time = 117.0, epoch 13, iter = 1100, loss = 1.6655047637224198, 22.53427004814148 s per 100 iters\n","time = 117.0, epoch 13, iter = 1200, loss = 1.6663772588968278, 23.995418071746826 s per 100 iters\n","time = 118.0, epoch 13, iter = 1300, loss = 1.6689857149124145, 23.523958921432495 s per 100 iters\n","time = 118.0, epoch 13, iter = 1400, loss = 1.6646733224391936, 22.823957920074463 s per 100 iters\n","time = 118.0, epoch 13, iter = 1500, loss = 1.6803664869070054, 23.165880918502808 s per 100 iters\n","time = 119.0, epoch 13, iter = 1600, loss = 1.682467330098152, 23.29192543029785 s per 100 iters\n","time = 119.0, epoch 13, iter = 1700, loss = 1.6766965103149414, 24.057944536209106 s per 100 iters\n","time = 120.0, epoch 13, iter = 1800, loss = 1.681596405506134, 23.26555633544922 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 120.0, epoch 13, iter = 1900, loss = 1.679259483218193, 22.323561906814575 s per 100 iters\n","time = 120.0, epoch 13, iter = 2000, loss = 1.66658416390419, 23.38862156867981 s per 100 iters\n","time = 121.0, epoch 13, iter = 2100, loss = 1.6913997036218644, 23.316564798355103 s per 100 iters\n","time = 121.0, epoch 13, iter = 2200, loss = 1.6799576359987258, 23.95806574821472 s per 100 iters\n","time = 121.0, epoch 13, iter = 2300, loss = 1.7020846605300903, 24.04845666885376 s per 100 iters\n","time = 122.0, epoch 13, iter = 2400, loss = 1.6957686829566956, 24.968934297561646 s per 100 iters\n","time = 122.0, epoch 13, iter = 2500, loss = 1.6779256308078765, 23.22215509414673 s per 100 iters\n","time = 123.0, epoch 13, iter = 2600, loss = 1.6980379617214203, 23.33953309059143 s per 100 iters\n","time = 123.0, epoch 13, iter = 2700, loss = 1.683372836112976, 23.584018230438232 s per 100 iters\n","time = 123.0, epoch 13, iter = 2800, loss = 1.6751531380414963, 23.12136697769165 s per 100 iters\n","time = 124.0, epoch 13, iter = 2900, loss = 1.688524449467659, 23.240540504455566 s per 100 iters\n","time = 124.0, epoch 13, iter = 3000, loss = 1.6637988817691802, 22.48518204689026 s per 100 iters\n","time = 125.0, epoch 13, iter = 3100, loss = 1.6905339217185975, 23.569135665893555 s per 100 iters\n","time = 125.0, epoch 13, iter = 3200, loss = 1.6903098517656325, 24.146814107894897 s per 100 iters\n","time = 125.0, epoch 13, iter = 3300, loss = 1.707965516448021, 23.05500817298889 s per 100 iters\n","time = 126.0, epoch 13, iter = 3400, loss = 1.688398545384407, 22.995047092437744 s per 100 iters\n","time = 126.0, epoch 13, iter = 3500, loss = 1.70341363966465, 23.976404666900635 s per 100 iters\n","time = 127.0, epoch 13, iter = 3600, loss = 1.6966841769218446, 23.404213190078735 s per 100 iters\n","time = 127.0, epoch 13, iter = 3700, loss = 1.7084053260087968, 22.739015102386475 s per 100 iters\n","time = 127.0, epoch 13, iter = 3800, loss = 1.7132596546411514, 23.954598426818848 s per 100 iters\n","time = 128.0, epoch 13, iter = 3900, loss = 1.6936102443933487, 23.27507734298706 s per 100 iters\n","time = 128.0, epoch 13, iter = 4000, loss = 1.7277726912498474, 23.694809675216675 s per 100 iters\n","time = 129.0, epoch 13, iter = 4100, loss = 1.721270830631256, 23.564325094223022 s per 100 iters\n","time = 129.0, epoch 13, iter = 4200, loss = 1.697916584610939, 22.726468563079834 s per 100 iters\n","time = 129.0, epoch 13, iter = 4300, loss = 1.6931692987680436, 23.312588691711426 s per 100 iters\n","time = 130.0, epoch 13, iter = 4400, loss = 1.7075548774003984, 23.916284799575806 s per 100 iters\n","time = 130.0, epoch 13, iter = 4500, loss = 1.717691708803177, 23.761985301971436 s per 100 iters\n","time = 130.0, epoch 13, iter = 4600, loss = 1.7004680722951888, 22.57105326652527 s per 100 iters\n","time = 131.0, epoch 13, iter = 4700, loss = 1.7188698065280914, 23.56149458885193 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 131.0, epoch 13, iter = 4800, loss = 1.7145126700401305, 23.640326499938965 s per 100 iters\n","time = 132.0, epoch 13, iter = 4900, loss = 1.7084196281433106, 22.7594952583313 s per 100 iters\n","time = 132.0, epoch 13, iter = 5000, loss = 1.7090218681097031, 23.460903644561768 s per 100 iters\n","time = 132.0, epoch 13, iter = 5100, loss = 1.7017577213048936, 23.917152404785156 s per 100 iters\n","time = 133.0, epoch 13, iter = 5200, loss = 1.7110487252473832, 23.3373761177063 s per 100 iters\n","time = 133.0, epoch 13, iter = 5300, loss = 1.7088060033321382, 22.933181762695312 s per 100 iters\n","time = 134.0, epoch 13, iter = 5400, loss = 1.7217296516895295, 24.274476528167725 s per 100 iters\n","time = 134.0, epoch 13, iter = 5500, loss = 1.7112063211202622, 22.74721598625183 s per 100 iters\n","time = 134.0, epoch 13, iter = 5600, loss = 1.6956691652536393, 23.14864730834961 s per 100 iters\n","time = 135.0, epoch 13, iter = 5700, loss = 1.731465643644333, 23.622287034988403 s per 100 iters\n","time = 135.0, epoch 13, iter = 5800, loss = 1.719657323360443, 23.1900372505188 s per 100 iters\n","time = 136.0, epoch 13, iter = 5900, loss = 1.713982594013214, 23.160971641540527 s per 100 iters\n","time = 136.0, epoch 13, iter = 6000, loss = 1.7104077517986298, 23.605931997299194 s per 100 iters\n","time = 136.0, epoch 13, iter = 6100, loss = 1.731430903673172, 23.55618143081665 s per 100 iters\n","time = 137.0, epoch 13, iter = 6200, loss = 1.7250349801778793, 23.996026039123535 s per 100 iters\n","time = 137.0, epoch 13, iter = 6300, loss = 1.7236394256353378, 23.647474765777588 s per 100 iters\n","time = 137.0, epoch 13, iter = 6400, loss = 1.7233047318458556, 23.84616708755493 s per 100 iters\n","time = 138.0, epoch 13, iter = 6500, loss = 1.7214756298065186, 23.382009029388428 s per 100 iters\n","time = 138.0, epoch 13, iter = 6600, loss = 1.7416464513540268, 23.28733777999878 s per 100 iters\n","time = 139.0, epoch 13, iter = 6700, loss = 1.7179809772968293, 23.437259435653687 s per 100 iters\n","time = 139.0, epoch 13, iter = 6800, loss = 1.7199629151821136, 22.827672243118286 s per 100 iters\n","time = 139.0, epoch 13, iter = 6900, loss = 1.7384385812282561, 23.249458074569702 s per 100 iters\n","time = 140.0, epoch 13, iter = 7000, loss = 1.7487215715646744, 24.11910319328308 s per 100 iters\n","time = 140.0, epoch 13, iter = 7100, loss = 1.7368784254789353, 23.213552951812744 s per 100 iters\n","time = 141.0, epoch 13, iter = 7200, loss = 1.7215470993518829, 23.89315676689148 s per 100 iters\n","time = 141.0, epoch 13, iter = 7300, loss = 1.7331253957748414, 24.309142112731934 s per 100 iters\n","time = 141.0, epoch 13, iter = 7400, loss = 1.7168922632932664, 23.358357191085815 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 142.0, epoch 13, iter = 7500, loss = 1.7478827631473541, 23.2785701751709 s per 100 iters\n","time = 142.0, epoch 13, iter = 7600, loss = 1.7306580978631974, 23.42516326904297 s per 100 iters\n","time = 143.0, epoch 13, iter = 7700, loss = 1.7172010272741318, 22.88153886795044 s per 100 iters\n","time = 143.0, epoch 13, iter = 7800, loss = 1.7253981256484985, 23.757769107818604 s per 100 iters\n","time = 143.0, epoch 13, iter = 7900, loss = 1.7337737083435059, 22.965811491012573 s per 100 iters\n","time = 144.0, epoch 13, iter = 8000, loss = 1.7292154490947724, 23.08623766899109 s per 100 iters\n","time = 144.0, epoch 13, iter = 8100, loss = 1.721959067583084, 23.655056953430176 s per 100 iters\n","time = 145.0, epoch 13, iter = 8200, loss = 1.7402029383182525, 23.663280963897705 s per 100 iters\n","time = 145.0, epoch 13, iter = 8300, loss = 1.7390761280059814, 24.12072777748108 s per 100 iters\n","time = 145.0, epoch 13, iter = 8400, loss = 1.734813253879547, 22.908403158187866 s per 100 iters\n","time = 146.0, epoch 13, iter = 8500, loss = 1.7463013988733291, 23.865944862365723 s per 100 iters\n","time = 146.0, epoch 13, iter = 8600, loss = 1.724254207611084, 23.23355460166931 s per 100 iters\n","time = 146.0, epoch 13, iter = 8700, loss = 1.7396947246789933, 23.76561951637268 s per 100 iters\n","time = 147.0, epoch 13, iter = 8800, loss = 1.7611104583740234, 23.74788761138916 s per 100 iters\n","time = 147.0, epoch 13, iter = 8900, loss = 1.7423519521951676, 23.614306688308716 s per 100 iters\n","time = 148.0, epoch 13, iter = 9000, loss = 1.7440745794773103, 23.70069193840027 s per 100 iters\n","time = 148.0, epoch 13, iter = 9100, loss = 1.7259073334932327, 23.311164140701294 s per 100 iters\n","time = 148.0, epoch 13, iter = 9200, loss = 1.7387664777040481, 23.464972734451294 s per 100 iters\n","time = 149.0, epoch 13, iter = 9300, loss = 1.7419762933254241, 23.004693031311035 s per 100 iters\n","time = 149.0, epoch 13, iter = 9400, loss = 1.7511439287662507, 23.81083583831787 s per 100 iters\n","time = 150.0, epoch 13, iter = 9500, loss = 1.76035173535347, 23.26740574836731 s per 100 iters\n","time = 150.0, epoch 13, iter = 9600, loss = 1.731793331503868, 22.91223168373108 s per 100 iters\n","time = 150.0, epoch 13, iter = 9700, loss = 1.7419112563133239, 22.867955923080444 s per 100 iters\n","time = 151.0, epoch 13, iter = 9800, loss = 1.7615667468309402, 23.908055067062378 s per 100 iters\n","time = 151.0, epoch 13, iter = 9900, loss = 1.7418158733844757, 23.493690490722656 s per 100 iters\n","time = 152.0, epoch 13, iter = 10000, loss = 1.7522370767593385, 23.419334173202515 s per 100 iters\n","time = 152.0, epoch 13, iter = 10100, loss = 1.7378537315130234, 23.81864643096924 s per 100 iters\n","time = 152.0, epoch 13, iter = 10200, loss = 1.7362656688690186, 23.452184677124023 s per 100 iters\n","time = 153.0, epoch 13, iter = 10300, loss = 1.7406963539123534, 23.29919981956482 s per 100 iters\n","time = 153.0, epoch 13, iter = 10400, loss = 1.7413603687286376, 23.68294072151184 s per 100 iters\n","time = 154.0, epoch 13, iter = 10500, loss = 1.742861004471779, 23.257298946380615 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 154.0, epoch 13, iter = 10600, loss = 1.7382689183950424, 23.301472663879395 s per 100 iters\n","time = 154.0, epoch 13, iter = 10700, loss = 1.7716374862194062, 22.93184232711792 s per 100 iters\n","time = 155.0, epoch 13, iter = 10800, loss = 1.7392356562614442, 23.75607466697693 s per 100 iters\n","time = 155.0, epoch 13, iter = 10900, loss = 1.7494686818122864, 23.279163122177124 s per 100 iters\n","time = 155.0, epoch 13, iter = 11000, loss = 1.731195421218872, 24.15993070602417 s per 100 iters\n","time = 156.0, epoch 13, iter = 11100, loss = 1.7701250618696214, 23.672677516937256 s per 100 iters\n","time = 156.0, epoch 13, iter = 11200, loss = 1.741556144952774, 23.403433322906494 s per 100 iters\n","time = 157.0, epoch 13, iter = 11300, loss = 1.7552016443014145, 22.903523445129395 s per 100 iters\n","time = 157.0, epoch 13, iter = 11400, loss = 1.760046306848526, 23.948720455169678 s per 100 iters\n","time = 157.0, epoch 13, iter = 11500, loss = 1.7575736719369888, 23.485822677612305 s per 100 iters\n","time = 158.0, epoch 13, iter = 11600, loss = 1.7587402749061585, 23.18489956855774 s per 100 iters\n","time = 158.0, epoch 13, iter = 11700, loss = 1.7496025049686432, 23.49059510231018 s per 100 iters\n","time = 159.0, epoch 13, iter = 11800, loss = 1.7446108573675156, 23.727484226226807 s per 100 iters\n","time = 159.0, epoch 13, iter = 11900, loss = 1.7431028532981871, 22.60425877571106 s per 100 iters\n","time = 159.0, epoch 13, iter = 12000, loss = 1.74211170732975, 23.23260259628296 s per 100 iters\n","time = 160.0, epoch 13, iter = 12100, loss = 1.7397279739379883, 23.352418661117554 s per 100 iters\n","time = 160.0, epoch 13, iter = 12200, loss = 1.750746978521347, 23.175339698791504 s per 100 iters\n","time = 161.0, epoch 13, iter = 12300, loss = 1.7588284677267074, 23.287702083587646 s per 100 iters\n","time = 161.0, epoch 13, iter = 12400, loss = 1.768512836098671, 22.757168531417847 s per 100 iters\n","time = 161.0, epoch 13, iter = 12500, loss = 1.7592318844795227, 22.94351291656494 s per 100 iters\n","time = 162.0, epoch 13, iter = 12600, loss = 1.7531201660633087, 23.08366584777832 s per 100 iters\n","time = 162.0, epoch 13, iter = 12700, loss = 1.7529713934659958, 23.591974020004272 s per 100 iters\n","time = 162.0, epoch 13, iter = 12800, loss = 1.7623901629447938, 23.661401748657227 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 163.0, epoch 13, iter = 12900, loss = 1.7681288999319076, 22.848279237747192 s per 100 iters\n","time = 163.0, epoch 13, iter = 13000, loss = 1.773684838414192, 23.992064237594604 s per 100 iters\n","time = 164.0, epoch 13, iter = 13100, loss = 1.7424720299243928, 23.34217071533203 s per 100 iters\n","time = 164.0, epoch 13, iter = 13200, loss = 1.7651008039712905, 23.77453923225403 s per 100 iters\n","time = 164.0, epoch 13, iter = 13300, loss = 1.7730716919898988, 24.392392873764038 s per 100 iters\n","time = 165.0, epoch 13, iter = 13400, loss = 1.7651793819665909, 23.206196784973145 s per 100 iters\n","time = 165.0, epoch 13, iter = 13500, loss = 1.7504314684867859, 22.585089445114136 s per 100 iters\n","time = 166.0, epoch 13, iter = 13600, loss = 1.7592720431089401, 24.37137484550476 s per 100 iters\n","time = 166.0, epoch 13, iter = 13700, loss = 1.7587199062108994, 23.20614767074585 s per 100 iters\n","time = 166.0, epoch 13, iter = 13800, loss = 1.7424240279197694, 23.67514133453369 s per 100 iters\n","time = 167.0, epoch 13, iter = 13900, loss = 1.7340609788894654, 23.4658043384552 s per 100 iters\n","time = 167.0, epoch 13, iter = 14000, loss = 1.7567135447263718, 23.340394735336304 s per 100 iters\n","time = 168.0, epoch 13, iter = 14100, loss = 1.7821885251998901, 23.635342597961426 s per 100 iters\n","time = 168.0, epoch 13, iter = 14200, loss = 1.7508008146286012, 24.000465631484985 s per 100 iters\n","time = 168.0, epoch 13, iter = 14300, loss = 1.7755131888389588, 23.665321350097656 s per 100 iters\n","--- Balidazioa ---\n","30.769402027130127 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '｟B rosanna ｟C spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodiatsua eta betea ￭.', '｟C eta ｟C dulcinea ￭?', '｟C afaritan ￭, ｟C siziliako itsasertzean oinatzik jarri gabe ￭, eta nesken xarma ￭, aita ｟C pirronearen austeritatea ￭, eta ｟C don ｟C fabriziok ｟C donnafugatako jauregia ez zela ｟C capraroko angaramea ￭, eta hantxe utziko zuela seguru aski bizirik ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaile eta exekuziogileen eta beste zenbait ofizial ￭, judizialen eta exekuzio artisauen artean ￭, sari eta zigorrak ￭, subiranotasun-lekura azkar eramanak ￭, bakoitzak bere eginkizuna betetzera mugatzen direlarik ￭, nerbioak dira gorputz naturalean ere ￭, aberastasun eta ondasun partikularrak ￭, herri guztiak ￭, beren segurtasuna ￭, ｟C salusenak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau haien ideala da ￭, gaur egun eta beharbada beste inor ez ￭, horiek dira ￭, beren ekoizpen izpiritualik izpiritualenak ￭, haren gerlari eta eskumendetako biltzaile aurreratuenak ￭, haren sedukzio delikatuen eta elikatzeko erarik ahulena ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain pobre ￭.', '｟C duela gutxi ￭, ｟C derwatt-en kontuarekin ￭, eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 9.924716829150052\n","8.36664366722107 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C musika interesgarria izan da ￭, ｟C marty ￭.', '｟C nondik uste duzu ｟C nick zaharrak janaria eraman duela ￭?', '- ｟C ezagutzen dugu ｟C corvettek buruzko historia ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira baso honetan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ｟C ez dizu axola ￭?', '｟C eta argazkia dut 1960an eta semea 1940ko uniforme batean erakusten ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C lo egizu berriro ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C seguru zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.748555108823624\n","BLEU puntuazioa (biak): 12.898300389506634\n","time = 170.0, epoch 14, iter = 100, loss = 1.6123017764091492, 24.45379137992859 s per 100 iters\n","time = 170.0, epoch 14, iter = 200, loss = 1.6049187916517258, 23.337764263153076 s per 100 iters\n","time = 170.0, epoch 14, iter = 300, loss = 1.6210936349630356, 23.205803394317627 s per 100 iters\n","time = 171.0, epoch 14, iter = 400, loss = 1.6003075331449508, 23.06845760345459 s per 100 iters\n","time = 171.0, epoch 14, iter = 500, loss = 1.6380650573968887, 24.075122833251953 s per 100 iters\n","time = 172.0, epoch 14, iter = 600, loss = 1.6048465484380723, 23.454538583755493 s per 100 iters\n","time = 172.0, epoch 14, iter = 700, loss = 1.6303075808286667, 23.187230110168457 s per 100 iters\n","time = 172.0, epoch 14, iter = 800, loss = 1.6303005194664002, 23.739598989486694 s per 100 iters\n","time = 173.0, epoch 14, iter = 900, loss = 1.6330714505910873, 23.646111011505127 s per 100 iters\n","time = 173.0, epoch 14, iter = 1000, loss = 1.6460224157571792, 23.26607584953308 s per 100 iters\n","time = 173.0, epoch 14, iter = 1100, loss = 1.6443682861328126, 24.1564199924469 s per 100 iters\n","time = 174.0, epoch 14, iter = 1200, loss = 1.642117447257042, 24.266674757003784 s per 100 iters\n","time = 174.0, epoch 14, iter = 1300, loss = 1.6212025856971741, 23.18165135383606 s per 100 iters\n","time = 175.0, epoch 14, iter = 1400, loss = 1.6380785775184632, 23.633000135421753 s per 100 iters\n","time = 175.0, epoch 14, iter = 1500, loss = 1.6224954271316527, 22.673303842544556 s per 100 iters\n","time = 175.0, epoch 14, iter = 1600, loss = 1.6410913729667664, 23.098397970199585 s per 100 iters\n","time = 176.0, epoch 14, iter = 1700, loss = 1.629056842327118, 22.729532957077026 s per 100 iters\n","time = 176.0, epoch 14, iter = 1800, loss = 1.6584125036001205, 23.48661470413208 s per 100 iters\n","time = 177.0, epoch 14, iter = 1900, loss = 1.6350270146131516, 23.102176427841187 s per 100 iters\n","time = 177.0, epoch 14, iter = 2000, loss = 1.672278892993927, 23.941094636917114 s per 100 iters\n","time = 177.0, epoch 14, iter = 2100, loss = 1.668830161690712, 23.384854078292847 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 178.0, epoch 14, iter = 2200, loss = 1.6496095967292785, 23.438676357269287 s per 100 iters\n","time = 178.0, epoch 14, iter = 2300, loss = 1.6642333072423936, 23.430908679962158 s per 100 iters\n","time = 179.0, epoch 14, iter = 2400, loss = 1.6597043603658677, 23.690133810043335 s per 100 iters\n","time = 179.0, epoch 14, iter = 2500, loss = 1.645257789492607, 24.141069173812866 s per 100 iters\n","time = 179.0, epoch 14, iter = 2600, loss = 1.6633179062604904, 23.931244611740112 s per 100 iters\n","time = 180.0, epoch 14, iter = 2700, loss = 1.6751231753826141, 23.56373643875122 s per 100 iters\n","time = 180.0, epoch 14, iter = 2800, loss = 1.6531119298934938, 23.939284324645996 s per 100 iters\n","time = 181.0, epoch 14, iter = 2900, loss = 1.6758295923471451, 23.215116500854492 s per 100 iters\n","time = 181.0, epoch 14, iter = 3000, loss = 1.6575980585813523, 23.457796573638916 s per 100 iters\n","time = 181.0, epoch 14, iter = 3100, loss = 1.685877258181572, 23.616119623184204 s per 100 iters\n","time = 182.0, epoch 14, iter = 3200, loss = 1.6681977927684783, 23.75426983833313 s per 100 iters\n","time = 182.0, epoch 14, iter = 3300, loss = 1.6575024753808976, 23.106945037841797 s per 100 iters\n","time = 183.0, epoch 14, iter = 3400, loss = 1.6680488312244415, 23.66948628425598 s per 100 iters\n","time = 183.0, epoch 14, iter = 3500, loss = 1.6680371487140655, 23.59785795211792 s per 100 iters\n","time = 183.0, epoch 14, iter = 3600, loss = 1.6605591070652008, 23.282466411590576 s per 100 iters\n","time = 184.0, epoch 14, iter = 3700, loss = 1.6791501986980437, 23.796183109283447 s per 100 iters\n","time = 184.0, epoch 14, iter = 3800, loss = 1.6780487209558488, 23.028050661087036 s per 100 iters\n","time = 184.0, epoch 14, iter = 3900, loss = 1.683501136302948, 23.657363891601562 s per 100 iters\n","time = 185.0, epoch 14, iter = 4000, loss = 1.6644072425365448, 23.688770294189453 s per 100 iters\n","time = 185.0, epoch 14, iter = 4100, loss = 1.6560238647460936, 22.658101558685303 s per 100 iters\n","time = 186.0, epoch 14, iter = 4200, loss = 1.7183544963598252, 23.436805486679077 s per 100 iters\n","time = 186.0, epoch 14, iter = 4300, loss = 1.6962894576787948, 24.21403217315674 s per 100 iters\n","time = 186.0, epoch 14, iter = 4400, loss = 1.675871901512146, 23.288848638534546 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 187.0, epoch 14, iter = 4500, loss = 1.6541969418525695, 22.496864557266235 s per 100 iters\n","time = 187.0, epoch 14, iter = 4600, loss = 1.6631171315908433, 22.91011118888855 s per 100 iters\n","time = 188.0, epoch 14, iter = 4700, loss = 1.6849711191654206, 23.606197595596313 s per 100 iters\n","time = 188.0, epoch 14, iter = 4800, loss = 1.6924200499057769, 23.069153785705566 s per 100 iters\n","time = 188.0, epoch 14, iter = 4900, loss = 1.6904723167419433, 23.579493284225464 s per 100 iters\n","time = 189.0, epoch 14, iter = 5000, loss = 1.6690048629045486, 22.73474144935608 s per 100 iters\n","time = 189.0, epoch 14, iter = 5100, loss = 1.6725610929727555, 23.511048078536987 s per 100 iters\n","time = 190.0, epoch 14, iter = 5200, loss = 1.6897273641824722, 23.34838342666626 s per 100 iters\n","time = 190.0, epoch 14, iter = 5300, loss = 1.6691510301828385, 23.1200270652771 s per 100 iters\n","time = 190.0, epoch 14, iter = 5400, loss = 1.6913894838094712, 23.606661081314087 s per 100 iters\n","time = 191.0, epoch 14, iter = 5500, loss = 1.6928627914190293, 22.713913440704346 s per 100 iters\n","time = 191.0, epoch 14, iter = 5600, loss = 1.6954056495428085, 23.132655382156372 s per 100 iters\n","time = 191.0, epoch 14, iter = 5700, loss = 1.6693687933683394, 23.822515726089478 s per 100 iters\n","time = 192.0, epoch 14, iter = 5800, loss = 1.6845671421289443, 23.395706176757812 s per 100 iters\n","time = 192.0, epoch 14, iter = 5900, loss = 1.6836783957481385, 22.594205856323242 s per 100 iters\n","time = 193.0, epoch 14, iter = 6000, loss = 1.6950005400180816, 23.606473922729492 s per 100 iters\n","time = 193.0, epoch 14, iter = 6100, loss = 1.6867973929643632, 23.511388063430786 s per 100 iters\n","time = 193.0, epoch 14, iter = 6200, loss = 1.696067722439766, 23.017462968826294 s per 100 iters\n","time = 194.0, epoch 14, iter = 6300, loss = 1.7042119824886321, 23.38578152656555 s per 100 iters\n","time = 194.0, epoch 14, iter = 6400, loss = 1.6888265174627304, 23.021787405014038 s per 100 iters\n","time = 195.0, epoch 14, iter = 6500, loss = 1.6930689203739167, 22.865330696105957 s per 100 iters\n","time = 195.0, epoch 14, iter = 6600, loss = 1.6967013388872147, 23.513434648513794 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 195.0, epoch 14, iter = 6700, loss = 1.6957640063762665, 23.596766710281372 s per 100 iters\n","time = 196.0, epoch 14, iter = 6800, loss = 1.695757297873497, 24.723299026489258 s per 100 iters\n","time = 196.0, epoch 14, iter = 6900, loss = 1.6829838186502457, 22.738231420516968 s per 100 iters\n","time = 197.0, epoch 14, iter = 7000, loss = 1.7139422434568405, 23.97294807434082 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 197.0, epoch 14, iter = 7100, loss = 1.7218602180480957, 24.434006214141846 s per 100 iters\n","time = 197.0, epoch 14, iter = 7200, loss = 1.700193921327591, 23.758179187774658 s per 100 iters\n","time = 198.0, epoch 14, iter = 7300, loss = 1.6838524043560028, 22.27489471435547 s per 100 iters\n","time = 198.0, epoch 14, iter = 7400, loss = 1.698622201681137, 23.439044713974 s per 100 iters\n","time = 198.0, epoch 14, iter = 7500, loss = 1.7060189324617385, 23.433169841766357 s per 100 iters\n","time = 199.0, epoch 14, iter = 7600, loss = 1.6851016199588775, 23.105029106140137 s per 100 iters\n","time = 199.0, epoch 14, iter = 7700, loss = 1.717116527557373, 23.248718976974487 s per 100 iters\n","time = 200.0, epoch 14, iter = 7800, loss = 1.7268813997507095, 23.39937400817871 s per 100 iters\n","time = 200.0, epoch 14, iter = 7900, loss = 1.6752777820825577, 23.160850048065186 s per 100 iters\n","time = 200.0, epoch 14, iter = 8000, loss = 1.6949619233608246, 23.00004816055298 s per 100 iters\n","time = 201.0, epoch 14, iter = 8100, loss = 1.6930924987792968, 23.34184503555298 s per 100 iters\n","time = 201.0, epoch 14, iter = 8200, loss = 1.6966603231430053, 23.142311573028564 s per 100 iters\n","time = 202.0, epoch 14, iter = 8300, loss = 1.6987238824367523, 23.32103204727173 s per 100 iters\n","time = 202.0, epoch 14, iter = 8400, loss = 1.71511745929718, 24.21656632423401 s per 100 iters\n","time = 202.0, epoch 14, iter = 8500, loss = 1.7220158863067627, 23.429258584976196 s per 100 iters\n","time = 203.0, epoch 14, iter = 8600, loss = 1.7097688323259355, 23.063690900802612 s per 100 iters\n","time = 203.0, epoch 14, iter = 8700, loss = 1.7156487929821014, 22.783692836761475 s per 100 iters\n","time = 204.0, epoch 14, iter = 8800, loss = 1.7143245077133178, 23.83690881729126 s per 100 iters\n","time = 204.0, epoch 14, iter = 8900, loss = 1.7177069509029388, 23.783032417297363 s per 100 iters\n","time = 204.0, epoch 14, iter = 9000, loss = 1.721319721341133, 24.069706678390503 s per 100 iters\n","time = 205.0, epoch 14, iter = 9100, loss = 1.7092300307750703, 23.420490980148315 s per 100 iters\n","time = 205.0, epoch 14, iter = 9200, loss = 1.7272302740812302, 23.79497790336609 s per 100 iters\n","time = 205.0, epoch 14, iter = 9300, loss = 1.7137043517827988, 23.410830974578857 s per 100 iters\n","time = 206.0, epoch 14, iter = 9400, loss = 1.724949666261673, 23.118114709854126 s per 100 iters\n","time = 206.0, epoch 14, iter = 9500, loss = 1.6981949013471604, 23.664966821670532 s per 100 iters\n","time = 207.0, epoch 14, iter = 9600, loss = 1.7206354343891144, 23.487550258636475 s per 100 iters\n","time = 207.0, epoch 14, iter = 9700, loss = 1.704257344007492, 23.03557562828064 s per 100 iters\n","time = 207.0, epoch 14, iter = 9800, loss = 1.698329620361328, 23.808421850204468 s per 100 iters\n","time = 208.0, epoch 14, iter = 9900, loss = 1.7125254780054093, 23.323020458221436 s per 100 iters\n","time = 208.0, epoch 14, iter = 10000, loss = 1.7171999824047088, 23.208370685577393 s per 100 iters\n","time = 209.0, epoch 14, iter = 10100, loss = 1.7139506864547729, 23.047423839569092 s per 100 iters\n","time = 209.0, epoch 14, iter = 10200, loss = 1.722390758395195, 23.97047209739685 s per 100 iters\n","time = 209.0, epoch 14, iter = 10300, loss = 1.6978119832277299, 22.76698660850525 s per 100 iters\n","time = 210.0, epoch 14, iter = 10400, loss = 1.7062863969802857, 23.019895315170288 s per 100 iters\n","time = 210.0, epoch 14, iter = 10500, loss = 1.7242060375213624, 23.387104988098145 s per 100 iters\n","time = 211.0, epoch 14, iter = 10600, loss = 1.705483934879303, 23.271337509155273 s per 100 iters\n","time = 211.0, epoch 14, iter = 10700, loss = 1.721951687335968, 22.8063747882843 s per 100 iters\n","time = 211.0, epoch 14, iter = 10800, loss = 1.7272269743680955, 23.455626487731934 s per 100 iters\n","time = 212.0, epoch 14, iter = 10900, loss = 1.7127777552604675, 23.352354288101196 s per 100 iters\n","time = 212.0, epoch 14, iter = 11000, loss = 1.723699276447296, 23.318674564361572 s per 100 iters\n","time = 212.0, epoch 14, iter = 11100, loss = 1.6893013679981232, 24.067063093185425 s per 100 iters\n","time = 213.0, epoch 14, iter = 11200, loss = 1.7362390822172165, 24.064411401748657 s per 100 iters\n","time = 213.0, epoch 14, iter = 11300, loss = 1.7373899132013322, 24.04203224182129 s per 100 iters\n","time = 214.0, epoch 14, iter = 11400, loss = 1.7083911061286927, 23.260978937149048 s per 100 iters\n","time = 214.0, epoch 14, iter = 11500, loss = 1.7510698878765105, 24.07338833808899 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 214.0, epoch 14, iter = 11600, loss = 1.734751188158989, 24.178056716918945 s per 100 iters\n","time = 215.0, epoch 14, iter = 11700, loss = 1.7083866745233536, 23.873059272766113 s per 100 iters\n","time = 215.0, epoch 14, iter = 11800, loss = 1.734734598994255, 23.668874979019165 s per 100 iters\n","time = 216.0, epoch 14, iter = 11900, loss = 1.7219576328992843, 23.463897943496704 s per 100 iters\n","time = 216.0, epoch 14, iter = 12000, loss = 1.7142917984724044, 22.9937744140625 s per 100 iters\n","time = 216.0, epoch 14, iter = 12100, loss = 1.7386162608861924, 23.10932159423828 s per 100 iters\n","time = 217.0, epoch 14, iter = 12200, loss = 1.7329891514778137, 23.60688829421997 s per 100 iters\n","time = 217.0, epoch 14, iter = 12300, loss = 1.736353320479393, 22.781955003738403 s per 100 iters\n","time = 218.0, epoch 14, iter = 12400, loss = 1.729538061618805, 24.008996725082397 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 218.0, epoch 14, iter = 12500, loss = 1.72941126704216, 23.857141256332397 s per 100 iters\n","time = 218.0, epoch 14, iter = 12600, loss = 1.7087342643737793, 23.004656314849854 s per 100 iters\n","time = 219.0, epoch 14, iter = 12700, loss = 1.7374622517824172, 23.906723022460938 s per 100 iters\n","time = 219.0, epoch 14, iter = 12800, loss = 1.730544154047966, 22.878445625305176 s per 100 iters\n","time = 220.0, epoch 14, iter = 12900, loss = 1.746571364402771, 24.14099907875061 s per 100 iters\n","time = 220.0, epoch 14, iter = 13000, loss = 1.7166945350170135, 23.02782654762268 s per 100 iters\n","time = 220.0, epoch 14, iter = 13100, loss = 1.7121474331617355, 23.93896794319153 s per 100 iters\n","time = 221.0, epoch 14, iter = 13200, loss = 1.7365865814685821, 23.431506633758545 s per 100 iters\n","time = 221.0, epoch 14, iter = 13300, loss = 1.744554705619812, 24.169517278671265 s per 100 iters\n","time = 222.0, epoch 14, iter = 13400, loss = 1.723892171382904, 22.937798976898193 s per 100 iters\n","time = 222.0, epoch 14, iter = 13500, loss = 1.748720081448555, 23.42323088645935 s per 100 iters\n","time = 222.0, epoch 14, iter = 13600, loss = 1.7149944162368775, 23.34536838531494 s per 100 iters\n","time = 223.0, epoch 14, iter = 13700, loss = 1.7483219307661058, 23.88055944442749 s per 100 iters\n","time = 223.0, epoch 14, iter = 13800, loss = 1.756359024643898, 24.451149463653564 s per 100 iters\n","time = 224.0, epoch 14, iter = 13900, loss = 1.7429097712039947, 23.400153160095215 s per 100 iters\n","time = 224.0, epoch 14, iter = 14000, loss = 1.736610191464424, 24.104315757751465 s per 100 iters\n","time = 224.0, epoch 14, iter = 14100, loss = 1.751053999066353, 23.866185426712036 s per 100 iters\n","time = 225.0, epoch 14, iter = 14200, loss = 1.7340530109405519, 23.482421875 s per 100 iters\n","time = 225.0, epoch 14, iter = 14300, loss = 1.7541977900266648, 23.58265209197998 s per 100 iters\n","--- Balidazioa ---\n","17.40320134162903 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miles habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '\"￭ ｟B rosanna ｟C spearman ｟E ￭\"', '｟C ez al da arraroa ￭?', '｟C colinek berriro ere ￭:', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere dulcinea ￭?', '｟C afarian ongi jaten zuen ｟C siziliako itsasertzean ￭, eta nesken xarma ￭, aita ｟C pirronearen austeritatea ￭, eta ｟C don ｟C fabriziok argi ikusi zuen ｟C donnafugatako jauregia ez zela ｟C capraroko antxea ￭, eta han utziko zuela seguru aski bizirik ￭.', '｟C erosketak egiten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaile eta exekuzioetako beste ofizialak ￭, joynes artifizialak ￭, sarien eta zigorraren (￭ subiranotasunaren jarlekurako azkarki prestatua ￭, bakoitza bere eginbeharrak betetzeko ￭) nerbioak dira ￭, gorputz naturalean berdina egiten dutenak ￭, aberastasun eta ondasun partikularrak ￭, boterea dira ￭, ｟C salusio herriak (￭ ｟C populus ￭) ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau haien ideala besterik ez da ￭, gaur egun eta agian beste inorengan ez dute errepresentatzen ￭, horiek dira ￭, beren izpiritualik izpiritualenak ￭, bere inbasio eta iruzurtien bilakaera aitzinatuak ￭, bere delikatuena eta sedukzioaren forma delikatuena ￭.', '｟C hegoaldean ez dago esklaburik ez izatea bezain familia pobreik ￭.', '｟C duela gutxi ￭, ｟C derwatt-en eta orain ｟C mafiaren akusazioa ￭?']\n","BLEU puntuazioa (1): 9.796278574108607\n","5.930795431137085 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nick zaharrak gure janaria eraman duela uste duzu ￭?', '- ｟C badakigu ｟C corvetteko istorioa ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorria zela uste izan nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C argazki bat daukat 1960an eta bere semea 1940ko uniforme batean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C segi lotan ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.675749900974697\n","BLEU puntuazioa (biak): 12.786547418190311\n","time = 226.0, epoch 15, iter = 100, loss = 1.605044401884079, 24.791565895080566 s per 100 iters\n","time = 226.0, epoch 15, iter = 200, loss = 1.581688904762268, 23.64871048927307 s per 100 iters\n","time = 227.0, epoch 15, iter = 300, loss = 1.577196171283722, 22.937154293060303 s per 100 iters\n","time = 227.0, epoch 15, iter = 400, loss = 1.5897560048103332, 22.933231830596924 s per 100 iters\n","time = 228.0, epoch 15, iter = 500, loss = 1.5983602583408356, 22.885895490646362 s per 100 iters\n","time = 228.0, epoch 15, iter = 600, loss = 1.6055833572149276, 23.972700595855713 s per 100 iters\n","time = 228.0, epoch 15, iter = 700, loss = 1.6011581063270568, 23.044086933135986 s per 100 iters\n","time = 229.0, epoch 15, iter = 800, loss = 1.608175972700119, 24.165971755981445 s per 100 iters\n","time = 229.0, epoch 15, iter = 900, loss = 1.6242366492748261, 23.512805700302124 s per 100 iters\n","time = 230.0, epoch 15, iter = 1000, loss = 1.5920273017883302, 22.829718828201294 s per 100 iters\n","time = 230.0, epoch 15, iter = 1100, loss = 1.6101512444019317, 23.70356059074402 s per 100 iters\n","time = 230.0, epoch 15, iter = 1200, loss = 1.6021212244033813, 23.996970176696777 s per 100 iters\n","time = 231.0, epoch 15, iter = 1300, loss = 1.6148864471912383, 23.722683429718018 s per 100 iters\n","time = 231.0, epoch 15, iter = 1400, loss = 1.621105054616928, 22.97863745689392 s per 100 iters\n","time = 232.0, epoch 15, iter = 1500, loss = 1.613757650256157, 23.162331104278564 s per 100 iters\n","time = 232.0, epoch 15, iter = 1600, loss = 1.5947776979207993, 23.38504981994629 s per 100 iters\n","time = 232.0, epoch 15, iter = 1700, loss = 1.635329981446266, 24.00662589073181 s per 100 iters\n","time = 233.0, epoch 15, iter = 1800, loss = 1.59797902405262, 23.607367038726807 s per 100 iters\n","time = 233.0, epoch 15, iter = 1900, loss = 1.6224004083871841, 24.069833278656006 s per 100 iters\n","time = 233.0, epoch 15, iter = 2000, loss = 1.6257633829116822, 22.809775590896606 s per 100 iters\n","time = 234.0, epoch 15, iter = 2100, loss = 1.6366136759519576, 23.923691749572754 s per 100 iters\n","time = 234.0, epoch 15, iter = 2200, loss = 1.6230646830797195, 23.85483980178833 s per 100 iters\n","time = 235.0, epoch 15, iter = 2300, loss = 1.63411099255085, 24.27432346343994 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 235.0, epoch 15, iter = 2400, loss = 1.6208347475528717, 23.304163455963135 s per 100 iters\n","time = 235.0, epoch 15, iter = 2500, loss = 1.6391487854719162, 23.76174020767212 s per 100 iters\n","time = 236.0, epoch 15, iter = 2600, loss = 1.6218935364484788, 23.490182638168335 s per 100 iters\n","time = 236.0, epoch 15, iter = 2700, loss = 1.6228576678037643, 23.92973780632019 s per 100 iters\n","time = 237.0, epoch 15, iter = 2800, loss = 1.6123658579587936, 22.989901542663574 s per 100 iters\n","time = 237.0, epoch 15, iter = 2900, loss = 1.629610846042633, 23.100792407989502 s per 100 iters\n","time = 237.0, epoch 15, iter = 3000, loss = 1.6712779378890992, 23.42351222038269 s per 100 iters\n","time = 238.0, epoch 15, iter = 3100, loss = 1.6245776122808457, 23.986326932907104 s per 100 iters\n","time = 238.0, epoch 15, iter = 3200, loss = 1.6325491440296174, 23.352243900299072 s per 100 iters\n","time = 239.0, epoch 15, iter = 3300, loss = 1.6210988134145736, 23.597344875335693 s per 100 iters\n","time = 239.0, epoch 15, iter = 3400, loss = 1.6430559784173966, 23.701215267181396 s per 100 iters\n","time = 239.0, epoch 15, iter = 3500, loss = 1.644475330710411, 23.283752918243408 s per 100 iters\n","time = 240.0, epoch 15, iter = 3600, loss = 1.6636451148986817, 23.65446376800537 s per 100 iters\n","time = 240.0, epoch 15, iter = 3700, loss = 1.6368382155895234, 23.42116641998291 s per 100 iters\n","time = 241.0, epoch 15, iter = 3800, loss = 1.6299245250225067, 23.172829627990723 s per 100 iters\n","time = 241.0, epoch 15, iter = 3900, loss = 1.6468239742517472, 23.66464066505432 s per 100 iters\n","time = 241.0, epoch 15, iter = 4000, loss = 1.6468336862325668, 23.91069459915161 s per 100 iters\n","time = 242.0, epoch 15, iter = 4100, loss = 1.6679068326950073, 23.197525024414062 s per 100 iters\n","time = 242.0, epoch 15, iter = 4200, loss = 1.6440883958339692, 23.834344625473022 s per 100 iters\n","time = 243.0, epoch 15, iter = 4300, loss = 1.6510943406820298, 23.35577416419983 s per 100 iters\n","time = 243.0, epoch 15, iter = 4400, loss = 1.6254461288452149, 23.010249137878418 s per 100 iters\n","time = 243.0, epoch 15, iter = 4500, loss = 1.6639529323577882, 23.16543436050415 s per 100 iters\n","time = 244.0, epoch 15, iter = 4600, loss = 1.6643489217758178, 23.906346797943115 s per 100 iters\n","time = 244.0, epoch 15, iter = 4700, loss = 1.6410186749696731, 23.926202058792114 s per 100 iters\n","time = 244.0, epoch 15, iter = 4800, loss = 1.6732961982488632, 24.304181575775146 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 245.0, epoch 15, iter = 4900, loss = 1.6709153121709823, 23.24088478088379 s per 100 iters\n","time = 245.0, epoch 15, iter = 5000, loss = 1.6493914026021956, 22.785198211669922 s per 100 iters\n","time = 246.0, epoch 15, iter = 5100, loss = 1.674388194680214, 23.250431299209595 s per 100 iters\n","time = 246.0, epoch 15, iter = 5200, loss = 1.6533538699150085, 23.31912851333618 s per 100 iters\n","time = 246.0, epoch 15, iter = 5300, loss = 1.656374717950821, 23.077610731124878 s per 100 iters\n","time = 247.0, epoch 15, iter = 5400, loss = 1.6462802755832673, 22.9953715801239 s per 100 iters\n","time = 247.0, epoch 15, iter = 5500, loss = 1.6630012059211732, 23.9560866355896 s per 100 iters\n","time = 248.0, epoch 15, iter = 5600, loss = 1.6448605060577393, 23.997201442718506 s per 100 iters\n","time = 248.0, epoch 15, iter = 5700, loss = 1.6424645859003066, 23.196403741836548 s per 100 iters\n","time = 248.0, epoch 15, iter = 5800, loss = 1.6699818575382233, 22.809738159179688 s per 100 iters\n","time = 249.0, epoch 15, iter = 5900, loss = 1.6820812398195266, 23.363106727600098 s per 100 iters\n","time = 249.0, epoch 15, iter = 6000, loss = 1.6761615699529648, 23.414571523666382 s per 100 iters\n","time = 250.0, epoch 15, iter = 6100, loss = 1.6484295040369035, 23.43754744529724 s per 100 iters\n","time = 250.0, epoch 15, iter = 6200, loss = 1.6492630767822265, 23.929373741149902 s per 100 iters\n","time = 250.0, epoch 15, iter = 6300, loss = 1.6657236540317535, 23.342036247253418 s per 100 iters\n","time = 251.0, epoch 15, iter = 6400, loss = 1.670594072341919, 23.261117458343506 s per 100 iters\n","time = 251.0, epoch 15, iter = 6500, loss = 1.6627747458219528, 22.763168811798096 s per 100 iters\n","time = 251.0, epoch 15, iter = 6600, loss = 1.651205489039421, 23.179826021194458 s per 100 iters\n","time = 252.0, epoch 15, iter = 6700, loss = 1.683756421804428, 23.511188745498657 s per 100 iters\n","time = 252.0, epoch 15, iter = 6800, loss = 1.6636771661043168, 22.975257396697998 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 253.0, epoch 15, iter = 6900, loss = 1.6907840383052826, 23.592617750167847 s per 100 iters\n","time = 253.0, epoch 15, iter = 7000, loss = 1.6824459183216094, 23.127079963684082 s per 100 iters\n","time = 253.0, epoch 15, iter = 7100, loss = 1.6686228889226913, 23.552152156829834 s per 100 iters\n","time = 254.0, epoch 15, iter = 7200, loss = 1.6538214260339736, 22.808828353881836 s per 100 iters\n","time = 254.0, epoch 15, iter = 7300, loss = 1.6703160631656646, 22.55292320251465 s per 100 iters\n","time = 255.0, epoch 15, iter = 7400, loss = 1.6592690354585649, 23.58103656768799 s per 100 iters\n","time = 255.0, epoch 15, iter = 7500, loss = 1.6794090563058852, 22.707518815994263 s per 100 iters\n","time = 255.0, epoch 15, iter = 7600, loss = 1.668645713329315, 23.47081470489502 s per 100 iters\n","time = 256.0, epoch 15, iter = 7700, loss = 1.6711327362060546, 23.896270990371704 s per 100 iters\n","time = 256.0, epoch 15, iter = 7800, loss = 1.6992432421445847, 23.076220989227295 s per 100 iters\n","time = 257.0, epoch 15, iter = 7900, loss = 1.6784830701351166, 23.82948398590088 s per 100 iters\n","time = 257.0, epoch 15, iter = 8000, loss = 1.6645984166860581, 22.906877279281616 s per 100 iters\n","time = 257.0, epoch 15, iter = 8100, loss = 1.6679900109767913, 24.08866286277771 s per 100 iters\n","time = 258.0, epoch 15, iter = 8200, loss = 1.6742237478494644, 23.084465265274048 s per 100 iters\n","time = 258.0, epoch 15, iter = 8300, loss = 1.6777460020780564, 22.84459948539734 s per 100 iters\n","time = 258.0, epoch 15, iter = 8400, loss = 1.6942900717258453, 23.88433861732483 s per 100 iters\n","time = 259.0, epoch 15, iter = 8500, loss = 1.679085423350334, 23.720306158065796 s per 100 iters\n","time = 259.0, epoch 15, iter = 8600, loss = 1.685032185316086, 23.266847372055054 s per 100 iters\n","time = 260.0, epoch 15, iter = 8700, loss = 1.680746048092842, 23.475439310073853 s per 100 iters\n","time = 260.0, epoch 15, iter = 8800, loss = 1.6935092473030091, 23.977936506271362 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 260.0, epoch 15, iter = 8900, loss = 1.7034931910037994, 24.07805633544922 s per 100 iters\n","time = 261.0, epoch 15, iter = 9000, loss = 1.688356174826622, 23.738139629364014 s per 100 iters\n","time = 261.0, epoch 15, iter = 9100, loss = 1.6706793093681336, 23.423738956451416 s per 100 iters\n","time = 262.0, epoch 15, iter = 9200, loss = 1.6682569980621338, 22.978164434432983 s per 100 iters\n","time = 262.0, epoch 15, iter = 9300, loss = 1.66707688331604, 22.914333820343018 s per 100 iters\n","time = 262.0, epoch 15, iter = 9400, loss = 1.6659010523557662, 23.19897222518921 s per 100 iters\n","time = 263.0, epoch 15, iter = 9500, loss = 1.679159945845604, 23.435144186019897 s per 100 iters\n","time = 263.0, epoch 15, iter = 9600, loss = 1.6973277342319488, 23.584537744522095 s per 100 iters\n","time = 264.0, epoch 15, iter = 9700, loss = 1.6918355494737625, 23.589985132217407 s per 100 iters\n","time = 264.0, epoch 15, iter = 9800, loss = 1.7096040415763856, 25.032466650009155 s per 100 iters\n","time = 264.0, epoch 15, iter = 9900, loss = 1.6977664315700531, 23.34161639213562 s per 100 iters\n","time = 265.0, epoch 15, iter = 10000, loss = 1.6801331979036331, 24.00333881378174 s per 100 iters\n","time = 265.0, epoch 15, iter = 10100, loss = 1.6940872985124589, 22.755050659179688 s per 100 iters\n","time = 266.0, epoch 15, iter = 10200, loss = 1.6750181001424789, 23.81900644302368 s per 100 iters\n","time = 266.0, epoch 15, iter = 10300, loss = 1.6886166167259216, 23.585874319076538 s per 100 iters\n","time = 266.0, epoch 15, iter = 10400, loss = 1.6876585894823075, 23.463730573654175 s per 100 iters\n","time = 267.0, epoch 15, iter = 10500, loss = 1.6696279388666153, 22.749377727508545 s per 100 iters\n","time = 267.0, epoch 15, iter = 10600, loss = 1.7067271500825882, 24.001190662384033 s per 100 iters\n","time = 267.0, epoch 15, iter = 10700, loss = 1.69853422164917, 23.03450107574463 s per 100 iters\n","time = 268.0, epoch 15, iter = 10800, loss = 1.6995507830381393, 23.039854288101196 s per 100 iters\n","time = 268.0, epoch 15, iter = 10900, loss = 1.710145816206932, 24.50971794128418 s per 100 iters\n","time = 269.0, epoch 15, iter = 11000, loss = 1.6877513951063157, 24.593764066696167 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 269.0, epoch 15, iter = 11100, loss = 1.6773782098293304, 23.732280254364014 s per 100 iters\n","time = 269.0, epoch 15, iter = 11200, loss = 1.7154355716705323, 24.287502765655518 s per 100 iters\n","time = 270.0, epoch 15, iter = 11300, loss = 1.698890060186386, 23.581480503082275 s per 100 iters\n","time = 270.0, epoch 15, iter = 11400, loss = 1.69757130920887, 23.6207537651062 s per 100 iters\n","time = 271.0, epoch 15, iter = 11500, loss = 1.6992654770612716, 23.588138818740845 s per 100 iters\n","time = 271.0, epoch 15, iter = 11600, loss = 1.7115948987007141, 24.057560920715332 s per 100 iters\n","time = 271.0, epoch 15, iter = 11700, loss = 1.7225998163223266, 23.433860540390015 s per 100 iters\n","time = 272.0, epoch 15, iter = 11800, loss = 1.706906530857086, 23.216492414474487 s per 100 iters\n","time = 272.0, epoch 15, iter = 11900, loss = 1.6888366729021071, 23.664663791656494 s per 100 iters\n","time = 273.0, epoch 15, iter = 12000, loss = 1.6874203562736512, 23.558327198028564 s per 100 iters\n","time = 273.0, epoch 15, iter = 12100, loss = 1.6907206773757935, 23.30011749267578 s per 100 iters\n","time = 273.0, epoch 15, iter = 12200, loss = 1.6967636585235595, 23.262685537338257 s per 100 iters\n","time = 274.0, epoch 15, iter = 12300, loss = 1.7147956919670104, 23.016441106796265 s per 100 iters\n","time = 274.0, epoch 15, iter = 12400, loss = 1.7074089258909226, 23.332401752471924 s per 100 iters\n","time = 275.0, epoch 15, iter = 12500, loss = 1.6819658082723619, 23.367847681045532 s per 100 iters\n","time = 275.0, epoch 15, iter = 12600, loss = 1.7008749806880952, 22.956196546554565 s per 100 iters\n","time = 275.0, epoch 15, iter = 12700, loss = 1.6885902714729308, 22.83797025680542 s per 100 iters\n","time = 276.0, epoch 15, iter = 12800, loss = 1.690614560842514, 22.97575330734253 s per 100 iters\n","time = 276.0, epoch 15, iter = 12900, loss = 1.7206808483600617, 23.524564743041992 s per 100 iters\n","time = 277.0, epoch 15, iter = 13000, loss = 1.6985423785448075, 23.894229888916016 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 277.0, epoch 15, iter = 13100, loss = 1.708547888994217, 23.27590012550354 s per 100 iters\n","time = 277.0, epoch 15, iter = 13200, loss = 1.7108826011419296, 24.29745841026306 s per 100 iters\n","time = 278.0, epoch 15, iter = 13300, loss = 1.7157506674528122, 23.98502802848816 s per 100 iters\n","time = 278.0, epoch 15, iter = 13400, loss = 1.7174647253751756, 23.57020401954651 s per 100 iters\n","time = 278.0, epoch 15, iter = 13500, loss = 1.6876883345842362, 22.74468183517456 s per 100 iters\n","time = 279.0, epoch 15, iter = 13600, loss = 1.704671021103859, 24.156055688858032 s per 100 iters\n","time = 279.0, epoch 15, iter = 13700, loss = 1.693245016336441, 23.017659902572632 s per 100 iters\n","time = 280.0, epoch 15, iter = 13800, loss = 1.7048699676990509, 23.1856529712677 s per 100 iters\n","time = 280.0, epoch 15, iter = 13900, loss = 1.6869501930475235, 24.060959339141846 s per 100 iters\n","time = 280.0, epoch 15, iter = 14000, loss = 1.73147989153862, 25.535321712493896 s per 100 iters\n","time = 281.0, epoch 15, iter = 14100, loss = 1.7065923309326172, 24.522512912750244 s per 100 iters\n","time = 281.0, epoch 15, iter = 14200, loss = 1.7036120671033859, 23.032912492752075 s per 100 iters\n","time = 282.0, epoch 15, iter = 14300, loss = 1.7081703823804855, 23.662276029586792 s per 100 iters\n","--- Balidazioa ---\n","31.81658434867859 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haecta tam culta novalia miles habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina berandu da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da gozoa eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afalorduan ￭, ｟C siziliako kostetan oinez hasi eta gero ￭, eta nesken xarma ￭, aita ｟C pirronearen austeritatea ￭, eta ｟C don ｟C fabriziok argi eta garbi ikusi zuen ｟C donnafugatako jauregia ez zela ｟C capraroko kornea ￭, eta bizirik irtengo zela ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaileak eta epaileak ￭, eta exekuzio eta delitugileak ￭, joynes artisau artifizialak ￭, saritu eta zigorrak ￭, subiranoaren jarlekura azkar doanak ￭, bakoitza bere eginbeharrak betearazteko balio duelarik ￭) nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau ￭, beren ideala besterik ez da ￭, orain eta agian beste inorengan errepresentatzen dute ￭, eta horiek berak dira ￭, beren eragingarririk izpiritualenak ￭, bere probatzaile eta eskrupulurik aurreratuenak ￭, bere sedukzio-forma delikorrenak ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain pobrea den familiarik ￭.', '｟C duela gutxi behintzat ￭, ｟C derwatt-en eta orain ｟C mafiako madarikatuak ￭?']\n","BLEU puntuazioa (1): 10.043361473219862\n","8.298484563827515 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C musika interesgarria zen oso ￭.', '｟C nick zaharra jatekoa lortzeko gai dela uste duzu ￭?', '- ｟C corvette istorio hori ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earlle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorri zela uste izan nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C basoan otsorik egongo da ￭?', '｟C marchal jaunak zurekin hitz egin nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez dizu axola ￭?', '｟C eta argazki bat dut 1960ean eta bere semea 1940ko uniforme batean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C lo egin berriro ￭, maitea ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C seguru zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.152150343923076\n","BLEU puntuazioa (biak): 12.845165701209979\n","time = 283.0, epoch 16, iter = 100, loss = 1.5527894026041031, 25.050548791885376 s per 100 iters\n","time = 283.0, epoch 16, iter = 200, loss = 1.5542941796779632, 24.445229530334473 s per 100 iters\n","time = 284.0, epoch 16, iter = 300, loss = 1.5601300525665283, 23.155678749084473 s per 100 iters\n","time = 284.0, epoch 16, iter = 400, loss = 1.5631787925958633, 23.49535059928894 s per 100 iters\n","time = 285.0, epoch 16, iter = 500, loss = 1.5464197087287903, 23.515440940856934 s per 100 iters\n","time = 285.0, epoch 16, iter = 600, loss = 1.5775871825218202, 23.340177059173584 s per 100 iters\n","time = 285.0, epoch 16, iter = 700, loss = 1.5563424581289291, 23.314490795135498 s per 100 iters\n","time = 286.0, epoch 16, iter = 800, loss = 1.5816549265384674, 24.01123547554016 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 286.0, epoch 16, iter = 900, loss = 1.590927268266678, 25.085999965667725 s per 100 iters\n","time = 286.0, epoch 16, iter = 1000, loss = 1.5893791764974594, 23.836143016815186 s per 100 iters\n","time = 287.0, epoch 16, iter = 1100, loss = 1.5779698276519776, 23.607492446899414 s per 100 iters\n","time = 287.0, epoch 16, iter = 1200, loss = 1.5881940019130707, 24.431111574172974 s per 100 iters\n","time = 288.0, epoch 16, iter = 1300, loss = 1.593766296505928, 24.069090127944946 s per 100 iters\n","time = 288.0, epoch 16, iter = 1400, loss = 1.5784197175502777, 24.029953718185425 s per 100 iters\n","time = 288.0, epoch 16, iter = 1500, loss = 1.586389538049698, 23.419785737991333 s per 100 iters\n","time = 289.0, epoch 16, iter = 1600, loss = 1.5914127057790757, 23.702467679977417 s per 100 iters\n","time = 289.0, epoch 16, iter = 1700, loss = 1.599516589641571, 24.046942710876465 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 290.0, epoch 16, iter = 1800, loss = 1.5949793344736098, 23.344429969787598 s per 100 iters\n","time = 290.0, epoch 16, iter = 1900, loss = 1.5954974621534348, 23.778400182724 s per 100 iters\n","time = 290.0, epoch 16, iter = 2000, loss = 1.5936184984445572, 23.49951410293579 s per 100 iters\n","time = 291.0, epoch 16, iter = 2100, loss = 1.5828353464603424, 23.573436498641968 s per 100 iters\n","time = 291.0, epoch 16, iter = 2200, loss = 1.5690180617570877, 23.5252902507782 s per 100 iters\n","time = 292.0, epoch 16, iter = 2300, loss = 1.5873037499189377, 23.41649603843689 s per 100 iters\n","time = 292.0, epoch 16, iter = 2400, loss = 1.5990936315059663, 23.731600761413574 s per 100 iters\n","time = 292.0, epoch 16, iter = 2500, loss = 1.5989083135128022, 23.80631160736084 s per 100 iters\n","time = 293.0, epoch 16, iter = 2600, loss = 1.5940579712390899, 23.807931423187256 s per 100 iters\n","time = 293.0, epoch 16, iter = 2700, loss = 1.5979511284828185, 23.825546503067017 s per 100 iters\n","time = 294.0, epoch 16, iter = 2800, loss = 1.5807266163825988, 23.508951902389526 s per 100 iters\n","time = 294.0, epoch 16, iter = 2900, loss = 1.6184119987487793, 23.999831914901733 s per 100 iters\n","time = 294.0, epoch 16, iter = 3000, loss = 1.5944347709417344, 23.676593780517578 s per 100 iters\n","time = 295.0, epoch 16, iter = 3100, loss = 1.6086050546169282, 23.697314977645874 s per 100 iters\n","time = 295.0, epoch 16, iter = 3200, loss = 1.6105157929658889, 23.71434783935547 s per 100 iters\n","time = 296.0, epoch 16, iter = 3300, loss = 1.6176816517114638, 23.64415669441223 s per 100 iters\n","time = 296.0, epoch 16, iter = 3400, loss = 1.6107985919713974, 23.261873245239258 s per 100 iters\n","time = 296.0, epoch 16, iter = 3500, loss = 1.6031414091587066, 23.18436098098755 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-2272163bfc70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mentrenatu_bakarra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasi_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-21cc8959f132>\u001b[0m in \u001b[0;36mentrenatu_bakarra\u001b[0;34m(lang, hasi_epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             loss = F.cross_entropy(preds.view(-1, preds.size(-1)),\n\u001b[0;32m---> 26\u001b[0;31m                 targets.cuda(), ignore_index=pad)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"q5DEZc2jgV5l","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"msjHZghNgVs9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1594901590388,"user_tz":-120,"elapsed":17388166,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"f85cd82b-ddab-422f-f41c-0504996346df"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","checkpoint = torch.load('HACOSDatuak/enbakarrik-15.pt')\n","\n","model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(checkpoint['model'])\n","#optim.load_state_dict(checkpoint['optimizer'])\n","amp.load_state_dict(checkpoint['amp'])\n","\n","entrenatu_bakarra(lang=1, hasi_epoch=16)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","time = 0.0, epoch 16, iter = 100, loss = 1.5730157738924027, 24.18692898750305 s per 100 iters\n","time = 0.0, epoch 16, iter = 200, loss = 1.5715276485681533, 23.327953815460205 s per 100 iters\n","time = 1.0, epoch 16, iter = 300, loss = 1.5803621536493302, 23.748095989227295 s per 100 iters\n","time = 1.0, epoch 16, iter = 400, loss = 1.5654676324129104, 24.102790594100952 s per 100 iters\n","time = 1.0, epoch 16, iter = 500, loss = 1.5878568971157074, 23.615426301956177 s per 100 iters\n","time = 2.0, epoch 16, iter = 600, loss = 1.5864921504259109, 22.912342071533203 s per 100 iters\n","time = 2.0, epoch 16, iter = 700, loss = 1.5567206990718843, 23.884161949157715 s per 100 iters\n","time = 3.0, epoch 16, iter = 800, loss = 1.6032735979557038, 24.811954021453857 s per 100 iters\n","time = 3.0, epoch 16, iter = 900, loss = 1.566579949259758, 23.352238178253174 s per 100 iters\n","time = 3.0, epoch 16, iter = 1000, loss = 1.5856984394788742, 23.147209644317627 s per 100 iters\n","time = 4.0, epoch 16, iter = 1100, loss = 1.5935609912872315, 23.355494737625122 s per 100 iters\n","time = 4.0, epoch 16, iter = 1200, loss = 1.5722097641229629, 23.60567045211792 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 5.0, epoch 16, iter = 1300, loss = 1.5861348748207091, 23.688199996948242 s per 100 iters\n","time = 5.0, epoch 16, iter = 1400, loss = 1.616713593006134, 24.06349492073059 s per 100 iters\n","time = 5.0, epoch 16, iter = 1500, loss = 1.5969528830051423, 23.464364290237427 s per 100 iters\n","time = 6.0, epoch 16, iter = 1600, loss = 1.5881765651702882, 23.703152179718018 s per 100 iters\n","time = 6.0, epoch 16, iter = 1700, loss = 1.5761196494102478, 23.587836503982544 s per 100 iters\n","time = 7.0, epoch 16, iter = 1800, loss = 1.580197455883026, 23.704407930374146 s per 100 iters\n","time = 7.0, epoch 16, iter = 1900, loss = 1.5982872194051743, 23.580587148666382 s per 100 iters\n","time = 7.0, epoch 16, iter = 2000, loss = 1.5967808896303177, 23.33507204055786 s per 100 iters\n","time = 8.0, epoch 16, iter = 2100, loss = 1.5890825241804123, 23.089494705200195 s per 100 iters\n","time = 8.0, epoch 16, iter = 2200, loss = 1.6188601636886597, 24.349184036254883 s per 100 iters\n","time = 9.0, epoch 16, iter = 2300, loss = 1.5987591421604157, 24.545262575149536 s per 100 iters\n","time = 9.0, epoch 16, iter = 2400, loss = 1.6038965231180191, 23.700820922851562 s per 100 iters\n","time = 9.0, epoch 16, iter = 2500, loss = 1.5929957848787308, 23.50218439102173 s per 100 iters\n","time = 10.0, epoch 16, iter = 2600, loss = 1.598664826154709, 23.76200580596924 s per 100 iters\n","time = 10.0, epoch 16, iter = 2700, loss = 1.598797264099121, 23.748088836669922 s per 100 iters\n","time = 11.0, epoch 16, iter = 2800, loss = 1.6074613064527512, 23.621893644332886 s per 100 iters\n","time = 11.0, epoch 16, iter = 2900, loss = 1.6319316339492798, 24.371474266052246 s per 100 iters\n","time = 11.0, epoch 16, iter = 3000, loss = 1.6302523958683013, 23.86917996406555 s per 100 iters\n","time = 12.0, epoch 16, iter = 3100, loss = 1.6137944459915161, 24.201414823532104 s per 100 iters\n","time = 12.0, epoch 16, iter = 3200, loss = 1.6350177496671676, 24.107216835021973 s per 100 iters\n","time = 13.0, epoch 16, iter = 3300, loss = 1.6125851106643676, 24.138588666915894 s per 100 iters\n","time = 13.0, epoch 16, iter = 3400, loss = 1.6025705361366271, 23.781381368637085 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 13.0, epoch 16, iter = 3500, loss = 1.5990273404121398, 23.029356956481934 s per 100 iters\n","time = 14.0, epoch 16, iter = 3600, loss = 1.6102510130405425, 23.570481061935425 s per 100 iters\n","time = 14.0, epoch 16, iter = 3700, loss = 1.6142694193124771, 23.858468770980835 s per 100 iters\n","time = 15.0, epoch 16, iter = 3800, loss = 1.633948388695717, 24.450366973876953 s per 100 iters\n","time = 15.0, epoch 16, iter = 3900, loss = 1.6161566865444184, 23.807594060897827 s per 100 iters\n","time = 15.0, epoch 16, iter = 4000, loss = 1.6146346479654312, 23.806890726089478 s per 100 iters\n","time = 16.0, epoch 16, iter = 4100, loss = 1.6555369406938554, 24.458855628967285 s per 100 iters\n","time = 16.0, epoch 16, iter = 4200, loss = 1.6228839993476867, 24.82089352607727 s per 100 iters\n","time = 17.0, epoch 16, iter = 4300, loss = 1.6344278156757355, 24.366570711135864 s per 100 iters\n","time = 17.0, epoch 16, iter = 4400, loss = 1.61978033721447, 23.548426389694214 s per 100 iters\n","time = 17.0, epoch 16, iter = 4500, loss = 1.61691115796566, 23.465782403945923 s per 100 iters\n","time = 18.0, epoch 16, iter = 4600, loss = 1.6307166874408723, 23.949037075042725 s per 100 iters\n","time = 18.0, epoch 16, iter = 4700, loss = 1.6051791381835938, 23.252103805541992 s per 100 iters\n","time = 19.0, epoch 16, iter = 4800, loss = 1.6374768513441085, 23.045864820480347 s per 100 iters\n","time = 19.0, epoch 16, iter = 4900, loss = 1.628126477599144, 24.208264350891113 s per 100 iters\n","time = 19.0, epoch 16, iter = 5000, loss = 1.646889997124672, 23.940513849258423 s per 100 iters\n","time = 20.0, epoch 16, iter = 5100, loss = 1.6197786647081376, 23.801125288009644 s per 100 iters\n","time = 20.0, epoch 16, iter = 5200, loss = 1.6353020137548446, 23.82371163368225 s per 100 iters\n","time = 21.0, epoch 16, iter = 5300, loss = 1.6431948584318161, 23.75049114227295 s per 100 iters\n","time = 21.0, epoch 16, iter = 5400, loss = 1.6219499325752258, 23.75479030609131 s per 100 iters\n","time = 21.0, epoch 16, iter = 5500, loss = 1.6356312906742096, 24.092082023620605 s per 100 iters\n","time = 22.0, epoch 16, iter = 5600, loss = 1.634149050116539, 24.49656581878662 s per 100 iters\n","time = 22.0, epoch 16, iter = 5700, loss = 1.6336625146865844, 23.233288764953613 s per 100 iters\n","time = 23.0, epoch 16, iter = 5800, loss = 1.6380276149511337, 24.021418809890747 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 23.0, epoch 16, iter = 5900, loss = 1.6437646508216859, 23.920341968536377 s per 100 iters\n","time = 23.0, epoch 16, iter = 6000, loss = 1.6432559239864348, 23.779038190841675 s per 100 iters\n","time = 24.0, epoch 16, iter = 6100, loss = 1.6463107717037202, 22.961694478988647 s per 100 iters\n","time = 24.0, epoch 16, iter = 6200, loss = 1.674165237545967, 25.215169429779053 s per 100 iters\n","time = 25.0, epoch 16, iter = 6300, loss = 1.6435414552688599, 24.360276222229004 s per 100 iters\n","time = 25.0, epoch 16, iter = 6400, loss = 1.6566321367025376, 24.546547174453735 s per 100 iters\n","time = 25.0, epoch 16, iter = 6500, loss = 1.6836721622943878, 25.39869523048401 s per 100 iters\n","time = 26.0, epoch 16, iter = 6600, loss = 1.6602015453577041, 23.64953899383545 s per 100 iters\n","time = 26.0, epoch 16, iter = 6700, loss = 1.6761100435256957, 23.973853826522827 s per 100 iters\n","time = 27.0, epoch 16, iter = 6800, loss = 1.6452507960796356, 23.81829857826233 s per 100 iters\n","time = 27.0, epoch 16, iter = 6900, loss = 1.6375166940689088, 23.69489097595215 s per 100 iters\n","time = 27.0, epoch 16, iter = 7000, loss = 1.6378059494495392, 24.46931767463684 s per 100 iters\n","time = 28.0, epoch 16, iter = 7100, loss = 1.6585288643836975, 24.183966159820557 s per 100 iters\n","time = 28.0, epoch 16, iter = 7200, loss = 1.6470842742919922, 23.31272292137146 s per 100 iters\n","time = 29.0, epoch 16, iter = 7300, loss = 1.6496414476633072, 24.147920608520508 s per 100 iters\n","time = 29.0, epoch 16, iter = 7400, loss = 1.6492844212055207, 24.062955617904663 s per 100 iters\n","time = 29.0, epoch 16, iter = 7500, loss = 1.6525223064422607, 23.544421672821045 s per 100 iters\n","time = 30.0, epoch 16, iter = 7600, loss = 1.654773155450821, 23.34878158569336 s per 100 iters\n","time = 30.0, epoch 16, iter = 7700, loss = 1.6509579974412918, 23.682414293289185 s per 100 iters\n","time = 31.0, epoch 16, iter = 7800, loss = 1.6493651139736176, 23.788649320602417 s per 100 iters\n","time = 31.0, epoch 16, iter = 7900, loss = 1.6429267591238021, 24.238239526748657 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 31.0, epoch 16, iter = 8000, loss = 1.6432337605953216, 23.628445625305176 s per 100 iters\n","time = 32.0, epoch 16, iter = 8100, loss = 1.6676607370376586, 22.82336711883545 s per 100 iters\n","time = 32.0, epoch 16, iter = 8200, loss = 1.6722079867124557, 23.788150310516357 s per 100 iters\n","time = 32.0, epoch 16, iter = 8300, loss = 1.6558977288007737, 23.040862321853638 s per 100 iters\n","time = 33.0, epoch 16, iter = 8400, loss = 1.6410166865587235, 23.806769609451294 s per 100 iters\n","time = 33.0, epoch 16, iter = 8500, loss = 1.6604727399349213, 23.62738847732544 s per 100 iters\n","time = 34.0, epoch 16, iter = 8600, loss = 1.6492584097385405, 23.93786096572876 s per 100 iters\n","time = 34.0, epoch 16, iter = 8700, loss = 1.641635686159134, 24.02473473548889 s per 100 iters\n","time = 34.0, epoch 16, iter = 8800, loss = 1.6593910437822341, 24.209525108337402 s per 100 iters\n","time = 35.0, epoch 16, iter = 8900, loss = 1.6636097425222396, 23.771901845932007 s per 100 iters\n","time = 35.0, epoch 16, iter = 9000, loss = 1.6451702952384948, 23.905081033706665 s per 100 iters\n","time = 36.0, epoch 16, iter = 9100, loss = 1.6545217788219453, 23.74667525291443 s per 100 iters\n","time = 36.0, epoch 16, iter = 9200, loss = 1.6540023005008697, 23.85236692428589 s per 100 iters\n","time = 36.0, epoch 16, iter = 9300, loss = 1.6518249082565308, 23.182799577713013 s per 100 iters\n","time = 37.0, epoch 16, iter = 9400, loss = 1.6642606818675996, 23.777401208877563 s per 100 iters\n","time = 37.0, epoch 16, iter = 9500, loss = 1.6581052976846695, 24.028146266937256 s per 100 iters\n","time = 38.0, epoch 16, iter = 9600, loss = 1.664898750782013, 24.513014316558838 s per 100 iters\n","time = 38.0, epoch 16, iter = 9700, loss = 1.6787180149555205, 24.438613891601562 s per 100 iters\n","time = 38.0, epoch 16, iter = 9800, loss = 1.6754566091299057, 23.573742389678955 s per 100 iters\n","time = 39.0, epoch 16, iter = 9900, loss = 1.6732895857095718, 24.408552646636963 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 39.0, epoch 16, iter = 10000, loss = 1.6608542132377624, 23.868998289108276 s per 100 iters\n","time = 40.0, epoch 16, iter = 10100, loss = 1.6579408049583435, 24.089147806167603 s per 100 iters\n","time = 40.0, epoch 16, iter = 10200, loss = 1.671767116189003, 23.387413263320923 s per 100 iters\n","time = 40.0, epoch 16, iter = 10300, loss = 1.6740633404254914, 23.345510721206665 s per 100 iters\n","time = 41.0, epoch 16, iter = 10400, loss = 1.6594300174713135, 23.772186994552612 s per 100 iters\n","time = 41.0, epoch 16, iter = 10500, loss = 1.6526029479503632, 22.866703748703003 s per 100 iters\n","time = 42.0, epoch 16, iter = 10600, loss = 1.6705496191978455, 23.96222186088562 s per 100 iters\n","time = 42.0, epoch 16, iter = 10700, loss = 1.6625974506139756, 23.850597620010376 s per 100 iters\n","time = 42.0, epoch 16, iter = 10800, loss = 1.6653507763147355, 24.48835849761963 s per 100 iters\n","time = 43.0, epoch 16, iter = 10900, loss = 1.6668387752771379, 22.829206705093384 s per 100 iters\n","time = 43.0, epoch 16, iter = 11000, loss = 1.666017695069313, 23.87029004096985 s per 100 iters\n","time = 44.0, epoch 16, iter = 11100, loss = 1.6787086623907088, 24.114744901657104 s per 100 iters\n","time = 44.0, epoch 16, iter = 11200, loss = 1.6664537954330445, 23.384270906448364 s per 100 iters\n","time = 44.0, epoch 16, iter = 11300, loss = 1.6837472701072693, 23.954947471618652 s per 100 iters\n","time = 45.0, epoch 16, iter = 11400, loss = 1.6359724920988084, 24.184930324554443 s per 100 iters\n","time = 45.0, epoch 16, iter = 11500, loss = 1.6781113958358764, 23.937554359436035 s per 100 iters\n","time = 46.0, epoch 16, iter = 11600, loss = 1.6700824493169784, 23.034533739089966 s per 100 iters\n","time = 46.0, epoch 16, iter = 11700, loss = 1.672819275856018, 23.79018759727478 s per 100 iters\n","time = 46.0, epoch 16, iter = 11800, loss = 1.6826481610536574, 24.055946350097656 s per 100 iters\n","time = 47.0, epoch 16, iter = 11900, loss = 1.6593410801887511, 23.89807629585266 s per 100 iters\n","time = 47.0, epoch 16, iter = 12000, loss = 1.6759292662143708, 23.414547443389893 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 48.0, epoch 16, iter = 12100, loss = 1.6757168781757354, 24.48381543159485 s per 100 iters\n","time = 48.0, epoch 16, iter = 12200, loss = 1.6819379818439484, 23.836924076080322 s per 100 iters\n","time = 48.0, epoch 16, iter = 12300, loss = 1.6750864273309707, 23.153772115707397 s per 100 iters\n","time = 49.0, epoch 16, iter = 12400, loss = 1.6822009736299515, 23.350013494491577 s per 100 iters\n","time = 49.0, epoch 16, iter = 12500, loss = 1.6740049296617507, 23.65135383605957 s per 100 iters\n","time = 50.0, epoch 16, iter = 12600, loss = 1.6817169660329818, 24.367204189300537 s per 100 iters\n","time = 50.0, epoch 16, iter = 12700, loss = 1.6621141535043717, 23.198808908462524 s per 100 iters\n","time = 50.0, epoch 16, iter = 12800, loss = 1.682001404762268, 23.643563747406006 s per 100 iters\n","time = 51.0, epoch 16, iter = 12900, loss = 1.6716491454839706, 23.681216716766357 s per 100 iters\n","time = 51.0, epoch 16, iter = 13000, loss = 1.6868667006492615, 24.581926822662354 s per 100 iters\n","time = 52.0, epoch 16, iter = 13100, loss = 1.6736848586797715, 23.316528797149658 s per 100 iters\n","time = 52.0, epoch 16, iter = 13200, loss = 1.7028659397363664, 24.02905559539795 s per 100 iters\n","time = 52.0, epoch 16, iter = 13300, loss = 1.693603402376175, 24.05548405647278 s per 100 iters\n","time = 53.0, epoch 16, iter = 13400, loss = 1.6816104596853256, 23.96593475341797 s per 100 iters\n","time = 53.0, epoch 16, iter = 13500, loss = 1.6831647485494614, 23.7089204788208 s per 100 iters\n","time = 53.0, epoch 16, iter = 13600, loss = 1.6650421136617661, 23.112024307250977 s per 100 iters\n","time = 54.0, epoch 16, iter = 13700, loss = 1.67409122467041, 23.820576190948486 s per 100 iters\n","time = 54.0, epoch 16, iter = 13800, loss = 1.680548895597458, 24.180739164352417 s per 100 iters\n","time = 55.0, epoch 16, iter = 13900, loss = 1.6889241057634354, 23.522618055343628 s per 100 iters\n","time = 55.0, epoch 16, iter = 14000, loss = 1.6963678854703903, 24.174590587615967 s per 100 iters\n","time = 55.0, epoch 16, iter = 14100, loss = 1.6831233650445938, 23.53923988342285 s per 100 iters\n","time = 56.0, epoch 16, iter = 14200, loss = 1.6880080771446229, 23.81892681121826 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 56.0, epoch 16, iter = 14300, loss = 1.700459732413292, 24.09122323989868 s per 100 iters\n","--- Balidazioa ---\n","22.548335075378418 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia mileto habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina berandu da ￭:', '｟C baina zer izan da hori ￭?', '｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodia eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ￭, ｟C siziliako itsasertzean oin bat jan zuen ￭, eta nesken xarma ￭, aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok aditzera eman zion ｟C donnafugatako jauregia ez zela ｟C capraroko ataria ￭, eta seguru aski bizirik aterako zela handik ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi dauzkat ￭.', '｟C epaileak eta beste zenbait funtzionari judutarrak eta exekutiboak ￭, joyntas artifizialak ￭, sarbide eta zigorrak ￭, subiranotasun-lekuarekin batera ￭, bakoitza bere betebeharrak betetzera mugatzen delarik ￭, nerbioak dira gorputz naturalean ￭, aberastasun eta atal guztiak dira herri-jainkoen indar guztiak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau ￭, hain zuzen ￭, ideal hori ￭, gaur egun irudikatzen dute ￭, eta agian beste inor ez ￭, horiek dira beren produkturik izpiritualenak ￭, bere asmatzaile eta esploratzaileen biloba aurreratuenak ￭, bere sedukzio-forma delikorren eta elikatzekoa ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain pobrea den familiarik ￭.', '｟C duela gutxi behintzat ￭, ｟C derwatt-tarren kontuarekin ￭, eta orain ｟C mafiaren akusatua ￭?']\n","BLEU puntuazioa (1): 9.791300146066721\n","8.77697205543518 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak janaria ekartzen digula ￭?', '- ｟C corvette-aren historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartzera etorri zela pentsatu nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hor dago koxka ￭.', '｟C basoan otsoak egongo dira ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez dizu inporta ￭?', '｟C argazki bat daukat 1960ean eta bere semea 1940ko uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer sarrerak ￭?', '｟C egizu lo ￭, maitea ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C delphinek badaki ￭?']\n","BLEU puntuazioa (2): 22.2298480111354\n","BLEU puntuazioa (biak): 12.6873734876573\n","time = 57.0, epoch 17, iter = 100, loss = 1.5448951959609984, 25.035234689712524 s per 100 iters\n","time = 58.0, epoch 17, iter = 200, loss = 1.5397452890872956, 23.882366180419922 s per 100 iters\n","time = 58.0, epoch 17, iter = 300, loss = 1.5402753406763077, 24.870919227600098 s per 100 iters\n","time = 59.0, epoch 17, iter = 400, loss = 1.5477651727199555, 23.710397243499756 s per 100 iters\n","time = 59.0, epoch 17, iter = 500, loss = 1.5415068995952605, 24.18151593208313 s per 100 iters\n","time = 59.0, epoch 17, iter = 600, loss = 1.5368777614831926, 23.677024364471436 s per 100 iters\n","time = 60.0, epoch 17, iter = 700, loss = 1.5630252200365067, 24.404229402542114 s per 100 iters\n","time = 60.0, epoch 17, iter = 800, loss = 1.5521760326623917, 24.153735637664795 s per 100 iters\n","time = 61.0, epoch 17, iter = 900, loss = 1.5454429066181183, 23.400128602981567 s per 100 iters\n","time = 61.0, epoch 17, iter = 1000, loss = 1.5680150592327118, 23.829765558242798 s per 100 iters\n","time = 61.0, epoch 17, iter = 1100, loss = 1.5552561247348786, 23.70734190940857 s per 100 iters\n","time = 62.0, epoch 17, iter = 1200, loss = 1.5484192430973054, 24.70449423789978 s per 100 iters\n","time = 62.0, epoch 17, iter = 1300, loss = 1.5570253348350525, 23.59697937965393 s per 100 iters\n","time = 63.0, epoch 17, iter = 1400, loss = 1.5636245274543763, 24.667445182800293 s per 100 iters\n","time = 63.0, epoch 17, iter = 1500, loss = 1.584225531220436, 23.84772777557373 s per 100 iters\n","time = 63.0, epoch 17, iter = 1600, loss = 1.5717679899930954, 23.963457107543945 s per 100 iters\n","time = 64.0, epoch 17, iter = 1700, loss = 1.5746937721967698, 24.730456113815308 s per 100 iters\n","time = 64.0, epoch 17, iter = 1800, loss = 1.571237450838089, 23.51891255378723 s per 100 iters\n","time = 65.0, epoch 17, iter = 1900, loss = 1.5707517683506012, 23.69992184638977 s per 100 iters\n","time = 65.0, epoch 17, iter = 2000, loss = 1.5795009356737137, 24.040531873703003 s per 100 iters\n","time = 65.0, epoch 17, iter = 2100, loss = 1.5578315526247024, 23.881027460098267 s per 100 iters\n","time = 66.0, epoch 17, iter = 2200, loss = 1.5609585237503052, 23.607295274734497 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 66.0, epoch 17, iter = 2300, loss = 1.585593649148941, 24.43107008934021 s per 100 iters\n","time = 67.0, epoch 17, iter = 2400, loss = 1.5798852109909058, 23.93329882621765 s per 100 iters\n","time = 67.0, epoch 17, iter = 2500, loss = 1.5897550052404403, 24.51210355758667 s per 100 iters\n","time = 67.0, epoch 17, iter = 2600, loss = 1.5854383844137192, 24.166240215301514 s per 100 iters\n","time = 68.0, epoch 17, iter = 2700, loss = 1.5722235065698624, 24.092088222503662 s per 100 iters\n","time = 68.0, epoch 17, iter = 2800, loss = 1.5694143390655517, 23.250494241714478 s per 100 iters\n","time = 69.0, epoch 17, iter = 2900, loss = 1.5889736986160279, 23.98357319831848 s per 100 iters\n","time = 69.0, epoch 17, iter = 3000, loss = 1.583284829854965, 23.63758611679077 s per 100 iters\n","time = 69.0, epoch 17, iter = 3100, loss = 1.5702765130996703, 23.793040990829468 s per 100 iters\n","time = 70.0, epoch 17, iter = 3200, loss = 1.5858201479911804, 24.364904165267944 s per 100 iters\n","time = 70.0, epoch 17, iter = 3300, loss = 1.5822429490089416, 23.780893087387085 s per 100 iters\n","time = 71.0, epoch 17, iter = 3400, loss = 1.5948256051540375, 23.74788522720337 s per 100 iters\n","time = 71.0, epoch 17, iter = 3500, loss = 1.6135337805747987, 24.267656564712524 s per 100 iters\n","time = 71.0, epoch 17, iter = 3600, loss = 1.5806116265058519, 25.047422409057617 s per 100 iters\n","time = 72.0, epoch 17, iter = 3700, loss = 1.585692549943924, 23.305018663406372 s per 100 iters\n","time = 72.0, epoch 17, iter = 3800, loss = 1.6228348714113237, 24.437874794006348 s per 100 iters\n","time = 73.0, epoch 17, iter = 3900, loss = 1.5841234833002091, 23.478325366973877 s per 100 iters\n","time = 73.0, epoch 17, iter = 4000, loss = 1.6006819272041322, 24.577035665512085 s per 100 iters\n","time = 73.0, epoch 17, iter = 4100, loss = 1.595795819759369, 24.258628845214844 s per 100 iters\n","time = 74.0, epoch 17, iter = 4200, loss = 1.584623046517372, 23.966612815856934 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 74.0, epoch 17, iter = 4300, loss = 1.6147541761398316, 24.3829448223114 s per 100 iters\n","time = 75.0, epoch 17, iter = 4400, loss = 1.6083961325883864, 24.50583815574646 s per 100 iters\n","time = 75.0, epoch 17, iter = 4500, loss = 1.59669264793396, 22.806261777877808 s per 100 iters\n","time = 75.0, epoch 17, iter = 4600, loss = 1.5796351331472396, 23.764700174331665 s per 100 iters\n","time = 76.0, epoch 17, iter = 4700, loss = 1.623454013466835, 25.398248195648193 s per 100 iters\n","time = 76.0, epoch 17, iter = 4800, loss = 1.6155955332517624, 24.27823257446289 s per 100 iters\n","time = 77.0, epoch 17, iter = 4900, loss = 1.6129845643043519, 24.658427715301514 s per 100 iters\n","time = 77.0, epoch 17, iter = 5000, loss = 1.6035095715522767, 24.013809204101562 s per 100 iters\n","time = 77.0, epoch 17, iter = 5100, loss = 1.6128249883651733, 24.048295736312866 s per 100 iters\n","time = 78.0, epoch 17, iter = 5200, loss = 1.5837618935108184, 23.09844398498535 s per 100 iters\n","time = 78.0, epoch 17, iter = 5300, loss = 1.625598429441452, 23.833297967910767 s per 100 iters\n","time = 79.0, epoch 17, iter = 5400, loss = 1.5835422509908677, 23.790327310562134 s per 100 iters\n","time = 79.0, epoch 17, iter = 5500, loss = 1.608869857788086, 24.56904673576355 s per 100 iters\n","time = 79.0, epoch 17, iter = 5600, loss = 1.6289943426847457, 23.818601608276367 s per 100 iters\n","time = 80.0, epoch 17, iter = 5700, loss = 1.6079705262184143, 23.752323865890503 s per 100 iters\n","time = 80.0, epoch 17, iter = 5800, loss = 1.6343100970983506, 24.50994849205017 s per 100 iters\n","time = 81.0, epoch 17, iter = 5900, loss = 1.607173406481743, 23.164143800735474 s per 100 iters\n","time = 81.0, epoch 17, iter = 6000, loss = 1.6236987620592118, 24.678566932678223 s per 100 iters\n","time = 81.0, epoch 17, iter = 6100, loss = 1.6203840321302414, 24.329723596572876 s per 100 iters\n","time = 82.0, epoch 17, iter = 6200, loss = 1.6181991398334503, 24.306800842285156 s per 100 iters\n","time = 82.0, epoch 17, iter = 6300, loss = 1.6020760828256606, 23.740660905838013 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 83.0, epoch 17, iter = 6400, loss = 1.618327413201332, 24.29712462425232 s per 100 iters\n","time = 83.0, epoch 17, iter = 6500, loss = 1.6300616604089737, 24.15588617324829 s per 100 iters\n","time = 83.0, epoch 17, iter = 6600, loss = 1.6020090001821519, 24.089873552322388 s per 100 iters\n","time = 84.0, epoch 17, iter = 6700, loss = 1.6051059120893478, 23.485843181610107 s per 100 iters\n","time = 84.0, epoch 17, iter = 6800, loss = 1.627718139886856, 24.59911608695984 s per 100 iters\n","time = 85.0, epoch 17, iter = 6900, loss = 1.6334137779474258, 24.76878309249878 s per 100 iters\n","time = 85.0, epoch 17, iter = 7000, loss = 1.6326657778024674, 24.06163787841797 s per 100 iters\n","time = 85.0, epoch 17, iter = 7100, loss = 1.628029831647873, 24.43174910545349 s per 100 iters\n","time = 86.0, epoch 17, iter = 7200, loss = 1.6201785057783127, 23.81778597831726 s per 100 iters\n","time = 86.0, epoch 17, iter = 7300, loss = 1.6262801891565324, 23.87062692642212 s per 100 iters\n","time = 87.0, epoch 17, iter = 7400, loss = 1.6214146554470061, 23.325685262680054 s per 100 iters\n","time = 87.0, epoch 17, iter = 7500, loss = 1.6167931711673738, 24.96248722076416 s per 100 iters\n","time = 87.0, epoch 17, iter = 7600, loss = 1.6315272027254104, 23.680341958999634 s per 100 iters\n","time = 88.0, epoch 17, iter = 7700, loss = 1.627649834752083, 23.818230390548706 s per 100 iters\n","time = 88.0, epoch 17, iter = 7800, loss = 1.610006670355797, 24.80761456489563 s per 100 iters\n","time = 89.0, epoch 17, iter = 7900, loss = 1.622637952566147, 24.23919129371643 s per 100 iters\n","time = 89.0, epoch 17, iter = 8000, loss = 1.6242744433879852, 24.5228910446167 s per 100 iters\n","time = 89.0, epoch 17, iter = 8100, loss = 1.6499975794553756, 24.71297001838684 s per 100 iters\n","time = 90.0, epoch 17, iter = 8200, loss = 1.639479839205742, 23.635407209396362 s per 100 iters\n","time = 90.0, epoch 17, iter = 8300, loss = 1.6401134657859802, 24.191131830215454 s per 100 iters\n","time = 91.0, epoch 17, iter = 8400, loss = 1.628720254302025, 23.818193435668945 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 91.0, epoch 17, iter = 8500, loss = 1.6371516907215118, 24.018014430999756 s per 100 iters\n","time = 91.0, epoch 17, iter = 8600, loss = 1.6514466726779937, 23.977637767791748 s per 100 iters\n","time = 92.0, epoch 17, iter = 8700, loss = 1.6330745977163315, 23.800549030303955 s per 100 iters\n","time = 92.0, epoch 17, iter = 8800, loss = 1.6319766187667846, 23.375479221343994 s per 100 iters\n","time = 93.0, epoch 17, iter = 8900, loss = 1.6314311319589614, 24.017244577407837 s per 100 iters\n","time = 93.0, epoch 17, iter = 9000, loss = 1.6309657561779023, 23.6458420753479 s per 100 iters\n","time = 93.0, epoch 17, iter = 9100, loss = 1.6354150301218033, 23.7255859375 s per 100 iters\n","time = 94.0, epoch 17, iter = 9200, loss = 1.634247639775276, 24.124529123306274 s per 100 iters\n","time = 94.0, epoch 17, iter = 9300, loss = 1.6437490791082383, 24.510400772094727 s per 100 iters\n","time = 95.0, epoch 17, iter = 9400, loss = 1.6303070265054702, 23.865005254745483 s per 100 iters\n","time = 95.0, epoch 17, iter = 9500, loss = 1.6468887346982957, 24.64621114730835 s per 100 iters\n","time = 95.0, epoch 17, iter = 9600, loss = 1.6549521577358246, 23.800847053527832 s per 100 iters\n","time = 96.0, epoch 17, iter = 9700, loss = 1.6261403739452363, 24.623010635375977 s per 100 iters\n","time = 96.0, epoch 17, iter = 9800, loss = 1.644532099366188, 24.34548568725586 s per 100 iters\n","time = 97.0, epoch 17, iter = 9900, loss = 1.6123351681232452, 24.07122015953064 s per 100 iters\n","time = 97.0, epoch 17, iter = 10000, loss = 1.6242209023237228, 23.627020835876465 s per 100 iters\n","time = 97.0, epoch 17, iter = 10100, loss = 1.6359325015544892, 23.776227951049805 s per 100 iters\n","time = 98.0, epoch 17, iter = 10200, loss = 1.644415221810341, 23.294493675231934 s per 100 iters\n","time = 98.0, epoch 17, iter = 10300, loss = 1.6471592152118684, 23.675362825393677 s per 100 iters\n","time = 99.0, epoch 17, iter = 10400, loss = 1.6491852581501008, 24.55760884284973 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 99.0, epoch 17, iter = 10500, loss = 1.6473100310564042, 25.017953634262085 s per 100 iters\n","time = 99.0, epoch 17, iter = 10600, loss = 1.6095041197538376, 23.501807928085327 s per 100 iters\n","time = 100.0, epoch 17, iter = 10700, loss = 1.6568491160869598, 24.347479343414307 s per 100 iters\n","time = 100.0, epoch 17, iter = 10800, loss = 1.6346407270431518, 24.187877893447876 s per 100 iters\n","time = 101.0, epoch 17, iter = 10900, loss = 1.634241999387741, 24.14106774330139 s per 100 iters\n","time = 101.0, epoch 17, iter = 11000, loss = 1.6428878962993623, 24.037827491760254 s per 100 iters\n","time = 102.0, epoch 17, iter = 11100, loss = 1.666201651096344, 24.546442985534668 s per 100 iters\n","time = 102.0, epoch 17, iter = 11200, loss = 1.6528042447566986, 23.858752012252808 s per 100 iters\n","time = 102.0, epoch 17, iter = 11300, loss = 1.629714114665985, 23.19045352935791 s per 100 iters\n","time = 103.0, epoch 17, iter = 11400, loss = 1.635374476313591, 24.241438627243042 s per 100 iters\n","time = 103.0, epoch 17, iter = 11500, loss = 1.6571278178691864, 24.516598224639893 s per 100 iters\n","time = 103.0, epoch 17, iter = 11600, loss = 1.648065257668495, 23.936991214752197 s per 100 iters\n","time = 104.0, epoch 17, iter = 11700, loss = 1.6624478501081468, 24.101003646850586 s per 100 iters\n","time = 104.0, epoch 17, iter = 11800, loss = 1.6515572249889374, 23.61549949645996 s per 100 iters\n","time = 105.0, epoch 17, iter = 11900, loss = 1.6613235408067704, 24.298606872558594 s per 100 iters\n","time = 105.0, epoch 17, iter = 12000, loss = 1.6601036441326142, 24.07023048400879 s per 100 iters\n","time = 106.0, epoch 17, iter = 12100, loss = 1.6511370289325713, 24.768903255462646 s per 100 iters\n","time = 106.0, epoch 17, iter = 12200, loss = 1.6411943054199218, 23.274017333984375 s per 100 iters\n","time = 106.0, epoch 17, iter = 12300, loss = 1.6735802167654037, 24.60630965232849 s per 100 iters\n","time = 107.0, epoch 17, iter = 12400, loss = 1.6516492903232574, 24.068193912506104 s per 100 iters\n","time = 107.0, epoch 17, iter = 12500, loss = 1.6597594207525252, 24.58540940284729 s per 100 iters\n","time = 108.0, epoch 17, iter = 12600, loss = 1.6426812767982484, 24.157013177871704 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 108.0, epoch 17, iter = 12700, loss = 1.6512667542696, 23.474480628967285 s per 100 iters\n","time = 108.0, epoch 17, iter = 12800, loss = 1.6622137129306793, 23.967763662338257 s per 100 iters\n","time = 109.0, epoch 17, iter = 12900, loss = 1.6686103928089142, 23.71030831336975 s per 100 iters\n","time = 109.0, epoch 17, iter = 13000, loss = 1.6593784129619598, 24.14114475250244 s per 100 iters\n","time = 110.0, epoch 17, iter = 13100, loss = 1.6551270169019698, 24.81986355781555 s per 100 iters\n","time = 110.0, epoch 17, iter = 13200, loss = 1.65706687271595, 24.080172061920166 s per 100 iters\n","time = 110.0, epoch 17, iter = 13300, loss = 1.6729540926218034, 24.653310298919678 s per 100 iters\n","time = 111.0, epoch 17, iter = 13400, loss = 1.6626570200920106, 24.170643091201782 s per 100 iters\n","time = 111.0, epoch 17, iter = 13500, loss = 1.664362815618515, 23.99122428894043 s per 100 iters\n","time = 112.0, epoch 17, iter = 13600, loss = 1.6654281610250472, 24.184123754501343 s per 100 iters\n","time = 112.0, epoch 17, iter = 13700, loss = 1.6720274883508681, 24.287771224975586 s per 100 iters\n","time = 112.0, epoch 17, iter = 13800, loss = 1.673478171825409, 24.41944122314453 s per 100 iters\n","time = 113.0, epoch 17, iter = 13900, loss = 1.6303059470653534, 24.018919944763184 s per 100 iters\n","time = 113.0, epoch 17, iter = 14000, loss = 1.6554598164558412, 23.578256130218506 s per 100 iters\n","time = 114.0, epoch 17, iter = 14100, loss = 1.6727617955207825, 24.218559741973877 s per 100 iters\n","time = 114.0, epoch 17, iter = 14200, loss = 1.684674435853958, 24.628597497940063 s per 100 iters\n","time = 114.0, epoch 17, iter = 14300, loss = 1.6872759890556335, 24.527888298034668 s per 100 iters\n","--- Balidazioa ---\n","26.729081392288208 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milesebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '｟B rosanna spearman ｟E', '｟C ez al da bitxia ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da gozoa eta betea ￭.', '｟C eta bere dulcinea ￭?', '｟C afarian ￭, ｟C siziliako kostetan oinik jarri eta nesken xarma ￭, aita ｟C pirronearen austeritatea eta ｟C don ｟C fabriziok aditzera eman zionez ￭, ｟C donnafugatako jauregia ez zela ｟C capraroko ezkongaia ￭, eta seguru asko bizirik irtengo zela ￭.', '｟C erosketak egiten ari dira ￭.', '｟C ederra zen ￭.', '｟C aaaa ￭!', '｟C orain bi dauzkat ￭.', '｟C epaileak ￭, eta betearazleek ￭, epaile eta exekutiboek ￭, joynts lapurtuak ￭, saritu eta zigorrak ￭, subiranotasunaren jarlekura azkar mugituz ￭, bere betebeharra betetzeko ardura guztiak ￭, gorputz naturalean egiten duten nerbioak dira ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau haien ideala besterik ez da ￭, orain irudikatzen dute ￭, eta agian beste inor ez ￭, horiek dira bere produkturik izpiritualenenak ￭, bere asmatzaile eta eskandalurik aurreratuenak ￭, sedukzioaren forma delikatuena eta eleztatuena ￭.', '｟C hegoaldean ez dago familiarik ￭, ez esklaborik ￭.', '｟C duela gutxi behintzat ￭, ｟C derwatt-tarren kontuarekin ￭, eta orain ｟C mafia leporatu ziotena ￭?']\n","BLEU puntuazioa (1): 9.916147880665397\n","5.756385326385498 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C musika interesgarria zen ｟C marty ￭.', '｟C nick zaharrak non uste duzu janaria eramango duela ￭?', '- ｟C ezagutzen dugu ｟C corvette istorio hori ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C windom ｟C earle ｟C twin ｟C peaks-era iritsi zenean ￭, mendekua hartzera etorria zela pentsatu nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hor dago koxka ￭.', '｟C basoan otsoak egongo dira ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez dizu axola ￭?', '｟C eta argazki bat daukat 1960ean eta bere semea 1940ko uniforme batean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C itzuli ohera ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaks-era etorriko da ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.449010543673058\n","BLEU puntuazioa (biak): 12.809290825949397\n","time = 116.0, epoch 18, iter = 100, loss = 1.5252945584058761, 25.702476263046265 s per 100 iters\n","time = 116.0, epoch 18, iter = 200, loss = 1.5065468579530716, 24.47757911682129 s per 100 iters\n","time = 116.0, epoch 18, iter = 300, loss = 1.5156204283237458, 24.62287735939026 s per 100 iters\n","time = 117.0, epoch 18, iter = 400, loss = 1.516530305147171, 24.35025191307068 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 117.0, epoch 18, iter = 500, loss = 1.5119287222623825, 24.298834800720215 s per 100 iters\n","time = 118.0, epoch 18, iter = 600, loss = 1.5385692465305327, 24.576730012893677 s per 100 iters\n","time = 118.0, epoch 18, iter = 700, loss = 1.5175173264741897, 24.43590497970581 s per 100 iters\n","time = 118.0, epoch 18, iter = 800, loss = 1.5168346560001373, 23.56121063232422 s per 100 iters\n","time = 119.0, epoch 18, iter = 900, loss = 1.5255397963523865, 24.189741611480713 s per 100 iters\n","time = 119.0, epoch 18, iter = 1000, loss = 1.5452615505456924, 24.277685403823853 s per 100 iters\n","time = 120.0, epoch 18, iter = 1100, loss = 1.5279638075828552, 24.256598949432373 s per 100 iters\n","time = 120.0, epoch 18, iter = 1200, loss = 1.5228708469867707, 24.18502926826477 s per 100 iters\n","time = 120.0, epoch 18, iter = 1300, loss = 1.5546653723716737, 24.672027826309204 s per 100 iters\n","time = 121.0, epoch 18, iter = 1400, loss = 1.5476544165611268, 24.786744356155396 s per 100 iters\n","time = 121.0, epoch 18, iter = 1500, loss = 1.5224321758747101, 24.527596473693848 s per 100 iters\n","time = 122.0, epoch 18, iter = 1600, loss = 1.5272962760925293, 23.734182357788086 s per 100 iters\n","time = 122.0, epoch 18, iter = 1700, loss = 1.5440086442232133, 24.443127632141113 s per 100 iters\n","time = 122.0, epoch 18, iter = 1800, loss = 1.5459243834018708, 23.579015493392944 s per 100 iters\n","time = 123.0, epoch 18, iter = 1900, loss = 1.5613938707113266, 23.784539699554443 s per 100 iters\n","time = 123.0, epoch 18, iter = 2000, loss = 1.5415986293554307, 24.773316144943237 s per 100 iters\n","time = 124.0, epoch 18, iter = 2100, loss = 1.538057998418808, 23.847825050354004 s per 100 iters\n","time = 124.0, epoch 18, iter = 2200, loss = 1.549713585972786, 24.107955932617188 s per 100 iters\n","time = 124.0, epoch 18, iter = 2300, loss = 1.5386730706691742, 23.88193964958191 s per 100 iters\n","time = 125.0, epoch 18, iter = 2400, loss = 1.569172681570053, 24.271923542022705 s per 100 iters\n","time = 125.0, epoch 18, iter = 2500, loss = 1.5413826274871827, 24.130730390548706 s per 100 iters\n","time = 126.0, epoch 18, iter = 2600, loss = 1.5675689333677292, 23.754581689834595 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 126.0, epoch 18, iter = 2700, loss = 1.5628212773799897, 23.784010648727417 s per 100 iters\n","time = 126.0, epoch 18, iter = 2800, loss = 1.556465718150139, 24.521658658981323 s per 100 iters\n","time = 127.0, epoch 18, iter = 2900, loss = 1.556400174498558, 24.43027925491333 s per 100 iters\n","time = 127.0, epoch 18, iter = 3000, loss = 1.5644232153892517, 24.077709913253784 s per 100 iters\n","time = 128.0, epoch 18, iter = 3100, loss = 1.5754861676692962, 24.788678407669067 s per 100 iters\n","time = 128.0, epoch 18, iter = 3200, loss = 1.5682838761806488, 24.854422092437744 s per 100 iters\n","time = 128.0, epoch 18, iter = 3300, loss = 1.5643727242946626, 24.12509274482727 s per 100 iters\n","time = 129.0, epoch 18, iter = 3400, loss = 1.5975656723976135, 24.029985427856445 s per 100 iters\n","time = 129.0, epoch 18, iter = 3500, loss = 1.5458585298061371, 23.786460161209106 s per 100 iters\n","time = 130.0, epoch 18, iter = 3600, loss = 1.5838564693927766, 23.827845335006714 s per 100 iters\n","time = 130.0, epoch 18, iter = 3700, loss = 1.5702528077363969, 23.93360733985901 s per 100 iters\n","time = 130.0, epoch 18, iter = 3800, loss = 1.5530826270580291, 23.727082014083862 s per 100 iters\n","time = 131.0, epoch 18, iter = 3900, loss = 1.5578834915161133, 23.920039892196655 s per 100 iters\n","time = 131.0, epoch 18, iter = 4000, loss = 1.5735094392299651, 23.126381397247314 s per 100 iters\n","time = 132.0, epoch 18, iter = 4100, loss = 1.5832166963815688, 24.763909339904785 s per 100 iters\n","time = 132.0, epoch 18, iter = 4200, loss = 1.6005872142314912, 23.74217915534973 s per 100 iters\n","time = 132.0, epoch 18, iter = 4300, loss = 1.554833880662918, 23.997111797332764 s per 100 iters\n","time = 133.0, epoch 18, iter = 4400, loss = 1.5742545878887177, 23.45752263069153 s per 100 iters\n","time = 133.0, epoch 18, iter = 4500, loss = 1.5769506710767747, 23.771963119506836 s per 100 iters\n","time = 134.0, epoch 18, iter = 4600, loss = 1.5851484948396684, 23.948427200317383 s per 100 iters\n","time = 134.0, epoch 18, iter = 4700, loss = 1.5828856456279754, 24.217958450317383 s per 100 iters\n","time = 134.0, epoch 18, iter = 4800, loss = 1.5833444613218308, 23.698837995529175 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 135.0, epoch 18, iter = 4900, loss = 1.5967683225870133, 24.131800889968872 s per 100 iters\n","time = 135.0, epoch 18, iter = 5000, loss = 1.5648984813690185, 23.717806577682495 s per 100 iters\n","time = 136.0, epoch 18, iter = 5100, loss = 1.5722734826803206, 23.733126401901245 s per 100 iters\n","time = 136.0, epoch 18, iter = 5200, loss = 1.581741116642952, 23.930129766464233 s per 100 iters\n","time = 136.0, epoch 18, iter = 5300, loss = 1.5676571065187455, 24.056503772735596 s per 100 iters\n","time = 137.0, epoch 18, iter = 5400, loss = 1.5714689028263091, 23.730154037475586 s per 100 iters\n","time = 137.0, epoch 18, iter = 5500, loss = 1.608112192749977, 24.765256643295288 s per 100 iters\n","time = 138.0, epoch 18, iter = 5600, loss = 1.5902985310554505, 23.93579864501953 s per 100 iters\n","time = 138.0, epoch 18, iter = 5700, loss = 1.5821188378334046, 24.670605421066284 s per 100 iters\n","time = 138.0, epoch 18, iter = 5800, loss = 1.603716917037964, 24.59512209892273 s per 100 iters\n","time = 139.0, epoch 18, iter = 5900, loss = 1.603245719075203, 24.901458501815796 s per 100 iters\n","time = 139.0, epoch 18, iter = 6000, loss = 1.5684979033470154, 23.886911630630493 s per 100 iters\n","time = 140.0, epoch 18, iter = 6100, loss = 1.583131131529808, 23.623785734176636 s per 100 iters\n","time = 140.0, epoch 18, iter = 6200, loss = 1.59671435713768, 24.220622062683105 s per 100 iters\n","time = 140.0, epoch 18, iter = 6300, loss = 1.5980902498960494, 24.002367973327637 s per 100 iters\n","time = 141.0, epoch 18, iter = 6400, loss = 1.6112061196565628, 23.61394715309143 s per 100 iters\n","time = 141.0, epoch 18, iter = 6500, loss = 1.5820279735326768, 23.8862886428833 s per 100 iters\n","time = 142.0, epoch 18, iter = 6600, loss = 1.588489179611206, 24.64374852180481 s per 100 iters\n","time = 142.0, epoch 18, iter = 6700, loss = 1.5972769951820374, 24.732913970947266 s per 100 iters\n","time = 142.0, epoch 18, iter = 6800, loss = 1.596848601102829, 24.264567375183105 s per 100 iters\n","time = 143.0, epoch 18, iter = 6900, loss = 1.5753950053453445, 23.26897644996643 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 143.0, epoch 18, iter = 7000, loss = 1.5969819086790085, 24.311061143875122 s per 100 iters\n","time = 144.0, epoch 18, iter = 7100, loss = 1.5922019582986833, 23.894145250320435 s per 100 iters\n","time = 144.0, epoch 18, iter = 7200, loss = 1.607599229812622, 24.939165592193604 s per 100 iters\n","time = 144.0, epoch 18, iter = 7300, loss = 1.601883230805397, 24.088114976882935 s per 100 iters\n","time = 145.0, epoch 18, iter = 7400, loss = 1.6176289451122283, 24.392653703689575 s per 100 iters\n","time = 145.0, epoch 18, iter = 7500, loss = 1.612838042974472, 24.264395236968994 s per 100 iters\n","time = 146.0, epoch 18, iter = 7600, loss = 1.585162851214409, 24.172818422317505 s per 100 iters\n","time = 146.0, epoch 18, iter = 7700, loss = 1.6197149401903153, 24.716496467590332 s per 100 iters\n","time = 147.0, epoch 18, iter = 7800, loss = 1.6008419060707093, 23.999377965927124 s per 100 iters\n","time = 147.0, epoch 18, iter = 7900, loss = 1.6198103088140487, 24.181718826293945 s per 100 iters\n","time = 147.0, epoch 18, iter = 8000, loss = 1.5964628428220748, 23.23706293106079 s per 100 iters\n","time = 148.0, epoch 18, iter = 8100, loss = 1.6189029359817504, 23.46576452255249 s per 100 iters\n","time = 148.0, epoch 18, iter = 8200, loss = 1.614884884953499, 23.85999083518982 s per 100 iters\n","time = 148.0, epoch 18, iter = 8300, loss = 1.6217697781324387, 24.52486300468445 s per 100 iters\n","time = 149.0, epoch 18, iter = 8400, loss = 1.6225282853841783, 23.756266593933105 s per 100 iters\n","time = 149.0, epoch 18, iter = 8500, loss = 1.6206636154651641, 24.072509765625 s per 100 iters\n","time = 150.0, epoch 18, iter = 8600, loss = 1.609795669913292, 24.161277055740356 s per 100 iters\n","time = 150.0, epoch 18, iter = 8700, loss = 1.625163204073906, 23.536327838897705 s per 100 iters\n","time = 151.0, epoch 18, iter = 8800, loss = 1.631008841395378, 24.623377084732056 s per 100 iters\n","time = 151.0, epoch 18, iter = 8900, loss = 1.6171776503324509, 23.291852474212646 s per 100 iters\n","time = 151.0, epoch 18, iter = 9000, loss = 1.608972529768944, 23.478731155395508 s per 100 iters\n","time = 152.0, epoch 18, iter = 9100, loss = 1.6204085606336593, 24.34970211982727 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 152.0, epoch 18, iter = 9200, loss = 1.6151135683059692, 23.317884922027588 s per 100 iters\n","time = 152.0, epoch 18, iter = 9300, loss = 1.6156512248516082, 23.824434995651245 s per 100 iters\n","time = 153.0, epoch 18, iter = 9400, loss = 1.60795392870903, 24.412052869796753 s per 100 iters\n","time = 153.0, epoch 18, iter = 9500, loss = 1.618769974708557, 23.815511465072632 s per 100 iters\n","time = 154.0, epoch 18, iter = 9600, loss = 1.6239678847789765, 22.773913621902466 s per 100 iters\n","time = 154.0, epoch 18, iter = 9700, loss = 1.6184406715631485, 23.381269454956055 s per 100 iters\n","time = 154.0, epoch 18, iter = 9800, loss = 1.6180651128292083, 23.89919114112854 s per 100 iters\n","time = 155.0, epoch 18, iter = 9900, loss = 1.615110808610916, 24.055070638656616 s per 100 iters\n","time = 155.0, epoch 18, iter = 10000, loss = 1.62568517267704, 23.774864435195923 s per 100 iters\n","time = 156.0, epoch 18, iter = 10100, loss = 1.6185170793533326, 23.37469220161438 s per 100 iters\n","time = 156.0, epoch 18, iter = 10200, loss = 1.6098920613527299, 23.424378871917725 s per 100 iters\n","time = 156.0, epoch 18, iter = 10300, loss = 1.643702465891838, 24.308505535125732 s per 100 iters\n","time = 157.0, epoch 18, iter = 10400, loss = 1.6059461778402329, 23.43652057647705 s per 100 iters\n","time = 157.0, epoch 18, iter = 10500, loss = 1.6322180205583572, 23.71041774749756 s per 100 iters\n","time = 158.0, epoch 18, iter = 10600, loss = 1.6417542153596878, 23.520172119140625 s per 100 iters\n","time = 158.0, epoch 18, iter = 10700, loss = 1.649844526052475, 24.941978693008423 s per 100 iters\n","time = 158.0, epoch 18, iter = 10800, loss = 1.609866891503334, 23.553101778030396 s per 100 iters\n","time = 159.0, epoch 18, iter = 10900, loss = 1.6412254530191421, 23.570298194885254 s per 100 iters\n","time = 159.0, epoch 18, iter = 11000, loss = 1.6185000050067901, 23.533847332000732 s per 100 iters\n","time = 160.0, epoch 18, iter = 11100, loss = 1.6222347205877303, 23.788983821868896 s per 100 iters\n","time = 160.0, epoch 18, iter = 11200, loss = 1.637003231048584, 23.95999550819397 s per 100 iters\n","time = 160.0, epoch 18, iter = 11300, loss = 1.6184227520227432, 23.801470279693604 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 161.0, epoch 18, iter = 11400, loss = 1.6155756151676177, 23.289782524108887 s per 100 iters\n","time = 161.0, epoch 18, iter = 11500, loss = 1.6218741923570632, 23.4867684841156 s per 100 iters\n","time = 162.0, epoch 18, iter = 11600, loss = 1.6066129463911056, 23.868777990341187 s per 100 iters\n","time = 162.0, epoch 18, iter = 11700, loss = 1.6082252585887908, 23.363579511642456 s per 100 iters\n","time = 162.0, epoch 18, iter = 11800, loss = 1.6147828197479248, 23.205199241638184 s per 100 iters\n","time = 163.0, epoch 18, iter = 11900, loss = 1.6306445717811584, 23.474209308624268 s per 100 iters\n","time = 163.0, epoch 18, iter = 12000, loss = 1.6405195444822311, 23.738588094711304 s per 100 iters\n","time = 164.0, epoch 18, iter = 12100, loss = 1.6190081965923309, 23.995854139328003 s per 100 iters\n","time = 164.0, epoch 18, iter = 12200, loss = 1.6294001805782319, 23.096190929412842 s per 100 iters\n","time = 164.0, epoch 18, iter = 12300, loss = 1.6238363260030746, 23.923216342926025 s per 100 iters\n","time = 165.0, epoch 18, iter = 12400, loss = 1.6522586393356322, 23.70218586921692 s per 100 iters\n","time = 165.0, epoch 18, iter = 12500, loss = 1.6547254467010497, 23.73649787902832 s per 100 iters\n","time = 166.0, epoch 18, iter = 12600, loss = 1.6279734241962434, 23.850846529006958 s per 100 iters\n","time = 166.0, epoch 18, iter = 12700, loss = 1.6047677677869796, 23.189207077026367 s per 100 iters\n","time = 166.0, epoch 18, iter = 12800, loss = 1.6217681354284286, 23.251022577285767 s per 100 iters\n","time = 167.0, epoch 18, iter = 12900, loss = 1.6423896378278733, 23.480082988739014 s per 100 iters\n","time = 167.0, epoch 18, iter = 13000, loss = 1.642132549881935, 24.11682939529419 s per 100 iters\n","time = 167.0, epoch 18, iter = 13100, loss = 1.6443334853649139, 23.39030957221985 s per 100 iters\n","time = 168.0, epoch 18, iter = 13200, loss = 1.649400139451027, 23.67085337638855 s per 100 iters\n","time = 168.0, epoch 18, iter = 13300, loss = 1.6601896303892136, 24.74457883834839 s per 100 iters\n","time = 169.0, epoch 18, iter = 13400, loss = 1.644160920381546, 24.097453832626343 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 169.0, epoch 18, iter = 13500, loss = 1.631844716668129, 24.430068254470825 s per 100 iters\n","time = 169.0, epoch 18, iter = 13600, loss = 1.6295458495616912, 23.92438292503357 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 170.0, epoch 18, iter = 13700, loss = 1.6384142869710923, 24.211838722229004 s per 100 iters\n","time = 170.0, epoch 18, iter = 13800, loss = 1.626200938820839, 23.65825581550598 s per 100 iters\n","time = 171.0, epoch 18, iter = 13900, loss = 1.6450105500221253, 23.03554058074951 s per 100 iters\n","time = 171.0, epoch 18, iter = 14000, loss = 1.6600791609287262, 24.52401304244995 s per 100 iters\n","time = 171.0, epoch 18, iter = 14100, loss = 1.630515508055687, 23.289101123809814 s per 100 iters\n","time = 172.0, epoch 18, iter = 14200, loss = 1.6402410650253296, 23.744734287261963 s per 100 iters\n","time = 172.0, epoch 18, iter = 14300, loss = 1.637457447052002, 23.653759956359863 s per 100 iters\n","--- Balidazioa ---\n","26.94413185119629 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['impius haec tam culta novalia miles habebit ￭!', '-￭ ｟C zure adiskidea da ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodikoa eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afalorduan ￭, ｟C siziliako kostetan oin bat jarri eta ￭, nesken xarma ￭, ｟C aita ｟C pirroneren austeritatea ￭, eta ｟C don ｟C fabriziok konbentzitu zuenez ￭, ｟C donnafugatako jauregia ez zela ｟C capraroko angaria ￭, eta hantxe utziko zuela seguru aski bizia ￭.', '｟C denak ari ziren erosten ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi ditut ￭.', '｟C epaileak eta beste zenbait exekutibo ￭, ekimen artifizialak ￭, joyntasak ￭, sarien eta zigorraren artean ￭, subiranoaren jarlekura azkar mugatzen den bitartean ￭, subiranoaren esku dagoenaren sariaz eta kide bakoitza bere eginbeharrak betetzera mugatzen den nerbioak dira ￭, gorputz naturalean gauza bera egiten dutenak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori ￭, hain zuzen ere ￭, ideal hori ￭, orain eta agian beste inorengan ere ez dute errepresentatzen ￭, horiek dira ￭, beren eragile izpiritualik gorena ￭, bere inprobisatzaile eta esploratzaileen artean aurreratuena ￭, sedukzioaren forma delikatuena eta elikaezinena ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain pobreak direnik ￭.', '｟C duela gutxi behintzat ￭, ｟C derwatt-tarren gauzarekin ￭, eta orain ｟C mafia madarikatuarekin ￭?']\n","BLEU puntuazioa (1): 9.937544842054045\n","5.206187963485718 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C musika interesgarria zen oso ￭.', '｟C non uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '- ｟C ezagutzen dugu ｟C corvette istorio hori ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartu zuela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazkia daukat 1960ean eta bere semea 1940ko uniformean erakusten ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C lotara itzuli ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera doa ￭.', '｟C delphinek badaki ￭?']\n","BLEU puntuazioa (2): 21.986237264235264\n","BLEU puntuazioa (biak): 12.702081084634308\n","time = 173.0, epoch 19, iter = 100, loss = 1.5027891343832016, 24.72479510307312 s per 100 iters\n","time = 174.0, epoch 19, iter = 200, loss = 1.5027035009860992, 24.39596939086914 s per 100 iters\n","time = 174.0, epoch 19, iter = 300, loss = 1.4905637818574906, 23.145421743392944 s per 100 iters\n","time = 175.0, epoch 19, iter = 400, loss = 1.4984507024288178, 23.44202470779419 s per 100 iters\n","time = 175.0, epoch 19, iter = 500, loss = 1.5090111535787583, 23.919466257095337 s per 100 iters\n","time = 175.0, epoch 19, iter = 600, loss = 1.5106295573711395, 23.752111673355103 s per 100 iters\n","time = 176.0, epoch 19, iter = 700, loss = 1.5046478575468063, 23.7367160320282 s per 100 iters\n","time = 176.0, epoch 19, iter = 800, loss = 1.496606514453888, 23.652244091033936 s per 100 iters\n","time = 177.0, epoch 19, iter = 900, loss = 1.4989140295982362, 23.260419130325317 s per 100 iters\n","time = 177.0, epoch 19, iter = 1000, loss = 1.495980983376503, 22.95286273956299 s per 100 iters\n","time = 177.0, epoch 19, iter = 1100, loss = 1.5049940270185471, 23.657307624816895 s per 100 iters\n","time = 178.0, epoch 19, iter = 1200, loss = 1.5188757306337357, 24.38724398612976 s per 100 iters\n","time = 178.0, epoch 19, iter = 1300, loss = 1.5090466713905335, 23.285136222839355 s per 100 iters\n","time = 178.0, epoch 19, iter = 1400, loss = 1.5419463837146759, 23.75868535041809 s per 100 iters\n","time = 179.0, epoch 19, iter = 1500, loss = 1.5256176668405532, 23.95820689201355 s per 100 iters\n","time = 179.0, epoch 19, iter = 1600, loss = 1.5161378127336502, 24.32240080833435 s per 100 iters\n","time = 180.0, epoch 19, iter = 1700, loss = 1.5109698259830475, 23.995845794677734 s per 100 iters\n","time = 180.0, epoch 19, iter = 1800, loss = 1.5231705576181411, 24.082115650177002 s per 100 iters\n","time = 180.0, epoch 19, iter = 1900, loss = 1.516643316745758, 23.072377681732178 s per 100 iters\n","time = 181.0, epoch 19, iter = 2000, loss = 1.5447249239683152, 24.167025089263916 s per 100 iters\n","time = 181.0, epoch 19, iter = 2100, loss = 1.5497584468126298, 23.825806379318237 s per 100 iters\n","time = 182.0, epoch 19, iter = 2200, loss = 1.5087874400615693, 24.00253200531006 s per 100 iters\n","time = 182.0, epoch 19, iter = 2300, loss = 1.520393596291542, 23.386553287506104 s per 100 iters\n","time = 182.0, epoch 19, iter = 2400, loss = 1.540552304983139, 23.971383094787598 s per 100 iters\n","time = 183.0, epoch 19, iter = 2500, loss = 1.5312285071611405, 23.585090398788452 s per 100 iters\n","time = 183.0, epoch 19, iter = 2600, loss = 1.5346454656124116, 23.932392120361328 s per 100 iters\n","time = 184.0, epoch 19, iter = 2700, loss = 1.523396828174591, 23.278878211975098 s per 100 iters\n","time = 184.0, epoch 19, iter = 2800, loss = 1.5392680704593658, 23.623319387435913 s per 100 iters\n","time = 184.0, epoch 19, iter = 2900, loss = 1.5489669793844223, 24.65176558494568 s per 100 iters\n","time = 185.0, epoch 19, iter = 3000, loss = 1.5535871386528015, 23.568959951400757 s per 100 iters\n","time = 185.0, epoch 19, iter = 3100, loss = 1.561099797487259, 24.803895473480225 s per 100 iters\n","time = 186.0, epoch 19, iter = 3200, loss = 1.564058731198311, 24.0952467918396 s per 100 iters\n","time = 186.0, epoch 19, iter = 3300, loss = 1.5336896419525146, 22.592705249786377 s per 100 iters\n","time = 186.0, epoch 19, iter = 3400, loss = 1.5480610644817352, 23.608685731887817 s per 100 iters\n","time = 187.0, epoch 19, iter = 3500, loss = 1.566573594212532, 24.238246202468872 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 187.0, epoch 19, iter = 3600, loss = 1.536857493519783, 23.641807317733765 s per 100 iters\n","time = 188.0, epoch 19, iter = 3700, loss = 1.5359156340360642, 23.388915538787842 s per 100 iters\n","time = 188.0, epoch 19, iter = 3800, loss = 1.546883418560028, 23.187198638916016 s per 100 iters\n","time = 188.0, epoch 19, iter = 3900, loss = 1.539948508143425, 23.756946086883545 s per 100 iters\n","time = 189.0, epoch 19, iter = 4000, loss = 1.5356706607341766, 23.630362272262573 s per 100 iters\n","time = 189.0, epoch 19, iter = 4100, loss = 1.5539514982700349, 24.153140783309937 s per 100 iters\n","time = 190.0, epoch 19, iter = 4200, loss = 1.5418726623058319, 23.471593856811523 s per 100 iters\n","time = 190.0, epoch 19, iter = 4300, loss = 1.5446191054582596, 23.7322416305542 s per 100 iters\n","time = 190.0, epoch 19, iter = 4400, loss = 1.5477127492427827, 23.103936195373535 s per 100 iters\n","time = 191.0, epoch 19, iter = 4500, loss = 1.5537407726049424, 25.084243297576904 s per 100 iters\n","time = 191.0, epoch 19, iter = 4600, loss = 1.568831045627594, 23.759500741958618 s per 100 iters\n","time = 192.0, epoch 19, iter = 4700, loss = 1.5589749830961228, 23.848125219345093 s per 100 iters\n","time = 192.0, epoch 19, iter = 4800, loss = 1.5511455702781678, 23.32348322868347 s per 100 iters\n","time = 192.0, epoch 19, iter = 4900, loss = 1.5560742861032486, 23.51723051071167 s per 100 iters\n","time = 193.0, epoch 19, iter = 5000, loss = 1.5503787618875504, 23.476966619491577 s per 100 iters\n","time = 193.0, epoch 19, iter = 5100, loss = 1.5863686925172806, 24.494433641433716 s per 100 iters\n","time = 194.0, epoch 19, iter = 5200, loss = 1.5538854479789734, 23.179903030395508 s per 100 iters\n","time = 194.0, epoch 19, iter = 5300, loss = 1.555902950167656, 23.50598931312561 s per 100 iters\n","time = 194.0, epoch 19, iter = 5400, loss = 1.5768079268932342, 24.55223059654236 s per 100 iters\n","time = 195.0, epoch 19, iter = 5500, loss = 1.583462941646576, 24.088578462600708 s per 100 iters\n","time = 195.0, epoch 19, iter = 5600, loss = 1.5520953989028932, 23.309890508651733 s per 100 iters\n","time = 196.0, epoch 19, iter = 5700, loss = 1.5509022325277328, 23.156633853912354 s per 100 iters\n","time = 196.0, epoch 19, iter = 5800, loss = 1.569575862288475, 23.850085020065308 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 196.0, epoch 19, iter = 5900, loss = 1.5498240584135055, 22.797789335250854 s per 100 iters\n","time = 197.0, epoch 19, iter = 6000, loss = 1.5486091899871826, 24.241127967834473 s per 100 iters\n","time = 197.0, epoch 19, iter = 6100, loss = 1.5671363031864167, 23.49897813796997 s per 100 iters\n","time = 197.0, epoch 19, iter = 6200, loss = 1.561669288277626, 23.593984842300415 s per 100 iters\n","time = 198.0, epoch 19, iter = 6300, loss = 1.576074439883232, 23.279080867767334 s per 100 iters\n","time = 198.0, epoch 19, iter = 6400, loss = 1.5738251197338105, 23.448243856430054 s per 100 iters\n","time = 199.0, epoch 19, iter = 6500, loss = 1.5727519053220749, 23.344340562820435 s per 100 iters\n","time = 199.0, epoch 19, iter = 6600, loss = 1.573937293291092, 23.562138319015503 s per 100 iters\n","time = 199.0, epoch 19, iter = 6700, loss = 1.5641570967435836, 24.137088537216187 s per 100 iters\n","time = 200.0, epoch 19, iter = 6800, loss = 1.5804045897722245, 24.257696866989136 s per 100 iters\n","time = 200.0, epoch 19, iter = 6900, loss = 1.5839579766988754, 23.732863187789917 s per 100 iters\n","time = 201.0, epoch 19, iter = 7000, loss = 1.5867448395490646, 23.555270433425903 s per 100 iters\n","time = 201.0, epoch 19, iter = 7100, loss = 1.5777235907316207, 23.47106146812439 s per 100 iters\n","time = 201.0, epoch 19, iter = 7200, loss = 1.583964850306511, 24.22601342201233 s per 100 iters\n","time = 202.0, epoch 19, iter = 7300, loss = 1.6036487263441086, 23.971092700958252 s per 100 iters\n","time = 202.0, epoch 19, iter = 7400, loss = 1.573992949128151, 23.848763704299927 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 203.0, epoch 19, iter = 7500, loss = 1.5728661221265794, 24.09494113922119 s per 100 iters\n","time = 203.0, epoch 19, iter = 7600, loss = 1.580244550704956, 22.783289670944214 s per 100 iters\n","time = 203.0, epoch 19, iter = 7700, loss = 1.5728689861297607, 24.23257327079773 s per 100 iters\n","time = 204.0, epoch 19, iter = 7800, loss = 1.5721420615911483, 23.733142852783203 s per 100 iters\n","time = 204.0, epoch 19, iter = 7900, loss = 1.5916289967298507, 23.350467920303345 s per 100 iters\n","time = 205.0, epoch 19, iter = 8000, loss = 1.5879503512382507, 24.033570766448975 s per 100 iters\n","time = 205.0, epoch 19, iter = 8100, loss = 1.597914446592331, 24.310433387756348 s per 100 iters\n","time = 205.0, epoch 19, iter = 8200, loss = 1.5916698414087296, 23.28579020500183 s per 100 iters\n","time = 206.0, epoch 19, iter = 8300, loss = 1.5960525697469712, 24.11886763572693 s per 100 iters\n","time = 206.0, epoch 19, iter = 8400, loss = 1.5933592772483827, 23.75553011894226 s per 100 iters\n","time = 207.0, epoch 19, iter = 8500, loss = 1.6068070924282074, 23.383495807647705 s per 100 iters\n","time = 207.0, epoch 19, iter = 8600, loss = 1.5910774546861648, 23.223564386367798 s per 100 iters\n","time = 207.0, epoch 19, iter = 8700, loss = 1.6000419080257415, 23.345417737960815 s per 100 iters\n","time = 208.0, epoch 19, iter = 8800, loss = 1.6041404706239701, 24.17719292640686 s per 100 iters\n","time = 208.0, epoch 19, iter = 8900, loss = 1.5946181643009185, 23.63531994819641 s per 100 iters\n","time = 209.0, epoch 19, iter = 9000, loss = 1.5924812811613083, 23.917688608169556 s per 100 iters\n","time = 209.0, epoch 19, iter = 9100, loss = 1.5896559822559357, 24.6371488571167 s per 100 iters\n","time = 209.0, epoch 19, iter = 9200, loss = 1.5973790436983109, 23.926499605178833 s per 100 iters\n","time = 210.0, epoch 19, iter = 9300, loss = 1.6025504595041276, 23.90040397644043 s per 100 iters\n","time = 210.0, epoch 19, iter = 9400, loss = 1.5762483763694763, 23.540395736694336 s per 100 iters\n","time = 211.0, epoch 19, iter = 9500, loss = 1.6016968864202499, 23.949201107025146 s per 100 iters\n","time = 211.0, epoch 19, iter = 9600, loss = 1.590726730823517, 23.586829662322998 s per 100 iters\n","time = 211.0, epoch 19, iter = 9700, loss = 1.5940538245439528, 23.763973474502563 s per 100 iters\n","time = 212.0, epoch 19, iter = 9800, loss = 1.5974893260002136, 23.883238792419434 s per 100 iters\n","time = 212.0, epoch 19, iter = 9900, loss = 1.5912302839756012, 23.58381152153015 s per 100 iters\n","time = 213.0, epoch 19, iter = 10000, loss = 1.5994973069429397, 23.067359447479248 s per 100 iters\n","time = 213.0, epoch 19, iter = 10100, loss = 1.6311228102445603, 24.384056329727173 s per 100 iters\n","time = 213.0, epoch 19, iter = 10200, loss = 1.5860915046930313, 23.450723886489868 s per 100 iters\n","time = 214.0, epoch 19, iter = 10300, loss = 1.5950238186120986, 23.85638976097107 s per 100 iters\n","time = 214.0, epoch 19, iter = 10400, loss = 1.6050974380970002, 23.416018962860107 s per 100 iters\n","time = 215.0, epoch 19, iter = 10500, loss = 1.6034175854921342, 23.795340299606323 s per 100 iters\n","time = 215.0, epoch 19, iter = 10600, loss = 1.6059682542085647, 23.765364408493042 s per 100 iters\n","time = 215.0, epoch 19, iter = 10700, loss = 1.6000395709276198, 24.133395433425903 s per 100 iters\n","time = 216.0, epoch 19, iter = 10800, loss = 1.60877927839756, 23.595385789871216 s per 100 iters\n","time = 216.0, epoch 19, iter = 10900, loss = 1.5912703078985215, 23.173365592956543 s per 100 iters\n","time = 216.0, epoch 19, iter = 11000, loss = 1.6282372426986695, 24.275628805160522 s per 100 iters\n","time = 217.0, epoch 19, iter = 11100, loss = 1.5944670563936234, 23.508498907089233 s per 100 iters\n","time = 217.0, epoch 19, iter = 11200, loss = 1.6057479923963547, 23.74910259246826 s per 100 iters\n","time = 218.0, epoch 19, iter = 11300, loss = 1.6041976636648179, 22.68047070503235 s per 100 iters\n","time = 218.0, epoch 19, iter = 11400, loss = 1.601688376069069, 22.858409881591797 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 218.0, epoch 19, iter = 11500, loss = 1.608500651717186, 23.91745138168335 s per 100 iters\n","time = 219.0, epoch 19, iter = 11600, loss = 1.6148540043830872, 24.14339566230774 s per 100 iters\n","time = 219.0, epoch 19, iter = 11700, loss = 1.6001893013715744, 24.30450987815857 s per 100 iters\n","time = 220.0, epoch 19, iter = 11800, loss = 1.6269096040725708, 24.408891677856445 s per 100 iters\n","time = 220.0, epoch 19, iter = 11900, loss = 1.6025444638729096, 23.547744035720825 s per 100 iters\n","time = 220.0, epoch 19, iter = 12000, loss = 1.610817604660988, 24.198885440826416 s per 100 iters\n","time = 221.0, epoch 19, iter = 12100, loss = 1.6043640661239624, 22.525391817092896 s per 100 iters\n","time = 221.0, epoch 19, iter = 12200, loss = 1.6080465549230576, 23.270318031311035 s per 100 iters\n","time = 222.0, epoch 19, iter = 12300, loss = 1.6109585350751876, 23.035787105560303 s per 100 iters\n","time = 222.0, epoch 19, iter = 12400, loss = 1.6075216364860534, 23.70691990852356 s per 100 iters\n","time = 222.0, epoch 19, iter = 12500, loss = 1.6118518793582917, 24.988672256469727 s per 100 iters\n","time = 223.0, epoch 19, iter = 12600, loss = 1.6113170993328094, 23.857730865478516 s per 100 iters\n","time = 223.0, epoch 19, iter = 12700, loss = 1.610206245779991, 23.748904705047607 s per 100 iters\n","time = 224.0, epoch 19, iter = 12800, loss = 1.6088724333047866, 24.28365182876587 s per 100 iters\n","time = 224.0, epoch 19, iter = 12900, loss = 1.5990058928728104, 22.801518440246582 s per 100 iters\n","time = 224.0, epoch 19, iter = 13000, loss = 1.611103982925415, 24.01945424079895 s per 100 iters\n","time = 225.0, epoch 19, iter = 13100, loss = 1.6076930129528046, 24.581725597381592 s per 100 iters\n","time = 225.0, epoch 19, iter = 13200, loss = 1.6278048783540726, 24.01530933380127 s per 100 iters\n","time = 226.0, epoch 19, iter = 13300, loss = 1.6170895832777024, 23.198399305343628 s per 100 iters\n","time = 226.0, epoch 19, iter = 13400, loss = 1.6292478728294373, 24.56126117706299 s per 100 iters\n","time = 226.0, epoch 19, iter = 13500, loss = 1.609295231103897, 23.420588493347168 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 227.0, epoch 19, iter = 13600, loss = 1.6248246234655381, 22.45981764793396 s per 100 iters\n","time = 227.0, epoch 19, iter = 13700, loss = 1.628849658370018, 23.94989562034607 s per 100 iters\n","time = 228.0, epoch 19, iter = 13800, loss = 1.6083936268091201, 24.2177095413208 s per 100 iters\n","time = 228.0, epoch 19, iter = 13900, loss = 1.6376581370830536, 24.20554542541504 s per 100 iters\n","time = 228.0, epoch 19, iter = 14000, loss = 1.6307700383663177, 23.85962724685669 s per 100 iters\n","time = 229.0, epoch 19, iter = 14100, loss = 1.6232462507486343, 23.733330249786377 s per 100 iters\n","time = 229.0, epoch 19, iter = 14200, loss = 1.6092599445581437, 24.456645965576172 s per 100 iters\n","time = 230.0, epoch 19, iter = 14300, loss = 1.6205063253641128, 23.556519031524658 s per 100 iters\n","--- Balidazioa ---\n","21.65744185447693 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia miliat habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '-￭ ｟C rosanna ｟C spearman ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodikoa eta betea ￭.', '｟C eta ｟C dulcinea ￭?', '｟C afalorduan ￭, ｟C siziliako itsasertzean oinak jarri zituen lehen aldiz ￭, eta nesken xarma ￭, aita ｟C pirroneen austeritatea ￭, eta ｟C don ｟C fabriziok sinestarazi zion ｟C donnafugatako jauregia ez zela ｟C capraroko antxea ￭, eta han bizirik irtengo zela seguru aski ￭.', '｟C denek erosten zuten ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', '｟C epaileak eta beste batzuk exekuzio eta ekimen artifizialak ￭, joyntasak ￭, sariz eta zigorrik ￭, subiranotasunaren jarlekura azkar heltzen den sari eta zigorrak ￭, bakoitza bere betebeharrak betetzea galarazten duelarik ￭) nerbioak dira ￭, gorputz naturalean ere gauza bera egiten dutenak ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hau ￭, beren ideal hutsa besterik ez da ￭, gaur egun irudikatzen dute ￭, eta agian beste inor ez ￭, horiek dira ￭, beren produkturik izpiritualenak ￭, bere aurkitzaile eta esploratzaileen aitzindaririk aitzinatuena ￭, sedukzioaren forma delikatuena eta malgua ￭.', '｟C hegoaldean ez dago familiarik esklaburik ez izateko bezain pobrea denik ￭.', '｟C orain dela gutxi ￭, derwatt-tarren kontuarekin ￭, eta orain ｟C mafi leporatzen ziotenarekin ￭?']\n","BLEU puntuazioa (1): 10.011336192645903\n","5.380652904510498 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C marty ￭, musika interesgarria zen oso ￭.', '｟C nondik uste duzu ateratzen duela gure janaria ｟C nick zahar horrek ￭?', '- ｟C corvetteko istorioaz ari gara ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendeku bila etorri zela pentsatu nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hor dago koxka ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. ez zaizu axola ￭?', '｟C eta argazki bat daukat 1960ean eta bere semea 1940ko uniformea jantzita ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C lo egizu berriro ￭, laztana ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C ziur zaude ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 22.70125219775395\n","BLEU puntuazioa (biak): 12.95351706800183\n","time = 231.0, epoch 20, iter = 100, loss = 1.4808822965621948, 24.82684588432312 s per 100 iters\n","time = 231.0, epoch 20, iter = 200, loss = 1.4830650246143342, 24.553219318389893 s per 100 iters\n","time = 231.0, epoch 20, iter = 300, loss = 1.4822318542003632, 23.953879594802856 s per 100 iters\n","time = 232.0, epoch 20, iter = 400, loss = 1.477167903780937, 25.36091709136963 s per 100 iters\n","time = 232.0, epoch 20, iter = 500, loss = 1.4905171293020247, 24.400758266448975 s per 100 iters\n","time = 233.0, epoch 20, iter = 600, loss = 1.4931871634721756, 24.22901749610901 s per 100 iters\n","time = 233.0, epoch 20, iter = 700, loss = 1.4655708092451096, 24.21672224998474 s per 100 iters\n","time = 233.0, epoch 20, iter = 800, loss = 1.486066187620163, 24.32454538345337 s per 100 iters\n","time = 234.0, epoch 20, iter = 900, loss = 1.459126632809639, 23.278578758239746 s per 100 iters\n","time = 234.0, epoch 20, iter = 1000, loss = 1.497772472500801, 24.1732017993927 s per 100 iters\n","time = 235.0, epoch 20, iter = 1100, loss = 1.5042726403474809, 24.769400119781494 s per 100 iters\n","time = 235.0, epoch 20, iter = 1200, loss = 1.5053508740663528, 25.34595561027527 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 235.0, epoch 20, iter = 1300, loss = 1.4985281127691268, 24.316993236541748 s per 100 iters\n","time = 236.0, epoch 20, iter = 1400, loss = 1.5229791277647018, 24.266525745391846 s per 100 iters\n","time = 236.0, epoch 20, iter = 1500, loss = 1.4941039806604386, 23.661009550094604 s per 100 iters\n","time = 237.0, epoch 20, iter = 1600, loss = 1.507228320837021, 24.221205711364746 s per 100 iters\n","time = 237.0, epoch 20, iter = 1700, loss = 1.4936779814958572, 23.794488430023193 s per 100 iters\n","time = 237.0, epoch 20, iter = 1800, loss = 1.5291923320293426, 23.89367175102234 s per 100 iters\n","time = 238.0, epoch 20, iter = 1900, loss = 1.5109825402498245, 24.384461402893066 s per 100 iters\n","time = 238.0, epoch 20, iter = 2000, loss = 1.513349882364273, 25.01498055458069 s per 100 iters\n","time = 239.0, epoch 20, iter = 2100, loss = 1.5127072554826737, 23.765933513641357 s per 100 iters\n","time = 239.0, epoch 20, iter = 2200, loss = 1.5036017566919326, 24.748435497283936 s per 100 iters\n","time = 240.0, epoch 20, iter = 2300, loss = 1.5125889974832534, 23.872934818267822 s per 100 iters\n","time = 240.0, epoch 20, iter = 2400, loss = 1.5098055762052536, 23.6747567653656 s per 100 iters\n","time = 240.0, epoch 20, iter = 2500, loss = 1.5181897008419036, 24.453361988067627 s per 100 iters\n","time = 241.0, epoch 20, iter = 2600, loss = 1.489499005675316, 23.665826559066772 s per 100 iters\n","time = 241.0, epoch 20, iter = 2700, loss = 1.5285773783922196, 24.888471364974976 s per 100 iters\n","time = 242.0, epoch 20, iter = 2800, loss = 1.5182072693109512, 23.59231424331665 s per 100 iters\n","time = 242.0, epoch 20, iter = 2900, loss = 1.5308589428663253, 23.892313957214355 s per 100 iters\n","time = 242.0, epoch 20, iter = 3000, loss = 1.5172397935390471, 24.313568830490112 s per 100 iters\n","time = 243.0, epoch 20, iter = 3100, loss = 1.527636052966118, 24.129687547683716 s per 100 iters\n","time = 243.0, epoch 20, iter = 3200, loss = 1.5141564923524857, 24.0267117023468 s per 100 iters\n","time = 244.0, epoch 20, iter = 3300, loss = 1.5183470702171327, 23.66648840904236 s per 100 iters\n","time = 244.0, epoch 20, iter = 3400, loss = 1.5363395500183106, 23.505736112594604 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 244.0, epoch 20, iter = 3500, loss = 1.5389752012491227, 23.496337175369263 s per 100 iters\n","time = 245.0, epoch 20, iter = 3600, loss = 1.5041848367452622, 23.722388982772827 s per 100 iters\n","time = 245.0, epoch 20, iter = 3700, loss = 1.5308758413791657, 23.616583585739136 s per 100 iters\n","time = 245.0, epoch 20, iter = 3800, loss = 1.520486204624176, 23.449161529541016 s per 100 iters\n","time = 246.0, epoch 20, iter = 3900, loss = 1.5292729860544205, 24.35401678085327 s per 100 iters\n","time = 246.0, epoch 20, iter = 4000, loss = 1.5205940794944763, 23.362711668014526 s per 100 iters\n","time = 247.0, epoch 20, iter = 4100, loss = 1.5278162610530854, 24.118796348571777 s per 100 iters\n","time = 247.0, epoch 20, iter = 4200, loss = 1.531921163201332, 23.836626768112183 s per 100 iters\n","time = 247.0, epoch 20, iter = 4300, loss = 1.5294407337903977, 22.941713571548462 s per 100 iters\n","time = 248.0, epoch 20, iter = 4400, loss = 1.5270786601305009, 23.352290153503418 s per 100 iters\n","time = 248.0, epoch 20, iter = 4500, loss = 1.5296392357349395, 23.537333011627197 s per 100 iters\n","time = 249.0, epoch 20, iter = 4600, loss = 1.544268793463707, 24.26171565055847 s per 100 iters\n","time = 249.0, epoch 20, iter = 4700, loss = 1.5335894495248794, 23.161447048187256 s per 100 iters\n","time = 249.0, epoch 20, iter = 4800, loss = 1.520430178642273, 24.118520736694336 s per 100 iters\n","time = 250.0, epoch 20, iter = 4900, loss = 1.527809271812439, 23.793196201324463 s per 100 iters\n","time = 250.0, epoch 20, iter = 5000, loss = 1.5314633816480636, 23.958064556121826 s per 100 iters\n","time = 251.0, epoch 20, iter = 5100, loss = 1.5493782937526703, 24.511494636535645 s per 100 iters\n","time = 251.0, epoch 20, iter = 5200, loss = 1.5288093501329423, 24.241581201553345 s per 100 iters\n","time = 251.0, epoch 20, iter = 5300, loss = 1.5298253273963929, 24.0961811542511 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","time = 252.0, epoch 20, iter = 5400, loss = 1.5323689699172973, 24.02410888671875 s per 100 iters\n","time = 252.0, epoch 20, iter = 5500, loss = 1.5190955901145935, 24.08440899848938 s per 100 iters\n","time = 253.0, epoch 20, iter = 5600, loss = 1.5338327872753144, 23.80362296104431 s per 100 iters\n","time = 253.0, epoch 20, iter = 5700, loss = 1.5675319081544876, 24.66819143295288 s per 100 iters\n","time = 253.0, epoch 20, iter = 5800, loss = 1.537842841744423, 23.85431933403015 s per 100 iters\n","time = 254.0, epoch 20, iter = 5900, loss = 1.552060222029686, 23.772928476333618 s per 100 iters\n","time = 254.0, epoch 20, iter = 6000, loss = 1.5470740121603013, 23.49697709083557 s per 100 iters\n","time = 255.0, epoch 20, iter = 6100, loss = 1.5634764617681502, 24.852591514587402 s per 100 iters\n","time = 255.0, epoch 20, iter = 6200, loss = 1.5623539638519288, 24.590886116027832 s per 100 iters\n","time = 255.0, epoch 20, iter = 6300, loss = 1.5561547297239304, 23.670079231262207 s per 100 iters\n","time = 256.0, epoch 20, iter = 6400, loss = 1.5608126801252364, 23.876487255096436 s per 100 iters\n","time = 256.0, epoch 20, iter = 6500, loss = 1.543617144227028, 23.548189640045166 s per 100 iters\n","time = 257.0, epoch 20, iter = 6600, loss = 1.5579427325725554, 24.276484489440918 s per 100 iters\n","time = 257.0, epoch 20, iter = 6700, loss = 1.557358848452568, 23.357373237609863 s per 100 iters\n","time = 257.0, epoch 20, iter = 6800, loss = 1.5647808933258056, 24.438051223754883 s per 100 iters\n","time = 258.0, epoch 20, iter = 6900, loss = 1.5593751096725463, 24.5660183429718 s per 100 iters\n","time = 258.0, epoch 20, iter = 7000, loss = 1.5735408955812453, 24.430956602096558 s per 100 iters\n","time = 259.0, epoch 20, iter = 7100, loss = 1.5537772130966188, 23.837329387664795 s per 100 iters\n","time = 259.0, epoch 20, iter = 7200, loss = 1.5793013238906861, 24.131462812423706 s per 100 iters\n","time = 259.0, epoch 20, iter = 7300, loss = 1.576067122220993, 24.418962478637695 s per 100 iters\n","time = 260.0, epoch 20, iter = 7400, loss = 1.5701170843839645, 23.90248680114746 s per 100 iters\n","time = 260.0, epoch 20, iter = 7500, loss = 1.566070464849472, 23.87748670578003 s per 100 iters\n","time = 261.0, epoch 20, iter = 7600, loss = 1.5547395074367523, 23.75555157661438 s per 100 iters\n","time = 261.0, epoch 20, iter = 7700, loss = 1.5652129942178725, 23.72120952606201 s per 100 iters\n","time = 261.0, epoch 20, iter = 7800, loss = 1.5456227600574493, 23.42638635635376 s per 100 iters\n","time = 262.0, epoch 20, iter = 7900, loss = 1.5412696319818497, 23.67361354827881 s per 100 iters\n","time = 262.0, epoch 20, iter = 8000, loss = 1.5844491350650787, 24.842299222946167 s per 100 iters\n","time = 263.0, epoch 20, iter = 8100, loss = 1.575700078010559, 24.334502935409546 s per 100 iters\n","time = 263.0, epoch 20, iter = 8200, loss = 1.5681870859861373, 24.36017870903015 s per 100 iters\n","time = 263.0, epoch 20, iter = 8300, loss = 1.5595865607261659, 23.757798671722412 s per 100 iters\n","time = 264.0, epoch 20, iter = 8400, loss = 1.5597967022657395, 23.58376979827881 s per 100 iters\n","time = 264.0, epoch 20, iter = 8500, loss = 1.5775496226549148, 25.032707691192627 s per 100 iters\n","time = 265.0, epoch 20, iter = 8600, loss = 1.5458620995283128, 23.639965772628784 s per 100 iters\n","time = 265.0, epoch 20, iter = 8700, loss = 1.5595922517776488, 23.331580638885498 s per 100 iters\n","time = 265.0, epoch 20, iter = 8800, loss = 1.5743889093399048, 24.66846227645874 s per 100 iters\n","time = 266.0, epoch 20, iter = 8900, loss = 1.585865923166275, 25.023808479309082 s per 100 iters\n","time = 266.0, epoch 20, iter = 9000, loss = 1.5761980336904526, 24.143627405166626 s per 100 iters\n","time = 267.0, epoch 20, iter = 9100, loss = 1.5635843515396117, 24.184176921844482 s per 100 iters\n","time = 267.0, epoch 20, iter = 9200, loss = 1.5759035646915436, 23.437052726745605 s per 100 iters\n","time = 267.0, epoch 20, iter = 9300, loss = 1.5682292312383652, 23.786700963974 s per 100 iters\n","time = 268.0, epoch 20, iter = 9400, loss = 1.5802327501773834, 25.146000146865845 s per 100 iters\n","time = 268.0, epoch 20, iter = 9500, loss = 1.5810669493675231, 23.959253549575806 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 269.0, epoch 20, iter = 9600, loss = 1.5558008456230163, 24.091824769973755 s per 100 iters\n","time = 269.0, epoch 20, iter = 9700, loss = 1.5974069732427596, 24.0993435382843 s per 100 iters\n","time = 269.0, epoch 20, iter = 9800, loss = 1.5626083248853684, 23.78538227081299 s per 100 iters\n","time = 270.0, epoch 20, iter = 9900, loss = 1.5681477165222169, 23.581238269805908 s per 100 iters\n","time = 270.0, epoch 20, iter = 10000, loss = 1.5946498143672942, 24.285454750061035 s per 100 iters\n","time = 271.0, epoch 20, iter = 10100, loss = 1.5765099567174912, 24.473029375076294 s per 100 iters\n","time = 271.0, epoch 20, iter = 10200, loss = 1.5765266358852386, 24.272154808044434 s per 100 iters\n","time = 272.0, epoch 20, iter = 10300, loss = 1.5819467812776566, 24.33102321624756 s per 100 iters\n","time = 272.0, epoch 20, iter = 10400, loss = 1.591187589764595, 23.8680522441864 s per 100 iters\n","time = 272.0, epoch 20, iter = 10500, loss = 1.5733023363351821, 24.487879753112793 s per 100 iters\n","time = 273.0, epoch 20, iter = 10600, loss = 1.5806387370824815, 24.343726873397827 s per 100 iters\n","time = 273.0, epoch 20, iter = 10700, loss = 1.5983328032493591, 24.00383472442627 s per 100 iters\n","time = 274.0, epoch 20, iter = 10800, loss = 1.5925700551271438, 24.91444754600525 s per 100 iters\n","time = 274.0, epoch 20, iter = 10900, loss = 1.6073792797327042, 23.716801643371582 s per 100 iters\n","time = 274.0, epoch 20, iter = 11000, loss = 1.5818040513992309, 24.320131063461304 s per 100 iters\n","time = 275.0, epoch 20, iter = 11100, loss = 1.5476114815473556, 24.75498366355896 s per 100 iters\n","time = 275.0, epoch 20, iter = 11200, loss = 1.5791007804870605, 23.53800058364868 s per 100 iters\n","time = 276.0, epoch 20, iter = 11300, loss = 1.5855221790075302, 24.720840215682983 s per 100 iters\n","time = 276.0, epoch 20, iter = 11400, loss = 1.5871663683652877, 24.808958292007446 s per 100 iters\n","time = 276.0, epoch 20, iter = 11500, loss = 1.5644495034217833, 23.399179697036743 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 277.0, epoch 20, iter = 11600, loss = 1.5796759259700774, 24.11446785926819 s per 100 iters\n","time = 277.0, epoch 20, iter = 11700, loss = 1.5938220876455307, 24.25285315513611 s per 100 iters\n","time = 278.0, epoch 20, iter = 11800, loss = 1.5891338473558425, 24.288334608078003 s per 100 iters\n","time = 278.0, epoch 20, iter = 11900, loss = 1.6122712790966034, 24.59829831123352 s per 100 iters\n","time = 278.0, epoch 20, iter = 12000, loss = 1.5896822434663773, 24.58700156211853 s per 100 iters\n","time = 279.0, epoch 20, iter = 12100, loss = 1.588248269557953, 23.383745908737183 s per 100 iters\n","time = 279.0, epoch 20, iter = 12200, loss = 1.5963470554351806, 24.318259477615356 s per 100 iters\n","time = 280.0, epoch 20, iter = 12300, loss = 1.5744594663381577, 23.414421558380127 s per 100 iters\n","time = 280.0, epoch 20, iter = 12400, loss = 1.601194217801094, 23.86003017425537 s per 100 iters\n","time = 280.0, epoch 20, iter = 12500, loss = 1.598004651069641, 24.050527811050415 s per 100 iters\n","time = 281.0, epoch 20, iter = 12600, loss = 1.576040945649147, 24.10468888282776 s per 100 iters\n","time = 281.0, epoch 20, iter = 12700, loss = 1.599391285777092, 23.779328107833862 s per 100 iters\n","time = 282.0, epoch 20, iter = 12800, loss = 1.606654515862465, 24.719271659851074 s per 100 iters\n","time = 282.0, epoch 20, iter = 12900, loss = 1.5951331424713135, 23.267269134521484 s per 100 iters\n","time = 282.0, epoch 20, iter = 13000, loss = 1.5764190739393233, 23.8483784198761 s per 100 iters\n","time = 283.0, epoch 20, iter = 13100, loss = 1.599693523645401, 24.12950587272644 s per 100 iters\n","time = 283.0, epoch 20, iter = 13200, loss = 1.6138299262523652, 24.110068798065186 s per 100 iters\n","time = 284.0, epoch 20, iter = 13300, loss = 1.6011359077692031, 24.478649616241455 s per 100 iters\n","time = 284.0, epoch 20, iter = 13400, loss = 1.5783549857139587, 23.72705340385437 s per 100 iters\n","time = 284.0, epoch 20, iter = 13500, loss = 1.5863463437557221, 24.32394504547119 s per 100 iters\n","time = 285.0, epoch 20, iter = 13600, loss = 1.6017837154865264, 24.40772843360901 s per 100 iters\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","time = 285.0, epoch 20, iter = 13700, loss = 1.6074369108676911, 24.45305037498474 s per 100 iters\n","time = 286.0, epoch 20, iter = 13800, loss = 1.6018635618686676, 24.548258066177368 s per 100 iters\n","time = 286.0, epoch 20, iter = 13900, loss = 1.5885202533006668, 24.555668115615845 s per 100 iters\n","time = 286.0, epoch 20, iter = 14000, loss = 1.600890752673149, 24.52951431274414 s per 100 iters\n","time = 287.0, epoch 20, iter = 14100, loss = 1.6002765083312989, 23.736669778823853 s per 100 iters\n","time = 287.0, epoch 20, iter = 14200, loss = 1.6176640570163727, 24.844271659851074 s per 100 iters\n","time = 288.0, epoch 20, iter = 14300, loss = 1.601174739599228, 24.2786922454834 s per 100 iters\n","--- Balidazioa ---\n","26.016589164733887 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius haec tam culta novalia milia habebit ￭!', '-￭ ｟C zure laguna ￭.', '｟C baina beranduegi da ￭:', '｟C baina zer izan da hori ￭?', '｟B rosanna spearman ｟E', '｟C ez al da arraroa ￭?', '｟C colinek berriro ere gelditu egin zen ￭.', '-￭ ｟C ralph ￭!', '｟C hain da melodikoa eta betea ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afaltzen ari zela ￭, ｟C siziliako itsasertzetan oinatzez eta nesken xarmaz ￭, aita ｟C pirroneren austeritateaz ￭, eta ｟C don ｟C fabriziok aditzera eman zion ｟C donnafugatako jauregia ez zela ｟C capraroko antxina ￭, eta hantxe utziko zuela seguru asko bizirik ￭.', '｟C erosketak egiten ari ziren ￭.', '｟C ederra zen ￭.', '｟C a ￭!', '｟C orain bi ditut ￭.', '｟C epaile eta exekutiboen beste ofizialak ￭, egintza artifizialak ￭, sarien eta zigorraren (￭ subiranotasunaren jarlekurako azkarki eta kideak subiranotasunaren jarlekura mugatzen direlarik ￭) nerbio eta kide guztiak nerbio dira ￭, gorputz naturalean bezalaxe ￭, gizakume guztien aberastasuna eta aberastasuna ￭, boterea direlako ￭, herri-jainkoen babesa (￭ salia ￭) ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zuen deitu ￭.', 'ideal hau haien ideala besterik ez da ￭, orain eta agian beste inor ez ￭, horiek berak dira ￭, bere produkturik izpiritualenaz ￭, bere aurkari eta esploratzaileen bilerarik aurreratuenak ￭, sedukzioaren forma delikatuena eta errazena ￭.', '｟C hegoaldean ez dago familia urrikalgarririk esklaborik ez izateko bezain behartsurik ￭.', '｟C duela gutxi behintzat ￭, ｟C derwatt-en gauzarekin ￭, eta orain ｟C mafi leporatzen zaionarekin ￭?']\n","BLEU puntuazioa (1): 9.70693362973307\n","5.79890251159668 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C tori ￭.', '｟C musika interesgarria zen ｟C marty ￭, oso interesgarria ￭.', '｟C nondik uste duzu ateratzen duela ｟C nick zaharrak gure janaria ￭?', '- ｟C corvetteko istorioa ezagutzen dugu ￭, ｟C matt ￭.', '｟C ikus ditzakegu ￭.', '｟C jaunok ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean ￭, mendekua hartu zuela uste izan nuen ￭.', '｟C du ｟C ponten ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoak egongo dira basoan ￭?', '｟C marchal jaunak ikusi nahi zaitu ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago ￭, eta ￭. ￭. ￭. berdin zaizu ￭?', '｟C eta argazkia erakutsi diot 1960an eta bere semea 1940ko uniformean ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zein txartel ￭?', '｟C egizu lo ￭, laztana ￭.', '｟C ez dakit zer gertatzen den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera etorriko da ￭.', '｟C delphinek badaki ￭?']\n","BLEU puntuazioa (2): 22.384688470731565\n","BLEU puntuazioa (biak): 12.636454571898629\n","time = 289.0, epoch 21, iter = 100, loss = 1.4539211744070053, 25.090035438537598 s per 100 iters\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-44d28e1a43ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mentrenatu_bakarra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasi_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-46-21cc8959f132>\u001b[0m in \u001b[0;36mentrenatu_bakarra\u001b[0;34m(lang, hasi_epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"RmbW12K0XzSN","colab_type":"text"},"source":["# Probatu"]},{"cell_type":"code","metadata":{"id":"ATaAKfCpVcL5","colab_type":"code","colab":{}},"source":["# Errorea ematen badu (tentsore bat gailu batean eta bestea bestean), begiratu\n","# \"Itzultzailea_probatzeko\" notebookeko aldaketa \n","\n","def zuzendu_beam(model, src, k, b_s):\n","    \n","    hasi = time.time()\n","    \n","    model.eval()\n","\n","    with torch.no_grad():\n","   \n","        src = [(esaldia[0], esaldia[1], i) for i, esaldia in enumerate(src)]\n","        src.sort(key=ordenatzeko)\n","        idazteko = len(src) * [\"\\n\"]\n","        \n","        # encoder-erako eta decoder-eko 1. posiziorako tamaina:\n","        batch_size_enc = b_s // k\n","        \n","        #for j in range(0, len(src), batch_size_enc):\n","        berriro_saiatu = False\n","        j = 0\n","        while j < len(src):\n","            \n","            print(torch.cuda.memory_allocated(0))\n","\n","            if berriro_saiatu and batch_size_enc > 1:\n","                batch_size_enc //= 2\n","                #if batch_size_enc == 0:\n","                #    print(\"Ezin da jarraitu.\")\n","                #    idatzi(idazteko, pe_fitx)\n","                #    return\n","            \n","            print(\"{}. esalditik aurrera zuzentzen...\".format(j+1))\n","\n","            batch = src[j : j+batch_size_enc]\n","            luzeena = len(batch[-1][0])\n","            src1 = [sartu_padding(esaldia[0], luzeena) for esaldia in batch]\n","            luzeena = max([len(esaldia[1]) for esaldia in batch])\n","            src2 = [sartu_padding(esaldia[1], luzeena) for esaldia in batch]\n","            src1 = torch.LongTensor(src1)\n","            src2 = torch.LongTensor(src2)\n","\n","            src1_mask = (src1 != pad).unsqueeze(-2).cuda()\n","            src2_mask = (src2 != pad).unsqueeze(-2).cuda()\n","            emb1 = model.embed(src1.cuda())\n","            e1_outputs = model.encoder(emb1, src1_mask)\n","            emb2 = model.embed(src2.cuda())\n","            e2_outputs = model.encoder(emb2, src2_mask)\n","\n","            # Lehenengo hitzerako aukerak lortu:\n","\n","            trg_mask = torch.tril(torch.ones(1, 1, 1, dtype=torch.uint8)).cuda()\n","\n","            hasierakoa = torch.full(\n","                (len(src1), 1), sos, dtype=src1.dtype).cuda()\n","            embed = model.embed(hasierakoa)\n","            out = model.out(model.decoder(embed, \n","                e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask))\n","            out = F.softmax(out, dim=-1)\n","\n","            val, ix = out[:, -1].topk(k)\n","\n","            # Hurrengo hitzetarako begizta prestatu:\n","\n","            batch_size_dec = k*len(src1)\n","            outputs = torch.zeros(\n","                batch_size_dec, max_seq_len, dtype=src1.dtype)#.cuda()\n","            outputs[:, 0] = torch.LongTensor([sos])\n","            outputs[:, 1] = ix.flatten()\n","            beam_prob = val.flatten().log().float()\n","\n","            src1_mask = src1_mask.repeat_interleave(k, dim=0)\n","            src2_mask = src2_mask.repeat_interleave(k, dim=0)\n","            e1_outputs = e1_outputs.repeat_interleave(k, dim=0)\n","            e2_outputs = e2_outputs.repeat_interleave(k, dim=0)\n","\n","            bukatu_du = batch_size_dec*[False]\n","            \n","            berriro_saiatu = False\n","\n","            # Hurrengo hitzetarako begizta:\n","\n","            for i in range(2, max_seq_len):\n","\n","                if torch.cuda.memory_allocated(0) > 12_000_000_000 and \\\n","                    batch_size_enc > 1:\n","                    print(\"Memoria betetzen ari da.\")\n","                    berriro_saiatu = True\n","                    break\n","\n","                trg_mask = torch.tril(torch.ones(1, i, i, dtype=torch.uint8)).cuda()\n","                embed = model.embed(outputs[:, :i].cuda())\n","                out = model.decoder(embed, \n","                    e1_outputs, e2_outputs, src1_mask, src2_mask, trg_mask)\n","                out = model.out(out)\n","                out = out[:, -1]\n","                out = F.softmax(out, dim=-1)\n","                out = out.log()\n","                out = out.cpu()\n","                out = out.float()\n","\n","                outputs_berria = torch.zeros_like(outputs)\n","                bukatu_du_berria = batch_size_dec*[False]\n","\n","                for batch_ix in range(0, batch_size_dec, k):\n","                    aukera_guztiak = torch.tensor([])\n","                    for k_ix in range(k):\n","                        if not bukatu_du[batch_ix+k_ix]:\n","                            berriak = beam_prob[batch_ix+k_ix]+ \\\n","                                out[batch_ix+k_ix]\n","                            aukera_guztiak = torch.cat((aukera_guztiak, berriak))\n","                        else:\n","                            # Aukera hau <eos>era iritsi bada, ez dugu zabaldu nahi,\n","                            # baina aukera bezala utzi nahi dugu. Beraz, behin\n","                            # sartzen da, eta gainontzeko tokiak -inf-ekin betetzen\n","                            # dira.\n","                            berriak = torch.tensor(\n","                            [beam_prob[batch_ix+k_ix]]+(vocab_size-1)*[-math.inf])\n","                            aukera_guztiak = torch.cat((aukera_guztiak, berriak))\n","\n","                    val, ix = aukera_guztiak.topk(k)\n","\n","                    for k_ix in range(k):\n","                        # zenbatgarren aukeratik datorren:\n","                        ix_zahar = ix[k_ix] // vocab_size \n","                        # hitz berriaren zenbakia:\n","                        hitza = ix[k_ix] % vocab_size\n","\n","                        # bukatu_du eguneratu:\n","                        if hitza == eos:\n","                            bukatu_du_berria[batch_ix+k_ix] = True\n","                        else:\n","                            bukatu_du_berria[batch_ix+k_ix] = \\\n","                                bukatu_du[batch_ix+ix_zahar]\n","\n","                        # Aurreko hitzak hartu:\n","                        outputs_berria[batch_ix+k_ix] = outputs[batch_ix+ix_zahar]\n","\n","                        # Hitz berria gehitu:\n","                        outputs_berria[batch_ix+k_ix, i] = hitza\n","                        # Aukeren probabilitateak eguneratu:\n","                        beam_prob[batch_ix+k_ix] = val[k_ix]\n","\n","                outputs = outputs_berria\n","                bukatu_du = bukatu_du_berria\n","\n","                # Aukera guztiak bukatu badira, hurrengo batch-era pasa\n","                if not (False in bukatu_du):\n","                    break\n","\n","            if berriro_saiatu:\n","                continue\n","                    \n","            # Aukera onena hartu eta idatzi:\n","            #for esaldia in outputs:\n","            for batch_ix in range(0, batch_size_dec, k):\n","                max_ix = beam_prob[batch_ix : batch_ix+k].argmax()\n","                onena = outputs[batch_ix + max_ix]\n","                for pos in range(max_seq_len):\n","                    if onena[pos] == eos:\n","                        break\n","                deskodetuta = bpe_hirurak.decode(onena[1:pos].tolist())[0]\n","                ordenatuko_ix = j + batch_ix//k\n","                jatorrizko_ix = src[ordenatuko_ix][2]\n","                idazteko[jatorrizko_ix] = deskodetuta\n","                \n","            j = j + batch_size_enc\n","        \n","    print(\"{} minutu behar izan ditu.\".format((time.time()-hasi)/60))\n","    return idazteko"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmhF_NMisnPv","colab_type":"code","colab":{}},"source":["def zuzendu_beam_bakarra(model, src, lang, k, b_s):\n","    \n","    hasi = time.time()\n","    \n","    model.eval()\n","\n","    with torch.no_grad():\n","   \n","        src = [(esaldia[lang], i) for i, esaldia in enumerate(src)]\n","        src.sort(key=ordenatzeko)\n","        idazteko = len(src) * [\"\\n\"]\n","        \n","        # encoder-erako eta decoder-eko 1. posiziorako tamaina:\n","        batch_size_enc = b_s // k\n","        \n","        #for j in range(0, len(src), batch_size_enc):\n","        berriro_saiatu = False\n","        j = 0\n","        while j < len(src):\n","            \n","            print(torch.cuda.memory_allocated(0))\n","\n","            if berriro_saiatu and batch_size_enc > 1:\n","                batch_size_enc //= 2\n","                #if batch_size_enc == 0:\n","                #    print(\"Ezin da jarraitu.\")\n","                #    idatzi(idazteko, pe_fitx)\n","                #    return\n","            \n","            print(\"{}. esalditik aurrera zuzentzen...\".format(j+1))\n","\n","            batch = src[j : j+batch_size_enc]\n","            luzeena = len(batch[-1][0])\n","            src1 = [sartu_padding(esaldia[0], luzeena) for esaldia in batch]\n","            src1 = torch.LongTensor(src1)\n","\n","            src1_mask = (src1 != pad).unsqueeze(-2).cuda()\n","            emb1 = model.embed(src1.cuda())\n","            e1_outputs = model.encoder(emb1, src1_mask)\n","\n","            # Lehenengo hitzerako aukerak lortu:\n","\n","            trg_mask = torch.tril(torch.ones(1, 1, 1, dtype=torch.uint8)).cuda()\n","\n","            hasierakoa = torch.full(\n","                (len(src1), 1), sos, dtype=src1.dtype).cuda()\n","            embed = model.embed(hasierakoa)\n","            out = model.out(model.decoder(embed, \n","                e1_outputs, src1_mask, trg_mask))\n","            out = F.softmax(out, dim=-1)\n","\n","            val, ix = out[:, -1].topk(k)\n","\n","            # Hurrengo hitzetarako begizta prestatu:\n","\n","            batch_size_dec = k*len(src1)\n","            outputs = torch.zeros(\n","                batch_size_dec, max_seq_len, dtype=src1.dtype)#.cuda()\n","            outputs[:, 0] = torch.LongTensor([sos])\n","            outputs[:, 1] = ix.flatten()\n","            beam_prob = val.flatten().log().float()\n","\n","            src1_mask = src1_mask.repeat_interleave(k, dim=0)\n","            e1_outputs = e1_outputs.repeat_interleave(k, dim=0)\n","\n","            bukatu_du = batch_size_dec*[False]\n","            \n","            berriro_saiatu = False\n","\n","            # Hurrengo hitzetarako begizta:\n","\n","            for i in range(2, max_seq_len):\n","\n","                if torch.cuda.memory_allocated(0) > 12_000_000_000 and \\\n","                    batch_size_enc > 1:\n","                    print(\"Memoria betetzen ari da.\")\n","                    berriro_saiatu = True\n","                    break\n","\n","                trg_mask = torch.tril(torch.ones(1, i, i, dtype=torch.uint8)).cuda()\n","                embed = model.embed(outputs[:, :i].cuda())\n","                out = model.decoder(embed, \n","                    e1_outputs, src1_mask, trg_mask)\n","                out = model.out(out)\n","                out = out[:, -1]\n","                out = F.softmax(out, dim=-1)\n","                out = out.log()\n","                out = out.cpu()\n","                out = out.float()\n","\n","                outputs_berria = torch.zeros_like(outputs)\n","                bukatu_du_berria = batch_size_dec*[False]\n","\n","                for batch_ix in range(0, batch_size_dec, k):\n","                    aukera_guztiak = torch.tensor([])\n","                    for k_ix in range(k):\n","                        if not bukatu_du[batch_ix+k_ix]:\n","                            berriak = beam_prob[batch_ix+k_ix]+ \\\n","                                out[batch_ix+k_ix]\n","                            aukera_guztiak = torch.cat((aukera_guztiak, berriak))\n","                        else:\n","                            # Aukera hau <eos>era iritsi bada, ez dugu zabaldu nahi,\n","                            # baina aukera bezala utzi nahi dugu. Beraz, behin\n","                            # sartzen da, eta gainontzeko tokiak -inf-ekin betetzen\n","                            # dira.\n","                            berriak = torch.tensor(\n","                            [beam_prob[batch_ix+k_ix]]+(vocab_size-1)*[-math.inf])\n","                            aukera_guztiak = torch.cat((aukera_guztiak, berriak))\n","\n","                    val, ix = aukera_guztiak.topk(k)\n","\n","                    for k_ix in range(k):\n","                        # zenbatgarren aukeratik datorren:\n","                        ix_zahar = ix[k_ix] // vocab_size \n","                        # hitz berriaren zenbakia:\n","                        hitza = ix[k_ix] % vocab_size\n","\n","                        # bukatu_du eguneratu:\n","                        if hitza == eos:\n","                            bukatu_du_berria[batch_ix+k_ix] = True\n","                        else:\n","                            bukatu_du_berria[batch_ix+k_ix] = \\\n","                                bukatu_du[batch_ix+ix_zahar]\n","\n","                        # Aurreko hitzak hartu:\n","                        outputs_berria[batch_ix+k_ix] = outputs[batch_ix+ix_zahar]\n","\n","                        # Hitz berria gehitu:\n","                        outputs_berria[batch_ix+k_ix, i] = hitza\n","                        # Aukeren probabilitateak eguneratu:\n","                        beam_prob[batch_ix+k_ix] = val[k_ix]\n","\n","                outputs = outputs_berria\n","                bukatu_du = bukatu_du_berria\n","\n","                # Aukera guztiak bukatu badira, hurrengo batch-era pasa\n","                if not (False in bukatu_du):\n","                    break\n","\n","            if berriro_saiatu:\n","                continue\n","                    \n","            # Aukera onena hartu eta idatzi:\n","            #for esaldia in outputs:\n","            for batch_ix in range(0, batch_size_dec, k):\n","                max_ix = beam_prob[batch_ix : batch_ix+k].argmax()\n","                onena = outputs[batch_ix + max_ix]\n","                for pos in range(max_seq_len):\n","                    if onena[pos] == eos:\n","                        break\n","                deskodetuta = bpe_hirurak.decode(onena[1:pos].tolist())[0]\n","                ordenatuko_ix = j + batch_ix//k\n","                jatorrizko_ix = src[ordenatuko_ix][1]\n","                idazteko[jatorrizko_ix] = deskodetuta\n","                \n","            j = j + batch_size_enc\n","        \n","    print(\"{} minutu behar izan ditu.\".format((time.time()-hasi)/60))\n","    return idazteko"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSLe62s-jJSn","colab_type":"code","colab":{}},"source":["def batezbeste3(izena1, izena2, izena3):\n","    model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    model1, optim = amp.initialize(model, optim, opt_level='O2')\n","    model1.load_state_dict(torch.load(izena1)['model'])\n","\n","    model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    model2, optim = amp.initialize(model, optim, opt_level='O2')\n","    model2.load_state_dict(torch.load(izena2)['model'])\n","\n","    model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    model3, optim = amp.initialize(model, optim, opt_level='O2')\n","    model3.load_state_dict(torch.load(izena3)['model'])\n","\n","    params1 = model1.named_parameters()\n","    dict_params2 = model2.state_dict()\n","    dict_params3 = model3.state_dict()\n","\n","\n","    for name1, param1 in params1:\n","        if name1 in dict_params2:\n","            dict_params2[name1].data.copy_(1/3*param1.data + \n","                                        1/3*dict_params2[name1].data + \n","                                        1/3*dict_params3[name1].data)\n","\n","    model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    model = amp.initialize(model, opt_level='O2')\n","    model.load_state_dict(dict_params2)\n","\n","    model.eval()\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x36WmYolwfog","colab_type":"code","colab":{}},"source":["def batezbeste3_bakarra(izena1, izena2, izena3):\n","    model = SharedTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    model1, optim = amp.initialize(model, optim, opt_level='O2')\n","    model1.load_state_dict(torch.load(izena1)['model'])\n","\n","    model = SharedTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    model2, optim = amp.initialize(model, optim, opt_level='O2')\n","    model2.load_state_dict(torch.load(izena2)['model'])\n","\n","    model = SharedTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","    model3, optim = amp.initialize(model, optim, opt_level='O2')\n","    model3.load_state_dict(torch.load(izena3)['model'])\n","\n","    params1 = model1.named_parameters()\n","    dict_params2 = model2.state_dict()\n","    dict_params3 = model3.state_dict()\n","\n","\n","    for name1, param1 in params1:\n","        if name1 in dict_params2:\n","            dict_params2[name1].data.copy_(1/3*param1.data + \n","                                        1/3*dict_params2[name1].data + \n","                                        1/3*dict_params3[name1].data)\n","\n","    model = SharedTransformer(vocab_size, d_model, N, heads)\n","    model.cuda()\n","    model = amp.initialize(model, opt_level='O2')\n","    model.load_state_dict(dict_params2)\n","\n","    model.eval()\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xJe6Etpuzp3a","colab_type":"text"},"source":["## Emaitzak 'hobea'"]},{"cell_type":"code","metadata":{"id":"ViO82IjyHttY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592164428122,"user_tz":-120,"elapsed":7144,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"b90e8263-cf18-4632-eab5-7becbf7a5110"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('EhuHac/modeloahobea-22.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"Kz6eZt1tB5Fx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592135951422,"user_tz":-120,"elapsed":27459,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"dca4b73e-17ce-4c3b-f9b0-00bccb2bec10"},"source":["zuzendua = zuzendu_zenbakitua(model, dev1, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["26.728488206863403 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sz-xZSXJGQt-","colab_type":"code","colab":{}},"source":["references = [[esaldia[2].split()] for esaldia in dev1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0jO1Tnul4wM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592135989094,"user_tz":-120,"elapsed":670,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"f7013878-bca7-4e80-c69a-ad4b1a1144f8"},"source":["references[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['Impius', 'hæc', 'tam', 'culta', 'novalia', 'miles', 'habebit', '!']]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"AyqGdD60DSRP","colab_type":"code","colab":{}},"source":["candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRhcOvTfEj98","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585926747457,"user_tz":-120,"elapsed":738,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6170b9cb-a2fa-4e75-d0ec-f5da0e70037c"},"source":["# EMAITZA ZAHARRA\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.20753612864055"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"NBN856RTs3le","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592136015065,"user_tz":-120,"elapsed":927,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"449d791b-27a2-48ee-aafb-9247cff1adc5"},"source":["# BERRIA\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.214403846809434"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"wT9Jix-fdroW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"ok","timestamp":1592136044775,"user_tz":-120,"elapsed":1570,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"69b4e49c-3b92-4d29-ed86-27847e0b5ff0"},"source":["for reference in references[:30]:\n","    print(' '.join(reference[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Impius hæc tam culta novalia miles habebit !\n","\" Zure lagun \" .\n","Baina beranduegi da :\n","Baina zer zen hura ?\n","Rosanna Spearman\n","Ez da bitxia ?\n","Colin berriro gelditu zen .\n","- Ralph !\n","Hain da melodiatsu eta betea .\n","Eta haren Dulcinea ?\n","Afarian lehen aldiz jan zuen ondo Siziliako itsasertzak ikutu zituenetik , eta nesken edertasunak , aita Pirroneren austeritateak eta Don Fabrizioren manera handiek sinestarazi egin zioten azkenik Donnafugatako jauregia ez zela Capraro bandiduaren kobazuloa eta segur aski bizirik irtengo zela handik ;\n","Denak erosten ari ziren .\n","Ederra zen .\n","A !\n","Orain bi dauzkat .\n","epailetzako eta exekutiboko magistratuak eta beste funtzionari batzuk dituzu artikulazio artifizialak ; saria eta zigorra , berriz , subiranotasunaren guneari loturik dauden artikulazio eta gorputzadarrak mugiarazten dituztenak bakoitzak bere eginkizuna bete dezan , zainak dituzu , gorputz naturalean eginkizun huraxe bera dutenak ; menbro partikular bakoitzaren dirua eta aberastasunak , indarra dira ; salus populi edo herri-segurtasuna , helburu duena ; aholkulariak , gorputz artifizial horri ezagutu beharreko gauza guztiak iradokitzen dizkiotenak , haren memoria dira ; ekitatea eta legeak , arrazoi eta nahimen artifiziala ; konkordia , osasuna ; sedizioa , eritasuna ;\n","Jimmyk aurkitu zuenean ez zion poliziari deitu .\n","ideal hura hain zuzen ere beren ideal dute , berek , eta agian beste inork ez , errepresentatzen dute gaur hura , berak dira ilorrik izpiritualduena , gerrari eta miaketarien tropa aurreratuena , beren sedukzio-era maltzur , delikatu , atzemaezinezkoena :\n","Hegoaldean ez dago familiarik esklabuak ez izateko bezain behartsurik .\n","Azkenaldi hartan behintzat , Derwatt kasuan , eta orain Mafia madarikatuarekin ?\n","Ausartuko ote zen beste mahai baten esertzera L ' Aigle Noir hoteleko jangelan edo tabernan , Reeves Trevannyrekin elkarrizketatzen zenean ?\n","A , bai :\n","Mahaira itzuli eta eserita denbora piska batean nere artean pentsatzen aritu nintzen ea zergatik Menendez bezalako gaizkile lokal aski inportanteak pentsatzen zuen merezi zuela bere denbora galtzeak nere bulegora etorri eta muturrik ez sartzeko berak zuzenean esaten , hain zuzen ere minutu batuk lehenago Sewell Endicottek beste antzeko abisu bat , nahiz eta beste modu batera , eman ondoren .\n","Katolikoen artean , gizarte erlijiosoa bi elementuz bakarrik osatzen da : apaiza eta herria .\n","guda zen , guda gogorra , hari onekoa , guztiz sinpatikoa , eta bertan ez zegoen kaiserren , errepublikaren , lurralde mugen , bandera eta kolore eta antzerako gauza apaingarri eta teatralen , azken batean , ergelkerien aztarrenik , eta bertan aldiz arnas hartzeko espaziorik ez zuenak eta bizitza benaz atsegingarri topatzen ez zuenak bere amorruari kolpeka irtenbidea ematen zion eta hojalatazko mundu zibilizatuari xahuketa osoa prestatzen saiatzen zen bakoitza .\n","7 . Horregatik , gogamenaren higidurak arretaz begiratu eta ezagutzarako normalean zein bide hartzen duen ikusten jartzen bagara , uste dut aurkituko dugula gogamenak kontenplazioan edo diskurtsoan erabil dezakeela uste duen ideia bat erdiesten duelarik , lehenbizi ideia hori abstraitu eta izen bat jartzen diola eta ideia bere biltegian , oroimenean , gordetzen duela espezie bateko gauzen esentzia barne hartuz , izen hori beti esentzia horren seinale izango delarik .\n","E ?\n","Gizaki ez-zibilizatuak gure etxe-animaliak baliagarri zitzaizkiolako eta hesipeko egoeran erraz umatzen zirelako , eta gero distantzia handietara garraia zitezkeela ikusi zuelako , haiek aukeratu zituela inferi genezakeenez gero , gure etxe-animalia guztiek klima ezberdinei eusteko ezezik , haietan erabat umekor izateko duten ahalmena ( erizpide seguruagoa berau ) argudiotzat erabil daiteke honako honen aldeko argudiotzat , alegia , gaur natur egoeran dauden beste animaliarik askok ere jasan ditzakeela klima oso ezberdinak .\n","Egoera gorena , berrerospena bera , hipnotizazio erabateko hura eta azkenean lorturiko azken gelditasun hura , haiek beti bere baitako misteriotzat hartzen dituzte , zein adierazteko ez baitira aski ezta sinbolo jasoenak ere , gauzen barrenera itzuli eta bihurtzeaz , hitz egiten dutenak bezalakoak lilura orotatik askatzeaz , \" jakiteaz \" , \" egiaz \" , \" izateaz \" , xede , desira eta egintza ororekiko desatxikitzeaz , ongia eta gaizkiaz haraindi batez ere .\n","Madarikazio hau zuen kontra , ene etsaiok !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hwrIF6BZH2hB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"ok","timestamp":1592136051059,"user_tz":-120,"elapsed":954,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"80e74eb7-c856-480c-ab32-270a230e5739"},"source":["for candidate in candidates[:30]:\n","    print(' '.join(candidate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Impius haec tam culta novalia miles habebit !\n","- Zure laguna .\n","Baina beranduegi da :\n","Baina , zer zen hura ?\n","Rosanna Spearman \" .\n","Ez al da arraroa ?\n","Colin beste behin gelditu zen .\n","- Ralph !\n","Hain da melodiatsua eta betea .\n","Eta Dulcinea bera ?\n","Afarian , Siziliako itsasertzean oinez joan zenetik , eta nesken xarma , aita Pirronearen austeritatea eta Don Fabriziaren portaera bikainaz jabetu ziren Donnafugata jauregia ez zela Kapraroko bandidoaren antropua , eta ziur aski bizirik aterako zela .\n","Denak erosten ari ziren .\n","Ederra zen .\n","Ah !\n","Orain bi ditut .\n","magistratuak eta epailetza eta exekuzio-propuntuak dira ; saria eta zigorra ( subiranotasunaren egoitza betetzeko erkide diren zati bakoitza bere eginkizuna betetzeko mugiarazten duten zigorrak ) gorputz naturalean gauza bera egiten duten nerbioak dira ; dirua eta aberastasunak , gorputz naturalean , gizartearen aberastasunak , edo herriaren boterea , edo segurtasuna , haren kontseilari artifizialak , haren gorputz artifizialak , zeintzuk gauza guztiak baitira .\n","Jimmyk aurkitu zuenean , ez zion poliziari deitu .\n","ideal hura , hain zuzen , beren ideal propioa da , beraiek ere , eta agian beste inor ez , gaur egun errepresentatzen dute , beraiek dira beren sortzaile izpiritualatuenik azkarrena , gerrari eta esploratzaileen talde aurreratuenik azkarrena , bere sedukzio-era delikagarri eta delikatua .\n","Hegoaldean ez dago esklaborik ez izateko bezain familia txirokorik .\n","Oraintsu behintzat , Derwatt-eko kasuan , eta orain Mafia madarikatuarekin ?\n","Beste mahai bat hartzen ausartuko ote zen L ' Aigle Noir hoteleko tabernan , Reevesek Trevannyrekin elkartzen zuenean ?\n","A , bai :\n","Neure idazmahaira itzuli eta eseri egin nintzen eta denbora pixka bat eman nuen Menendez bezalako txantai dotore eta giroan , Menendezek bezala , bere aldetik , bere denbora alferrik galtzeko balioko zuela uste izango zuen , sudurra garbi gordetzeko , minutu batzuk besterik gabe , Sewell Endicotten antzeko oharpen bat jaso eta gero , hitz-arazoa esan arren .\n","Katolikoek , erlijio-elekutarren artean , bi elementu bakarrik osatzen dute elkar : apaizak eta herriak .\n","gerra , gerra bortitz , indartsu eta aldi atseginean , non ez baitzen enperadore , mugaz , mugaz , banderez eta kolore berdinez , mota eta bestelako gauza apaingarriez arduratzen , funtsean , frustraziaz eta beroki , baizik eta arnasa hartzeko aire falta zitzaion edonori eta bizitza ongi dastatzen ez zuenari , bere adierazpen atsegin eta atseginari , bere zuhurtasun orokorra prestatzeko .\n","7 . Horregatik , gogamenak ezagutza bidean duen ibilbidea arretaz aztertzen badugu , uste dut , gogamenak kontenplazioan edo diskurtsotan erabil zezakeelako ideia bat eskuratu ondoren , lehenik ideia hori abstraitzen zaiola eta , horrela , lehenengo gauza , bere baitan geratzen da , eta horrela , oroimenean , nolabait esateko , nolabait , nolabait esateko , bere izena ezartzen duena , eta horrela , bere oroimenean , nolabait , beti ere , bere izena , nolabait , bere baitan .\n","E ?\n","Gure etxe-animaliak , lehen suposatu dugunez , gizaki basatiak aukeratuak izan zirela , baliagarriak zirelako eta gatibutasunean erraz hazten zirelako , eta ez distantzia handitan garrai zitezkeenez gero , etxe-animalien gaitasun arrunta eta apartekoena , klima ez bakarrik klima ezberdinei aurre egiteko gai zirela-eta , baizik eta erabat ugalkorrak direnengan ere ( askoz ziurragoa berau ) , argumentu bat erabil daiteke , animalia baten tamainako arrazonamendu bat bezala , beste animalia baten egoeran oso azkar heda daitekeena , oso erraz , oso erraz ,\n","Estatu gorena , bere burua salbatzea bera , hipnosia orokor hura eta bake hura , beti beren baitan misteriotzat hartzen dira , eta hori adierazteko ez dira aski sinbolorik gorenagoek ere , gauzen mamu eta itzulera gisa , \" jakite \" , \" egia \" ren , \" egia \" ren askapen gisa , \" xede oro \" , \" xede oro \" , \" gaizkiaren \" , eta , gainera , gaitzetik , gauza baten eta gaizkiaren desio gisa .\n","Zuen kontra madarikazio hori , ene etsaiok !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tE_RkfETd-7l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1585927225846,"user_tz":-120,"elapsed":10111,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"e0bb6369-4308-43c3-d1a7-7d1ddcbbc64f"},"source":["# ZAHARRA\n","zuzendua_train = zuzendu_zenbakitua(model, train[:1000], batch_size)\n","references = [[berrezarri_maiuskulak(bpe_hirurak.decode(esaldia[2][1:-1])[0])]\n","              for esaldia in train[:1000]]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua_train]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9.237994194030762 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["57.98044292675848"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"5zU_iaIO_EmT","colab_type":"code","colab":{}},"source":["itzultzeko = [['el trabajo que yo hice estaba muy bien',\n","               'the work ｟C i did was very good'],\n","              ['el trabajo que yo hice estaba muy bien ￭.',\n","               'the work ｟C i did was very good ￭.'],\n","              ['el trabajo que él hizo estaba muy bien',\n","               'the work he did was very well done'],\n","              ['mi nombre es ｟C jokin ￭.',\n","               'my name is ｟C jokin ￭.'],\n","              ['｟C bittor está completamente de acuerdo',\n","               '｟C bittor completely agrees with it'],\n","              ['｟C irá a ｟C croacia a estudiar el año que viene ￭.',\n","              '｟C she will study in ｟C croatia next year ￭.'],\n","              ['｟C el secretario general del ｟C parlament inicia los trámites para relevar a ｟C torra como diputado',\n","               '｟C the general secretary of the ｟C parliament of ｟C catalonia begins the procedures to relieve ｟C torra as a deputy'],\n","              ['｟C pese a todo ￭, le expliqué cómo me estaba sintiendo yo',\n","               '｟C nevertheless ￭, I told him how I was feeling'],\n","              ['｟C mientras lo llevaba a casa ￭, lo saqué del envoltorio ￭.',\n","               '｟C as ｟C i was taking it home, ｟C i took it out of the package ￭.'],\n","              ['lo que dijo era parcialmente correcto',\n","               'what she said was partially correct'],\n","              ['｟C este va a ser un ejemplo bastante largo ￭. ｟C veremos si funciona hasta el final o no ￭, ya que a veces suele dar problemas si se alarga mucho ￭.',\n","              '｟C this will be a quite long example ￭. ｟C we will see if it works until the end or not ￭, since sometimes it has problems if it gets too long']]\n","itzultzeko_zenb = [[bpe_hirurak.encode(jat[0]), bpe_hirurak.encode(jat[1])] \n","                   for jat in itzultzeko]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rpm8JJu8FEJr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1585927259743,"user_tz":-120,"elapsed":1595,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"cc5ad22f-11a7-4ec2-857c-22f923700d08"},"source":["zuzendua = zuzendu_zenbakitua(model, itzultzeko_zenb, batch_size)\n","zuzendua"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.936241626739502 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['egin nuen lana oso ongi egina zen',\n"," 'egin nuen lana oso ongi egina zen ￭.',\n"," 'ondo egin zuen lana',\n"," '｟C carin dut izena ￭.',\n"," '｟C bittor erabat ados dago horrekin ￭.',\n"," '｟C datorren urtean ikasiko du ｟C croarekin ￭.',\n"," '｟C kataliaren ｟C parlamentuko idazkari nagusiak diputatu gisa ｟C torra arintzeko dakartzan egiturak ￭.',\n"," '｟C dena den ￭, nik nola sentitzen nuen azaldu nion ￭.',\n"," '｟C etxera nindoala ￭, fardeletik atera nuen ￭.',\n"," 'partzialki zuzena esan zuena zen',\n"," '｟C adibide hori askoz luzerakoa izango da ￭. ｟C ikusiko dugu ea amaierara arte funtzionatzen duen ￭, batzuetan arazoak izaten dituen luzeegi bada ￭.']"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"3l2a-QMotXrz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1585927367327,"user_tz":-120,"elapsed":3227,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"5f9e2cb2-a891-47de-f8c8-3fb74df277e1"},"source":["zuzendua = zuzendu_beam(model, itzultzeko_zenb, 4)\n","zuzendua"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","0.04213618040084839 minutu behar izan ditu.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['egin nuen lana oso ongi egina zen',\n"," 'oso lan ona egin nuen ￭.',\n"," 'ondo egin zuen lana',\n"," '｟C carin dut izena ￭.',\n"," '｟C bittor erabat ados dago horrekin ￭.',\n"," '｟C datorren urtean ikasiko du ｟C croarekin ￭.',\n"," '｟C kataliaren ｟C parlamentuko idazkari nagusiak diputatu gisa ｟C torra desegin nahi du ￭.',\n"," '｟C dena den ￭, nik nola sentitzen nuen azaldu nion ￭.',\n"," '｟C etxera nindoala ￭, fardeletik atera nuen ￭.',\n"," 'partzialki zuzena esan zuena zen',\n"," '｟C honek adibide luze samarra izango du ￭.']"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"bvUa_49yy3m4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1585928435802,"user_tz":-120,"elapsed":966009,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d09828fa-db65-405e-c64a-043177608993"},"source":["# ZAHARRA:\n","zuzendua = zuzendu_beam(model, dev, 4)\n","references = [[esaldia[2].split()] for esaldia in dev]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","12263878144\n","23. esalditik aurrera zuzentzen...\n","1315690496\n","45. esalditik aurrera zuzentzen...\n","3915663360\n","67. esalditik aurrera zuzentzen...\n","1905872384\n","89. esalditik aurrera zuzentzen...\n","2943360512\n","111. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12245062656\n","111. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12365991424\n","111. esalditik aurrera zuzentzen...\n","550857216\n","116. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12214205952\n","116. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12219828224\n","116. esalditik aurrera zuzentzen...\n","279988736\n","117. esalditik aurrera zuzentzen...\n","211061248\n","118. esalditik aurrera zuzentzen...\n","197590016\n","119. esalditik aurrera zuzentzen...\n","220463616\n","120. esalditik aurrera zuzentzen...\n","7721610752\n","121. esalditik aurrera zuzentzen...\n","296026624\n","122. esalditik aurrera zuzentzen...\n","234877440\n","123. esalditik aurrera zuzentzen...\n","188675584\n","124. esalditik aurrera zuzentzen...\n","429393408\n","125. esalditik aurrera zuzentzen...\n","219741696\n","126. esalditik aurrera zuzentzen...\n","221148672\n","127. esalditik aurrera zuzentzen...\n","212320768\n","128. esalditik aurrera zuzentzen...\n","236352000\n","129. esalditik aurrera zuzentzen...\n","221148672\n","130. esalditik aurrera zuzentzen...\n","237116928\n","131. esalditik aurrera zuzentzen...\n","248107008\n","132. esalditik aurrera zuzentzen...\n","233341440\n","133. esalditik aurrera zuzentzen...\n","236352000\n","134. esalditik aurrera zuzentzen...\n","219766272\n","135. esalditik aurrera zuzentzen...\n","198738944\n","136. esalditik aurrera zuzentzen...\n","209789440\n","137. esalditik aurrera zuzentzen...\n","250512384\n","138. esalditik aurrera zuzentzen...\n","303952384\n","139. esalditik aurrera zuzentzen...\n","250512384\n","140. esalditik aurrera zuzentzen...\n","210419200\n","141. esalditik aurrera zuzentzen...\n","187124224\n","142. esalditik aurrera zuzentzen...\n","235617792\n","143. esalditik aurrera zuzentzen...\n","248908800\n","144. esalditik aurrera zuzentzen...\n","249716736\n","145. esalditik aurrera zuzentzen...\n","221833728\n","146. esalditik aurrera zuzentzen...\n","235617792\n","147. esalditik aurrera zuzentzen...\n","284636672\n","148. esalditik aurrera zuzentzen...\n","234124800\n","149. esalditik aurrera zuzentzen...\n","209159680\n","150. esalditik aurrera zuzentzen...\n","236352000\n","151. esalditik aurrera zuzentzen...\n","281825792\n","152. esalditik aurrera zuzentzen...\n","211691008\n","153. esalditik aurrera zuzentzen...\n","234877440\n","154. esalditik aurrera zuzentzen...\n","284630528\n","155. esalditik aurrera zuzentzen...\n","336340480\n","156. esalditik aurrera zuzentzen...\n","282756608\n","157. esalditik aurrera zuzentzen...\n","222524928\n","158. esalditik aurrera zuzentzen...\n","252948480\n","159. esalditik aurrera zuzentzen...\n","221839872\n","160. esalditik aurrera zuzentzen...\n","235617792\n","161. esalditik aurrera zuzentzen...\n","212320768\n","162. esalditik aurrera zuzentzen...\n","238616064\n","163. esalditik aurrera zuzentzen...\n","197590016\n","164. esalditik aurrera zuzentzen...\n","237104640\n","165. esalditik aurrera zuzentzen...\n","298997248\n","166. esalditik aurrera zuzentzen...\n","238616064\n","167. esalditik aurrera zuzentzen...\n","251320320\n","168. esalditik aurrera zuzentzen...\n","267423232\n","169. esalditik aurrera zuzentzen...\n","362376192\n","170. esalditik aurrera zuzentzen...\n","225980928\n","171. esalditik aurrera zuzentzen...\n","210419200\n","172. esalditik aurrera zuzentzen...\n","252942336\n","173. esalditik aurrera zuzentzen...\n","269137408\n","174. esalditik aurrera zuzentzen...\n","301955584\n","175. esalditik aurrera zuzentzen...\n","256982016\n","176. esalditik aurrera zuzentzen...\n","298978816\n","177. esalditik aurrera zuzentzen...\n","301955584\n","178. esalditik aurrera zuzentzen...\n","211672576\n","179. esalditik aurrera zuzentzen...\n","251320320\n","180. esalditik aurrera zuzentzen...\n","281825792\n","181. esalditik aurrera zuzentzen...\n","304883200\n","182. esalditik aurrera zuzentzen...\n","239350272\n","183. esalditik aurrera zuzentzen...\n","264802816\n","184. esalditik aurrera zuzentzen...\n","268274176\n","185. esalditik aurrera zuzentzen...\n","237838848\n","186. esalditik aurrera zuzentzen...\n","253744128\n","187. esalditik aurrera zuzentzen...\n","223203840\n","188. esalditik aurrera zuzentzen...\n","269137408\n","189. esalditik aurrera zuzentzen...\n","284618240\n","190. esalditik aurrera zuzentzen...\n","384657920\n","191. esalditik aurrera zuzentzen...\n","269137408\n","192. esalditik aurrera zuzentzen...\n","249710592\n","193. esalditik aurrera zuzentzen...\n","303940096\n","194. esalditik aurrera zuzentzen...\n","387152384\n","195. esalditik aurrera zuzentzen...\n","226659840\n","196. esalditik aurrera zuzentzen...\n","237104640\n","197. esalditik aurrera zuzentzen...\n","270839296\n","198. esalditik aurrera zuzentzen...\n","298978816\n","199. esalditik aurrera zuzentzen...\n","238603776\n","200. esalditik aurrera zuzentzen...\n","253744128\n","201. esalditik aurrera zuzentzen...\n","251338752\n","202. esalditik aurrera zuzentzen...\n","252942336\n","203. esalditik aurrera zuzentzen...\n","285567488\n","204. esalditik aurrera zuzentzen...\n","283705856\n","205. esalditik aurrera zuzentzen...\n","385926656\n","206. esalditik aurrera zuzentzen...\n","319276544\n","207. esalditik aurrera zuzentzen...\n","250536960\n","208. esalditik aurrera zuzentzen...\n","270025216\n","209. esalditik aurrera zuzentzen...\n","300981760\n","210. esalditik aurrera zuzentzen...\n","237869568\n","211. esalditik aurrera zuzentzen...\n","270900736\n","212. esalditik aurrera zuzentzen...\n","239368704\n","213. esalditik aurrera zuzentzen...\n","284618240\n","214. esalditik aurrera zuzentzen...\n","242373120\n","215. esalditik aurrera zuzentzen...\n","236376576\n","216. esalditik aurrera zuzentzen...\n","288310784\n","217. esalditik aurrera zuzentzen...\n","269161984\n","218. esalditik aurrera zuzentzen...\n","285567488\n","219. esalditik aurrera zuzentzen...\n","279606784\n","220. esalditik aurrera zuzentzen...\n","289235456\n","221. esalditik aurrera zuzentzen...\n","227363328\n","222. esalditik aurrera zuzentzen...\n","271763968\n","223. esalditik aurrera zuzentzen...\n","270888448\n","224. esalditik aurrera zuzentzen...\n","285542912\n","225. esalditik aurrera zuzentzen...\n","269137408\n","226. esalditik aurrera zuzentzen...\n","255372288\n","227. esalditik aurrera zuzentzen...\n","289235456\n","228. esalditik aurrera zuzentzen...\n","341922304\n","229. esalditik aurrera zuzentzen...\n","241614336\n","230. esalditik aurrera zuzentzen...\n","408508928\n","231. esalditik aurrera zuzentzen...\n","330861056\n","232. esalditik aurrera zuzentzen...\n","272590336\n","233. esalditik aurrera zuzentzen...\n","224598528\n","234. esalditik aurrera zuzentzen...\n","326646272\n","235. esalditik aurrera zuzentzen...\n","253744128\n","236. esalditik aurrera zuzentzen...\n","345218560\n","237. esalditik aurrera zuzentzen...\n","405873152\n","238. esalditik aurrera zuzentzen...\n","288353792\n","239. esalditik aurrera zuzentzen...\n","325543424\n","240. esalditik aurrera zuzentzen...\n","327706112\n","241. esalditik aurrera zuzentzen...\n","290172416\n","242. esalditik aurrera zuzentzen...\n","325598720\n","243. esalditik aurrera zuzentzen...\n","257000448\n","244. esalditik aurrera zuzentzen...\n","240102912\n","245. esalditik aurrera zuzentzen...\n","322419200\n","246. esalditik aurrera zuzentzen...\n","257000448\n","247. esalditik aurrera zuzentzen...\n","256186368\n","248. esalditik aurrera zuzentzen...\n","290172416\n","249. esalditik aurrera zuzentzen...\n","307878400\n","250. esalditik aurrera zuzentzen...\n","261860352\n","251. esalditik aurrera zuzentzen...\n","273465856\n","252. esalditik aurrera zuzentzen...\n","292070912\n","253. esalditik aurrera zuzentzen...\n","398380544\n","254. esalditik aurrera zuzentzen...\n","387164672\n","255. esalditik aurrera zuzentzen...\n","369503232\n","256. esalditik aurrera zuzentzen...\n","368332800\n","257. esalditik aurrera zuzentzen...\n","368332800\n","258. esalditik aurrera zuzentzen...\n","349685248\n","259. esalditik aurrera zuzentzen...\n","274292224\n","260. esalditik aurrera zuzentzen...\n","390792704\n","261. esalditik aurrera zuzentzen...\n","367094784\n","262. esalditik aurrera zuzentzen...\n","372977664\n","263. esalditik aurrera zuzentzen...\n","346339840\n","264. esalditik aurrera zuzentzen...\n","256155648\n","265. esalditik aurrera zuzentzen...\n","371819520\n","266. esalditik aurrera zuzentzen...\n","288310784\n","267. esalditik aurrera zuzentzen...\n","246087168\n","268. esalditik aurrera zuzentzen...\n","240084480\n","269. esalditik aurrera zuzentzen...\n","326603264\n","270. esalditik aurrera zuzentzen...\n","308821504\n","271. esalditik aurrera zuzentzen...\n","258542592\n","272. esalditik aurrera zuzentzen...\n","273465856\n","273. esalditik aurrera zuzentzen...\n","292027904\n","274. esalditik aurrera zuzentzen...\n","347405824\n","275. esalditik aurrera zuzentzen...\n","389603840\n","276. esalditik aurrera zuzentzen...\n","372977664\n","277. esalditik aurrera zuzentzen...\n","370630656\n","278. esalditik aurrera zuzentzen...\n","225950208\n","279. esalditik aurrera zuzentzen...\n","309856768\n","280. esalditik aurrera zuzentzen...\n","271727104\n","281. esalditik aurrera zuzentzen...\n","274292224\n","282. esalditik aurrera zuzentzen...\n","361193472\n","283. esalditik aurrera zuzentzen...\n","390792704\n","284. esalditik aurrera zuzentzen...\n","328710656\n","285. esalditik aurrera zuzentzen...\n","305893888\n","286. esalditik aurrera zuzentzen...\n","344109568\n","287. esalditik aurrera zuzentzen...\n","312815104\n","288. esalditik aurrera zuzentzen...\n","329813504\n","289. esalditik aurrera zuzentzen...\n","306929152\n","290. esalditik aurrera zuzentzen...\n","374215680\n","291. esalditik aurrera zuzentzen...\n","289284608\n","292. esalditik aurrera zuzentzen...\n","373057536\n","293. esalditik aurrera zuzentzen...\n","316851712\n","294. esalditik aurrera zuzentzen...\n","363614208\n","295. esalditik aurrera zuzentzen...\n","336141824\n","296. esalditik aurrera zuzentzen...\n","291146240\n","297. esalditik aurrera zuzentzen...\n","332956160\n","298. esalditik aurrera zuzentzen...\n","308913664\n","299. esalditik aurrera zuzentzen...\n","347510272\n","300. esalditik aurrera zuzentzen...\n","329813504\n","301. esalditik aurrera zuzentzen...\n","328710656\n","302. esalditik aurrera zuzentzen...\n","310892032\n","303. esalditik aurrera zuzentzen...\n","257808384\n","304. esalditik aurrera zuzentzen...\n","292027904\n","305. esalditik aurrera zuzentzen...\n","307915264\n","306. esalditik aurrera zuzentzen...\n","474100224\n","307. esalditik aurrera zuzentzen...\n","399624704\n","308. esalditik aurrera zuzentzen...\n","327706112\n","309. esalditik aurrera zuzentzen...\n","335081984\n","310. esalditik aurrera zuzentzen...\n","293926400\n","311. esalditik aurrera zuzentzen...\n","371868672\n","312. esalditik aurrera zuzentzen...\n","397111808\n","313. esalditik aurrera zuzentzen...\n","291146240\n","314. esalditik aurrera zuzentzen...\n","348576256\n","315. esalditik aurrera zuzentzen...\n","395867648\n","316. esalditik aurrera zuzentzen...\n","315847168\n","317. esalditik aurrera zuzentzen...\n","474081792\n","318. esalditik aurrera zuzentzen...\n","314836480\n","319. esalditik aurrera zuzentzen...\n","418990592\n","320. esalditik aurrera zuzentzen...\n","276980224\n","321. esalditik aurrera zuzentzen...\n","394635776\n","322. esalditik aurrera zuzentzen...\n","334003712\n","323. esalditik aurrera zuzentzen...\n","297649664\n","324. esalditik aurrera zuzentzen...\n","332968448\n","325. esalditik aurrera zuzentzen...\n","356437504\n","326. esalditik aurrera zuzentzen...\n","309899776\n","327. esalditik aurrera zuzentzen...\n","468300288\n","328. esalditik aurrera zuzentzen...\n","331908608\n","329. esalditik aurrera zuzentzen...\n","378952704\n","330. esalditik aurrera zuzentzen...\n","310842880\n","331. esalditik aurrera zuzentzen...\n","395892224\n","332. esalditik aurrera zuzentzen...\n","351976960\n","333. esalditik aurrera zuzentzen...\n","275241472\n","334. esalditik aurrera zuzentzen...\n","300454400\n","335. esalditik aurrera zuzentzen...\n","356443648\n","336. esalditik aurrera zuzentzen...\n","353085952\n","337. esalditik aurrera zuzentzen...\n","377776128\n","338. esalditik aurrera zuzentzen...\n","355303936\n","339. esalditik aurrera zuzentzen...\n","351976960\n","340. esalditik aurrera zuzentzen...\n","293889536\n","341. esalditik aurrera zuzentzen...\n","382513152\n","342. esalditik aurrera zuzentzen...\n","428129792\n","343. esalditik aurrera zuzentzen...\n","365407744\n","344. esalditik aurrera zuzentzen...\n","311841280\n","345. esalditik aurrera zuzentzen...\n","448654848\n","346. esalditik aurrera zuzentzen...\n","291146240\n","347. esalditik aurrera zuzentzen...\n","472622592\n","348. esalditik aurrera zuzentzen...\n","417635840\n","349. esalditik aurrera zuzentzen...\n","349740544\n","350. esalditik aurrera zuzentzen...\n","370692096\n","351. esalditik aurrera zuzentzen...\n","527994880\n","352. esalditik aurrera zuzentzen...\n","425537024\n","353. esalditik aurrera zuzentzen...\n","295775744\n","354. esalditik aurrera zuzentzen...\n","426842624\n","355. esalditik aurrera zuzentzen...\n","429416960\n","356. esalditik aurrera zuzentzen...\n","355303936\n","357. esalditik aurrera zuzentzen...\n","432095744\n","358. esalditik aurrera zuzentzen...\n","540651520\n","359. esalditik aurrera zuzentzen...\n","356400640\n","360. esalditik aurrera zuzentzen...\n","450003456\n","361. esalditik aurrera zuzentzen...\n","506510336\n","362. esalditik aurrera zuzentzen...\n","353073664\n","363. esalditik aurrera zuzentzen...\n","397111808\n","364. esalditik aurrera zuzentzen...\n","383671296\n","365. esalditik aurrera zuzentzen...\n","355303936\n","366. esalditik aurrera zuzentzen...\n","354182656\n","367. esalditik aurrera zuzentzen...\n","398343680\n","368. esalditik aurrera zuzentzen...\n","447250944\n","369. esalditik aurrera zuzentzen...\n","331853312\n","370. esalditik aurrera zuzentzen...\n","438691328\n","371. esalditik aurrera zuzentzen...\n","430753280\n","372. esalditik aurrera zuzentzen...\n","474094080\n","373. esalditik aurrera zuzentzen...\n","398380544\n","374. esalditik aurrera zuzentzen...\n","377776128\n","375. esalditik aurrera zuzentzen...\n","652688384\n","376. esalditik aurrera zuzentzen...\n","1121808896\n","377. esalditik aurrera zuzentzen...\n","404601344\n","378. esalditik aurrera zuzentzen...\n","534372352\n","379. esalditik aurrera zuzentzen...\n","426873344\n","380. esalditik aurrera zuzentzen...\n","380135424\n","381. esalditik aurrera zuzentzen...\n","356443648\n","382. esalditik aurrera zuzentzen...\n","528050176\n","383. esalditik aurrera zuzentzen...\n","404601344\n","384. esalditik aurrera zuzentzen...\n","481254912\n","385. esalditik aurrera zuzentzen...\n","299499008\n","386. esalditik aurrera zuzentzen...\n","334028288\n","387. esalditik aurrera zuzentzen...\n","376587264\n","388. esalditik aurrera zuzentzen...\n","595253760\n","389. esalditik aurrera zuzentzen...\n","338243072\n","390. esalditik aurrera zuzentzen...\n","459671040\n","391. esalditik aurrera zuzentzen...\n","409596416\n","392. esalditik aurrera zuzentzen...\n","333979136\n","393. esalditik aurrera zuzentzen...\n","532784128\n","394. esalditik aurrera zuzentzen...\n","430802432\n","395. esalditik aurrera zuzentzen...\n","509557760\n","396. esalditik aurrera zuzentzen...\n","481316352\n","397. esalditik aurrera zuzentzen...\n","356437504\n","398. esalditik aurrera zuzentzen...\n","479863296\n","399. esalditik aurrera zuzentzen...\n","433432064\n","400. esalditik aurrera zuzentzen...\n","382500864\n","401. esalditik aurrera zuzentzen...\n","459671040\n","402. esalditik aurrera zuzentzen...\n","532784128\n","403. esalditik aurrera zuzentzen...\n","572009472\n","404. esalditik aurrera zuzentzen...\n","399624704\n","405. esalditik aurrera zuzentzen...\n","430802432\n","406. esalditik aurrera zuzentzen...\n","631634944\n","407. esalditik aurrera zuzentzen...\n","378958848\n","408. esalditik aurrera zuzentzen...\n","451376640\n","409. esalditik aurrera zuzentzen...\n","382500864\n","410. esalditik aurrera zuzentzen...\n","407095808\n","411. esalditik aurrera zuzentzen...\n","479863296\n","412. esalditik aurrera zuzentzen...\n","383683584\n","413. esalditik aurrera zuzentzen...\n","479875584\n","414. esalditik aurrera zuzentzen...\n","408346112\n","415. esalditik aurrera zuzentzen...\n","421632512\n","416. esalditik aurrera zuzentzen...\n","505063424\n","417. esalditik aurrera zuzentzen...\n","514162688\n","418. esalditik aurrera zuzentzen...\n","433376768\n","419. esalditik aurrera zuzentzen...\n","2175703040\n","420. esalditik aurrera zuzentzen...\n","413341184\n","421. esalditik aurrera zuzentzen...\n","378952704\n","422. esalditik aurrera zuzentzen...\n","434749952\n","423. esalditik aurrera zuzentzen...\n","430802432\n","424. esalditik aurrera zuzentzen...\n","515683328\n","425. esalditik aurrera zuzentzen...\n","485657088\n","426. esalditik aurrera zuzentzen...\n","540700672\n","427. esalditik aurrera zuzentzen...\n","482769408\n","428. esalditik aurrera zuzentzen...\n","500150784\n","429. esalditik aurrera zuzentzen...\n","487097856\n","430. esalditik aurrera zuzentzen...\n","565343232\n","431. esalditik aurrera zuzentzen...\n","484148736\n","432. esalditik aurrera zuzentzen...\n","663704576\n","433. esalditik aurrera zuzentzen...\n","482695680\n","434. esalditik aurrera zuzentzen...\n","514101248\n","435. esalditik aurrera zuzentzen...\n","607274496\n","436. esalditik aurrera zuzentzen...\n","458242560\n","437. esalditik aurrera zuzentzen...\n","408290816\n","438. esalditik aurrera zuzentzen...\n","465114624\n","439. esalditik aurrera zuzentzen...\n","414536192\n","440. esalditik aurrera zuzentzen...\n","428129792\n","441. esalditik aurrera zuzentzen...\n","415761920\n","442. esalditik aurrera zuzentzen...\n","566986752\n","443. esalditik aurrera zuzentzen...\n","678622208\n","444. esalditik aurrera zuzentzen...\n","716403712\n","445. esalditik aurrera zuzentzen...\n","409541120\n","446. esalditik aurrera zuzentzen...\n","512525312\n","447. esalditik aurrera zuzentzen...\n","515609600\n","448. esalditik aurrera zuzentzen...\n","432058880\n","449. esalditik aurrera zuzentzen...\n","593505792\n","450. esalditik aurrera zuzentzen...\n","429416960\n","451. esalditik aurrera zuzentzen...\n","498630144\n","452. esalditik aurrera zuzentzen...\n","578558976\n","453. esalditik aurrera zuzentzen...\n","365297152\n","454. esalditik aurrera zuzentzen...\n","642325504\n","455. esalditik aurrera zuzentzen...\n","509557760\n","456. esalditik aurrera zuzentzen...\n","640540672\n","457. esalditik aurrera zuzentzen...\n","409541120\n","458. esalditik aurrera zuzentzen...\n","545379328\n","459. esalditik aurrera zuzentzen...\n","386055168\n","460. esalditik aurrera zuzentzen...\n","405863936\n","461. esalditik aurrera zuzentzen...\n","640583680\n","462. esalditik aurrera zuzentzen...\n","414585344\n","463. esalditik aurrera zuzentzen...\n","653188096\n","464. esalditik aurrera zuzentzen...\n","603938304\n","465. esalditik aurrera zuzentzen...\n","637020160\n","466. esalditik aurrera zuzentzen...\n","537536512\n","467. esalditik aurrera zuzentzen...\n","465200640\n","468. esalditik aurrera zuzentzen...\n","540700672\n","469. esalditik aurrera zuzentzen...\n","509625344\n","470. esalditik aurrera zuzentzen...\n","364274176\n","471. esalditik aurrera zuzentzen...\n","638823424\n","472. esalditik aurrera zuzentzen...\n","429502976\n","473. esalditik aurrera zuzentzen...\n","571948032\n","474. esalditik aurrera zuzentzen...\n","491438592\n","475. esalditik aurrera zuzentzen...\n","559716352\n","476. esalditik aurrera zuzentzen...\n","612542976\n","477. esalditik aurrera zuzentzen...\n","676904960\n","478. esalditik aurrera zuzentzen...\n","463815168\n","479. esalditik aurrera zuzentzen...\n","489985536\n","480. esalditik aurrera zuzentzen...\n","682419200\n","481. esalditik aurrera zuzentzen...\n","461056512\n","482. esalditik aurrera zuzentzen...\n","598761984\n","483. esalditik aurrera zuzentzen...\n","494301696\n","484. esalditik aurrera zuzentzen...\n","688105472\n","485. esalditik aurrera zuzentzen...\n","617633280\n","486. esalditik aurrera zuzentzen...\n","712588288\n","487. esalditik aurrera zuzentzen...\n","439990784\n","488. esalditik aurrera zuzentzen...\n","576958464\n","489. esalditik aurrera zuzentzen...\n","673169408\n","490. esalditik aurrera zuzentzen...\n","651378688\n","491. esalditik aurrera zuzentzen...\n","720366592\n","492. esalditik aurrera zuzentzen...\n","550193152\n","493. esalditik aurrera zuzentzen...\n","603932160\n","494. esalditik aurrera zuzentzen...\n","409577984\n","495. esalditik aurrera zuzentzen...\n","1037149696\n","496. esalditik aurrera zuzentzen...\n","708729856\n","497. esalditik aurrera zuzentzen...\n","640602112\n","498. esalditik aurrera zuzentzen...\n","647778304\n","499. esalditik aurrera zuzentzen...\n","410846720\n","500. esalditik aurrera zuzentzen...\n","363159040\n","501. esalditik aurrera zuzentzen...\n","647778304\n","502. esalditik aurrera zuzentzen...\n","581895168\n","503. esalditik aurrera zuzentzen...\n","438629888\n","504. esalditik aurrera zuzentzen...\n","465200640\n","505. esalditik aurrera zuzentzen...\n","636695040\n","506. esalditik aurrera zuzentzen...\n","835508224\n","507. esalditik aurrera zuzentzen...\n","453163520\n","508. esalditik aurrera zuzentzen...\n","580270080\n","509. esalditik aurrera zuzentzen...\n","658530304\n","510. esalditik aurrera zuzentzen...\n","749492736\n","511. esalditik aurrera zuzentzen...\n","440003072\n","512. esalditik aurrera zuzentzen...\n","556533760\n","513. esalditik aurrera zuzentzen...\n","365395456\n","514. esalditik aurrera zuzentzen...\n","437373440\n","515. esalditik aurrera zuzentzen...\n","626311680\n","516. esalditik aurrera zuzentzen...\n","450441728\n","517. esalditik aurrera zuzentzen...\n","714508288\n","518. esalditik aurrera zuzentzen...\n","474843648\n","519. esalditik aurrera zuzentzen...\n","621055488\n","520. esalditik aurrera zuzentzen...\n","546936832\n","521. esalditik aurrera zuzentzen...\n","688080896\n","522. esalditik aurrera zuzentzen...\n","512605184\n","523. esalditik aurrera zuzentzen...\n","588512256\n","524. esalditik aurrera zuzentzen...\n","660290560\n","525. esalditik aurrera zuzentzen...\n","501554688\n","526. esalditik aurrera zuzentzen...\n","663909376\n","527. esalditik aurrera zuzentzen...\n","704742400\n","528. esalditik aurrera zuzentzen...\n","645925888\n","529. esalditik aurrera zuzentzen...\n","609071616\n","530. esalditik aurrera zuzentzen...\n","559605760\n","531. esalditik aurrera zuzentzen...\n","572305408\n","532. esalditik aurrera zuzentzen...\n","820948992\n","533. esalditik aurrera zuzentzen...\n","665698304\n","534. esalditik aurrera zuzentzen...\n","551750656\n","535. esalditik aurrera zuzentzen...\n","494301696\n","536. esalditik aurrera zuzentzen...\n","682511360\n","537. esalditik aurrera zuzentzen...\n","731997184\n","538. esalditik aurrera zuzentzen...\n","605655552\n","539. esalditik aurrera zuzentzen...\n","783421440\n","540. esalditik aurrera zuzentzen...\n","454475264\n","541. esalditik aurrera zuzentzen...\n","755541504\n","542. esalditik aurrera zuzentzen...\n","644190208\n","543. esalditik aurrera zuzentzen...\n","554920960\n","544. esalditik aurrera zuzentzen...\n","588536832\n","545. esalditik aurrera zuzentzen...\n","605033472\n","546. esalditik aurrera zuzentzen...\n","615959040\n","547. esalditik aurrera zuzentzen...\n","654886912\n","548. esalditik aurrera zuzentzen...\n","520165376\n","549. esalditik aurrera zuzentzen...\n","749468160\n","550. esalditik aurrera zuzentzen...\n","501573120\n","551. esalditik aurrera zuzentzen...\n","488557056\n","552. esalditik aurrera zuzentzen...\n","530840576\n","553. esalditik aurrera zuzentzen...\n","878557696\n","554. esalditik aurrera zuzentzen...\n","529313792\n","555. esalditik aurrera zuzentzen...\n","954464768\n","556. esalditik aurrera zuzentzen...\n","559685632\n","557. esalditik aurrera zuzentzen...\n","617676288\n","558. esalditik aurrera zuzentzen...\n","724139008\n","559. esalditik aurrera zuzentzen...\n","785495040\n","560. esalditik aurrera zuzentzen...\n","566032384\n","561. esalditik aurrera zuzentzen...\n","1032025600\n","562. esalditik aurrera zuzentzen...\n","671048704\n","563. esalditik aurrera zuzentzen...\n","658554880\n","564. esalditik aurrera zuzentzen...\n","749492736\n","565. esalditik aurrera zuzentzen...\n","622877184\n","566. esalditik aurrera zuzentzen...\n","763565568\n","567. esalditik aurrera zuzentzen...\n","470711808\n","568. esalditik aurrera zuzentzen...\n","590180352\n","569. esalditik aurrera zuzentzen...\n","634953216\n","570. esalditik aurrera zuzentzen...\n","610745856\n","571. esalditik aurrera zuzentzen...\n","660333568\n","572. esalditik aurrera zuzentzen...\n","474862080\n","573. esalditik aurrera zuzentzen...\n","575321088\n","574. esalditik aurrera zuzentzen...\n","678286336\n","575. esalditik aurrera zuzentzen...\n","684339200\n","576. esalditik aurrera zuzentzen...\n","591842304\n","577. esalditik aurrera zuzentzen...\n","808452096\n","578. esalditik aurrera zuzentzen...\n","647778304\n","579. esalditik aurrera zuzentzen...\n","751517184\n","580. esalditik aurrera zuzentzen...\n","731997184\n","581. esalditik aurrera zuzentzen...\n","753492480\n","582. esalditik aurrera zuzentzen...\n","767614464\n","583. esalditik aurrera zuzentzen...\n","867415552\n","584. esalditik aurrera zuzentzen...\n","878582272\n","585. esalditik aurrera zuzentzen...\n","708654080\n","586. esalditik aurrera zuzentzen...\n","673181696\n","587. esalditik aurrera zuzentzen...\n","706703360\n","588. esalditik aurrera zuzentzen...\n","653169664\n","589. esalditik aurrera zuzentzen...\n","846214144\n","590. esalditik aurrera zuzentzen...\n","722212864\n","591. esalditik aurrera zuzentzen...\n","831127552\n","592. esalditik aurrera zuzentzen...\n","869556736\n","593. esalditik aurrera zuzentzen...\n","1107009024\n","594. esalditik aurrera zuzentzen...\n","839772160\n","595. esalditik aurrera zuzentzen...\n","569141248\n","596. esalditik aurrera zuzentzen...\n","722212864\n","597. esalditik aurrera zuzentzen...\n","751418880\n","598. esalditik aurrera zuzentzen...\n","691755008\n","599. esalditik aurrera zuzentzen...\n","653059072\n","600. esalditik aurrera zuzentzen...\n","562794496\n","601. esalditik aurrera zuzentzen...\n","586617856\n","602. esalditik aurrera zuzentzen...\n","769614336\n","603. esalditik aurrera zuzentzen...\n","1052417536\n","604. esalditik aurrera zuzentzen...\n","699305984\n","605. esalditik aurrera zuzentzen...\n","735880192\n","606. esalditik aurrera zuzentzen...\n","536910848\n","607. esalditik aurrera zuzentzen...\n","885306880\n","608. esalditik aurrera zuzentzen...\n","680579072\n","609. esalditik aurrera zuzentzen...\n","1060039168\n","610. esalditik aurrera zuzentzen...\n","800108544\n","611. esalditik aurrera zuzentzen...\n","1101977088\n","612. esalditik aurrera zuzentzen...\n","562880512\n","613. esalditik aurrera zuzentzen...\n","672925696\n","614. esalditik aurrera zuzentzen...\n","536910848\n","615. esalditik aurrera zuzentzen...\n","871894528\n","616. esalditik aurrera zuzentzen...\n","791784960\n","617. esalditik aurrera zuzentzen...\n","850668544\n","618. esalditik aurrera zuzentzen...\n","446537216\n","619. esalditik aurrera zuzentzen...\n","672925696\n","620. esalditik aurrera zuzentzen...\n","823047168\n","621. esalditik aurrera zuzentzen...\n","654960640\n","622. esalditik aurrera zuzentzen...\n","634947072\n","623. esalditik aurrera zuzentzen...\n","662136832\n","624. esalditik aurrera zuzentzen...\n","971142656\n","625. esalditik aurrera zuzentzen...\n","765590016\n","626. esalditik aurrera zuzentzen...\n","728095744\n","627. esalditik aurrera zuzentzen...\n","658548736\n","628. esalditik aurrera zuzentzen...\n","600047616\n","629. esalditik aurrera zuzentzen...\n","946138624\n","630. esalditik aurrera zuzentzen...\n","510273024\n","631. esalditik aurrera zuzentzen...\n","934560256\n","632. esalditik aurrera zuzentzen...\n","588236800\n","633. esalditik aurrera zuzentzen...\n","704869376\n","634. esalditik aurrera zuzentzen...\n","1104585216\n","635. esalditik aurrera zuzentzen...\n","889724416\n","636. esalditik aurrera zuzentzen...\n","581840896\n","637. esalditik aurrera zuzentzen...\n","773638656\n","638. esalditik aurrera zuzentzen...\n","816795648\n","639. esalditik aurrera zuzentzen...\n","671134720\n","640. esalditik aurrera zuzentzen...\n","1052417536\n","641. esalditik aurrera zuzentzen...\n","710506496\n","642. esalditik aurrera zuzentzen...\n","779687424\n","643. esalditik aurrera zuzentzen...\n","596822016\n","644. esalditik aurrera zuzentzen...\n","925338112\n","645. esalditik aurrera zuzentzen...\n","726145024\n","646. esalditik aurrera zuzentzen...\n","697441280\n","647. esalditik aurrera zuzentzen...\n","665663488\n","648. esalditik aurrera zuzentzen...\n","971142656\n","649. esalditik aurrera zuzentzen...\n","1075276288\n","650. esalditik aurrera zuzentzen...\n","749418496\n","651. esalditik aurrera zuzentzen...\n","1529434624\n","652. esalditik aurrera zuzentzen...\n","878557696\n","653. esalditik aurrera zuzentzen...\n","1020880896\n","654. esalditik aurrera zuzentzen...\n","654948352\n","655. esalditik aurrera zuzentzen...\n","1120301568\n","656. esalditik aurrera zuzentzen...\n","704869376\n","657. esalditik aurrera zuzentzen...\n","633205248\n","658. esalditik aurrera zuzentzen...\n","812574720\n","659. esalditik aurrera zuzentzen...\n","948408832\n","660. esalditik aurrera zuzentzen...\n","733898752\n","661. esalditik aurrera zuzentzen...\n","950734336\n","662. esalditik aurrera zuzentzen...\n","2443581952\n","663. esalditik aurrera zuzentzen...\n","973548032\n","664. esalditik aurrera zuzentzen...\n","696196096\n","665. esalditik aurrera zuzentzen...\n","533844992\n","666. esalditik aurrera zuzentzen...\n","551787520\n","667. esalditik aurrera zuzentzen...\n","745535488\n","668. esalditik aurrera zuzentzen...\n","2388108288\n","669. esalditik aurrera zuzentzen...\n","1443473920\n","670. esalditik aurrera zuzentzen...\n","973903360\n","671. esalditik aurrera zuzentzen...\n","695545856\n","672. esalditik aurrera zuzentzen...\n","975977984\n","673. esalditik aurrera zuzentzen...\n","1025845248\n","674. esalditik aurrera zuzentzen...\n","1174565888\n","675. esalditik aurrera zuzentzen...\n","650420736\n","676. esalditik aurrera zuzentzen...\n","861460480\n","677. esalditik aurrera zuzentzen...\n","1398119424\n","678. esalditik aurrera zuzentzen...\n","903192064\n","679. esalditik aurrera zuzentzen...\n","773558784\n","680. esalditik aurrera zuzentzen...\n","929958400\n","681. esalditik aurrera zuzentzen...\n","804280320\n","682. esalditik aurrera zuzentzen...\n","854987776\n","683. esalditik aurrera zuzentzen...\n","685505536\n","684. esalditik aurrera zuzentzen...\n","975953408\n","685. esalditik aurrera zuzentzen...\n","1060423680\n","686. esalditik aurrera zuzentzen...\n","995073536\n","687. esalditik aurrera zuzentzen...\n","823047168\n","688. esalditik aurrera zuzentzen...\n","1233132032\n","689. esalditik aurrera zuzentzen...\n","987912704\n","690. esalditik aurrera zuzentzen...\n","859264000\n","691. esalditik aurrera zuzentzen...\n","818875392\n","692. esalditik aurrera zuzentzen...\n","662149120\n","693. esalditik aurrera zuzentzen...\n","946132480\n","694. esalditik aurrera zuzentzen...\n","856488960\n","695. esalditik aurrera zuzentzen...\n","867859456\n","696. esalditik aurrera zuzentzen...\n","857141248\n","697. esalditik aurrera zuzentzen...\n","850668544\n","698. esalditik aurrera zuzentzen...\n","719854592\n","699. esalditik aurrera zuzentzen...\n","1098251776\n","700. esalditik aurrera zuzentzen...\n","887345152\n","701. esalditik aurrera zuzentzen...\n","732003328\n","702. esalditik aurrera zuzentzen...\n","741609472\n","703. esalditik aurrera zuzentzen...\n","1210860032\n","704. esalditik aurrera zuzentzen...\n","1177260032\n","705. esalditik aurrera zuzentzen...\n","1025814528\n","706. esalditik aurrera zuzentzen...\n","1233156608\n","707. esalditik aurrera zuzentzen...\n","1048077312\n","708. esalditik aurrera zuzentzen...\n","1267547136\n","709. esalditik aurrera zuzentzen...\n","662149120\n","710. esalditik aurrera zuzentzen...\n","854993920\n","711. esalditik aurrera zuzentzen...\n","1438221824\n","712. esalditik aurrera zuzentzen...\n","973915648\n","713. esalditik aurrera zuzentzen...\n","831323136\n","714. esalditik aurrera zuzentzen...\n","1059940864\n","715. esalditik aurrera zuzentzen...\n","905339392\n","716. esalditik aurrera zuzentzen...\n","1258147328\n","717. esalditik aurrera zuzentzen...\n","1574372864\n","718. esalditik aurrera zuzentzen...\n","911959552\n","719. esalditik aurrera zuzentzen...\n","781619712\n","720. esalditik aurrera zuzentzen...\n","1494616576\n","721. esalditik aurrera zuzentzen...\n","1087936000\n","722. esalditik aurrera zuzentzen...\n","876510208\n","723. esalditik aurrera zuzentzen...\n","852742144\n","724. esalditik aurrera zuzentzen...\n","1141252608\n","725. esalditik aurrera zuzentzen...\n","1299099648\n","726. esalditik aurrera zuzentzen...\n","964564480\n","727. esalditik aurrera zuzentzen...\n","745498624\n","728. esalditik aurrera zuzentzen...\n","985396736\n","729. esalditik aurrera zuzentzen...\n","1235832320\n","730. esalditik aurrera zuzentzen...\n","1171755008\n","731. esalditik aurrera zuzentzen...\n","1216309760\n","732. esalditik aurrera zuzentzen...\n","995098112\n","733. esalditik aurrera zuzentzen...\n","1035718656\n","734. esalditik aurrera zuzentzen...\n","948457984\n","735. esalditik aurrera zuzentzen...\n","861466624\n","736. esalditik aurrera zuzentzen...\n","1155522560\n","737. esalditik aurrera zuzentzen...\n","1413252608\n","738. esalditik aurrera zuzentzen...\n","1167634944\n","739. esalditik aurrera zuzentzen...\n","768833536\n","740. esalditik aurrera zuzentzen...\n","835494912\n","741. esalditik aurrera zuzentzen...\n","842042368\n","742. esalditik aurrera zuzentzen...\n","831396864\n","743. esalditik aurrera zuzentzen...\n","1438215680\n","744. esalditik aurrera zuzentzen...\n","1014205952\n","745. esalditik aurrera zuzentzen...\n","1090587136\n","746. esalditik aurrera zuzentzen...\n","995073536\n","747. esalditik aurrera zuzentzen...\n","1227454976\n","748. esalditik aurrera zuzentzen...\n","894234112\n","749. esalditik aurrera zuzentzen...\n","1179978752\n","750. esalditik aurrera zuzentzen...\n","907671040\n","751. esalditik aurrera zuzentzen...\n","357730816\n","752. esalditik aurrera zuzentzen...\n","995098112\n","753. esalditik aurrera zuzentzen...\n","795796992\n","754. esalditik aurrera zuzentzen...\n","1011794432\n","755. esalditik aurrera zuzentzen...\n","1328437248\n","756. esalditik aurrera zuzentzen...\n","770808832\n","757. esalditik aurrera zuzentzen...\n","1143922176\n","758. esalditik aurrera zuzentzen...\n","1016580608\n","759. esalditik aurrera zuzentzen...\n","1090050048\n","760. esalditik aurrera zuzentzen...\n","1092998656\n","761. esalditik aurrera zuzentzen...\n","1011794432\n","762. esalditik aurrera zuzentzen...\n","626595840\n","763. esalditik aurrera zuzentzen...\n","1319267328\n","764. esalditik aurrera zuzentzen...\n","1007014400\n","765. esalditik aurrera zuzentzen...\n","1014144512\n","766. esalditik aurrera zuzentzen...\n","2367454208\n","767. esalditik aurrera zuzentzen...\n","1325048832\n","768. esalditik aurrera zuzentzen...\n","1019016704\n","769. esalditik aurrera zuzentzen...\n","1159755264\n","770. esalditik aurrera zuzentzen...\n","1115980288\n","771. esalditik aurrera zuzentzen...\n","1057950720\n","772. esalditik aurrera zuzentzen...\n","1668486656\n","773. esalditik aurrera zuzentzen...\n","836138496\n","774. esalditik aurrera zuzentzen...\n","953096704\n","775. esalditik aurrera zuzentzen...\n","1398137856\n","776. esalditik aurrera zuzentzen...\n","1016611328\n","777. esalditik aurrera zuzentzen...\n","1407227904\n","778. esalditik aurrera zuzentzen...\n","1635210752\n","779. esalditik aurrera zuzentzen...\n","1355536384\n","780. esalditik aurrera zuzentzen...\n","1685778944\n","781. esalditik aurrera zuzentzen...\n","1484993024\n","782. esalditik aurrera zuzentzen...\n","755196928\n","783. esalditik aurrera zuzentzen...\n","962331136\n","784. esalditik aurrera zuzentzen...\n","1180761600\n","785. esalditik aurrera zuzentzen...\n","1093127680\n","786. esalditik aurrera zuzentzen...\n","1452813312\n","787. esalditik aurrera zuzentzen...\n","2037064192\n","788. esalditik aurrera zuzentzen...\n","1220581376\n","789. esalditik aurrera zuzentzen...\n","1266616832\n","790. esalditik aurrera zuzentzen...\n","1546023424\n","791. esalditik aurrera zuzentzen...\n","1151857152\n","792. esalditik aurrera zuzentzen...\n","1204299776\n","793. esalditik aurrera zuzentzen...\n","1905428480\n","794. esalditik aurrera zuzentzen...\n","1014236672\n","795. esalditik aurrera zuzentzen...\n","1286041088\n","796. esalditik aurrera zuzentzen...\n","1301971968\n","797. esalditik aurrera zuzentzen...\n","1517051392\n","798. esalditik aurrera zuzentzen...\n","1093010944\n","799. esalditik aurrera zuzentzen...\n","1164885504\n","800. esalditik aurrera zuzentzen...\n","987857408\n","801. esalditik aurrera zuzentzen...\n","1228565504\n","802. esalditik aurrera zuzentzen...\n","1253021696\n","803. esalditik aurrera zuzentzen...\n","1410173952\n","804. esalditik aurrera zuzentzen...\n","1141576192\n","805. esalditik aurrera zuzentzen...\n","1675417088\n","806. esalditik aurrera zuzentzen...\n","1319199744\n","807. esalditik aurrera zuzentzen...\n","1797487104\n","808. esalditik aurrera zuzentzen...\n","1113538048\n","809. esalditik aurrera zuzentzen...\n","1227608576\n","810. esalditik aurrera zuzentzen...\n","1113538048\n","811. esalditik aurrera zuzentzen...\n","1102451712\n","812. esalditik aurrera zuzentzen...\n","1517125120\n","813. esalditik aurrera zuzentzen...\n","980873728\n","814. esalditik aurrera zuzentzen...\n","1361403904\n","815. esalditik aurrera zuzentzen...\n","1898421248\n","816. esalditik aurrera zuzentzen...\n","1536386560\n","817. esalditik aurrera zuzentzen...\n","1525601792\n","818. esalditik aurrera zuzentzen...\n","1645203968\n","819. esalditik aurrera zuzentzen...\n","1217856512\n","820. esalditik aurrera zuzentzen...\n","1269390848\n","821. esalditik aurrera zuzentzen...\n","1065271296\n","822. esalditik aurrera zuzentzen...\n","1288931840\n","823. esalditik aurrera zuzentzen...\n","1093182976\n","824. esalditik aurrera zuzentzen...\n","1414653952\n","825. esalditik aurrera zuzentzen...\n","1431552000\n","826. esalditik aurrera zuzentzen...\n","1080176640\n","827. esalditik aurrera zuzentzen...\n","1274871296\n","828. esalditik aurrera zuzentzen...\n","1425408000\n","829. esalditik aurrera zuzentzen...\n","1768874496\n","830. esalditik aurrera zuzentzen...\n","1167591936\n","831. esalditik aurrera zuzentzen...\n","1760134144\n","832. esalditik aurrera zuzentzen...\n","1263781376\n","833. esalditik aurrera zuzentzen...\n","1968176128\n","834. esalditik aurrera zuzentzen...\n","1555574272\n","835. esalditik aurrera zuzentzen...\n","1544347648\n","836. esalditik aurrera zuzentzen...\n","1737735680\n","837. esalditik aurrera zuzentzen...\n","1647983104\n","838. esalditik aurrera zuzentzen...\n","1964339200\n","839. esalditik aurrera zuzentzen...\n","1258147328\n","840. esalditik aurrera zuzentzen...\n","1614977536\n","841. esalditik aurrera zuzentzen...\n","1920327680\n","842. esalditik aurrera zuzentzen...\n","2051587072\n","843. esalditik aurrera zuzentzen...\n","3027142144\n","844. esalditik aurrera zuzentzen...\n","2169133056\n","845. esalditik aurrera zuzentzen...\n","1379031040\n","846. esalditik aurrera zuzentzen...\n","1228577792\n","847. esalditik aurrera zuzentzen...\n","2128778752\n","848. esalditik aurrera zuzentzen...\n","1754929664\n","849. esalditik aurrera zuzentzen...\n","2244897792\n","850. esalditik aurrera zuzentzen...\n","1423393792\n","851. esalditik aurrera zuzentzen...\n","2059279360\n","852. esalditik aurrera zuzentzen...\n","1601749504\n","853. esalditik aurrera zuzentzen...\n","2719628800\n","854. esalditik aurrera zuzentzen...\n","8739152384\n","855. esalditik aurrera zuzentzen...\n","2845406720\n","856. esalditik aurrera zuzentzen...\n","1603494400\n","857. esalditik aurrera zuzentzen...\n","1987213312\n","858. esalditik aurrera zuzentzen...\n","2245106688\n","859. esalditik aurrera zuzentzen...\n","1702745600\n","860. esalditik aurrera zuzentzen...\n","1727220224\n","861. esalditik aurrera zuzentzen...\n","1414641664\n","862. esalditik aurrera zuzentzen...\n","2141063680\n","863. esalditik aurrera zuzentzen...\n","1938842624\n","864. esalditik aurrera zuzentzen...\n","1833011712\n","865. esalditik aurrera zuzentzen...\n","1887475200\n","866. esalditik aurrera zuzentzen...\n","1645369856\n","867. esalditik aurrera zuzentzen...\n","2392992768\n","868. esalditik aurrera zuzentzen...\n","1702745600\n","869. esalditik aurrera zuzentzen...\n","1991013376\n","870. esalditik aurrera zuzentzen...\n","1801016832\n","871. esalditik aurrera zuzentzen...\n","1159390720\n","872. esalditik aurrera zuzentzen...\n","1486233600\n","873. esalditik aurrera zuzentzen...\n","2377168896\n","874. esalditik aurrera zuzentzen...\n","1283371520\n","875. esalditik aurrera zuzentzen...\n","1546035712\n","876. esalditik aurrera zuzentzen...\n","2078771200\n","877. esalditik aurrera zuzentzen...\n","2220431872\n","878. esalditik aurrera zuzentzen...\n","1779213824\n","879. esalditik aurrera zuzentzen...\n","2298761728\n","880. esalditik aurrera zuzentzen...\n","2460245504\n","881. esalditik aurrera zuzentzen...\n","9587049472\n","882. esalditik aurrera zuzentzen...\n","2830718976\n","883. esalditik aurrera zuzentzen...\n","2358714880\n","884. esalditik aurrera zuzentzen...\n","2244878848\n","885. esalditik aurrera zuzentzen...\n","1800140800\n","886. esalditik aurrera zuzentzen...\n","3187771392\n","887. esalditik aurrera zuzentzen...\n","2106348544\n","888. esalditik aurrera zuzentzen...\n","1291705856\n","889. esalditik aurrera zuzentzen...\n","2161065472\n","890. esalditik aurrera zuzentzen...\n","2913743872\n","891. esalditik aurrera zuzentzen...\n","2106348544\n","892. esalditik aurrera zuzentzen...\n","2314184192\n","893. esalditik aurrera zuzentzen...\n","2261449728\n","894. esalditik aurrera zuzentzen...\n","3145715200\n","895. esalditik aurrera zuzentzen...\n","2371632640\n","896. esalditik aurrera zuzentzen...\n","2177125888\n","897. esalditik aurrera zuzentzen...\n","1946393600\n","898. esalditik aurrera zuzentzen...\n","2401643520\n","899. esalditik aurrera zuzentzen...\n","2197085696\n","900. esalditik aurrera zuzentzen...\n","2061013504\n","901. esalditik aurrera zuzentzen...\n","1253132288\n","902. esalditik aurrera zuzentzen...\n","2047731712\n","903. esalditik aurrera zuzentzen...\n","2845381632\n","904. esalditik aurrera zuzentzen...\n","2550708736\n","905. esalditik aurrera zuzentzen...\n","2710117888\n","906. esalditik aurrera zuzentzen...\n","3104381952\n","907. esalditik aurrera zuzentzen...\n","2145456128\n","908. esalditik aurrera zuzentzen...\n","2002270720\n","909. esalditik aurrera zuzentzen...\n","1619779584\n","910. esalditik aurrera zuzentzen...\n","2245063680\n","911. esalditik aurrera zuzentzen...\n","1949410816\n","912. esalditik aurrera zuzentzen...\n","2021050368\n","913. esalditik aurrera zuzentzen...\n","1987506688\n","914. esalditik aurrera zuzentzen...\n","2009914368\n","915. esalditik aurrera zuzentzen...\n","2643296256\n","916. esalditik aurrera zuzentzen...\n","3256188416\n","917. esalditik aurrera zuzentzen...\n","2137622016\n","918. esalditik aurrera zuzentzen...\n","1616415744\n","919. esalditik aurrera zuzentzen...\n","3949958144\n","920. esalditik aurrera zuzentzen...\n","1743284224\n","921. esalditik aurrera zuzentzen...\n","2197091328\n","922. esalditik aurrera zuzentzen...\n","2318872064\n","923. esalditik aurrera zuzentzen...\n","2978229248\n","924. esalditik aurrera zuzentzen...\n","3779836416\n","925. esalditik aurrera zuzentzen...\n","1655086592\n","926. esalditik aurrera zuzentzen...\n","2859287040\n","927. esalditik aurrera zuzentzen...\n","2586645504\n","928. esalditik aurrera zuzentzen...\n","1914675712\n","929. esalditik aurrera zuzentzen...\n","2774963200\n","930. esalditik aurrera zuzentzen...\n","3617452544\n","931. esalditik aurrera zuzentzen...\n","2652487168\n","932. esalditik aurrera zuzentzen...\n","2972022784\n","933. esalditik aurrera zuzentzen...\n","3255922176\n","934. esalditik aurrera zuzentzen...\n","2702791680\n","935. esalditik aurrera zuzentzen...\n","2322911744\n","936. esalditik aurrera zuzentzen...\n","6057707008\n","937. esalditik aurrera zuzentzen...\n","3378518528\n","938. esalditik aurrera zuzentzen...\n","2047183872\n","939. esalditik aurrera zuzentzen...\n","1073581056\n","940. esalditik aurrera zuzentzen...\n","3595347456\n","941. esalditik aurrera zuzentzen...\n","3347207168\n","942. esalditik aurrera zuzentzen...\n","6519473152\n","943. esalditik aurrera zuzentzen...\n","2329356800\n","944. esalditik aurrera zuzentzen...\n","4430641664\n","945. esalditik aurrera zuzentzen...\n","3384590336\n","946. esalditik aurrera zuzentzen...\n","4560947712\n","947. esalditik aurrera zuzentzen...\n","3186405888\n","948. esalditik aurrera zuzentzen...\n","3132573696\n","949. esalditik aurrera zuzentzen...\n","3068046848\n","950. esalditik aurrera zuzentzen...\n","4372553216\n","951. esalditik aurrera zuzentzen...\n","2853065216\n","952. esalditik aurrera zuzentzen...\n","3470741504\n","953. esalditik aurrera zuzentzen...\n","3314055680\n","954. esalditik aurrera zuzentzen...\n","4342203904\n","955. esalditik aurrera zuzentzen...\n","3082477568\n","956. esalditik aurrera zuzentzen...\n","2889406976\n","957. esalditik aurrera zuzentzen...\n","4242758144\n","958. esalditik aurrera zuzentzen...\n","3615232512\n","959. esalditik aurrera zuzentzen...\n","4379204096\n","960. esalditik aurrera zuzentzen...\n","3069245440\n","961. esalditik aurrera zuzentzen...\n","3988656640\n","962. esalditik aurrera zuzentzen...\n","3642283520\n","963. esalditik aurrera zuzentzen...\n","3497581568\n","964. esalditik aurrera zuzentzen...\n","3098619904\n","965. esalditik aurrera zuzentzen...\n","4048486912\n","966. esalditik aurrera zuzentzen...\n","3387986432\n","967. esalditik aurrera zuzentzen...\n","3122247680\n","968. esalditik aurrera zuzentzen...\n","3269901824\n","969. esalditik aurrera zuzentzen...\n","5106082304\n","970. esalditik aurrera zuzentzen...\n","4920099840\n","971. esalditik aurrera zuzentzen...\n","4991070208\n","972. esalditik aurrera zuzentzen...\n","9228836352\n","973. esalditik aurrera zuzentzen...\n","5324167680\n","974. esalditik aurrera zuzentzen...\n","4774282752\n","975. esalditik aurrera zuzentzen...\n","5250079744\n","976. esalditik aurrera zuzentzen...\n","8122459648\n","977. esalditik aurrera zuzentzen...\n","4934029824\n","978. esalditik aurrera zuzentzen...\n","4118900736\n","979. esalditik aurrera zuzentzen...\n","4960908288\n","980. esalditik aurrera zuzentzen...\n","2662106624\n","981. esalditik aurrera zuzentzen...\n","6314600960\n","982. esalditik aurrera zuzentzen...\n","6387433984\n","983. esalditik aurrera zuzentzen...\n","9099826688\n","984. esalditik aurrera zuzentzen...\n","9347964416\n","985. esalditik aurrera zuzentzen...\n","9912180736\n","986. esalditik aurrera zuzentzen...\n","7657147904\n","987. esalditik aurrera zuzentzen...\n","6414737920\n","988. esalditik aurrera zuzentzen...\n","5752068096\n","989. esalditik aurrera zuzentzen...\n","10274575872\n","990. esalditik aurrera zuzentzen...\n","8296857088\n","991. esalditik aurrera zuzentzen...\n","9030126080\n","992. esalditik aurrera zuzentzen...\n","10182802944\n","993. esalditik aurrera zuzentzen...\n","7057825792\n","994. esalditik aurrera zuzentzen...\n","10148719104\n","995. esalditik aurrera zuzentzen...\n","6561845248\n","996. esalditik aurrera zuzentzen...\n","8626271744\n","997. esalditik aurrera zuzentzen...\n","6166546944\n","998. esalditik aurrera zuzentzen...\n","10274575872\n","999. esalditik aurrera zuzentzen...\n","2573337600\n","1000. esalditik aurrera zuzentzen...\n","16.085056479771932 minutu behar izan ditu.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["12.53922210132088"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"O9jvKaZ_uLP-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592164763132,"user_tz":-120,"elapsed":180303,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"1a4089c4-29c7-49d2-bc36-a6d9c8bd9a86"},"source":["# BERRIA\n","\n","with torch.no_grad():\n","    zuzendua = zuzendu_beam(model, dev1, 4, batch_size_val)\n","#with open('hobea1beam1.txt', 'w') as f:\n","#    f.write('\\n'.join(zuzendua))\n","references = [[esaldia[2].split()] for esaldia in dev1]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","144829952\n","13. esalditik aurrera zuzentzen...\n","143969280\n","25. esalditik aurrera zuzentzen...\n","143944704\n","37. esalditik aurrera zuzentzen...\n","144006144\n","49. esalditik aurrera zuzentzen...\n","144399360\n","61. esalditik aurrera zuzentzen...\n","144227328\n","73. esalditik aurrera zuzentzen...\n","144412160\n","85. esalditik aurrera zuzentzen...\n","144288768\n","97. esalditik aurrera zuzentzen...\n","144866816\n","109. esalditik aurrera zuzentzen...\n","149980160\n","121. esalditik aurrera zuzentzen...\n","145382912\n","133. esalditik aurrera zuzentzen...\n","145088000\n","145. esalditik aurrera zuzentzen...\n","145125376\n","157. esalditik aurrera zuzentzen...\n","144965632\n","169. esalditik aurrera zuzentzen...\n","145420288\n","181. esalditik aurrera zuzentzen...\n","145346560\n","193. esalditik aurrera zuzentzen...\n","145469440\n","205. esalditik aurrera zuzentzen...\n","145469440\n","217. esalditik aurrera zuzentzen...\n","145924608\n","229. esalditik aurrera zuzentzen...\n","145887232\n","241. esalditik aurrera zuzentzen...\n","145690624\n","253. esalditik aurrera zuzentzen...\n","146072064\n","265. esalditik aurrera zuzentzen...\n","145838080\n","277. esalditik aurrera zuzentzen...\n","145899520\n","289. esalditik aurrera zuzentzen...\n","146035200\n","301. esalditik aurrera zuzentzen...\n","146232320\n","313. esalditik aurrera zuzentzen...\n","146232320\n","325. esalditik aurrera zuzentzen...\n","146355200\n","337. esalditik aurrera zuzentzen...\n","146723840\n","349. esalditik aurrera zuzentzen...\n","147805184\n","361. esalditik aurrera zuzentzen...\n","146957312\n","373. esalditik aurrera zuzentzen...\n","147621888\n","385. esalditik aurrera zuzentzen...\n","147805696\n","397. esalditik aurrera zuzentzen...\n","147031552\n","409. esalditik aurrera zuzentzen...\n","148668928\n","421. esalditik aurrera zuzentzen...\n","148482048\n","433. esalditik aurrera zuzentzen...\n","147683328\n","445. esalditik aurrera zuzentzen...\n","147523584\n","457. esalditik aurrera zuzentzen...\n","147707904\n","469. esalditik aurrera zuzentzen...\n","148261376\n","481. esalditik aurrera zuzentzen...\n","147929088\n","493. esalditik aurrera zuzentzen...\n","148322816\n","505. esalditik aurrera zuzentzen...\n","149158400\n","517. esalditik aurrera zuzentzen...\n","148174848\n","529. esalditik aurrera zuzentzen...\n","148826624\n","541. esalditik aurrera zuzentzen...\n","149096448\n","553. esalditik aurrera zuzentzen...\n","148814336\n","565. esalditik aurrera zuzentzen...\n","149465600\n","577. esalditik aurrera zuzentzen...\n","148740608\n","589. esalditik aurrera zuzentzen...\n","149281280\n","601. esalditik aurrera zuzentzen...\n","149650944\n","613. esalditik aurrera zuzentzen...\n","149270016\n","625. esalditik aurrera zuzentzen...\n","149650944\n","637. esalditik aurrera zuzentzen...\n","149060608\n","649. esalditik aurrera zuzentzen...\n","149873152\n","661. esalditik aurrera zuzentzen...\n","152210432\n","673. esalditik aurrera zuzentzen...\n","150339584\n","685. esalditik aurrera zuzentzen...\n","150511616\n","697. esalditik aurrera zuzentzen...\n","150204416\n","709. esalditik aurrera zuzentzen...\n","150721024\n","721. esalditik aurrera zuzentzen...\n","150302720\n","733. esalditik aurrera zuzentzen...\n","150757888\n","745. esalditik aurrera zuzentzen...\n","150155776\n","757. esalditik aurrera zuzentzen...\n","152062976\n","769. esalditik aurrera zuzentzen...\n","151262720\n","781. esalditik aurrera zuzentzen...\n","151988224\n","793. esalditik aurrera zuzentzen...\n","151963648\n","805. esalditik aurrera zuzentzen...\n","152467968\n","817. esalditik aurrera zuzentzen...\n","152122880\n","829. esalditik aurrera zuzentzen...\n","153488896\n","841. esalditik aurrera zuzentzen...\n","153563648\n","853. esalditik aurrera zuzentzen...\n","156375040\n","865. esalditik aurrera zuzentzen...\n","153415168\n","877. esalditik aurrera zuzentzen...\n","159633920\n","889. esalditik aurrera zuzentzen...\n","154166784\n","901. esalditik aurrera zuzentzen...\n","154240000\n","913. esalditik aurrera zuzentzen...\n","158396416\n","925. esalditik aurrera zuzentzen...\n","160096256\n","937. esalditik aurrera zuzentzen...\n","158855680\n","949. esalditik aurrera zuzentzen...\n","160727040\n","961. esalditik aurrera zuzentzen...\n","160280576\n","973. esalditik aurrera zuzentzen...\n","164329472\n","985. esalditik aurrera zuzentzen...\n","164670976\n","997. esalditik aurrera zuzentzen...\n","2.98683473666509 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cNQsgT_4uPeQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592164861111,"user_tz":-120,"elapsed":875,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"1d885ab5-69af-4b9e-827d-7422830950b5"},"source":["bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.555426657563137"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"uxCAzcL4pLo7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"ok","timestamp":1592164879958,"user_tz":-120,"elapsed":775,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c2dff88c-6356-42da-c0bb-7f5655c8588b"},"source":["for candidate in candidates[:30]:\n","    print(' '.join(candidate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Impius haec tam culta novalia miles habebit !\n","- Zure adiskidea .\n","Baina beranduegi da :\n","Baina , zer zen hura ?\n","Rosanna Spearman \" .\n","Ez al da arraroa ?\n","Colin berriro gelditu zen .\n","- Ralph !\n","Hain da melodiatsua eta betea .\n","Eta bere Dulcinea ?\n","Afarian , Siziliako itsasertzetan lehorreratu zenetik , eta nesken xarma , aita Pirronearen austeritatea eta Don Fabriziaren portaera handiak konbentzitu zuten Donnafugata jauregia ez zela Kapraroko bandidoaren deskubrua , eta ziur aski bizirik irtengo zela .\n","Denak erosten ari ziren .\n","Ederra zen .\n","Ah !\n","Orain bi ditut .\n","magistratuak eta epailetza eta exekuzio artifizialaren beste ofizial batzuk ; saria eta zigorra ( subiranotasunaren egoitza betetzeko erkide diren zati bakoitza bere eginkizuna betetzeko mugi dadin ) , gorputz naturalean gauza bera egiten duten nerbioak dira ; dirua eta aberastasunak , kualitate partikular bakoitzaren indarra , salus populuaren edo segurtasuna da , haren kontseilari artifizialak , haren gorputz artifizialak beharrezkoak baitira .\n","Jimmyk aurkitu zuenean , ez zion poliziari deitu .\n","ideal hura , hain zuzen ere , beren ideal propioa da , eta agian beste inor irudikatzen dute , beraiek ere gaur egun sortutako izpiritualizatuenak dira , bere gerrari eta esploratzaileen talde aurreratuenak , bere faltsukeriarik apalena , delikagarriena , sedukzio-forma delikatua .\n","Hegoaldean , ez dago esklaborik ez esklaborik .\n","Oraintsu behintzat , Derwatt-en kasuan eta orain Mafia madarikatuarekin ?\n","Beste mahai bat hartzen ausartuko ote zen L ' Aigle Noir hoteleko tabernan , Reevesek Trevannyrekin elkartzen zuenean ?\n","A , bai :\n","Neure idazmahaira itzuli eta eseri egin nintzen , eta denbora pixka bat eman nuen Menendez bezalako txantajista bat zergatik ote zen galdetzen , Menendezek bezala garrantzizkoa , nire bulegoan sartzeko denbora alferrik galtzea merezi zuela uste izango nuen , sudurrik ez sartzeko ohartarazteagatik , minutu batzuk besterik gabe , Sewell Endicott-en antzeko abisu bat hartu eta gero .\n","Katolikoen artean , erlijiosoa bi elementuz osatua dago : apaizak eta herriak .\n","gerra bat zen , gerra bortitz , indartsu eta sinpatikoa , non ez baitzen enperadorerik , mugazainik , mugazainik , kolore eta antzeko beste gauza batzuk estilotik , funtsean apaingarri , frustoria eta luxuzkoak , baizik eta arnasa hartzeko aire falta zitzaion edonori , eta bizitza ongi dastatzen ez zuenari , bere adierazpen atsegin eta atseginaren adierazpena ematen zion , gure zibilizazioaren suntsipen orokorra prestatzeko .\n","7 . Horregatik gogamena arretaz aztertzen badugu eta ezagutzarako bidea hartzen duen bidea aztertzen badugu , uste dut , gogamenak kontenplazioan edo disziplinetan erabil dezakeen ideia bat eskuratu ondoren , besteekin komunikatzea komeni zaion ideia izan daitekeela , lehenengo gauza hori izenarekin abstraitzea da , eta horren barruan gordetzea , oroimenean bezala , nolabait esateko .\n","E ?\n","Gure etxe-animaliak hasiera batean gizaki basatiak aukeratuak izan zirela suposa dezakegu , baliagarriak zirelako eta gatibutasunean erraz hazten direlako , eta ez distantzia handitan garrai zitezkeenez gero , etxe-animalien gaitasun arrunta , klima ez bakarrik klimei eusteko gaitasun ez-ohikoa , baizik eta erabat ugalkorrak direnengan ere ( askoz ziurragoa berau ) , argumentu bat erabil daiteke , animalia baten tamainako arrazonamendu bat bezala , beste animalia batzuk oso erraz ohitu ahal izango liratekeelako , natur egoeran oso zabal izatera .\n","Estatu gorena , bere burua salbatzea bera , hipnosismo orokor hura eta azkenean lortutako lasaitasun hura , beti beren baitan misteriotzat hartzen dira , zeinarentzat sinbolo gorenenak ere ez baitira aski adieraztearren , gauzen sakonera itzultzea eta itzultzea , \" jakitea \" , \" egia \" , \" egia \" ren askapena , \" egia \" ren , \" helburu oro \" , \" gaizkiaren \" eta \" gaizkiaren \" nahia den aldetik \" askatzea bezala .\n","Zuen kontra madarikazio hori , ene etsaiok !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5RjQt4gftD0v","colab_type":"code","colab":{}},"source":["luzerak_es = [len(esaldia[0]) for esaldia in dev1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VeDzCRTMv_tB","colab_type":"code","colab":{}},"source":["luzerak_es = np.array(luzerak_es)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQ4FT5oSwHNP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592164924668,"user_tz":-120,"elapsed":673,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"261fa03d-eddb-4e6f-a14b-3717381f3bd7"},"source":["l_sort = np.sort(luzerak_es)\n","print(l_sort[249])\n","print(l_sort[499])\n","print(l_sort[574])\n","print(l_sort[999])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["15\n","27\n","31\n","120\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t4ydw__jxCWL","colab_type":"code","colab":{}},"source":["indizeak = luzerak_es.argsort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8vvtVCFxwvX","colab_type":"code","colab":{}},"source":["references_ord = [references[i] for i in indizeak]\n","candidates_ord = [candidates[i] for i in indizeak]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-6m1Q5hy5wV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585930107736,"user_tz":-120,"elapsed":795,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"230bf7ba-b9e8-4019-90fd-d76eb8f09976"},"source":["# ZAHARRA:\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[:250], \n","                                             candidates_ord[:250])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27.679988144489755"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"HwZLUqKHzIjL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585930129567,"user_tz":-120,"elapsed":706,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"88c9c9bb-40b8-45ba-ecca-4e26bfef217e"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[250:500], \n","                                             candidates_ord[250:500])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17.73227442765904"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"jec5QPJKzU1u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585930152211,"user_tz":-120,"elapsed":985,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"53de8e47-7dcb-49fa-ee90-20d5a5104518"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[500:750], \n","                                             candidates_ord[500:750])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11.748609887457283"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"YVTv8cw_zaS0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585930168409,"user_tz":-120,"elapsed":1762,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"e5cb5a16-7f45-4db7-ca0c-78575d405327"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[750:], \n","                                             candidates_ord[750:])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.011854293752503"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"oeI3WzYxzeD_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592165063118,"user_tz":-120,"elapsed":1058,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"f54b7fc8-37b9-4743-bcc8-1e71368f9d34"},"source":["# BERRIA:\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[:250], \n","                                             candidates_ord[:250])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[250:500], \n","                                             candidates_ord[250:500])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[500:750], \n","                                             candidates_ord[500:750])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[750:], \n","                                             candidates_ord[750:])*100\n","print(bleu)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["27.69981759750736\n","17.73457374739113\n","11.89313866067449\n","8.962512903319245\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZOqF7_XOdkSu","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1_0lTfI0DV_","colab_type":"text"},"source":["### OpenSubtitles proba"]},{"cell_type":"code","metadata":{"id":"HMPAgmivdxz5","colab_type":"code","colab":{}},"source":["itzultzeko = []\n","erreferentziak = []\n","with open('OpenSubtitles/OSprobatzeko-es.txt') as f_es,\\\n","     open('OpenSubtitles/OSprobatzeko-en.txt') as f_en,\\\n","     open('OpenSubtitles/OSprobatzeko-eu.txt') as f_eu:\n","    for lerroa_es, lerroa_en, lerroa_eu in zip(f_es, f_en, f_eu):\n","        itzultzeko.append([tokenizatu_str(lerroa_es), \n","                           tokenizatu_str(lerroa_en)])\n","        erreferentziak.append([tokenizatu_konparatzeko_str(lerroa_eu).split()])\n","itzultzeko_zenb = [[bpe_hirurak.encode(jat[0])[:max_seq_len], \n","                    bpe_hirurak.encode(jat[1])[:max_seq_len]] \n","                   for jat in itzultzeko]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D-p2EDLee71d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587066746850,"user_tz":-120,"elapsed":177012,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"57fd09e3-4ed1-431b-aa8b-3f979b024544"},"source":["zuzendua = zuzendu_beam(model, itzultzeko_zenb, 4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["8898122240\n","1. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12240512000\n","1. esalditik aurrera zuzentzen...\n","9585114624\n","12. esalditik aurrera zuzentzen...\n","10756860928\n","23. esalditik aurrera zuzentzen...\n","10072006656\n","34. esalditik aurrera zuzentzen...\n","9385370112\n","45. esalditik aurrera zuzentzen...\n","9480626688\n","56. esalditik aurrera zuzentzen...\n","9605915136\n","67. esalditik aurrera zuzentzen...\n","11274030080\n","78. esalditik aurrera zuzentzen...\n","9493271040\n","89. esalditik aurrera zuzentzen...\n","9892434432\n","100. esalditik aurrera zuzentzen...\n","9591986688\n","111. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12118494720\n","111. esalditik aurrera zuzentzen...\n","9106714624\n","116. esalditik aurrera zuzentzen...\n","11831613952\n","121. esalditik aurrera zuzentzen...\n","9160329728\n","126. esalditik aurrera zuzentzen...\n","9506221568\n","131. esalditik aurrera zuzentzen...\n","9289573888\n","136. esalditik aurrera zuzentzen...\n","9761620992\n","141. esalditik aurrera zuzentzen...\n","9180479488\n","146. esalditik aurrera zuzentzen...\n","9111875584\n","151. esalditik aurrera zuzentzen...\n","9160299008\n","156. esalditik aurrera zuzentzen...\n","9171819008\n","161. esalditik aurrera zuzentzen...\n","9111875584\n","166. esalditik aurrera zuzentzen...\n","9070817792\n","171. esalditik aurrera zuzentzen...\n","9829035520\n","176. esalditik aurrera zuzentzen...\n","9414416384\n","181. esalditik aurrera zuzentzen...\n","9216942080\n","186. esalditik aurrera zuzentzen...\n","9493180416\n","191. esalditik aurrera zuzentzen...\n","9339016704\n","196. esalditik aurrera zuzentzen...\n","9285884416\n","201. esalditik aurrera zuzentzen...\n","9192042496\n","206. esalditik aurrera zuzentzen...\n","9166068224\n","211. esalditik aurrera zuzentzen...\n","9216942080\n","216. esalditik aurrera zuzentzen...\n","9480188928\n","221. esalditik aurrera zuzentzen...\n","10044292608\n","226. esalditik aurrera zuzentzen...\n","9671856128\n","231. esalditik aurrera zuzentzen...\n","9335247360\n","236. esalditik aurrera zuzentzen...\n","9220097024\n","241. esalditik aurrera zuzentzen...\n","9278906368\n","246. esalditik aurrera zuzentzen...\n","9239004160\n","251. esalditik aurrera zuzentzen...\n","9957076480\n","256. esalditik aurrera zuzentzen...\n","9587102208\n","261. esalditik aurrera zuzentzen...\n","9306548736\n","266. esalditik aurrera zuzentzen...\n","9223167488\n","271. esalditik aurrera zuzentzen...\n","9166074368\n","276. esalditik aurrera zuzentzen...\n","9169037312\n","281. esalditik aurrera zuzentzen...\n","9497521152\n","286. esalditik aurrera zuzentzen...\n","11114336768\n","291. esalditik aurrera zuzentzen...\n","9357874176\n","296. esalditik aurrera zuzentzen...\n","9220012544\n","301. esalditik aurrera zuzentzen...\n","9174697472\n","306. esalditik aurrera zuzentzen...\n","9239004160\n","311. esalditik aurrera zuzentzen...\n","9168946688\n","316. esalditik aurrera zuzentzen...\n","9220103168\n","321. esalditik aurrera zuzentzen...\n","9168946688\n","326. esalditik aurrera zuzentzen...\n","9285799936\n","331. esalditik aurrera zuzentzen...\n","9216826880\n","336. esalditik aurrera zuzentzen...\n","9519237632\n","341. esalditik aurrera zuzentzen...\n","9686715392\n","346. esalditik aurrera zuzentzen...\n","9292929536\n","351. esalditik aurrera zuzentzen...\n","9350195712\n","356. esalditik aurrera zuzentzen...\n","9292656640\n","361. esalditik aurrera zuzentzen...\n","9519176192\n","366. esalditik aurrera zuzentzen...\n","9229458944\n","371. esalditik aurrera zuzentzen...\n","9289212928\n","376. esalditik aurrera zuzentzen...\n","9232613888\n","381. esalditik aurrera zuzentzen...\n","9438618112\n","386. esalditik aurrera zuzentzen...\n","9171794432\n","391. esalditik aurrera zuzentzen...\n","9166025216\n","396. esalditik aurrera zuzentzen...\n","9309961728\n","401. esalditik aurrera zuzentzen...\n","9514841600\n","406. esalditik aurrera zuzentzen...\n","9292656640\n","411. esalditik aurrera zuzentzen...\n","9380185088\n","416. esalditik aurrera zuzentzen...\n","9666845184\n","421. esalditik aurrera zuzentzen...\n","9442670080\n","426. esalditik aurrera zuzentzen...\n","9282319360\n","431. esalditik aurrera zuzentzen...\n","9376440320\n","436. esalditik aurrera zuzentzen...\n","9346463232\n","441. esalditik aurrera zuzentzen...\n","9232644608\n","446. esalditik aurrera zuzentzen...\n","9434680832\n","451. esalditik aurrera zuzentzen...\n","9532204544\n","456. esalditik aurrera zuzentzen...\n","9601040384\n","461. esalditik aurrera zuzentzen...\n","9379991552\n","466. esalditik aurrera zuzentzen...\n","9454838272\n","471. esalditik aurrera zuzentzen...\n","9510524928\n","476. esalditik aurrera zuzentzen...\n","9514847232\n","481. esalditik aurrera zuzentzen...\n","9306518016\n","486. esalditik aurrera zuzentzen...\n","9354055680\n","491. esalditik aurrera zuzentzen...\n","9395244032\n","496. esalditik aurrera zuzentzen...\n","9558359552\n","501. esalditik aurrera zuzentzen...\n","9358002688\n","506. esalditik aurrera zuzentzen...\n","9296131072\n","511. esalditik aurrera zuzentzen...\n","10022009856\n","516. esalditik aurrera zuzentzen...\n","9292687360\n","521. esalditik aurrera zuzentzen...\n","9296131072\n","526. esalditik aurrera zuzentzen...\n","9365174784\n","531. esalditik aurrera zuzentzen...\n","9968854528\n","536. esalditik aurrera zuzentzen...\n","9819500544\n","541. esalditik aurrera zuzentzen...\n","9438055936\n","546. esalditik aurrera zuzentzen...\n","9536532992\n","551. esalditik aurrera zuzentzen...\n","9814238208\n","556. esalditik aurrera zuzentzen...\n","9507643904\n","561. esalditik aurrera zuzentzen...\n","9376530944\n","566. esalditik aurrera zuzentzen...\n","9438617600\n","571. esalditik aurrera zuzentzen...\n","9619570688\n","576. esalditik aurrera zuzentzen...\n","9633575936\n","581. esalditik aurrera zuzentzen...\n","9514853376\n","586. esalditik aurrera zuzentzen...\n","9527876096\n","591. esalditik aurrera zuzentzen...\n","9624218624\n","596. esalditik aurrera zuzentzen...\n","9413980160\n","601. esalditik aurrera zuzentzen...\n","9656864768\n","606. esalditik aurrera zuzentzen...\n","9522194432\n","611. esalditik aurrera zuzentzen...\n","9726331904\n","616. esalditik aurrera zuzentzen...\n","9701531648\n","621. esalditik aurrera zuzentzen...\n","10244841984\n","626. esalditik aurrera zuzentzen...\n","9935084544\n","631. esalditik aurrera zuzentzen...\n","9376428032\n","636. esalditik aurrera zuzentzen...\n","9519194112\n","641. esalditik aurrera zuzentzen...\n","9462905344\n","646. esalditik aurrera zuzentzen...\n","9610317824\n","651. esalditik aurrera zuzentzen...\n","9840617472\n","656. esalditik aurrera zuzentzen...\n","9535844864\n","661. esalditik aurrera zuzentzen...\n","9923865600\n","666. esalditik aurrera zuzentzen...\n","9824657920\n","671. esalditik aurrera zuzentzen...\n","9619582976\n","676. esalditik aurrera zuzentzen...\n","9751132160\n","681. esalditik aurrera zuzentzen...\n","9548692992\n","686. esalditik aurrera zuzentzen...\n","9803664384\n","691. esalditik aurrera zuzentzen...\n","9536539136\n","696. esalditik aurrera zuzentzen...\n","9716335616\n","701. esalditik aurrera zuzentzen...\n","9716335616\n","706. esalditik aurrera zuzentzen...\n","9815255552\n","711. esalditik aurrera zuzentzen...\n","9831116288\n","716. esalditik aurrera zuzentzen...\n","11205557248\n","721. esalditik aurrera zuzentzen...\n","10122665472\n","726. esalditik aurrera zuzentzen...\n","9721309696\n","731. esalditik aurrera zuzentzen...\n","9711436288\n","736. esalditik aurrera zuzentzen...\n","9540904960\n","741. esalditik aurrera zuzentzen...\n","9918302720\n","746. esalditik aurrera zuzentzen...\n","9726258688\n","751. esalditik aurrera zuzentzen...\n","10017293312\n","756. esalditik aurrera zuzentzen...\n","9929447936\n","761. esalditik aurrera zuzentzen...\n","10290722816\n","766. esalditik aurrera zuzentzen...\n","10045548032\n","771. esalditik aurrera zuzentzen...\n","9845843456\n","776. esalditik aurrera zuzentzen...\n","9731262976\n","781. esalditik aurrera zuzentzen...\n","9731262976\n","786. esalditik aurrera zuzentzen...\n","10051455488\n","791. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12057674240\n","791. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12066619392\n","791. esalditik aurrera zuzentzen...\n","9144739328\n","792. esalditik aurrera zuzentzen...\n","9075966464\n","793. esalditik aurrera zuzentzen...\n","9031753216\n","794. esalditik aurrera zuzentzen...\n","9146044928\n","795. esalditik aurrera zuzentzen...\n","9717756416\n","796. esalditik aurrera zuzentzen...\n","9156016640\n","797. esalditik aurrera zuzentzen...\n","9024798208\n","798. esalditik aurrera zuzentzen...\n","8995739136\n","799. esalditik aurrera zuzentzen...\n","9045808640\n","800. esalditik aurrera zuzentzen...\n","9025649152\n","801. esalditik aurrera zuzentzen...\n","9102217728\n","802. esalditik aurrera zuzentzen...\n","9028275712\n","803. esalditik aurrera zuzentzen...\n","9009398784\n","804. esalditik aurrera zuzentzen...\n","9045808640\n","805. esalditik aurrera zuzentzen...\n","9057610240\n","806. esalditik aurrera zuzentzen...\n","9048644096\n","807. esalditik aurrera zuzentzen...\n","9100030464\n","808. esalditik aurrera zuzentzen...\n","9043990016\n","809. esalditik aurrera zuzentzen...\n","9071763968\n","810. esalditik aurrera zuzentzen...\n","9095569920\n","811. esalditik aurrera zuzentzen...\n","9064549888\n","812. esalditik aurrera zuzentzen...\n","9028275712\n","813. esalditik aurrera zuzentzen...\n","9153516032\n","814. esalditik aurrera zuzentzen...\n","9198193152\n","815. esalditik aurrera zuzentzen...\n","9088561664\n","816. esalditik aurrera zuzentzen...\n","9063514624\n","817. esalditik aurrera zuzentzen...\n","9010965504\n","818. esalditik aurrera zuzentzen...\n","9043947008\n","819. esalditik aurrera zuzentzen...\n","9178018304\n","820. esalditik aurrera zuzentzen...\n","9133555712\n","821. esalditik aurrera zuzentzen...\n","9001723392\n","822. esalditik aurrera zuzentzen...\n","9126508544\n","823. esalditik aurrera zuzentzen...\n","8994968064\n","824. esalditik aurrera zuzentzen...\n","9153454592\n","825. esalditik aurrera zuzentzen...\n","9062516224\n","826. esalditik aurrera zuzentzen...\n","9060519424\n","827. esalditik aurrera zuzentzen...\n","9042085376\n","828. esalditik aurrera zuzentzen...\n","9044871680\n","829. esalditik aurrera zuzentzen...\n","9082239488\n","830. esalditik aurrera zuzentzen...\n","9101096448\n","831. esalditik aurrera zuzentzen...\n","9105563136\n","832. esalditik aurrera zuzentzen...\n","9082239488\n","833. esalditik aurrera zuzentzen...\n","8996454912\n","834. esalditik aurrera zuzentzen...\n","9069462016\n","835. esalditik aurrera zuzentzen...\n","9126508544\n","836. esalditik aurrera zuzentzen...\n","9223362048\n","837. esalditik aurrera zuzentzen...\n","9102217728\n","838. esalditik aurrera zuzentzen...\n","9061530112\n","839. esalditik aurrera zuzentzen...\n","8936074240\n","840. esalditik aurrera zuzentzen...\n","9146044928\n","841. esalditik aurrera zuzentzen...\n","9088592384\n","842. esalditik aurrera zuzentzen...\n","9175431680\n","843. esalditik aurrera zuzentzen...\n","9089664512\n","844. esalditik aurrera zuzentzen...\n","9016682496\n","845. esalditik aurrera zuzentzen...\n","9092788736\n","846. esalditik aurrera zuzentzen...\n","9052361216\n","847. esalditik aurrera zuzentzen...\n","9016682496\n","848. esalditik aurrera zuzentzen...\n","8944900096\n","849. esalditik aurrera zuzentzen...\n","9151027712\n","850. esalditik aurrera zuzentzen...\n","9075929600\n","851. esalditik aurrera zuzentzen...\n","9142287872\n","852. esalditik aurrera zuzentzen...\n","9044920832\n","853. esalditik aurrera zuzentzen...\n","9084346880\n","854. esalditik aurrera zuzentzen...\n","9201037824\n","855. esalditik aurrera zuzentzen...\n","9053292032\n","856. esalditik aurrera zuzentzen...\n","9086497280\n","857. esalditik aurrera zuzentzen...\n","9196474880\n","858. esalditik aurrera zuzentzen...\n","9202411008\n","859. esalditik aurrera zuzentzen...\n","9067514368\n","860. esalditik aurrera zuzentzen...\n","9113436672\n","861. esalditik aurrera zuzentzen...\n","9135964160\n","862. esalditik aurrera zuzentzen...\n","9083330048\n","863. esalditik aurrera zuzentzen...\n","9069498880\n","864. esalditik aurrera zuzentzen...\n","8984358400\n","865. esalditik aurrera zuzentzen...\n","9085394432\n","866. esalditik aurrera zuzentzen...\n","9114508800\n","867. esalditik aurrera zuzentzen...\n","9105563136\n","868. esalditik aurrera zuzentzen...\n","9178067456\n","869. esalditik aurrera zuzentzen...\n","9127746560\n","870. esalditik aurrera zuzentzen...\n","9091765760\n","871. esalditik aurrera zuzentzen...\n","9153479168\n","872. esalditik aurrera zuzentzen...\n","9088604672\n","873. esalditik aurrera zuzentzen...\n","9108963840\n","874. esalditik aurrera zuzentzen...\n","9050487296\n","875. esalditik aurrera zuzentzen...\n","9131264000\n","876. esalditik aurrera zuzentzen...\n","9049562624\n","877. esalditik aurrera zuzentzen...\n","9048588800\n","878. esalditik aurrera zuzentzen...\n","9105563136\n","879. esalditik aurrera zuzentzen...\n","9135964160\n","880. esalditik aurrera zuzentzen...\n","9131264000\n","881. esalditik aurrera zuzentzen...\n","9224888832\n","882. esalditik aurrera zuzentzen...\n","9066479104\n","883. esalditik aurrera zuzentzen...\n","9065536000\n","884. esalditik aurrera zuzentzen...\n","9542427648\n","885. esalditik aurrera zuzentzen...\n","9155992064\n","886. esalditik aurrera zuzentzen...\n","9127746560\n","887. esalditik aurrera zuzentzen...\n","9227758080\n","888. esalditik aurrera zuzentzen...\n","9033491968\n","889. esalditik aurrera zuzentzen...\n","9059557888\n","890. esalditik aurrera zuzentzen...\n","9113436672\n","891. esalditik aurrera zuzentzen...\n","9101151744\n","892. esalditik aurrera zuzentzen...\n","9154735616\n","893. esalditik aurrera zuzentzen...\n","9046782464\n","894. esalditik aurrera zuzentzen...\n","9108963840\n","895. esalditik aurrera zuzentzen...\n","9229229568\n","896. esalditik aurrera zuzentzen...\n","9137153024\n","897. esalditik aurrera zuzentzen...\n","9128935424\n","898. esalditik aurrera zuzentzen...\n","8971077120\n","899. esalditik aurrera zuzentzen...\n","9125387264\n","900. esalditik aurrera zuzentzen...\n","9151027712\n","901. esalditik aurrera zuzentzen...\n","9110085120\n","902. esalditik aurrera zuzentzen...\n","9152259584\n","903. esalditik aurrera zuzentzen...\n","9064549888\n","904. esalditik aurrera zuzentzen...\n","9197798912\n","905. esalditik aurrera zuzentzen...\n","9112278528\n","906. esalditik aurrera zuzentzen...\n","9203735040\n","907. esalditik aurrera zuzentzen...\n","9231340032\n","908. esalditik aurrera zuzentzen...\n","9277102080\n","909. esalditik aurrera zuzentzen...\n","9459638272\n","910. esalditik aurrera zuzentzen...\n","9141914624\n","911. esalditik aurrera zuzentzen...\n","9268071424\n","912. esalditik aurrera zuzentzen...\n","9153479168\n","913. esalditik aurrera zuzentzen...\n","9113418240\n","914. esalditik aurrera zuzentzen...\n","9158468096\n","915. esalditik aurrera zuzentzen...\n","9368584192\n","916. esalditik aurrera zuzentzen...\n","9283461120\n","917. esalditik aurrera zuzentzen...\n","9203735040\n","918. esalditik aurrera zuzentzen...\n","9212029440\n","919. esalditik aurrera zuzentzen...\n","9132452864\n","920. esalditik aurrera zuzentzen...\n","9034342912\n","921. esalditik aurrera zuzentzen...\n","9560175616\n","922. esalditik aurrera zuzentzen...\n","9071471104\n","923. esalditik aurrera zuzentzen...\n","9110060544\n","924. esalditik aurrera zuzentzen...\n","9263552512\n","925. esalditik aurrera zuzentzen...\n","9255292416\n","926. esalditik aurrera zuzentzen...\n","9274190848\n","927. esalditik aurrera zuzentzen...\n","9240792576\n","928. esalditik aurrera zuzentzen...\n","9316988928\n","929. esalditik aurrera zuzentzen...\n","9320226816\n","930. esalditik aurrera zuzentzen...\n","9114557952\n","931. esalditik aurrera zuzentzen...\n","9040453120\n","932. esalditik aurrera zuzentzen...\n","9182008832\n","933. esalditik aurrera zuzentzen...\n","9165982208\n","934. esalditik aurrera zuzentzen...\n","9112321536\n","935. esalditik aurrera zuzentzen...\n","9120152064\n","936. esalditik aurrera zuzentzen...\n","9115673088\n","937. esalditik aurrera zuzentzen...\n","9341600256\n","938. esalditik aurrera zuzentzen...\n","9117909504\n","939. esalditik aurrera zuzentzen...\n","9155992064\n","940. esalditik aurrera zuzentzen...\n","9046782464\n","941. esalditik aurrera zuzentzen...\n","9162231296\n","942. esalditik aurrera zuzentzen...\n","9183314432\n","943. esalditik aurrera zuzentzen...\n","9382868992\n","944. esalditik aurrera zuzentzen...\n","8972990976\n","945. esalditik aurrera zuzentzen...\n","9229235712\n","946. esalditik aurrera zuzentzen...\n","9214818816\n","947. esalditik aurrera zuzentzen...\n","9214818816\n","948. esalditik aurrera zuzentzen...\n","9163481600\n","949. esalditik aurrera zuzentzen...\n","9036063232\n","950. esalditik aurrera zuzentzen...\n","9233502720\n","951. esalditik aurrera zuzentzen...\n","9167177216\n","952. esalditik aurrera zuzentzen...\n","9252244992\n","953. esalditik aurrera zuzentzen...\n","9207866880\n","954. esalditik aurrera zuzentzen...\n","9117866496\n","955. esalditik aurrera zuzentzen...\n","9272596480\n","956. esalditik aurrera zuzentzen...\n","9188512256\n","957. esalditik aurrera zuzentzen...\n","9070460416\n","958. esalditik aurrera zuzentzen...\n","9214695936\n","959. esalditik aurrera zuzentzen...\n","9321870336\n","960. esalditik aurrera zuzentzen...\n","9413129216\n","961. esalditik aurrera zuzentzen...\n","9291396096\n","962. esalditik aurrera zuzentzen...\n","9246574080\n","963. esalditik aurrera zuzentzen...\n","9240792576\n","964. esalditik aurrera zuzentzen...\n","9340114944\n","965. esalditik aurrera zuzentzen...\n","9321510912\n","966. esalditik aurrera zuzentzen...\n","9220323840\n","967. esalditik aurrera zuzentzen...\n","9395485696\n","968. esalditik aurrera zuzentzen...\n","9308829696\n","969. esalditik aurrera zuzentzen...\n","9473219584\n","970. esalditik aurrera zuzentzen...\n","10059680768\n","971. esalditik aurrera zuzentzen...\n","10332176384\n","972. esalditik aurrera zuzentzen...\n","9542427648\n","973. esalditik aurrera zuzentzen...\n","9275662336\n","974. esalditik aurrera zuzentzen...\n","9271155712\n","975. esalditik aurrera zuzentzen...\n","9509182464\n","976. esalditik aurrera zuzentzen...\n","9338465280\n","977. esalditik aurrera zuzentzen...\n","9368232960\n","978. esalditik aurrera zuzentzen...\n","9088388608\n","979. esalditik aurrera zuzentzen...\n","9439247360\n","980. esalditik aurrera zuzentzen...\n","9418829824\n","981. esalditik aurrera zuzentzen...\n","9620022784\n","982. esalditik aurrera zuzentzen...\n","9316746240\n","983. esalditik aurrera zuzentzen...\n","9684731392\n","984. esalditik aurrera zuzentzen...\n","9628999168\n","985. esalditik aurrera zuzentzen...\n","9583955968\n","986. esalditik aurrera zuzentzen...\n","9864139264\n","987. esalditik aurrera zuzentzen...\n","9402661888\n","988. esalditik aurrera zuzentzen...\n","9603355648\n","989. esalditik aurrera zuzentzen...\n","9763325952\n","990. esalditik aurrera zuzentzen...\n","9740415488\n","991. esalditik aurrera zuzentzen...\n","9973507584\n","992. esalditik aurrera zuzentzen...\n","9819427328\n","993. esalditik aurrera zuzentzen...\n","9766714880\n","994. esalditik aurrera zuzentzen...\n","9673739776\n","995. esalditik aurrera zuzentzen...\n","10096479232\n","996. esalditik aurrera zuzentzen...\n","11016137216\n","997. esalditik aurrera zuzentzen...\n","10652973056\n","998. esalditik aurrera zuzentzen...\n","10332733440\n","999. esalditik aurrera zuzentzen...\n","12758269952\n","1000. esalditik aurrera zuzentzen...\n","2.919056185086568 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w_v0J8nllJub","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587067545498,"user_tz":-120,"elapsed":1565,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"969e889d-af5f-45c2-dcaa-f63f53d820c4"},"source":["for jatorrizkoa, itzulpena in zip(erreferentziak[:50], zuzendua[:50]):\n","    print('JAT:', ' '.join(jatorrizkoa[0]))\n","    print('ITZ:', ' '.join(berrezarri_maiuskulak(itzulpena)))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["JAT: Ez duzu galtzen ezer 2016ra begira ￭.\n","ITZ: 2016an ez du inolako aukerarik ￭.\n","\n","JAT: Uste dut bazela zerbait Charlesek zuen hitzordu baten gainekoa ￭.\n","ITZ: Charlesek egondako zita bati buruz zerbait bazela iruditzen zait ￭. Norekin ￭?\n","\n","JAT: Goazen ￭!\n","ITZ: - Hortxe izango da ￭. Tira ￭.\n","\n","JAT: Zorionez ￭, nire ahizpa hilik dago . ￭. ￭.\n","ITZ: Zorionez nere ahizpa hila da ￭.\n","\n","JAT: -￭ Zer ￭? -￭ Zeri egiten diozu barre ￭?\n","ITZ: - Zeri egiten diok barre ￭?\n","\n","JAT: -￭ Nola du izena ￭?\n","ITZ: - Nola du izena ￭?\n","\n","JAT: Bera zen falta zitzaidan bakarra ￭. Street Art-eko jendeak esaten zuen ￭: \"￭ Ez dauka telefonorik ￭. ￭\"\n","ITZ: Bera bezalakoa zen ￭. ￭. ￭. nik ez nuen bakarra ￭. Eta kalean egondako jendeak esaten ziaten ￭: \"￭ Bai ￭, ez dauka telefonorik ￭\" ￭.\n","\n","JAT: Hauxe da familia ￭.\n","ITZ: Hura ￭, familia da ￭.\n","\n","JAT: Hamaika urtetik hona ￭.\n","ITZ: Hamaika urte ￭.\n","\n","JAT: Azkar ￭.\n","ITZ: Idatzi behar da ￭.\n","\n","JAT: Eta min egiten zizun hori jada ez dagoela espero dut ￭.\n","ITZ: Eta traba egiten dizun hura joana dela ￭.\n","\n","JAT: Ni ez naiz horrelakoa ￭.\n","ITZ: Eta hori ez naiz ni ￭.\n","\n","JAT: Burdina-Hiria da ￭, Eboshi Anderea da jabea ￭. Meategietatik atera eta burdina egiten dugu ￭.\n","ITZ: Lady Eboshi Myriun da ￭. Burdin egiten dugu hemen hondarretan ￭.\n","\n","JAT: Bayley ￭, nire bulegora ￭.\n","ITZ: Bayley ￭, nire bulegora ￭.\n","\n","JAT: Altxa besoak txori baten antzera ￭.\n","ITZ: Jaso zure besoak txori baten modura ￭.\n","\n","JAT: Jess ￭, ez ￭!\n","ITZ: Jess ￭! ￭, ez ￭!\n","\n","JAT: Amaitu da gure eguna ￭!\n","ITZ: Bukatu da gure eguna ￭!\n","\n","JAT: Goazen ￭, goazen ￭, goazen ￭!\n","ITZ: Tira ￭, tira ￭.\n","\n","JAT: Itxaropena behar du ￭.\n","ITZ: Esperantzaren beharra dauka ￭.\n","\n","JAT: Ez ￭. Ate okerra ￭.\n","ITZ: Gaizki egina ￭. Gaizki egina ￭.\n","\n","JAT: Baina landarekoa jaso izan dut ￭, bai ￭.\n","ITZ: - Nik arbasorik bai ￭!\n","\n","JAT: Neska hori oso gaizki dago ￭.\n","ITZ: Madarikatua ￭!\n","\n","JAT: Nirea zara ￭, Etta Place ￭.\n","ITZ: Nirea zara ￭, Etta Place ￭.\n","\n","JAT: - . ￭. ￭.￭ kotxea badut ￭, etorri nahi duzue gurekin ￭?\n","ITZ: - ￭. ￭. ￭.￭ kotxe bat badut ￭, gurekin etorri nahi duzue ￭?\n","\n","JAT: Tren geltokitik gertu ￭, uste dut ￭.\n","ITZ: Tren geltokiaren ondoan ￭, nik uste ￭.\n","\n","JAT: Horrela ￭, nola bukatu du munduak ￭?\n","ITZ: Hau da ￭, nola heldu da inoiz horrela ￭?\n","\n","JAT: Joan beharko genuke ￭, ospa egin ￭.\n","ITZ: Bagoaz ￭.\n","\n","JAT: Mutilok ￭! Aleman Beldurgarria ikusi dut ￭!\n","ITZ: Ikusi nuen nola Schary ￭. ￭. ￭.\n","\n","JAT: Hasierako kostuak ohi baino altuagoak dira ￭, baina ￭. ￭. ￭. bakarrak dira ￭, eta luzera ￭. ￭. ￭.\n","ITZ: Hasierako kostuak goratuak izan arren ￭. ￭. ￭. gastuez bakarrik eta luzarora ￭. ￭. ￭.\n","\n","JAT: Asmatu duzu ￭.\n","ITZ: Bai ￭! Polita ￭.\n","\n","JAT: Ellen andereñoa ￭, zoragarri aritu zara ￭.\n","ITZ: Ellen andereñoa ￭, ezin ederrago aritu zinen ￭.\n","\n","JAT: Esaten ari nintzen zure emazteak hemen egon behar duela arrazoi garbi batengatik ￭. Eta Berardelli irakaslea bat etorriko da nirekin ￭.\n","ITZ: Zure emaztea hemen egoteagatik ezinbestekoa izango zela pentsatzen genuen ￭. Eta Berardelli irakaslea ados egongo da nirekin ￭.\n","\n","JAT: Guztiz estirilizatzen dute ￭. ￭. ￭. Bitxia ￭.\n","ITZ: Esteriliza ￭, guztiz irrigarria da ￭.\n","\n","JAT: Ekitaldiz ekitaldi ibili naiz ￭. Harritzen naiz gose izatea Dunbarrekin bildu ostean ￭.\n","ITZ: Ez naiz harritzen Dunbarekin elkartu ondoren jateko gogoa izatea ￭.\n","\n","JAT: Presidenteak hau gera lezake ￭.\n","ITZ: Lehendakariak luma-kolpe batez geldiaraz zezakeen hau ￭.\n","\n","JAT: -￭ Lasaitu zaitez ￭.\n","ITZ: - Lasaitu hadi ￭!\n","\n","JAT: Nor izango ￭, eta Franco generala izan gidaria ￭.\n","ITZ: Franko jenerala omen zen ￭, eta hark gidatu omen zuen ￭.\n","\n","JAT: Ez esan ezer eta ez da ezer jazoko ￭.\n","ITZ: Ahoa hertsirik eduki eta dena ondo egongo da ￭.\n","\n","JAT: Zer aholku eman zion medikuak ￭?\n","ITZ: Zer gomendatu zioten horri buruz ￭?\n","\n","JAT: Gizon batekin maitasuna egin ￭? Umeak izan ￭?\n","ITZ: Gizon batenganako maitasuna piztu ￭?\n","\n","JAT: -￭ Eta hobe duzu Jeanek zehazki . ￭. ￭. zer gertatu den kontatzea inori errua bota aurretik ￭, ￭. ￭. ￭. ez baitut uste Jeanek inolako errurik duenik ￭.\n","ITZ: Hobe duzu Jeanen atzamarraz seinalatu baino lehen aurkitzea ￭.\n","\n","JAT: Baina zure etxean zaude ￭, lehengusu Hubert ￭.\n","ITZ: Nolanahi ere ￭, Hubert ￭, hona etorri zinen ￭.\n","\n","JAT: Esan zuen ￭, hori gertatzean ￭, esan behar genuela ￭, eta hitzez hitz diot ￭: \"￭ Zoazte ipurtzulotik hartzera ￭! ￭\" ￭.\n","ITZ: Hori gertatzen zenean esan zuen ￭, esan beharko genukeela ￭, eta iskanbila franko egingo dut ￭: \"￭ Begira ezazue ￭! ￭\"\n","\n","JAT: Herrialde musulman batean gaude ￭, felazio bat ere ezin dut enkargatu ￭!\n","ITZ: Musulmanen herrialdean gaude ￭, ezin dut makilarik aurkitu ￭!\n","\n","JAT: Adore handia behar da hori gainditzeko ￭.\n","ITZ: Adorea behar da hori gainditzeko ￭.\n","\n","JAT: Gizon bat behar duzu ￭.\n","ITZ: gizon baten beharra daukazu\n","\n","JAT: -￭ Basoan ￭? -￭ Bai ￭. Ez al da arraroa ￭?\n","ITZ: - Basoan ala ￭?\n","\n","JAT: - Zerbaitek kezkatzen zaitu ￭.\n","ITZ: - Zerbaitek gogaitzen hau ￭.\n","\n","JAT: -￭ Idatz al diezazuket ￭?\n","ITZ: Idatz diezazuket ￭?\n","\n","JAT: Oraindik ikusten dudan lagun bakarrenetakoa ￭.\n","ITZ: Oraindik ikusten ditudan lagun bakanetako bat ￭.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QyUXG1mTim9X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587067110520,"user_tz":-120,"elapsed":2128,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"95b263a6-0e31-4c80-d916-f150ee98c14f"},"source":["candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(erreferentziak, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15.005688280254311"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6CO2-_FB0FmL"},"source":["## Emaitzak 'orig'"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sxHtjTp80FmM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592165175892,"user_tz":-120,"elapsed":4063,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6de20a4a-8d7d-4519-b3cc-5829b7890cf6"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('EhuHac/modeloaorig-20.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"esoDBDtA0FmT","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592165215502,"user_tz":-120,"elapsed":27043,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4bc814ee-deb4-402d-b821-aa8b7c1543a6"},"source":["zuzendua = zuzendu_zenbakitua(model, dev1, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["26.068169116973877 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_HDwinRy0FmY","colab":{}},"source":["references = [[esaldia[2].split()] for esaldia in dev1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kxWMlojb0Fme","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592165226587,"user_tz":-120,"elapsed":3035,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"46115997-f1ca-4f69-c790-4946201db7e6"},"source":["references[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['Impius', 'hæc', 'tam', 'culta', 'novalia', 'miles', 'habebit', '!']]"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wgzWhEHZ0Fmi","colab":{}},"source":["candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PGHI6k800Fmk","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585930478241,"user_tz":-120,"elapsed":1711,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"13a28846-862f-4ea6-c0ce-440b9ce1c595"},"source":["# ZAHARRA:\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.427221417960189"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"v-iosQSAcW_d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592165249583,"user_tz":-120,"elapsed":743,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4462bf4b-5a6e-4286-8790-01ca54005614"},"source":["# BERRIA:\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.423759826841561"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5mKuYDTj0Fmn","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"ok","timestamp":1592165333183,"user_tz":-120,"elapsed":957,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"baee6b21-83e4-4789-b7c6-2a2bcc2fdc2e"},"source":["for reference in references[:30]:\n","    print(' '.join(reference[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Impius hæc tam culta novalia miles habebit !\n","\" Zure lagun \" .\n","Baina beranduegi da :\n","Baina zer zen hura ?\n","Rosanna Spearman\n","Ez da bitxia ?\n","Colin berriro gelditu zen .\n","- Ralph !\n","Hain da melodiatsu eta betea .\n","Eta haren Dulcinea ?\n","Afarian lehen aldiz jan zuen ondo Siziliako itsasertzak ikutu zituenetik , eta nesken edertasunak , aita Pirroneren austeritateak eta Don Fabrizioren manera handiek sinestarazi egin zioten azkenik Donnafugatako jauregia ez zela Capraro bandiduaren kobazuloa eta segur aski bizirik irtengo zela handik ;\n","Denak erosten ari ziren .\n","Ederra zen .\n","A !\n","Orain bi dauzkat .\n","epailetzako eta exekutiboko magistratuak eta beste funtzionari batzuk dituzu artikulazio artifizialak ; saria eta zigorra , berriz , subiranotasunaren guneari loturik dauden artikulazio eta gorputzadarrak mugiarazten dituztenak bakoitzak bere eginkizuna bete dezan , zainak dituzu , gorputz naturalean eginkizun huraxe bera dutenak ; menbro partikular bakoitzaren dirua eta aberastasunak , indarra dira ; salus populi edo herri-segurtasuna , helburu duena ; aholkulariak , gorputz artifizial horri ezagutu beharreko gauza guztiak iradokitzen dizkiotenak , haren memoria dira ; ekitatea eta legeak , arrazoi eta nahimen artifiziala ; konkordia , osasuna ; sedizioa , eritasuna ;\n","Jimmyk aurkitu zuenean ez zion poliziari deitu .\n","ideal hura hain zuzen ere beren ideal dute , berek , eta agian beste inork ez , errepresentatzen dute gaur hura , berak dira ilorrik izpiritualduena , gerrari eta miaketarien tropa aurreratuena , beren sedukzio-era maltzur , delikatu , atzemaezinezkoena :\n","Hegoaldean ez dago familiarik esklabuak ez izateko bezain behartsurik .\n","Azkenaldi hartan behintzat , Derwatt kasuan , eta orain Mafia madarikatuarekin ?\n","Ausartuko ote zen beste mahai baten esertzera L ' Aigle Noir hoteleko jangelan edo tabernan , Reeves Trevannyrekin elkarrizketatzen zenean ?\n","A , bai :\n","Mahaira itzuli eta eserita denbora piska batean nere artean pentsatzen aritu nintzen ea zergatik Menendez bezalako gaizkile lokal aski inportanteak pentsatzen zuen merezi zuela bere denbora galtzeak nere bulegora etorri eta muturrik ez sartzeko berak zuzenean esaten , hain zuzen ere minutu batuk lehenago Sewell Endicottek beste antzeko abisu bat , nahiz eta beste modu batera , eman ondoren .\n","Katolikoen artean , gizarte erlijiosoa bi elementuz bakarrik osatzen da : apaiza eta herria .\n","guda zen , guda gogorra , hari onekoa , guztiz sinpatikoa , eta bertan ez zegoen kaiserren , errepublikaren , lurralde mugen , bandera eta kolore eta antzerako gauza apaingarri eta teatralen , azken batean , ergelkerien aztarrenik , eta bertan aldiz arnas hartzeko espaziorik ez zuenak eta bizitza benaz atsegingarri topatzen ez zuenak bere amorruari kolpeka irtenbidea ematen zion eta hojalatazko mundu zibilizatuari xahuketa osoa prestatzen saiatzen zen bakoitza .\n","7 . Horregatik , gogamenaren higidurak arretaz begiratu eta ezagutzarako normalean zein bide hartzen duen ikusten jartzen bagara , uste dut aurkituko dugula gogamenak kontenplazioan edo diskurtsoan erabil dezakeela uste duen ideia bat erdiesten duelarik , lehenbizi ideia hori abstraitu eta izen bat jartzen diola eta ideia bere biltegian , oroimenean , gordetzen duela espezie bateko gauzen esentzia barne hartuz , izen hori beti esentzia horren seinale izango delarik .\n","E ?\n","Gizaki ez-zibilizatuak gure etxe-animaliak baliagarri zitzaizkiolako eta hesipeko egoeran erraz umatzen zirelako , eta gero distantzia handietara garraia zitezkeela ikusi zuelako , haiek aukeratu zituela inferi genezakeenez gero , gure etxe-animalia guztiek klima ezberdinei eusteko ezezik , haietan erabat umekor izateko duten ahalmena ( erizpide seguruagoa berau ) argudiotzat erabil daiteke honako honen aldeko argudiotzat , alegia , gaur natur egoeran dauden beste animaliarik askok ere jasan ditzakeela klima oso ezberdinak .\n","Egoera gorena , berrerospena bera , hipnotizazio erabateko hura eta azkenean lorturiko azken gelditasun hura , haiek beti bere baitako misteriotzat hartzen dituzte , zein adierazteko ez baitira aski ezta sinbolo jasoenak ere , gauzen barrenera itzuli eta bihurtzeaz , hitz egiten dutenak bezalakoak lilura orotatik askatzeaz , \" jakiteaz \" , \" egiaz \" , \" izateaz \" , xede , desira eta egintza ororekiko desatxikitzeaz , ongia eta gaizkiaz haraindi batez ere .\n","Madarikazio hau zuen kontra , ene etsaiok !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Jz1-XWYq0Fmq","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"ok","timestamp":1592165337646,"user_tz":-120,"elapsed":921,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"84faf1b5-7296-4000-d205-06f3b0abc592"},"source":["for candidate in candidates[:30]:\n","    print(' '.join(candidate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Impius haec tam culta novalia miles habebit !\n","\" Zure adiskidea \" .\n","Baina beranduegi duk :\n","Baina zer gertatzen zen hura ?\n","Rosanna Spearman\n","Ez al da arraroa ?\n","Colin gelditu egin zen berriro .\n","- Ralph !\n","Hain da melodiatsua eta betea .\n","Eta bere Dulcinea ?\n","Afarian ongi jan zuen aurreneko aldiz Sizilia orbanean lehorreratu zenetik , eta nesken xarma , aita Pirrone-ren austeritatea eta Don Fabriziorako manera onak , Donnafugatako jauregia ez zela Capraro bandiduaren antroa , eta ziurrenik bizirik aterako zela uste izan zuen .\n","Erosten ari ziren denak .\n","Zoragarria zen .\n","A !\n","Orain bi dauzkat .\n","magistratu eta beste ofizialak , epailearen eta exekutiboaren beste artikulazio artifizialak ; subiranotasunaren egikaritzari dagozkion boto eta zigorrari , zeinetatik subiranotasunaren egikaritzen diren guztiak higitzen diren , gorputz naturalean gauza bera egiten duten zainak dira ; eta gorputz partikular bakoitzaren dirua eta aberastasunak , salus populi-a , edo herriaren segurtasuna , kontseilari komuna , gorputz guztiak ezagutzea da ;\n","Jimmyk aurkitu zuenean , ez zion poliziari deitu .\n","ideal hura bera da beraien ideal , beraiek ere , eta agian beste inork ez , gaur egun errepresentatzen dute , beren izpiritualena , beren burukominen aurreratzen dutenena , bere gerragin eta esploratzaileen talde aurreratua , bere sedukzio-forma fin eta gupidagabeena .\n","Hegoaldean ez dago esklaborik hain familia pobreik .\n","Derwatt kasuaren kasuan behintzat , eta orain Mafia madarikatua ?\n","Beste mahai bat ere hartzera ausartuko ote zen L ' Aigle Noir hoteleko tabernan , edo Reevesek Trevannyrekin izandako elkarrizketan ?\n","A , bai :\n","Nire idazmahaira itzuli , eseri eta denbora puska batean egon nintzen galdezka zergatik Menendez bezalako xantajista garrantzitsu eta garrantzitsua den Menendezek bezala , bere denbora alferrik galtzen zuela uste izango zuen nire bulegoan sudurra ez sartzeko , eta , hain zuzen , Sewell Endicottik abisua jaso ondoren , nahiz eta hitz desberdinak adierazi .\n","Katolikoen artean , erlijio-elkartea bi elementuz bakarrik osatzen da : apaiza eta herria .\n","Gerra bazegoen , gerra gogorra , latza , bidezkoa , eta , non ez baitzen enperadorea , errepublikak , banderak , banderak eta antzekoak , eta estiloa , eta beste batzuk , berriz , hondoan , fruserrak , dena falta zitzaion , arnas hartzeko eta ongi dastatzen ez zuen edonork , bere bizitza atsegin zuenari , bere gogokoago eta gogobeterik ez zuen mundu zibilizatuaren suntsipenari aurre egiten eta herria zibilizatuaren suntsipenerako prestatzen saiatzen zen .\n","7 . Beraz , izenak gogamenaren mugimenduak arretaz aztertuz gero , ikusiko dugu normalean ezagutzarako bidean hartzen duen bidea , uste izateko moduan , gogamenak ideia bat hartu duela , kontenplazioaren bidez edo diskurtsoaren bidez , eta komunikatzeko balio duen ideiaren bidez , eta orduan izena jarri eta oroimenean jarri , eta oroimenean , oroimenean , gauza hori beti izenaren bidez , izen hori beti izenaren bidez inprimatzen duen moduan .\n","E ?\n","Gure etxe-animaliak , uste dugunez , gizakiak erabilgarriak zirelako aukeratutakoak izan ziren hasieran , eta , erraz haziak zirelako , eta ez , geroago , distantzia handienetara eraman ahal izan zituelako , gure etxe-animalien ahalmen aparteko eta klima desberdinen menpe ez ezik , erabat ernalkorrak direnez ere , hau da , hau erabat ernalkorragoa izatea , argumentu batean erabil daiteke , gaur egun beste animalia batzuk oso egoera oso-osoan eraman ahal izanen liratekeelako .\n","Egoera gorena , berrerospena bera , hipnosi orokor hura eta azkenik lortutako lasaitasuna , beti misterioak bezala hartzen dira , zeinari buruz ez baita sinbolorik gorenenak ere ez diren adierazteko , gauzen muinera itzultzeaz eta itzultzeaz eta itzuleraz hitz egiten dutenek bezala , ilusio guztietatik askapenetik askatze orotatik , \" egia \" ren , \" egia \" ren , \" izatearen aldetik \" , \" egia \" ren , egitearen eskuetatik , baita ekintza orotatik ere , eta gaitzarengandik .\n","Madarikazio hau zuen kontra , ene etsaiak !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-HqvGUFJ0Fmu","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1585930620451,"user_tz":-120,"elapsed":11979,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4c0e7bc7-1876-407f-a7df-c54dfc99df12"},"source":["zuzendua_train = zuzendu_zenbakitua(model, train[:1000], batch_size)\n","references = [[berrezarri_maiuskulak(bpe_hirurak.decode(esaldia[2][1:-1])[0])]\n","              for esaldia in train[:1000]]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua_train]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["8.939042568206787 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["51.13598484058552"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X_9Ph54N0Fmy","colab":{}},"source":["itzultzeko = [['el trabajo que yo hice estaba muy bien',\n","               'the work ｟C i did was very good'],\n","              ['el trabajo que yo hice estaba muy bien ￭.',\n","               'the work ｟C i did was very good ￭.'],\n","              ['el trabajo que él hizo estaba muy bien',\n","               'the work he did was very well done'],\n","              ['mi nombre es ｟C jokin ￭.',\n","               'my name is ｟C jokin ￭.'],\n","              ['｟C bittor está completamente de acuerdo',\n","               '｟C bittor completely agrees with it'],\n","              ['｟C irá a ｟C croacia a estudiar el año que viene ￭.',\n","              '｟C she will study in ｟C croatia next year ￭.'],\n","              ['｟C el secretario general del ｟C parlament inicia los trámites para relevar a ｟C torra como diputado',\n","               '｟C the general secretary of the ｟C parliament of ｟C catalonia begins the procedures to relieve ｟C torra as a deputy'],\n","              ['｟C pese a todo ￭, le expliqué cómo me estaba sintiendo yo',\n","               '｟C nevertheless ￭, I told him how I was feeling'],\n","              ['｟C mientras lo llevaba a casa ￭, lo saqué del envoltorio ￭.',\n","               '｟C as ｟C i was taking it home, ｟C i took it out of the package ￭.'],\n","              ['lo que dijo era parcialmente correcto',\n","               'what she said was partially correct'],\n","              ['｟C este va a ser un ejemplo bastante largo ￭. ｟C veremos si funciona hasta el final o no ￭, ya que a veces suele dar problemas si se alarga mucho ￭.',\n","              '｟C this will be a quite long example ￭. ｟C we will see if it works until the end or not ￭, since sometimes it has problems if it gets too long']]\n","itzultzeko_zenb = [[bpe_hirurak.encode(jat[0]), bpe_hirurak.encode(jat[1])] \n","                   for jat in itzultzeko]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VvbKjaEP0Fm1","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1585930637679,"user_tz":-120,"elapsed":1510,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6e867eef-ad3c-491b-e435-526807fd2613"},"source":["zuzendua = zuzendu_zenbakitua(model, itzultzeko_zenb, batch_size)\n","zuzendua"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.960953950881958 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['egin nuen lana oso ondo zegoen ￭, oso ongi egina ￭;',\n"," 'egin nuen lana oso ona zen ￭.',\n"," 'berak eginiko lana ￭, oso ongi egina zegoen ￭, oso ongi egina ￭;',\n"," 'nire izena ｟C txantxin ￭.',\n"," '｟C bittor erabat ados dago berarekin ￭.',\n"," '｟C datorren urtean ikasiko du ｟C croaziara ￭.',\n"," '｟C parlamentuko idazkari orokorra ｟C torra obra-emaile gisa ｟C demokratikoa errezitatzen hasten da antzerki-idatzia ￭.',\n"," '｟C hala ere ￭, esan nion nola nengoen ni kutsatuta ￭.',\n"," '｟C etxera neraman bezala ￭, fardeletik atera nuen ￭.',\n"," 'zentzu aldetik ￭, zuzen esan zuena zen ￭.',\n"," '｟C adibide luze samarra izango da hau ￭. ｟C ikusiko dugu bukaeraraino funtzionatzen duela ￭, batzuetan arazoak izaten baititu luzeegi agertzen bada ￭.']"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KGhGGZS70Fm7","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1585930725754,"user_tz":-120,"elapsed":4357,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"84b17b66-84f6-4316-b18c-d098fe4ccd45"},"source":["zuzendua = zuzendu_beam(model, itzultzeko_zenb, 4)\n","zuzendua"],"execution_count":null,"outputs":[{"output_type":"stream","text":["285769216\n","1. esalditik aurrera zuzentzen...\n","0.06228185494740804 minutu behar izan ditu.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['egin nuen lana ￭, oso ongi egina nuen ￭;',\n"," 'egin nuen lana oso ona zen ￭.',\n"," '｟C berak eginiko lana ￭, oso ongi egina zegoen ￭.',\n"," 'nire izena ｟C txantxin ￭.',\n"," '｟C bittor erabat ados dago berarekin ￭.',\n"," '｟C datorren urtean ikasiko du ｟C croaziara ￭.',\n"," '｟C parlamentuko idazkari orokorra ￭, ｟C torra diputatu gisa ｟C parlamenturako antzerki-lanak egiten hasten da ￭.',\n"," '｟C halere ￭, nola nengoen garbi azaldu nion ￭.',\n"," '｟C etxera nentorrela ￭, fardeletik atera nuen ￭.',\n"," 'zentzu aldetik ￭, zuzen esan zuena zen ￭.',\n"," '｟C adibide luze samarra izango da hau ￭. ｟C ikusiko dugu bukaera arte funtzionatzen badu edo ez ￭, batzuetan arazoak izaten baititu luzeegiz gero ￭.']"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GQijDK8W0Fm-","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1585931220930,"user_tz":-120,"elapsed":454105,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2fd84fb9-2961-46e1-aca7-108a0b127ab1"},"source":["# ZAHARRA:\n","zuzendua = zuzendu_beam(model, dev, 4)\n","references = [[esaldia[2].split()] for esaldia in dev]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["285769216\n","1. esalditik aurrera zuzentzen...\n","1210313216\n","23. esalditik aurrera zuzentzen...\n","2548736000\n","45. esalditik aurrera zuzentzen...\n","3660364288\n","67. esalditik aurrera zuzentzen...\n","2046572544\n","89. esalditik aurrera zuzentzen...\n","3093535744\n","111. esalditik aurrera zuzentzen...\n","3503674368\n","133. esalditik aurrera zuzentzen...\n","3912965120\n","155. esalditik aurrera zuzentzen...\n","3984106496\n","177. esalditik aurrera zuzentzen...\n","6280136192\n","199. esalditik aurrera zuzentzen...\n","6065921024\n","221. esalditik aurrera zuzentzen...\n","6472404480\n","243. esalditik aurrera zuzentzen...\n","6037266432\n","265. esalditik aurrera zuzentzen...\n","5960889856\n","287. esalditik aurrera zuzentzen...\n","7697933824\n","309. esalditik aurrera zuzentzen...\n","9592717824\n","331. esalditik aurrera zuzentzen...\n","8594131456\n","353. esalditik aurrera zuzentzen...\n","9973641216\n","375. esalditik aurrera zuzentzen...\n","9193249280\n","397. esalditik aurrera zuzentzen...\n","9931862528\n","419. esalditik aurrera zuzentzen...\n","10977886720\n","441. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12402886144\n","441. esalditik aurrera zuzentzen...\n","8415470592\n","452. esalditik aurrera zuzentzen...\n","6281653760\n","463. esalditik aurrera zuzentzen...\n","5691753984\n","474. esalditik aurrera zuzentzen...\n","6054866432\n","485. esalditik aurrera zuzentzen...\n","8488209408\n","496. esalditik aurrera zuzentzen...\n","8215163392\n","507. esalditik aurrera zuzentzen...\n","6890692608\n","518. esalditik aurrera zuzentzen...\n","6938488832\n","529. esalditik aurrera zuzentzen...\n","7527288832\n","540. esalditik aurrera zuzentzen...\n","8678467584\n","551. esalditik aurrera zuzentzen...\n","8585168384\n","562. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12103617024\n","562. esalditik aurrera zuzentzen...\n","3641358336\n","567. esalditik aurrera zuzentzen...\n","6003458560\n","572. esalditik aurrera zuzentzen...\n","3694097408\n","577. esalditik aurrera zuzentzen...\n","4206463488\n","582. esalditik aurrera zuzentzen...\n","4049717760\n","587. esalditik aurrera zuzentzen...\n","3662131200\n","592. esalditik aurrera zuzentzen...\n","6828740608\n","597. esalditik aurrera zuzentzen...\n","3526751744\n","602. esalditik aurrera zuzentzen...\n","4206451200\n","607. esalditik aurrera zuzentzen...\n","4448098304\n","612. esalditik aurrera zuzentzen...\n","4531826176\n","617. esalditik aurrera zuzentzen...\n","3693591552\n","622. esalditik aurrera zuzentzen...\n","3641357824\n","627. esalditik aurrera zuzentzen...\n","5646713856\n","632. esalditik aurrera zuzentzen...\n","3536824832\n","637. esalditik aurrera zuzentzen...\n","4684767232\n","642. esalditik aurrera zuzentzen...\n","4460045312\n","647. esalditik aurrera zuzentzen...\n","5931400192\n","652. esalditik aurrera zuzentzen...\n","5888862208\n","657. esalditik aurrera zuzentzen...\n","4543674880\n","662. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12299257856\n","662. esalditik aurrera zuzentzen...\n","5652455936\n","664. esalditik aurrera zuzentzen...\n","2377822208\n","666. esalditik aurrera zuzentzen...\n","1715553280\n","668. esalditik aurrera zuzentzen...\n","1948113408\n","670. esalditik aurrera zuzentzen...\n","1706722304\n","672. esalditik aurrera zuzentzen...\n","1972087296\n","674. esalditik aurrera zuzentzen...\n","2262958592\n","676. esalditik aurrera zuzentzen...\n","3243017216\n","678. esalditik aurrera zuzentzen...\n","1976898048\n","680. esalditik aurrera zuzentzen...\n","1782658560\n","682. esalditik aurrera zuzentzen...\n","1656538112\n","684. esalditik aurrera zuzentzen...\n","1952273408\n","686. esalditik aurrera zuzentzen...\n","2082438144\n","688. esalditik aurrera zuzentzen...\n","2572890112\n","690. esalditik aurrera zuzentzen...\n","1639740416\n","692. esalditik aurrera zuzentzen...\n","1433999360\n","694. esalditik aurrera zuzentzen...\n","1961544704\n","696. esalditik aurrera zuzentzen...\n","1962539520\n","698. esalditik aurrera zuzentzen...\n","2388826112\n","700. esalditik aurrera zuzentzen...\n","2207266304\n","702. esalditik aurrera zuzentzen...\n","1728603136\n","704. esalditik aurrera zuzentzen...\n","2176742912\n","706. esalditik aurrera zuzentzen...\n","2988822016\n","708. esalditik aurrera zuzentzen...\n","3403638784\n","710. esalditik aurrera zuzentzen...\n","2289199616\n","712. esalditik aurrera zuzentzen...\n","2217532928\n","714. esalditik aurrera zuzentzen...\n","2156307968\n","716. esalditik aurrera zuzentzen...\n","2624530432\n","718. esalditik aurrera zuzentzen...\n","1745744896\n","720. esalditik aurrera zuzentzen...\n","2788417536\n","722. esalditik aurrera zuzentzen...\n","1836240384\n","724. esalditik aurrera zuzentzen...\n","2043769344\n","726. esalditik aurrera zuzentzen...\n","2995113472\n","728. esalditik aurrera zuzentzen...\n","2578585600\n","730. esalditik aurrera zuzentzen...\n","1822840320\n","732. esalditik aurrera zuzentzen...\n","2451392512\n","734. esalditik aurrera zuzentzen...\n","1737253888\n","736. esalditik aurrera zuzentzen...\n","2434582528\n","738. esalditik aurrera zuzentzen...\n","3059281408\n","740. esalditik aurrera zuzentzen...\n","2000718336\n","742. esalditik aurrera zuzentzen...\n","2782445568\n","744. esalditik aurrera zuzentzen...\n","2399578112\n","746. esalditik aurrera zuzentzen...\n","1919740928\n","748. esalditik aurrera zuzentzen...\n","2367162368\n","750. esalditik aurrera zuzentzen...\n","1831847424\n","752. esalditik aurrera zuzentzen...\n","2171680256\n","754. esalditik aurrera zuzentzen...\n","2490308608\n","756. esalditik aurrera zuzentzen...\n","2029416960\n","758. esalditik aurrera zuzentzen...\n","2470000640\n","760. esalditik aurrera zuzentzen...\n","2394128384\n","762. esalditik aurrera zuzentzen...\n","2352212480\n","764. esalditik aurrera zuzentzen...\n","2212255232\n","766. esalditik aurrera zuzentzen...\n","5592686080\n","768. esalditik aurrera zuzentzen...\n","2326002176\n","770. esalditik aurrera zuzentzen...\n","2146612224\n","772. esalditik aurrera zuzentzen...\n","2873561088\n","774. esalditik aurrera zuzentzen...\n","3020801536\n","776. esalditik aurrera zuzentzen...\n","3039983104\n","778. esalditik aurrera zuzentzen...\n","2950256640\n","780. esalditik aurrera zuzentzen...\n","3091267072\n","782. esalditik aurrera zuzentzen...\n","1845259776\n","784. esalditik aurrera zuzentzen...\n","2767745024\n","786. esalditik aurrera zuzentzen...\n","3848644608\n","788. esalditik aurrera zuzentzen...\n","2855294976\n","790. esalditik aurrera zuzentzen...\n","4462756864\n","792. esalditik aurrera zuzentzen...\n","3581224960\n","794. esalditik aurrera zuzentzen...\n","2785439744\n","796. esalditik aurrera zuzentzen...\n","2830927872\n","798. esalditik aurrera zuzentzen...\n","2732220416\n","800. esalditik aurrera zuzentzen...\n","2367885824\n","802. esalditik aurrera zuzentzen...\n","3037593600\n","804. esalditik aurrera zuzentzen...\n","2891741184\n","806. esalditik aurrera zuzentzen...\n","3371396096\n","808. esalditik aurrera zuzentzen...\n","2931578880\n","810. esalditik aurrera zuzentzen...\n","3129814528\n","812. esalditik aurrera zuzentzen...\n","2331175424\n","814. esalditik aurrera zuzentzen...\n","4467452928\n","816. esalditik aurrera zuzentzen...\n","3645140992\n","818. esalditik aurrera zuzentzen...\n","3420751872\n","820. esalditik aurrera zuzentzen...\n","2263428608\n","822. esalditik aurrera zuzentzen...\n","2687770624\n","824. esalditik aurrera zuzentzen...\n","4014133760\n","826. esalditik aurrera zuzentzen...\n","2362718720\n","828. esalditik aurrera zuzentzen...\n","2562734080\n","830. esalditik aurrera zuzentzen...\n","3533693952\n","832. esalditik aurrera zuzentzen...\n","3344356352\n","834. esalditik aurrera zuzentzen...\n","3328120320\n","836. esalditik aurrera zuzentzen...\n","3545640960\n","838. esalditik aurrera zuzentzen...\n","3818778624\n","840. esalditik aurrera zuzentzen...\n","3609622528\n","842. esalditik aurrera zuzentzen...\n","3295052288\n","844. esalditik aurrera zuzentzen...\n","4363434496\n","846. esalditik aurrera zuzentzen...\n","4143512576\n","848. esalditik aurrera zuzentzen...\n","4105772544\n","850. esalditik aurrera zuzentzen...\n","3659241472\n","852. esalditik aurrera zuzentzen...\n","4728437760\n","854. esalditik aurrera zuzentzen...\n","4395493888\n","856. esalditik aurrera zuzentzen...\n","3341052416\n","858. esalditik aurrera zuzentzen...\n","3975682048\n","860. esalditik aurrera zuzentzen...\n","3638044672\n","862. esalditik aurrera zuzentzen...\n","4434449408\n","864. esalditik aurrera zuzentzen...\n","4190704640\n","866. esalditik aurrera zuzentzen...\n","4253322240\n","868. esalditik aurrera zuzentzen...\n","3418637312\n","870. esalditik aurrera zuzentzen...\n","2934171648\n","872. esalditik aurrera zuzentzen...\n","4879287296\n","874. esalditik aurrera zuzentzen...\n","5777445376\n","876. esalditik aurrera zuzentzen...\n","4736953344\n","878. esalditik aurrera zuzentzen...\n","4075002368\n","880. esalditik aurrera zuzentzen...\n","9645316096\n","882. esalditik aurrera zuzentzen...\n","4931535872\n","884. esalditik aurrera zuzentzen...\n","5703428096\n","886. esalditik aurrera zuzentzen...\n","4975644672\n","888. esalditik aurrera zuzentzen...\n","4613395456\n","890. esalditik aurrera zuzentzen...\n","5999864320\n","892. esalditik aurrera zuzentzen...\n","4822887424\n","894. esalditik aurrera zuzentzen...\n","4621818880\n","896. esalditik aurrera zuzentzen...\n","4237650944\n","898. esalditik aurrera zuzentzen...\n","4269130752\n","900. esalditik aurrera zuzentzen...\n","4385371136\n","902. esalditik aurrera zuzentzen...\n","4814091264\n","904. esalditik aurrera zuzentzen...\n","4411468288\n","906. esalditik aurrera zuzentzen...\n","4722643968\n","908. esalditik aurrera zuzentzen...\n","4557382656\n","910. esalditik aurrera zuzentzen...\n","4865954816\n","912. esalditik aurrera zuzentzen...\n","4883004416\n","914. esalditik aurrera zuzentzen...\n","5614898688\n","916. esalditik aurrera zuzentzen...\n","5700638208\n","918. esalditik aurrera zuzentzen...\n","4213060096\n","920. esalditik aurrera zuzentzen...\n","4411480576\n","922. esalditik aurrera zuzentzen...\n","5859256320\n","924. esalditik aurrera zuzentzen...\n","10881037312\n","926. esalditik aurrera zuzentzen...\n","4339723264\n","928. esalditik aurrera zuzentzen...\n","4539860480\n","930. esalditik aurrera zuzentzen...\n","6378392576\n","932. esalditik aurrera zuzentzen...\n","7888493056\n","934. esalditik aurrera zuzentzen...\n","5898184704\n","936. esalditik aurrera zuzentzen...\n","7258417152\n","938. esalditik aurrera zuzentzen...\n","6182429184\n","940. esalditik aurrera zuzentzen...\n","7564130816\n","942. esalditik aurrera zuzentzen...\n","8580670464\n","944. esalditik aurrera zuzentzen...\n","7879033344\n","946. esalditik aurrera zuzentzen...\n","6502489088\n","948. esalditik aurrera zuzentzen...\n","6844003840\n","950. esalditik aurrera zuzentzen...\n","7046089216\n","952. esalditik aurrera zuzentzen...\n","7302599680\n","954. esalditik aurrera zuzentzen...\n","8092350976\n","956. esalditik aurrera zuzentzen...\n","8284581376\n","958. esalditik aurrera zuzentzen...\n","8750362112\n","960. esalditik aurrera zuzentzen...\n","7030573056\n","962. esalditik aurrera zuzentzen...\n","7853789696\n","964. esalditik aurrera zuzentzen...\n","8593197568\n","966. esalditik aurrera zuzentzen...\n","5958262272\n","968. esalditik aurrera zuzentzen...\n","9146496000\n","970. esalditik aurrera zuzentzen...\n","9213940224\n","972. esalditik aurrera zuzentzen...\n","9519882240\n","974. esalditik aurrera zuzentzen...\n","10064933376\n","976. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12065962496\n","976. esalditik aurrera zuzentzen...\n","9438283776\n","977. esalditik aurrera zuzentzen...\n","4452191232\n","978. esalditik aurrera zuzentzen...\n","5075266048\n","979. esalditik aurrera zuzentzen...\n","4479863296\n","980. esalditik aurrera zuzentzen...\n","5554809856\n","981. esalditik aurrera zuzentzen...\n","5302361088\n","982. esalditik aurrera zuzentzen...\n","6287632896\n","983. esalditik aurrera zuzentzen...\n","7015241216\n","984. esalditik aurrera zuzentzen...\n","7757957120\n","985. esalditik aurrera zuzentzen...\n","7568492032\n","986. esalditik aurrera zuzentzen...\n","5551540224\n","987. esalditik aurrera zuzentzen...\n","8156486144\n","988. esalditik aurrera zuzentzen...\n","7541817856\n","989. esalditik aurrera zuzentzen...\n","8877689856\n","990. esalditik aurrera zuzentzen...\n","9325278208\n","991. esalditik aurrera zuzentzen...\n","9477536768\n","992. esalditik aurrera zuzentzen...\n","8507366400\n","993. esalditik aurrera zuzentzen...\n","8156486144\n","994. esalditik aurrera zuzentzen...\n","9513735168\n","995. esalditik aurrera zuzentzen...\n","7488229888\n","996. esalditik aurrera zuzentzen...\n","6617990144\n","997. esalditik aurrera zuzentzen...\n","8586052608\n","998. esalditik aurrera zuzentzen...\n","8441797632\n","999. esalditik aurrera zuzentzen...\n","8151308800\n","1000. esalditik aurrera zuzentzen...\n","7.552836298942566 minutu behar izan ditu.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["12.609771845250894"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"EQdkM_kpebZb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592165951484,"user_tz":-120,"elapsed":158547,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"a0d0edb8-fe93-4a78-b085-59178f058011"},"source":["# BERRIA:\n","zuzendua = zuzendu_beam(model, dev1, 4, batch_size_val)\n","references = [[esaldia[2].split()] for esaldia in dev1]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["284786176\n","1. esalditik aurrera zuzentzen...\n","285796864\n","13. esalditik aurrera zuzentzen...\n","285870592\n","25. esalditik aurrera zuzentzen...\n","286288384\n","37. esalditik aurrera zuzentzen...\n","286153216\n","49. esalditik aurrera zuzentzen...\n","286497280\n","61. esalditik aurrera zuzentzen...\n","286374400\n","73. esalditik aurrera zuzentzen...\n","286510080\n","85. esalditik aurrera zuzentzen...\n","286435840\n","97. esalditik aurrera zuzentzen...\n","286964736\n","109. esalditik aurrera zuzentzen...\n","287001600\n","121. esalditik aurrera zuzentzen...\n","287038464\n","133. esalditik aurrera zuzentzen...\n","287136768\n","145. esalditik aurrera zuzentzen...\n","287174144\n","157. esalditik aurrera zuzentzen...\n","287112704\n","169. esalditik aurrera zuzentzen...\n","287419904\n","181. esalditik aurrera zuzentzen...\n","287346176\n","193. esalditik aurrera zuzentzen...\n","287665664\n","205. esalditik aurrera zuzentzen...\n","287616512\n","217. esalditik aurrera zuzentzen...\n","288219136\n","229. esalditik aurrera zuzentzen...\n","287985152\n","241. esalditik aurrera zuzentzen...\n","287985152\n","253. esalditik aurrera zuzentzen...\n","288169984\n","265. esalditik aurrera zuzentzen...\n","287936000\n","277. esalditik aurrera zuzentzen...\n","288046592\n","289. esalditik aurrera zuzentzen...\n","288280576\n","301. esalditik aurrera zuzentzen...\n","288379392\n","313. esalditik aurrera zuzentzen...\n","288379392\n","325. esalditik aurrera zuzentzen...\n","289321472\n","337. esalditik aurrera zuzentzen...\n","289394688\n","349. esalditik aurrera zuzentzen...\n","289444352\n","361. esalditik aurrera zuzentzen...\n","289530368\n","373. esalditik aurrera zuzentzen...\n","288784896\n","385. esalditik aurrera zuzentzen...\n","290673664\n","397. esalditik aurrera zuzentzen...\n","290456576\n","409. esalditik aurrera zuzentzen...\n","290468864\n","421. esalditik aurrera zuzentzen...\n","290809344\n","433. esalditik aurrera zuzentzen...\n","290568192\n","445. esalditik aurrera zuzentzen...\n","290784768\n","457. esalditik aurrera zuzentzen...\n","290821632\n","469. esalditik aurrera zuzentzen...\n","290604544\n","481. esalditik aurrera zuzentzen...\n","290616832\n","493. esalditik aurrera zuzentzen...\n","290617344\n","505. esalditik aurrera zuzentzen...\n","290797056\n","517. esalditik aurrera zuzentzen...\n","291173888\n","529. esalditik aurrera zuzentzen...\n","291334144\n","541. esalditik aurrera zuzentzen...\n","290801664\n","553. esalditik aurrera zuzentzen...\n","290764800\n","565. esalditik aurrera zuzentzen...\n","291515392\n","577. esalditik aurrera zuzentzen...\n","291395584\n","589. esalditik aurrera zuzentzen...\n","291478528\n","601. esalditik aurrera zuzentzen...\n","291355648\n","613. esalditik aurrera zuzentzen...\n","291417088\n","625. esalditik aurrera zuzentzen...\n","291618304\n","637. esalditik aurrera zuzentzen...\n","291158528\n","649. esalditik aurrera zuzentzen...\n","293661184\n","661. esalditik aurrera zuzentzen...\n","295308288\n","673. esalditik aurrera zuzentzen...\n","292683776\n","685. esalditik aurrera zuzentzen...\n","292511232\n","697. esalditik aurrera zuzentzen...\n","292401152\n","709. esalditik aurrera zuzentzen...\n","292966400\n","721. esalditik aurrera zuzentzen...\n","292646912\n","733. esalditik aurrera zuzentzen...\n","293970432\n","745. esalditik aurrera zuzentzen...\n","293122048\n","757. esalditik aurrera zuzentzen...\n","295128064\n","769. esalditik aurrera zuzentzen...\n","294081536\n","781. esalditik aurrera zuzentzen...\n","295004160\n","793. esalditik aurrera zuzentzen...\n","295633920\n","805. esalditik aurrera zuzentzen...\n","296286720\n","817. esalditik aurrera zuzentzen...\n","295351808\n","829. esalditik aurrera zuzentzen...\n","296832000\n","841. esalditik aurrera zuzentzen...\n","296299008\n","853. esalditik aurrera zuzentzen...\n","297629696\n","865. esalditik aurrera zuzentzen...\n","298468352\n","877. esalditik aurrera zuzentzen...\n","299955200\n","889. esalditik aurrera zuzentzen...\n","296722432\n","901. esalditik aurrera zuzentzen...\n","297943552\n","913. esalditik aurrera zuzentzen...\n","301529088\n","925. esalditik aurrera zuzentzen...\n","302010880\n","937. esalditik aurrera zuzentzen...\n","300487168\n","949. esalditik aurrera zuzentzen...\n","300987392\n","961. esalditik aurrera zuzentzen...\n","302638592\n","973. esalditik aurrera zuzentzen...\n","305723904\n","985. esalditik aurrera zuzentzen...\n","305112576\n","997. esalditik aurrera zuzentzen...\n","2.6251861651738486 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hzs6vcqZegtI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592165954720,"user_tz":-120,"elapsed":710,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2d8d1ee0-55bf-47f2-b5c5-04598fb78757"},"source":["bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.654898160896588"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w1AJeKtf0FnC","colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"status":"ok","timestamp":1592165974691,"user_tz":-120,"elapsed":826,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"42492965-a904-4ce2-a657-a2abd87b1457"},"source":["for candidate in candidates[:30]:\n","    print(' '.join(candidate))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Impius haec tam culta novalia miles habebit !\n","\" Zure adiskidea \" .\n","Baina beranduegi duk :\n","Baina zer gertatzen zen hura ?\n","Rosanna Spearman\n","Ez al da arraroa ?\n","Colin gelditu egin zen berriro .\n","- Ralph !\n","Hain da melodiatsua eta betea .\n","Eta bere Dulcinea ?\n","Afarian ondo jan zuen aurreneko aldiz Siziliako itsasertzean lehorreratu zenetik , eta nesken xarma , aita Pirrone-ren austeritatea eta Don Fabrizioren portaerak garbi utzi zuten Donnafugatako jauregia ez zela Capraro bandiduaren antroa , eta ziurrenik bizirik aterako zela .\n","Erosten ari ziren denak .\n","Zoragarria zen .\n","A !\n","Orain bi dauzkat .\n","magistratu eta beste ofizialak , epailearen eta exekutiboko artikulazio artifizialak ; saria eta zigorra ( subiranotasunaren egikaritzari dagozkionak eta kide bakoitzari bere eginkizuna betetzeko mugimendua ematen diotenak ) , gorputz naturalean gauza bera egiten duten nerbioak dira ; gorputz partikular bakoitzaren dirua eta aberastasunak , Salus populi-a , edo herriaren segurtasuna , kontseilariak dira ;\n","Jimmyk aurkitu zuenean , ez zion poliziari deitu .\n","ideal hori bera da beraien ideala , beraiek ere , eta agian beste inor ez , gaur errepresentatzen dute , beraiek dira beren izpiritualena , bere borrokalari eta esploratzaileen aurrerapenik aurreratuenena , haren sedukzio-forma fin eta gupidagabeena .\n","Hegoaldean ez dago hain familia pobreik esklaborik ez duenik .\n","Derwatten kasuan behintzat , eta orain Mafia madarikatua ?\n","Beste mahai bat hartzera ausartuko ote zen L ' Aigle Noir hoteleko tabernan , edo Reeves Trevannyrekin elkartu zenean ?\n","A , bai :\n","Nire idazmahaira itzuli , eseri , eta denbora puska batez egon nintzen galdezka zergatik Menendez bezalako xantajista garrantzitsu eta garrantzitsua den Menendezek bezala , bere denbora galtzea merezi zuela uste izango zuen nire bulegora etortzea eta niri sudurra ez ezkutatzea , Sewell Endicottik abisua jaso ondoren .\n","Katolikoen artean , erlijio-elkartea bi elementuz baino ez da osatzen : apaiza eta herria .\n","Gerra zegoen , gerra gogorra , latza , bidezkoa , eta oso , non ez baitzen enperadorea , errepublikak , banderak , banderak eta antzekoak , apaindurak eta teatrozaleak , hondoan frijituak , baizik arnas hartzeko airea falta zitzaiona eta bizitza ongi dastatzen ez zuen edonork bere gustukoa ematen zion mundu zibilizatuaren suntsipenari .\n","7 . Beraz , izenak gogamenaren mugimenduak arretaz aztertuz gero , ikusiko dugu normalean ezagutzarako bidean hartzen duen bideari erreparatzen badiogu , ikusiko dugu gogamenak ideia bat hartu duela , kontenplazioaren bidez edo diskurtsoaren bidez erabil dezakeena , eta orduan izen hori abstraktu egiten zaio , eta orduan oroimenean jartzen du , eta horrela oroimenean jartzen du oroimenean .\n","E ?\n","Uste dugun moduan , gure etxe-animaliak gizakiak baliagarri zirelako aukeratutakoak izan zirela jatorriz , eta erraz sendatzen zutelako , eta , aldez aurretik , distantzia handira garraiatzeko gai zirenez gero , gure etxe-animalien aparteko gaitasuna ez ezik klima ezberdinetan erabat ernalkorrak izatekoa ere ez ezik-hori askoz ere ernalkorrago ernalkorragoa ere- , argumentu trinko bat erabil daiteke gaur egun beste animalia batzuen egoera oso-lekura garraiatzeko .\n","Egoera gorena , berrerospena bera , hipnosi orokor hura eta azkenik lortutako lasaitasuna , bere baitan misterioa bezala kontsideratzen dira beti , zeinari sinbolorik gorenenak ere ez baitzaizkio adierazten , gauzen itzuleraz eta itzuleraz hitz egiten dutenek bezala , ilusio guztietatik askapenetik askatze orotatik , \" egia \" ■ atik \" , \" egia \" ren aldetik , \" egia \" ren aldetik , ekintza orotatik , baita gaitzetik ere .\n","Madarikazio hau zuen kontra , ene etsaiak !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cJmStwoL0FnG","colab":{}},"source":["luzerak_es = [len(esaldia[0]) for esaldia in dev1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"idb5H0u30FnL","colab":{}},"source":["luzerak_es = np.array(luzerak_es)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"35YpEW4m0FnO","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592166091798,"user_tz":-120,"elapsed":714,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"aa13b034-3c1e-4ed4-faa2-b8bda673040b"},"source":["l_sort = np.sort(luzerak_es)\n","print(l_sort[249])\n","print(l_sort[499])\n","print(l_sort[574])\n","print(l_sort[999])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["15\n","27\n","31\n","120\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kZ9219ip0FnR","colab":{}},"source":["indizeak = luzerak_es.argsort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Gj9H9GbW0FnW","colab":{}},"source":["references_ord = [references[i] for i in indizeak]\n","candidates_ord = [candidates[i] for i in indizeak]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YQ58Jg3V0FnZ","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585931521648,"user_tz":-120,"elapsed":522,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6352ee9a-3c49-4adf-f19f-0536638b415f"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[:250], \n","                                             candidates_ord[:250])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24.960448267164285"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OOOs480G0Fnd","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585931523217,"user_tz":-120,"elapsed":572,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"34432e1c-55d8-48f2-c3b5-3741609d2b08"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[250:500], \n","                                             candidates_ord[250:500])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17.344031393809992"]},"metadata":{"tags":[]},"execution_count":96}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XQKhL6m80Fng","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585931524676,"user_tz":-120,"elapsed":495,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"39632a4e-afa2-410e-d7bf-5f74c87c277c"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[500:750], \n","                                             candidates_ord[500:750])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11.75114176172635"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"thmE5w_r0Fnj","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585931526807,"user_tz":-120,"elapsed":576,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9517295c-0c2a-4caa-d537-daf6c2fc4c4d"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[750:], \n","                                             candidates_ord[750:])*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.750787941488738"]},"metadata":{"tags":[]},"execution_count":98}]},{"cell_type":"code","metadata":{"id":"9jNrHcHWfw83","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592166128073,"user_tz":-120,"elapsed":912,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"99694664-ed44-4a34-e6c3-6fa957cc4295"},"source":["# BERRIA:\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[:250], \n","                                             candidates_ord[:250])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[250:500], \n","                                             candidates_ord[250:500])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[500:750], \n","                                             candidates_ord[500:750])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[750:], \n","                                             candidates_ord[750:])*100\n","print(bleu)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["24.962305374696587\n","17.188752248415938\n","11.770046076655099\n","9.888378952833154\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"97j5YkYC0Fnl","colab":{}},"source":["itzultzeko = [['｟C ya lo había dicho ￭.',\n","               '｟C she had already said it ￭.'],\n","              ['｟C ya lo había dicho ￭.',\n","               '｟C i had already said it ￭.'],\n","              ['｟C fui solo una vez ￭.',\n","               '｟C i just went once ￭.'],\n","              ['｟C fui solo una vez ￭.',\n","               '｟C i went alone once ￭.'],\n","              ['｟C el tiempo vuela como una flecha',\n","               '｟C time flies like an arrow'],\n","              ['｟C a las moscas del tiempo les gusta una flecha',\n","              '｟C time flies like an arrow'],\n","              ['｟C todavía estaba tocando cuando yo llegué ￭.',\n","              '｟C he was still playing when ｟C I arrived ￭.'],\n","              #HAU KONPONDU\n","              ['｟C todavía estaba jugando cuando yo llegué ￭.',\n","              '｟C he was still playing when ｟C I arrived ￭.']]\n","itzultzeko_zenb = [[bpe_hirurak.encode(jat[0]), bpe_hirurak.encode(jat[1])] \n","                   for jat in itzultzeko]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUsfMJCq-b5D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1585933780293,"user_tz":-120,"elapsed":1420,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c3e54d46-7494-4ac7-c54c-3fe0ad509040"},"source":["zuzendua = zuzendu_beam(model, itzultzeko_zenb, 4)\n","zuzendua"],"execution_count":null,"outputs":[{"output_type":"stream","text":["285769216\n","1. esalditik aurrera zuzentzen...\n","0.011868894100189209 minutu behar izan ditu.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['｟C esana zion lehenago ere ￭.',\n"," '｟C esana nuen jada ￭.',\n"," '｟C behin bakarrik joan nintzen ￭.',\n"," '｟C behin bakarrik joan nintzen ￭.',\n"," '｟C denbora gezi batek bezala hegan doa ￭.',\n"," '｟C denborako euliei gezi bat gustatzen zaie',\n"," '｟C oraindik jotzen ari zen ni iritsi nintzenean ￭.',\n"," '｟C oraindik jostatzen ari zen ni iritsi nintzenean ￭.']"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"id":"Xm9ku9e9-u0Q","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZq44zJ1oQz0","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ru0HT0AOoRWz"},"source":["### OpenSubtitles proba"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pU1XySTUoRW1","colab":{}},"source":["itzultzeko = []\n","erreferentziak = []\n","with open('OpenSubtitles/OSprobatzeko-es.txt') as f_es,\\\n","     open('OpenSubtitles/OSprobatzeko-en.txt') as f_en,\\\n","     open('OpenSubtitles/OSprobatzeko-eu.txt') as f_eu:\n","    for lerroa_es, lerroa_en, lerroa_eu in zip(f_es, f_en, f_eu):\n","        itzultzeko.append([tokenizatu_str(lerroa_es), \n","                           tokenizatu_str(lerroa_en)])\n","        erreferentziak.append([tokenizatu_konparatzeko_str(lerroa_eu).split()])\n","itzultzeko_zenb = [[bpe_hirurak.encode(jat[0])[:max_seq_len], \n","                    bpe_hirurak.encode(jat[1])[:max_seq_len]] \n","                   for jat in itzultzeko]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xJO7W9EaoRW8","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587068703145,"user_tz":-120,"elapsed":81578,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"8b759caa-0e10-4268-db63-0ac652972fa7"},"source":["zuzendua = zuzendu_beam(model, itzultzeko_zenb, 4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","3486068224\n","23. esalditik aurrera zuzentzen...\n","1898571264\n","45. esalditik aurrera zuzentzen...\n","1311242752\n","67. esalditik aurrera zuzentzen...\n","2559486464\n","89. esalditik aurrera zuzentzen...\n","1844401152\n","111. esalditik aurrera zuzentzen...\n","3189087744\n","133. esalditik aurrera zuzentzen...\n","1658264576\n","155. esalditik aurrera zuzentzen...\n","1866757120\n","177. esalditik aurrera zuzentzen...\n","1561817088\n","199. esalditik aurrera zuzentzen...\n","1967369216\n","221. esalditik aurrera zuzentzen...\n","2487075328\n","243. esalditik aurrera zuzentzen...\n","2932886528\n","265. esalditik aurrera zuzentzen...\n","2432647168\n","287. esalditik aurrera zuzentzen...\n","2190689280\n","309. esalditik aurrera zuzentzen...\n","1851227136\n","331. esalditik aurrera zuzentzen...\n","2553499648\n","353. esalditik aurrera zuzentzen...\n","2225278464\n","375. esalditik aurrera zuzentzen...\n","3251493888\n","397. esalditik aurrera zuzentzen...\n","2610380800\n","419. esalditik aurrera zuzentzen...\n","2279762432\n","441. esalditik aurrera zuzentzen...\n","3311970304\n","463. esalditik aurrera zuzentzen...\n","3337612288\n","485. esalditik aurrera zuzentzen...\n","7217943552\n","507. esalditik aurrera zuzentzen...\n","6152856064\n","529. esalditik aurrera zuzentzen...\n","3415610880\n","551. esalditik aurrera zuzentzen...\n","4908021248\n","573. esalditik aurrera zuzentzen...\n","3811463680\n","595. esalditik aurrera zuzentzen...\n","3932004352\n","617. esalditik aurrera zuzentzen...\n","7877697024\n","639. esalditik aurrera zuzentzen...\n","3967848448\n","661. esalditik aurrera zuzentzen...\n","4845815296\n","683. esalditik aurrera zuzentzen...\n","3398153216\n","705. esalditik aurrera zuzentzen...\n","5605005312\n","727. esalditik aurrera zuzentzen...\n","4284032000\n","749. esalditik aurrera zuzentzen...\n","5861130752\n","771. esalditik aurrera zuzentzen...\n","5817293312\n","793. esalditik aurrera zuzentzen...\n","8171184128\n","815. esalditik aurrera zuzentzen...\n","6433546752\n","837. esalditik aurrera zuzentzen...\n","9201794048\n","859. esalditik aurrera zuzentzen...\n","7070173696\n","881. esalditik aurrera zuzentzen...\n","9430752768\n","903. esalditik aurrera zuzentzen...\n","11537162240\n","925. esalditik aurrera zuzentzen...\n","9504909824\n","947. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12521882624\n","947. esalditik aurrera zuzentzen...\n","5107676160\n","958. esalditik aurrera zuzentzen...\n","7587866624\n","969. esalditik aurrera zuzentzen...\n","9653673472\n","980. esalditik aurrera zuzentzen...\n","10559754752\n","991. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12352269824\n","991. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12431694848\n","991. esalditik aurrera zuzentzen...\n","Memoria betetzen ari da.\n","12373946368\n","991. esalditik aurrera zuzentzen...\n","1078492672\n","992. esalditik aurrera zuzentzen...\n","1107930624\n","993. esalditik aurrera zuzentzen...\n","926482944\n","994. esalditik aurrera zuzentzen...\n","763656192\n","995. esalditik aurrera zuzentzen...\n","1340270592\n","996. esalditik aurrera zuzentzen...\n","1745157632\n","997. esalditik aurrera zuzentzen...\n","2089074176\n","998. esalditik aurrera zuzentzen...\n","1933699584\n","999. esalditik aurrera zuzentzen...\n","5540721664\n","1000. esalditik aurrera zuzentzen...\n","1.3435365955034893 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-q8NQ30voRXB","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587068707727,"user_tz":-120,"elapsed":1714,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9f444809-5641-45f4-cdf7-676bfbc37777"},"source":["for jatorrizkoa, itzulpena in zip(erreferentziak[:50], zuzendua[:50]):\n","    print('JAT:', ' '.join(jatorrizkoa[0]))\n","    print('ITZ:', ' '.join(berrezarri_maiuskulak(itzulpena)))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["JAT: Ez duzu galtzen ezer 2016ra begira ￭.\n","ITZ: 2016koa ez da zure aukera ￭.\n","\n","JAT: Uste dut bazela zerbait Charlesek zuen hitzordu baten gainekoa ￭.\n","ITZ: Charlesek egin zuen hitzaldiaz zerbait esan zela uste dut ￭.\n","\n","JAT: Goazen ￭!\n","ITZ: Goazen ￭.\n","\n","JAT: Zorionez ￭, nire ahizpa hilik dago . ￭. ￭.\n","ITZ: Eskerrak ￭, nire arreba hil zen ￭. ￭. ￭.\n","\n","JAT: -￭ Zer ￭? -￭ Zeri egiten diozu barre ￭?\n","ITZ: -￭ Zer ￭? -￭ Nolatan egiten duk barre ￭?\n","\n","JAT: -￭ Nola du izena ￭?\n","ITZ: -￭ Nola du izena ￭?\n","\n","JAT: Bera zen falta zitzaidan bakarra ￭. Street Art-eko jendeak esaten zuen ￭: \"￭ Ez dauka telefonorik ￭. ￭\"\n","ITZ: Bera zen ￭. ￭. ￭. nik ez nuen bakarra ￭. Eta kaleko jendeak ￭, berriz ￭, denek esaten zizun ￭: \"￭ Bai ￭, ez du telefonorik ￭\" ￭.\n","\n","JAT: Hauxe da familia ￭.\n","ITZ: Hau ￭, Aita ￭.\n","\n","JAT: Hamaika urtetik hona ￭.\n","ITZ: Hamaika urte ￭.\n","\n","JAT: Azkar ￭.\n","ITZ: Hara ￭.\n","\n","JAT: Eta min egiten zizun hori jada ez dagoela espero dut ￭.\n","ITZ: Eta gogaitzen hinduena joan zitzaizula ￭.\n","\n","JAT: Ni ez naiz horrelakoa ￭.\n","ITZ: Eta hori ez naiz ni ￭.\n","\n","JAT: Burdina-Hiria da ￭, Eboshi Anderea da jabea ￭. Meategietatik atera eta burdina egiten dugu ￭.\n","ITZ: Lady Eboshi Burntown da ￭. Hementxe egiten dugu burdina lurrean ￭.\n","\n","JAT: Bayley ￭, nire bulegora ￭.\n","ITZ: Bayley ￭, nire bulegora ￭.\n","\n","JAT: Altxa besoak txori baten antzera ￭.\n","ITZ: Agur barra aldera eta zure auhen oihua ￭.\n","\n","JAT: Jess ￭, ez ￭!\n","ITZ: Jess ￭, ez ￭!\n","\n","JAT: Amaitu da gure eguna ￭!\n","ITZ: Akabo gure eguna ￭!\n","\n","JAT: Goazen ￭, goazen ￭, goazen ￭!\n","ITZ: Tira ￭, tira ￭, tira ￭!\n","\n","JAT: Itxaropena behar du ￭.\n","ITZ: Premia du ￭.\n","\n","JAT: Ez ￭. Ate okerra ￭.\n","ITZ: Gaizki egina ￭.\n","\n","JAT: Baina landarekoa jaso izan dut ￭, bai ￭.\n","ITZ: -￭ Nik arbasia ￭.\n","\n","JAT: Neska hori oso gaizki dago ￭.\n","ITZ: Jesus ￭, oso urrun dago ￭.\n","\n","JAT: Nirea zara ￭, Etta Place ￭.\n","ITZ: Zu zara nirea ￭, Etta Place ￭.\n","\n","JAT: - . ￭. ￭.￭ kotxea badut ￭, etorri nahi duzue gurekin ￭?\n","ITZ: -￭ Kotxe bat badut ￭. Gurekin etorri nahi duzue ￭?\n","\n","JAT: Tren geltokitik gertu ￭, uste dut ￭.\n","ITZ: Tren geltokiaren ondoan ￭, nik uste ￭.\n","\n","JAT: Horrela ￭, nola bukatu du munduak ￭?\n","ITZ: Hau da ￭, nola iritsi zen honantz ￭?\n","\n","JAT: Joan beharko genuke ￭, ospa egin ￭.\n","ITZ: Goazen ￭.\n","\n","JAT: Mutilok ￭! Aleman Beldurgarria ikusi dut ￭!\n","ITZ: Alemana ikusi nuen ￭!\n","\n","JAT: Hasierako kostuak ohi baino altuagoak dira ￭, baina ￭. ￭. ￭. bakarrak dira ￭, eta luzera ￭. ￭. ￭.\n","ITZ: Espero dut desabantaila garaiagoak izaten diren bitartean ￭. ￭. ￭. gutxiegi izaten dira hauek ￭, eta ￭, denboraren poderioan ￭. ￭. ￭.\n","\n","JAT: Asmatu duzu ￭.\n","ITZ: Ederki ￭.\n","\n","JAT: Ellen andereñoa ￭, zoragarri aritu zara ￭.\n","ITZ: Miss Ellen ￭, benetan bikaina izan zinen ￭.\n","\n","JAT: Esaten ari nintzen zure emazteak hemen egon behar duela arrazoi garbi batengatik ￭. Eta Berardelli irakaslea bat etorriko da nirekin ￭.\n","ITZ: Zure emaztea hemen izatea ezinbestekoa zela uste bagenuen arrazoi on batengatik zela ￭. Eta Berareli irakaslea ados egongo da nirekin ￭.\n","\n","JAT: Guztiz estirilizatzen dute ￭. ￭. ￭. Bitxia ￭.\n","ITZ: Erabat antzua duk ￭. ￭. ￭.\n","\n","JAT: Ekitaldiz ekitaldi ibili naiz ￭. Harritzen naiz gose izatea Dunbarrekin bildu ostean ￭.\n","ITZ: Seguru nago Dunbarekin elkartu ondoren goseak zaudela ￭.\n","\n","JAT: Presidenteak hau gera lezake ￭.\n","ITZ: Lehendakariak hori luma-mutur batez geldiaraz zezakeen ￭.\n","\n","JAT: -￭ Lasaitu zaitez ￭.\n","ITZ: -￭ Lasai ￭.\n","\n","JAT: Nor izango ￭, eta Franco generala izan gidaria ￭.\n","ITZ: Franco jenerala zen ￭, gidaria ￭.\n","\n","JAT: Ez esan ezer eta ez da ezer jazoko ￭.\n","ITZ: Zuk ahoa itxita edukitzen duzu eta dena ondo egongo ￭.\n","\n","JAT: Zer aholku eman zion medikuak ￭?\n","ITZ: Zer gomendatu zioten horri buruz ￭?\n","\n","JAT: Gizon batekin maitasuna egin ￭? Umeak izan ￭?\n","ITZ: Gizon batekin maitasuna egiten ￭?\n","\n","JAT: -￭ Eta hobe duzu Jeanek zehazki . ￭. ￭. zer gertatu den kontatzea inori errua bota aurretik ￭, ￭. ￭. ￭. ez baitut uste Jeanek inolako errurik duenik ￭.\n","ITZ: Hobe duzu Jeanengandik zehatz deskribatu zenuena ￭, behatzak seinalatzen hasi aurretik ￭. Jeanen errugabea dela uste dut ￭.\n","\n","JAT: Baina zure etxean zaude ￭, lehengusu Hubert ￭.\n","ITZ: Dena dela ￭, Hubert ￭, hona etxera ￭.\n","\n","JAT: Esan zuen ￭, hori gertatzean ￭, esan behar genuela ￭, eta hitzez hitz diot ￭: \"￭ Zoazte ipurtzulotik hartzera ￭! ￭\" ￭.\n","ITZ: Hori egin zutenean esan zuen ￭, esan beharko genukeela eta ni parafraseratzera noa ￭.\n","\n","JAT: Herrialde musulman batean gaude ￭, felazio bat ere ezin dut enkargatu ￭!\n","ITZ: Muslimgo herri batean gaude ￭, ezin dut kolpe bat ere eskatu ￭!\n","\n","JAT: Adore handia behar da hori gainditzeko ￭.\n","ITZ: Ausardia handia behar da hori gainditzeko ￭.\n","\n","JAT: Gizon bat behar duzu ￭.\n","ITZ: -￭ Gizonen bat behar duzulako\n","\n","JAT: -￭ Basoan ￭? -￭ Bai ￭. Ez al da arraroa ￭?\n","ITZ: -￭ Bai ￭. Ez al da arraroa ￭, e ￭?\n","\n","JAT: - Zerbaitek kezkatzen zaitu ￭.\n","ITZ: -￭ Zerbaitek gogaitzen zaitu ￭.\n","\n","JAT: -￭ Idatz al diezazuket ￭?\n","ITZ: Idatzi al diezazuket ￭?\n","\n","JAT: Oraindik ikusten dudan lagun bakarrenetakoa ￭.\n","ITZ: Oraindik ere ikusten ditudan lagun gutietako bat ￭.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TJ_GqSdGoRXG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587068724344,"user_tz":-120,"elapsed":1904,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"a229ef40-7747-4784-c0c0-b5cf6c4ff9bd"},"source":["candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(erreferentziak, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14.309749273337669"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"EcPcPX9wohC5","colab_type":"text"},"source":["## origetaos1"]},{"cell_type":"markdown","metadata":{"id":"LV0RQ1A-qr3y","colab_type":"text"},"source":["### Balidazio elkartuak"]},{"cell_type":"code","metadata":{"id":"Eh6TPfN1rdcw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1590680044490,"user_tz":-120,"elapsed":2497,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"63116aab-017d-4ebe-8b93-90160d61d052"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('HACOSDatuak/origetaos1-13.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"i5XyEabHogS0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1590677953540,"user_tz":-120,"elapsed":45545,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"018d4ad3-3784-4559-a124-8a4ed922b01b"},"source":["balidatu2(dev1, dev2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--- Balidazioa ---\n","35.766823053359985 segundo behar izan ditu zuzentzeko.\n","Batzuk (1):\n","['｟C impius h<UNK>c tam culta novalia miles habebit ￭!', '\"￭ ｟C zure laguna ￭. ￭\"', '｟C baina beranduegi da ￭:', '｟C baina zer zen hura ￭?', '\"￭ ｟C rosanna ｟C spearman ￭\" ￭.', '｟C ez al da arraroa ￭?', '｟C colin gelditu egin zen berriro ￭.', '-￭ ｟C ralph ￭!', '｟C hain da dotorea eta osoa ￭.', '｟C eta bere ｟C dulcinea ￭?', '｟C afarian ￭, aurreneko aldiz jan zuen ondo ￭, ｟C siziliako itsasertzetan lehorreratu zenetik ￭, eta ｟C aita ｟C pirrone-ren austeritatea eta ｟C don ｟C fabrizioren modaluak komentzitu zuten ｟C donnafugatako jauregia ez zela ｟C caprugaradoko antroa ￭, eta seguru aski bizirik aterako zela ￭.', '｟C denak erosten ari ziren ￭.', '｟C ederra zen ￭.', '｟C ah ￭!', '｟C orain bi dauzkat ￭.', 'magistratuak eta epailetzaren eta exekutiboaren beste ofizialak ￭, saria eta zigorra ￭, subiranotasunaren jarlekura mugatzen diren bakoitza ￭, eta kide bakoitza bere eginkizuna betetzeko mugatzen diren horietakoak ￭, gorputz naturalean gauza bera egiten duten nerbioak dira ￭; dirua eta ondasunak ￭, eta ondasunak ￭, oro ￭, populus populua edo herriaren segurtasuna dira ￭, eta ￭, orotariko aholkuak ￭, eta ￭, beraz ￭, gauza guztien ardura ￭;', '｟C jimmyk aurkitu zuenean ￭, ez zion poliziari deitu ￭.', 'ideal hori da ￭, hain zuzen ere ￭, beren ideala ￭, berek ere gaur egun ￭, beren sorkari izpiritualena ￭, bere gerra eta esploratzaileen tropa aurreratuenak ￭, bere xarmatzeko forma sentikorra ￭, xamurra ￭.', '｟C hegoaldean ez dago familiarik esklaborik ez izateko bezain behartsurik ￭.', '｟C derwatt-en kasuan ￭, behintzat ￭, eta orain ｟C mafiarekin ￭?']\n","BLEU puntuazioa (1): 11.882806171928879\n","8.288058519363403 segundo behar izan ditu zuzentzeko.\n","Batzuk (2):\n","['｟C hemen ￭.', '｟C marty ￭, musika interesgarria izan da ￭.', '｟C nondik uste duzu ｟C nick zaharrak gure janaria lortzen duela ￭?', '｟C corvetteren historia ezagutzen dugu ￭, ｟C matt ￭.', '｟C oraindik ikus ditzakegu ￭.', '｟C jaunak ￭, ｟C windom ｟C earle ｟C twin ｟C peaksera iritsi zenean mendeku bila etorri zela uste izan nuen ￭.', '｟C du ｟C pont jaunaren ama hil egin zen ￭.', '｟C erosiko duzu ￭, ｟C john ￭?', '｟C hori da arazoa ￭.', '｟C otsoen bat basoan ￭?', '｟C marchal jaunak zurekin egon nahi du ￭.', '｟C jende asko ikusi dut ￭. ￭. ￭.', '｟C zure emaztea beste gizon batekin dago eta ￭. ￭. ￭. ez dizu axola ￭?', '｟C eta argazki bat dut 1960an eta bere semea 1940ko uniformean erakusten ￭.', '｟C gero dena aldatu zen ￭.', '- ｟C zer txartel ￭?', '｟C zoaz lotara ￭, maitea ￭.', '｟C ez dakit zer gertatzen ari den ￭.', '｟B m.￭ t ｟E ￭. ｟C wentz ｟C twin ｟C peaksera dator ￭.', '｟C ziur ｟C delphinek badakiela ￭?']\n","BLEU puntuazioa (2): 26.599044004565485\n","BLEU puntuazioa (biak): 15.288110148466988\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["15.288110148466988"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"yPw9yhTx6lMr","colab_type":"text"},"source":["### 13ko greedy gorde"]},{"cell_type":"code","metadata":{"id":"CfUcXmIh6tHi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590680405157,"user_tz":-120,"elapsed":8711,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2464ea95-71b4-4773-f70b-ea15dfeab13a"},"source":["zuzendua2 = zuzendu_zenbakitua(model, dev2, batch_size_val)\n","lerroak = [' '.join(berrezarri_maiuskulak(lerroa)) for lerroa in zuzendua2]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7.933772325515747 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KmjUGAgj7HEx","colab_type":"code","colab":{}},"source":["with open('OpenSubtitles/OS-val-origetaos1-13-greedy.txt', 'w') as f:\n","    f.write('\\n'.join(lerroak))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PktR3ccHglIi","colab_type":"text"},"source":["## 'hobea2'"]},{"cell_type":"code","metadata":{"id":"bgggrVtFgphD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592166481865,"user_tz":-120,"elapsed":7062,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"79e34372-5044-4530-e85b-bc78e9cb5681"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('EhuHac/trainhobea2-18.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"bxzyLN4ihN8B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592166583728,"user_tz":-120,"elapsed":23946,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"68aac183-5472-4767-89d6-e3d26d52c53e"},"source":["zuzendua = zuzendu_zenbakitua(model, dev1, 50)\n","references = [[esaldia[2].split()] for esaldia in dev1]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100\n","bleu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.086646795272827 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["12.07539327293524"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"QUhXvwqshmoB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592166793232,"user_tz":-120,"elapsed":170656,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ee38c21d-0355-46c4-fee3-0854144e6ae6"},"source":["zuzendua = zuzendu_beam(model, dev1, 4, batch_size_val)\n","references = [[esaldia[2].split()] for esaldia in dev1]\n","candidates = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua]\n","bleu = nltk.translate.bleu_score.corpus_bleu(references, candidates)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["429390848\n","1. esalditik aurrera zuzentzen...\n","430794752\n","13. esalditik aurrera zuzentzen...\n","430524416\n","25. esalditik aurrera zuzentzen...\n","430893056\n","37. esalditik aurrera zuzentzen...\n","430757888\n","49. esalditik aurrera zuzentzen...\n","430807040\n","61. esalditik aurrera zuzentzen...\n","430979072\n","73. esalditik aurrera zuzentzen...\n","431163904\n","85. esalditik aurrera zuzentzen...\n","431138816\n","97. esalditik aurrera zuzentzen...\n","431569408\n","109. esalditik aurrera zuzentzen...\n","431557120\n","121. esalditik aurrera zuzentzen...\n","431839744\n","133. esalditik aurrera zuzentzen...\n","431692288\n","145. esalditik aurrera zuzentzen...\n","431877120\n","157. esalditik aurrera zuzentzen...\n","431717376\n","169. esalditik aurrera zuzentzen...\n","432270336\n","181. esalditik aurrera zuzentzen...\n","431950848\n","193. esalditik aurrera zuzentzen...\n","433335296\n","205. esalditik aurrera zuzentzen...\n","432221184\n","217. esalditik aurrera zuzentzen...\n","433593856\n","229. esalditik aurrera zuzentzen...\n","432540672\n","241. esalditik aurrera zuzentzen...\n","432491520\n","253. esalditik aurrera zuzentzen...\n","433741312\n","265. esalditik aurrera zuzentzen...\n","432540672\n","277. esalditik aurrera zuzentzen...\n","432799232\n","289. esalditik aurrera zuzentzen...\n","433851904\n","301. esalditik aurrera zuzentzen...\n","435032576\n","313. esalditik aurrera zuzentzen...\n","433950208\n","325. esalditik aurrera zuzentzen...\n","434122752\n","337. esalditik aurrera zuzentzen...\n","434196480\n","349. esalditik aurrera zuzentzen...\n","434245632\n","361. esalditik aurrera zuzentzen...\n","435363840\n","373. esalditik aurrera zuzentzen...\n","434356224\n","385. esalditik aurrera zuzentzen...\n","435573248\n","397. esalditik aurrera zuzentzen...\n","435634688\n","409. esalditik aurrera zuzentzen...\n","438458368\n","421. esalditik aurrera zuzentzen...\n","435266560\n","433. esalditik aurrera zuzentzen...\n","435549696\n","445. esalditik aurrera zuzentzen...\n","435389440\n","457. esalditik aurrera zuzentzen...\n","435524608\n","469. esalditik aurrera zuzentzen...\n","435635712\n","481. esalditik aurrera zuzentzen...\n","436532224\n","493. esalditik aurrera zuzentzen...\n","435500032\n","505. esalditik aurrera zuzentzen...\n","436139520\n","517. esalditik aurrera zuzentzen...\n","436581376\n","529. esalditik aurrera zuzentzen...\n","436790784\n","541. esalditik aurrera zuzentzen...\n","436716544\n","553. esalditik aurrera zuzentzen...\n","436434432\n","565. esalditik aurrera zuzentzen...\n","436496384\n","577. esalditik aurrera zuzentzen...\n","436262400\n","589. esalditik aurrera zuzentzen...\n","436656640\n","601. esalditik aurrera zuzentzen...\n","436829184\n","613. esalditik aurrera zuzentzen...\n","437726208\n","625. esalditik aurrera zuzentzen...\n","437713920\n","637. esalditik aurrera zuzentzen...\n","436288000\n","649. esalditik aurrera zuzentzen...\n","436952576\n","661. esalditik aurrera zuzentzen...\n","439289856\n","673. esalditik aurrera zuzentzen...\n","437713920\n","685. esalditik aurrera zuzentzen...\n","437345280\n","697. esalditik aurrera zuzentzen...\n","437530112\n","709. esalditik aurrera zuzentzen...\n","437357568\n","721. esalditik aurrera zuzentzen...\n","437087232\n","733. esalditik aurrera zuzentzen...\n","437592064\n","745. esalditik aurrera zuzentzen...\n","436841984\n","757. esalditik aurrera zuzentzen...\n","438913536\n","769. esalditik aurrera zuzentzen...\n","438211584\n","781. esalditik aurrera zuzentzen...\n","441139200\n","793. esalditik aurrera zuzentzen...\n","438813696\n","805. esalditik aurrera zuzentzen...\n","439761408\n","817. esalditik aurrera zuzentzen...\n","439268864\n","829. esalditik aurrera zuzentzen...\n","440780800\n","841. esalditik aurrera zuzentzen...\n","439724032\n","853. esalditik aurrera zuzentzen...\n","441396224\n","865. esalditik aurrera zuzentzen...\n","441100800\n","877. esalditik aurrera zuzentzen...\n","446415872\n","889. esalditik aurrera zuzentzen...\n","442246656\n","901. esalditik aurrera zuzentzen...\n","441827840\n","913. esalditik aurrera zuzentzen...\n","445328896\n","925. esalditik aurrera zuzentzen...\n","445174272\n","937. esalditik aurrera zuzentzen...\n","446411776\n","949. esalditik aurrera zuzentzen...\n","445629952\n","961. esalditik aurrera zuzentzen...\n","448480256\n","973. esalditik aurrera zuzentzen...\n","450556928\n","985. esalditik aurrera zuzentzen...\n","450636288\n","997. esalditik aurrera zuzentzen...\n","2.8244595925013223 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QxjkKc9lhrJC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592166804362,"user_tz":-120,"elapsed":782,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"8aacecc3-d396-4cf2-ab7f-bed5b85ec20d"},"source":["bleu"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12.519417995542199"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"ss6V3dTrh7jh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592166851604,"user_tz":-120,"elapsed":943,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"96e50269-4735-495f-926d-49129a7a44bf"},"source":["luzerak_es = [len(esaldia[0]) for esaldia in dev1]\n","luzerak_es = np.array(luzerak_es)\n","l_sort = np.sort(luzerak_es)\n","print(l_sort[249])\n","print(l_sort[499])\n","print(l_sort[574])\n","print(l_sort[999])\n","indizeak = luzerak_es.argsort()\n","references_ord = [references[i] for i in indizeak]\n","candidates_ord = [candidates[i] for i in indizeak]\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["15\n","27\n","31\n","120\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AU2F7YmoiNoN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1592166853608,"user_tz":-120,"elapsed":755,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"892ba9b5-eca5-417a-ae27-72a6d00b3c9b"},"source":["bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[:250], \n","                                             candidates_ord[:250])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[250:500], \n","                                             candidates_ord[250:500])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[500:750], \n","                                             candidates_ord[500:750])*100\n","print(bleu)\n","bleu = nltk.translate.bleu_score.corpus_bleu(references_ord[750:], \n","                                             candidates_ord[750:])*100\n","print(bleu)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["25.639637013716342\n","17.772314065194486\n","11.230090942737565\n","9.583737621667296\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mzHlakocIC3u","colab_type":"text"},"source":["## origetahobea3"]},{"cell_type":"code","metadata":{"id":"PhYq2L9NIGp7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593619591698,"user_tz":-120,"elapsed":14409,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"fe3f93c0-500c-4aaa-8bc5-aef5ccd1d711"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('EhuHac/origetahobea3-11.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"HVYBFc5eN245","colab_type":"code","colab":{}},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvhKS7UZIUGG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593621864756,"user_tz":-120,"elapsed":3184,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"f45c77ac-804c-437b-b7df-d8345bafc805"},"source":["references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.265842600256383, 20.060037512163138, 14.066417453610752)"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"_u7_jI1aI-N5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593622410458,"user_tz":-120,"elapsed":174555,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"dce861ef-3a1e-4e51-f15b-ed66e436d005"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","143600640\n","13. esalditik aurrera zuzentzen...\n","144165888\n","25. esalditik aurrera zuzentzen...\n","143895552\n","37. esalditik aurrera zuzentzen...\n","143956992\n","49. esalditik aurrera zuzentzen...\n","144006144\n","61. esalditik aurrera zuzentzen...\n","144227328\n","73. esalditik aurrera zuzentzen...\n","144363008\n","85. esalditik aurrera zuzentzen...\n","144337920\n","97. esalditik aurrera zuzentzen...\n","144817664\n","109. esalditik aurrera zuzentzen...\n","144903680\n","121. esalditik aurrera zuzentzen...\n","144989696\n","133. esalditik aurrera zuzentzen...\n","145088000\n","145. esalditik aurrera zuzentzen...\n","145027072\n","157. esalditik aurrera zuzentzen...\n","144867328\n","169. esalditik aurrera zuzentzen...\n","145272832\n","181. esalditik aurrera zuzentzen...\n","145248256\n","193. esalditik aurrera zuzentzen...\n","145469440\n","205. esalditik aurrera zuzentzen...\n","145420288\n","217. esalditik aurrera zuzentzen...\n","146072064\n","229. esalditik aurrera zuzentzen...\n","145739776\n","241. esalditik aurrera zuzentzen...\n","145641472\n","253. esalditik aurrera zuzentzen...\n","146220032\n","265. esalditik aurrera zuzentzen...\n","145838080\n","277. esalditik aurrera zuzentzen...\n","145948672\n","289. esalditik aurrera zuzentzen...\n","146084352\n","301. esalditik aurrera zuzentzen...\n","146281472\n","313. esalditik aurrera zuzentzen...\n","146133504\n","325. esalditik aurrera zuzentzen...\n","147436544\n","337. esalditik aurrera zuzentzen...\n","147805184\n","349. esalditik aurrera zuzentzen...\n","146772992\n","361. esalditik aurrera zuzentzen...\n","147989504\n","373. esalditik aurrera zuzentzen...\n","147620864\n","385. esalditik aurrera zuzentzen...\n","146773504\n","397. esalditik aurrera zuzentzen...\n","147867136\n","409. esalditik aurrera zuzentzen...\n","147928576\n","421. esalditik aurrera zuzentzen...\n","148482048\n","433. esalditik aurrera zuzentzen...\n","148421120\n","445. esalditik aurrera zuzentzen...\n","147523584\n","457. esalditik aurrera zuzentzen...\n","147707904\n","469. esalditik aurrera zuzentzen...\n","147965952\n","481. esalditik aurrera zuzentzen...\n","148666368\n","493. esalditik aurrera zuzentzen...\n","148667392\n","505. esalditik aurrera zuzentzen...\n","148518912\n","517. esalditik aurrera zuzentzen...\n","148912640\n","529. esalditik aurrera zuzentzen...\n","149465600\n","541. esalditik aurrera zuzentzen...\n","148457472\n","553. esalditik aurrera zuzentzen...\n","149158400\n","565. esalditik aurrera zuzentzen...\n","149466112\n","577. esalditik aurrera zuzentzen...\n","148740608\n","589. esalditik aurrera zuzentzen...\n","152931328\n","601. esalditik aurrera zuzentzen...\n","149650944\n","613. esalditik aurrera zuzentzen...\n","149712384\n","625. esalditik aurrera zuzentzen...\n","149650944\n","637. esalditik aurrera zuzentzen...\n","149404672\n","649. esalditik aurrera zuzentzen...\n","150119424\n","661. esalditik aurrera zuzentzen...\n","152062464\n","673. esalditik aurrera zuzentzen...\n","151274496\n","685. esalditik aurrera zuzentzen...\n","150511104\n","697. esalditik aurrera zuzentzen...\n","150352384\n","709. esalditik aurrera zuzentzen...\n","150721024\n","721. esalditik aurrera zuzentzen...\n","150302720\n","733. esalditik aurrera zuzentzen...\n","150610432\n","745. esalditik aurrera zuzentzen...\n","150155776\n","757. esalditik aurrera zuzentzen...\n","152013824\n","769. esalditik aurrera zuzentzen...\n","151705088\n","781. esalditik aurrera zuzentzen...\n","151791616\n","793. esalditik aurrera zuzentzen...\n","151815680\n","805. esalditik aurrera zuzentzen...\n","152566272\n","817. esalditik aurrera zuzentzen...\n","152320000\n","829. esalditik aurrera zuzentzen...\n","153488896\n","841. esalditik aurrera zuzentzen...\n","153808896\n","853. esalditik aurrera zuzentzen...\n","153464832\n","865. esalditik aurrera zuzentzen...\n","154499584\n","877. esalditik aurrera zuzentzen...\n","159633920\n","889. esalditik aurrera zuzentzen...\n","154462720\n","901. esalditik aurrera zuzentzen...\n","154141696\n","913. esalditik aurrera zuzentzen...\n","158542848\n","925. esalditik aurrera zuzentzen...\n","158225408\n","937. esalditik aurrera zuzentzen...\n","159014912\n","949. esalditik aurrera zuzentzen...\n","158951424\n","961. esalditik aurrera zuzentzen...\n","159900160\n","973. esalditik aurrera zuzentzen...\n","162521088\n","985. esalditik aurrera zuzentzen...\n","164048384\n","997. esalditik aurrera zuzentzen...\n","2.827422018845876 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6Vgkk1tNJTSS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593622492487,"user_tz":-120,"elapsed":66102,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"99b9d0fa-c49f-452e-a783-e950e690b17e"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","143748096\n","13. esalditik aurrera zuzentzen...\n","143600640\n","25. esalditik aurrera zuzentzen...\n","143649792\n","37. esalditik aurrera zuzentzen...\n","143809536\n","49. esalditik aurrera zuzentzen...\n","143932416\n","61. esalditik aurrera zuzentzen...\n","143969280\n","73. esalditik aurrera zuzentzen...\n","143834112\n","85. esalditik aurrera zuzentzen...\n","143883264\n","97. esalditik aurrera zuzentzen...\n","143944704\n","109. esalditik aurrera zuzentzen...\n","143883264\n","121. esalditik aurrera zuzentzen...\n","144313856\n","133. esalditik aurrera zuzentzen...\n","144166400\n","145. esalditik aurrera zuzentzen...\n","143993856\n","157. esalditik aurrera zuzentzen...\n","143944704\n","169. esalditik aurrera zuzentzen...\n","143883264\n","181. esalditik aurrera zuzentzen...\n","144129536\n","193. esalditik aurrera zuzentzen...\n","144006144\n","205. esalditik aurrera zuzentzen...\n","144116736\n","217. esalditik aurrera zuzentzen...\n","144006144\n","229. esalditik aurrera zuzentzen...\n","144055296\n","241. esalditik aurrera zuzentzen...\n","144338432\n","253. esalditik aurrera zuzentzen...\n","144498176\n","265. esalditik aurrera zuzentzen...\n","144215040\n","277. esalditik aurrera zuzentzen...\n","144301568\n","289. esalditik aurrera zuzentzen...\n","144227328\n","301. esalditik aurrera zuzentzen...\n","144289280\n","313. esalditik aurrera zuzentzen...\n","144301568\n","325. esalditik aurrera zuzentzen...\n","144289280\n","337. esalditik aurrera zuzentzen...\n","144129024\n","349. esalditik aurrera zuzentzen...\n","144325632\n","361. esalditik aurrera zuzentzen...\n","144288768\n","373. esalditik aurrera zuzentzen...\n","144387072\n","385. esalditik aurrera zuzentzen...\n","144350720\n","397. esalditik aurrera zuzentzen...\n","144510464\n","409. esalditik aurrera zuzentzen...\n","144288768\n","421. esalditik aurrera zuzentzen...\n","144301568\n","433. esalditik aurrera zuzentzen...\n","144682496\n","445. esalditik aurrera zuzentzen...\n","144571904\n","457. esalditik aurrera zuzentzen...\n","144571904\n","469. esalditik aurrera zuzentzen...\n","144584192\n","481. esalditik aurrera zuzentzen...\n","145456640\n","493. esalditik aurrera zuzentzen...\n","144805376\n","505. esalditik aurrera zuzentzen...\n","144805376\n","517. esalditik aurrera zuzentzen...\n","145494016\n","529. esalditik aurrera zuzentzen...\n","144633344\n","541. esalditik aurrera zuzentzen...\n","144694784\n","553. esalditik aurrera zuzentzen...\n","144854528\n","565. esalditik aurrera zuzentzen...\n","144989696\n","577. esalditik aurrera zuzentzen...\n","144989696\n","589. esalditik aurrera zuzentzen...\n","145051136\n","601. esalditik aurrera zuzentzen...\n","144818176\n","613. esalditik aurrera zuzentzen...\n","145297408\n","625. esalditik aurrera zuzentzen...\n","144977920\n","637. esalditik aurrera zuzentzen...\n","145088512\n","649. esalditik aurrera zuzentzen...\n","144990208\n","661. esalditik aurrera zuzentzen...\n","145223680\n","673. esalditik aurrera zuzentzen...\n","145199104\n","685. esalditik aurrera zuzentzen...\n","145568256\n","697. esalditik aurrera zuzentzen...\n","145039360\n","709. esalditik aurrera zuzentzen...\n","145334272\n","721. esalditik aurrera zuzentzen...\n","145444864\n","733. esalditik aurrera zuzentzen...\n","145826304\n","745. esalditik aurrera zuzentzen...\n","145444864\n","757. esalditik aurrera zuzentzen...\n","145666048\n","769. esalditik aurrera zuzentzen...\n","145875456\n","781. esalditik aurrera zuzentzen...\n","145727488\n","793. esalditik aurrera zuzentzen...\n","145776640\n","805. esalditik aurrera zuzentzen...\n","145788928\n","817. esalditik aurrera zuzentzen...\n","145961472\n","829. esalditik aurrera zuzentzen...\n","145960960\n","841. esalditik aurrera zuzentzen...\n","146502656\n","853. esalditik aurrera zuzentzen...\n","146293760\n","865. esalditik aurrera zuzentzen...\n","146711552\n","877. esalditik aurrera zuzentzen...\n","146650112\n","889. esalditik aurrera zuzentzen...\n","146785280\n","901. esalditik aurrera zuzentzen...\n","148359168\n","913. esalditik aurrera zuzentzen...\n","148027392\n","925. esalditik aurrera zuzentzen...\n","147880448\n","937. esalditik aurrera zuzentzen...\n","147929088\n","949. esalditik aurrera zuzentzen...\n","148494848\n","961. esalditik aurrera zuzentzen...\n","149416960\n","973. esalditik aurrera zuzentzen...\n","149811200\n","985. esalditik aurrera zuzentzen...\n","152086528\n","997. esalditik aurrera zuzentzen...\n","1.0850364764531453 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eP8XOgLESsIs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593622495409,"user_tz":-120,"elapsed":709,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"97eaeea2-006e-4b3a-fe1b-5c81a9eee330"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.473947633946947, 20.616420460142173, 14.340168208069533)"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"markdown","metadata":{"id":"ccimAJ_Oc-hp","colab_type":"text"},"source":["### avg"]},{"cell_type":"code","metadata":{"id":"Xehm3yC3dB65","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593626307985,"user_tz":-120,"elapsed":14183,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"4f3a2c3a-60ca-4279-99a9-b45046e970b8"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","model1, optim = amp.initialize(model, optim, opt_level='O2')\n","model1.load_state_dict(torch.load('EhuHac/origetahobea3-10.pt')['model'])\n","\n","model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","model2, optim = amp.initialize(model, optim, opt_level='O2')\n","model2.load_state_dict(torch.load('EhuHac/origetahobea3-11.pt')['model'])\n","\n","model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","model3, optim = amp.initialize(model, optim, opt_level='O2')\n","model3.load_state_dict(torch.load('EhuHac/origetahobea3-12.pt')['model'])\n","\n","params1 = model1.named_parameters()\n","dict_params2 = model2.state_dict()\n","dict_params3 = model3.state_dict()\n","\n","\n","for name1, param1 in params1:\n","    if name1 in dict_params2:\n","        dict_params2[name1].data.copy_(1/3*param1.data + \n","                                       1/3*dict_params2[name1].data + \n","                                       1/3*dict_params3[name1].data)\n","\n","model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","model = amp.initialize(model, opt_level='O2')\n","model.load_state_dict(dict_params2)\n","\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"TTbaBd_fee8E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593625519839,"user_tz":-120,"elapsed":75585,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"28598552-dc56-4ed9-c844-51f5c49b2715"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["55.330010175704956 segundo behar izan ditu zuzentzeko.\n","18.71020793914795 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(12.518081216329028, 21.127925651276207, 14.520228375722727)"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"USJ8WRimh9RM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593626357502,"user_tz":-120,"elapsed":37050,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9af5ae34-583e-4421-a481-b0dfdd64e752"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["22.526533126831055 segundo behar izan ditu zuzentzeko.\n","9.964727640151978 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(12.528763788707693, 21.107329037888714, 14.520155608334576)"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"code","metadata":{"id":"uUpX10Cmi52v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593626743392,"user_tz":-120,"elapsed":172734,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"fdbd0a63-be60-4650-d52d-20e0e496135d"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2146950656\n","1. esalditik aurrera zuzentzen...\n","2148108800\n","13. esalditik aurrera zuzentzen...\n","2148133376\n","25. esalditik aurrera zuzentzen...\n","2148207104\n","37. esalditik aurrera zuzentzen...\n","2148317696\n","49. esalditik aurrera zuzentzen...\n","2148317696\n","61. esalditik aurrera zuzentzen...\n","2148538880\n","73. esalditik aurrera zuzentzen...\n","2148674560\n","85. esalditik aurrera zuzentzen...\n","2148600320\n","97. esalditik aurrera zuzentzen...\n","2149129216\n","109. esalditik aurrera zuzentzen...\n","2149166080\n","121. esalditik aurrera zuzentzen...\n","2149350400\n","133. esalditik aurrera zuzentzen...\n","2149301248\n","145. esalditik aurrera zuzentzen...\n","2149535232\n","157. esalditik aurrera zuzentzen...\n","2149178880\n","169. esalditik aurrera zuzentzen...\n","2149584384\n","181. esalditik aurrera zuzentzen...\n","2149559808\n","193. esalditik aurrera zuzentzen...\n","2149780992\n","205. esalditik aurrera zuzentzen...\n","2149780992\n","217. esalditik aurrera zuzentzen...\n","2150383616\n","229. esalditik aurrera zuzentzen...\n","2150100480\n","241. esalditik aurrera zuzentzen...\n","2149953024\n","253. esalditik aurrera zuzentzen...\n","2150432768\n","265. esalditik aurrera zuzentzen...\n","2150051328\n","277. esalditik aurrera zuzentzen...\n","2150260224\n","289. esalditik aurrera zuzentzen...\n","2150395904\n","301. esalditik aurrera zuzentzen...\n","2151395840\n","313. esalditik aurrera zuzentzen...\n","2150494208\n","325. esalditik aurrera zuzentzen...\n","2151518720\n","337. esalditik aurrera zuzentzen...\n","2151592448\n","349. esalditik aurrera zuzentzen...\n","2151084544\n","361. esalditik aurrera zuzentzen...\n","2151170048\n","373. esalditik aurrera zuzentzen...\n","2150900224\n","385. esalditik aurrera zuzentzen...\n","2151134208\n","397. esalditik aurrera zuzentzen...\n","2151392256\n","409. esalditik aurrera zuzentzen...\n","2152241152\n","421. esalditik aurrera zuzentzen...\n","2152744448\n","433. esalditik aurrera zuzentzen...\n","2152093184\n","445. esalditik aurrera zuzentzen...\n","2151884288\n","457. esalditik aurrera zuzentzen...\n","2152068608\n","469. esalditik aurrera zuzentzen...\n","2152130048\n","481. esalditik aurrera zuzentzen...\n","2153076224\n","493. esalditik aurrera zuzentzen...\n","2153077248\n","505. esalditik aurrera zuzentzen...\n","2154223616\n","517. esalditik aurrera zuzentzen...\n","2154174464\n","529. esalditik aurrera zuzentzen...\n","2154285056\n","541. esalditik aurrera zuzentzen...\n","2153473536\n","553. esalditik aurrera zuzentzen...\n","2153781248\n","565. esalditik aurrera zuzentzen...\n","2153744896\n","577. esalditik aurrera zuzentzen...\n","2153707520\n","589. esalditik aurrera zuzentzen...\n","2154248704\n","601. esalditik aurrera zuzentzen...\n","2153880576\n","613. esalditik aurrera zuzentzen...\n","2153794560\n","625. esalditik aurrera zuzentzen...\n","2154322944\n","637. esalditik aurrera zuzentzen...\n","2153830912\n","649. esalditik aurrera zuzentzen...\n","2154446848\n","661. esalditik aurrera zuzentzen...\n","2156472832\n","673. esalditik aurrera zuzentzen...\n","2154700288\n","685. esalditik aurrera zuzentzen...\n","2155119104\n","697. esalditik aurrera zuzentzen...\n","2154581504\n","709. esalditik aurrera zuzentzen...\n","2154688000\n","721. esalditik aurrera zuzentzen...\n","2154728960\n","733. esalditik aurrera zuzentzen...\n","2154872832\n","745. esalditik aurrera zuzentzen...\n","2154516480\n","757. esalditik aurrera zuzentzen...\n","2156374528\n","769. esalditik aurrera zuzentzen...\n","2155475968\n","781. esalditik aurrera zuzentzen...\n","2156053504\n","793. esalditik aurrera zuzentzen...\n","2156226048\n","805. esalditik aurrera zuzentzen...\n","2157617152\n","817. esalditik aurrera zuzentzen...\n","2156582400\n","829. esalditik aurrera zuzentzen...\n","2157702144\n","841. esalditik aurrera zuzentzen...\n","2157283840\n","853. esalditik aurrera zuzentzen...\n","2158268928\n","865. esalditik aurrera zuzentzen...\n","2160686592\n","877. esalditik aurrera zuzentzen...\n","2163697152\n","889. esalditik aurrera zuzentzen...\n","2158478336\n","901. esalditik aurrera zuzentzen...\n","2159107584\n","913. esalditik aurrera zuzentzen...\n","2161773568\n","925. esalditik aurrera zuzentzen...\n","2162783232\n","937. esalditik aurrera zuzentzen...\n","2163474944\n","949. esalditik aurrera zuzentzen...\n","2163090944\n","961. esalditik aurrera zuzentzen...\n","2166026240\n","973. esalditik aurrera zuzentzen...\n","2167620608\n","985. esalditik aurrera zuzentzen...\n","2167573504\n","997. esalditik aurrera zuzentzen...\n","2.8493937889734906 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HlU4RSIfi5my","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593626808757,"user_tz":-120,"elapsed":231579,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"b4b7a16f-05f1-41dd-a81b-1f33655bb1a6"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2146950656\n","1. esalditik aurrera zuzentzen...\n","2148108800\n","13. esalditik aurrera zuzentzen...\n","2148157952\n","25. esalditik aurrera zuzentzen...\n","2147961344\n","37. esalditik aurrera zuzentzen...\n","2148022784\n","49. esalditik aurrera zuzentzen...\n","2148243968\n","61. esalditik aurrera zuzentzen...\n","2148379136\n","73. esalditik aurrera zuzentzen...\n","2148145664\n","85. esalditik aurrera zuzentzen...\n","2148194816\n","97. esalditik aurrera zuzentzen...\n","2148207104\n","109. esalditik aurrera zuzentzen...\n","2148194816\n","121. esalditik aurrera zuzentzen...\n","2148477952\n","133. esalditik aurrera zuzentzen...\n","2148527104\n","145. esalditik aurrera zuzentzen...\n","2148452864\n","157. esalditik aurrera zuzentzen...\n","2148305408\n","169. esalditik aurrera zuzentzen...\n","2148194816\n","181. esalditik aurrera zuzentzen...\n","2148441088\n","193. esalditik aurrera zuzentzen...\n","2148317696\n","205. esalditik aurrera zuzentzen...\n","2148477440\n","217. esalditik aurrera zuzentzen...\n","2148366848\n","229. esalditik aurrera zuzentzen...\n","2148366848\n","241. esalditik aurrera zuzentzen...\n","2148699136\n","253. esalditik aurrera zuzentzen...\n","2148809728\n","265. esalditik aurrera zuzentzen...\n","2148526592\n","277. esalditik aurrera zuzentzen...\n","2148662272\n","289. esalditik aurrera zuzentzen...\n","2148489728\n","301. esalditik aurrera zuzentzen...\n","2148600832\n","313. esalditik aurrera zuzentzen...\n","2148662272\n","325. esalditik aurrera zuzentzen...\n","2148600832\n","337. esalditik aurrera zuzentzen...\n","2148440576\n","349. esalditik aurrera zuzentzen...\n","2148637184\n","361. esalditik aurrera zuzentzen...\n","2148600320\n","373. esalditik aurrera zuzentzen...\n","2148649472\n","385. esalditik aurrera zuzentzen...\n","2148662272\n","397. esalditik aurrera zuzentzen...\n","2148822016\n","409. esalditik aurrera zuzentzen...\n","2148600320\n","421. esalditik aurrera zuzentzen...\n","2148662272\n","433. esalditik aurrera zuzentzen...\n","2148994048\n","445. esalditik aurrera zuzentzen...\n","2148785152\n","457. esalditik aurrera zuzentzen...\n","2148883456\n","469. esalditik aurrera zuzentzen...\n","2148944896\n","481. esalditik aurrera zuzentzen...\n","2149768192\n","493. esalditik aurrera zuzentzen...\n","2149116928\n","505. esalditik aurrera zuzentzen...\n","2149166080\n","517. esalditik aurrera zuzentzen...\n","2149805568\n","529. esalditik aurrera zuzentzen...\n","2148944896\n","541. esalditik aurrera zuzentzen...\n","2149006336\n","553. esalditik aurrera zuzentzen...\n","2149166080\n","565. esalditik aurrera zuzentzen...\n","2149252096\n","577. esalditik aurrera zuzentzen...\n","2149301248\n","589. esalditik aurrera zuzentzen...\n","2149411840\n","601. esalditik aurrera zuzentzen...\n","2149178880\n","613. esalditik aurrera zuzentzen...\n","2149608960\n","625. esalditik aurrera zuzentzen...\n","2149240320\n","637. esalditik aurrera zuzentzen...\n","2149400064\n","649. esalditik aurrera zuzentzen...\n","2149301760\n","661. esalditik aurrera zuzentzen...\n","2149486080\n","673. esalditik aurrera zuzentzen...\n","2149510656\n","685. esalditik aurrera zuzentzen...\n","2149879808\n","697. esalditik aurrera zuzentzen...\n","2149449216\n","709. esalditik aurrera zuzentzen...\n","2149645824\n","721. esalditik aurrera zuzentzen...\n","2149756416\n","733. esalditik aurrera zuzentzen...\n","2150137856\n","745. esalditik aurrera zuzentzen...\n","2149903872\n","757. esalditik aurrera zuzentzen...\n","2149977600\n","769. esalditik aurrera zuzentzen...\n","2150383616\n","781. esalditik aurrera zuzentzen...\n","2149989888\n","793. esalditik aurrera zuzentzen...\n","2150088192\n","805. esalditik aurrera zuzentzen...\n","2150002176\n","817. esalditik aurrera zuzentzen...\n","2150322176\n","829. esalditik aurrera zuzentzen...\n","2150272512\n","841. esalditik aurrera zuzentzen...\n","2150617088\n","853. esalditik aurrera zuzentzen...\n","2150555648\n","865. esalditik aurrera zuzentzen...\n","2151023104\n","877. esalditik aurrera zuzentzen...\n","2151010816\n","889. esalditik aurrera zuzentzen...\n","2151047168\n","901. esalditik aurrera zuzentzen...\n","2151785984\n","913. esalditik aurrera zuzentzen...\n","2152289792\n","925. esalditik aurrera zuzentzen...\n","2151945728\n","937. esalditik aurrera zuzentzen...\n","2153076224\n","949. esalditik aurrera zuzentzen...\n","2154199040\n","961. esalditik aurrera zuzentzen...\n","2153843200\n","973. esalditik aurrera zuzentzen...\n","2153942016\n","985. esalditik aurrera zuzentzen...\n","2156151808\n","997. esalditik aurrera zuzentzen...\n","1.0986079533894857 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Is5ltDzGi5T-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593626808759,"user_tz":-120,"elapsed":226866,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d1aa6455-fc17-43b7-b28b-ee49cb000eb3"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.87006488575248, 21.57105645659844, 14.863051725074142)"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"wTL7w8NpW6pk","colab_type":"text"},"source":["## orig2"]},{"cell_type":"code","metadata":{"id":"P37ouN9TXAyZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593623498602,"user_tz":-120,"elapsed":8214,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ca05d444-fff3-4470-a38b-ce2b533b8c60"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('EhuHac/trainorig2-12.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"vrDaWzAfXQ82","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593623569427,"user_tz":-120,"elapsed":44604,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6e59325c-c76a-4415-bca6-be3daccecf04"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["33.181724309921265 segundo behar izan ditu zuzentzeko.\n","8.963477611541748 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6CYevyg_XT1G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593623569429,"user_tz":-120,"elapsed":34747,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"157301a0-b1df-47eb-9e64-0e3b57e86388"},"source":["references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.219797331430803, 19.403910498078528, 13.940247349969304)"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"ckHhz0SbXWOX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593623821067,"user_tz":-120,"elapsed":165872,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"7e5d1b58-100f-4041-8560-fddba5dc640d"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["285769216\n","1. esalditik aurrera zuzentzen...\n","286730752\n","13. esalditik aurrera zuzentzen...\n","286902784\n","25. esalditik aurrera zuzentzen...\n","287222272\n","37. esalditik aurrera zuzentzen...\n","290681344\n","49. esalditik aurrera zuzentzen...\n","287136256\n","61. esalditik aurrera zuzentzen...\n","287357440\n","73. esalditik aurrera zuzentzen...\n","287493120\n","85. esalditik aurrera zuzentzen...\n","287418880\n","97. esalditik aurrera zuzentzen...\n","287947776\n","109. esalditik aurrera zuzentzen...\n","287886336\n","121. esalditik aurrera zuzentzen...\n","288070656\n","133. esalditik aurrera zuzentzen...\n","288070656\n","145. esalditik aurrera zuzentzen...\n","288206336\n","157. esalditik aurrera zuzentzen...\n","288095744\n","169. esalditik aurrera zuzentzen...\n","288648704\n","181. esalditik aurrera zuzentzen...\n","288280064\n","193. esalditik aurrera zuzentzen...\n","288648704\n","205. esalditik aurrera zuzentzen...\n","288501248\n","217. esalditik aurrera zuzentzen...\n","289103872\n","229. esalditik aurrera zuzentzen...\n","288919040\n","241. esalditik aurrera zuzentzen...\n","288919040\n","253. esalditik aurrera zuzentzen...\n","290382336\n","265. esalditik aurrera zuzentzen...\n","288869888\n","277. esalditik aurrera zuzentzen...\n","289029632\n","289. esalditik aurrera zuzentzen...\n","289263616\n","301. esalditik aurrera zuzentzen...\n","289312768\n","313. esalditik aurrera zuzentzen...\n","289362432\n","325. esalditik aurrera zuzentzen...\n","289534464\n","337. esalditik aurrera zuzentzen...\n","289804288\n","349. esalditik aurrera zuzentzen...\n","289853952\n","361. esalditik aurrera zuzentzen...\n","290038272\n","373. esalditik aurrera zuzentzen...\n","289718784\n","385. esalditik aurrera zuzentzen...\n","290935808\n","397. esalditik aurrera zuzentzen...\n","290161664\n","409. esalditik aurrera zuzentzen...\n","291058688\n","421. esalditik aurrera zuzentzen...\n","290678272\n","433. esalditik aurrera zuzentzen...\n","290813440\n","445. esalditik aurrera zuzentzen...\n","291489280\n","457. esalditik aurrera zuzentzen...\n","291673600\n","469. esalditik aurrera zuzentzen...\n","290899456\n","481. esalditik aurrera zuzentzen...\n","291157504\n","493. esalditik aurrera zuzentzen...\n","291157504\n","505. esalditik aurrera zuzentzen...\n","291550720\n","517. esalditik aurrera zuzentzen...\n","291600384\n","529. esalditik aurrera zuzentzen...\n","291858432\n","541. esalditik aurrera zuzentzen...\n","291587584\n","553. esalditik aurrera zuzentzen...\n","291747840\n","565. esalditik aurrera zuzentzen...\n","292596224\n","577. esalditik aurrera zuzentzen...\n","292411392\n","589. esalditik aurrera zuzentzen...\n","292411904\n","601. esalditik aurrera zuzentzen...\n","292781056\n","613. esalditik aurrera zuzentzen...\n","292842496\n","625. esalditik aurrera zuzentzen...\n","292240384\n","637. esalditik aurrera zuzentzen...\n","292190720\n","649. esalditik aurrera zuzentzen...\n","292904448\n","661. esalditik aurrera zuzentzen...\n","295045120\n","673. esalditik aurrera zuzentzen...\n","293273088\n","685. esalditik aurrera zuzentzen...\n","293395968\n","697. esalditik aurrera zuzentzen...\n","293236224\n","709. esalditik aurrera zuzentzen...\n","293457408\n","721. esalditik aurrera zuzentzen...\n","293284864\n","733. esalditik aurrera zuzentzen...\n","293789696\n","745. esalditik aurrera zuzentzen...\n","293285888\n","757. esalditik aurrera zuzentzen...\n","294651392\n","769. esalditik aurrera zuzentzen...\n","294639104\n","781. esalditik aurrera zuzentzen...\n","295069184\n","793. esalditik aurrera zuzentzen...\n","294650368\n","805. esalditik aurrera zuzentzen...\n","295647232\n","817. esalditik aurrera zuzentzen...\n","295302144\n","829. esalditik aurrera zuzentzen...\n","296520704\n","841. esalditik aurrera zuzentzen...\n","296053248\n","853. esalditik aurrera zuzentzen...\n","296249856\n","865. esalditik aurrera zuzentzen...\n","296594944\n","877. esalditik aurrera zuzentzen...\n","302764032\n","889. esalditik aurrera zuzentzen...\n","297852416\n","901. esalditik aurrera zuzentzen...\n","297926144\n","913. esalditik aurrera zuzentzen...\n","303024128\n","925. esalditik aurrera zuzentzen...\n","301158400\n","937. esalditik aurrera zuzentzen...\n","300950016\n","949. esalditik aurrera zuzentzen...\n","302773248\n","961. esalditik aurrera zuzentzen...\n","303574528\n","973. esalditik aurrera zuzentzen...\n","308108800\n","985. esalditik aurrera zuzentzen...\n","308075520\n","997. esalditik aurrera zuzentzen...\n","2.6136837204297385 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5FOJBs5XXdl-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593623875757,"user_tz":-120,"elapsed":220203,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6bd04996-443f-4a89-8654-aafb135fb42a"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["285769216\n","1. esalditik aurrera zuzentzen...\n","286730752\n","13. esalditik aurrera zuzentzen...\n","286829056\n","25. esalditik aurrera zuzentzen...\n","286829056\n","37. esalditik aurrera zuzentzen...\n","286841344\n","49. esalditik aurrera zuzentzen...\n","286915072\n","61. esalditik aurrera zuzentzen...\n","287050240\n","73. esalditik aurrera zuzentzen...\n","287013376\n","85. esalditik aurrera zuzentzen...\n","287013376\n","97. esalditik aurrera zuzentzen...\n","287025664\n","109. esalditik aurrera zuzentzen...\n","287062528\n","121. esalditik aurrera zuzentzen...\n","287394816\n","133. esalditik aurrera zuzentzen...\n","287296512\n","145. esalditik aurrera zuzentzen...\n","287074816\n","157. esalditik aurrera zuzentzen...\n","287123968\n","169. esalditik aurrera zuzentzen...\n","287013376\n","181. esalditik aurrera zuzentzen...\n","287259648\n","193. esalditik aurrera zuzentzen...\n","287136256\n","205. esalditik aurrera zuzentzen...\n","287246848\n","217. esalditik aurrera zuzentzen...\n","287185408\n","229. esalditik aurrera zuzentzen...\n","287185408\n","241. esalditik aurrera zuzentzen...\n","287517696\n","253. esalditik aurrera zuzentzen...\n","287480832\n","265. esalditik aurrera zuzentzen...\n","287246848\n","277. esalditik aurrera zuzentzen...\n","287480832\n","289. esalditik aurrera zuzentzen...\n","287357440\n","301. esalditik aurrera zuzentzen...\n","287370240\n","313. esalditik aurrera zuzentzen...\n","287431680\n","325. esalditik aurrera zuzentzen...\n","287370240\n","337. esalditik aurrera zuzentzen...\n","287308288\n","349. esalditik aurrera zuzentzen...\n","287308288\n","361. esalditik aurrera zuzentzen...\n","287418880\n","373. esalditik aurrera zuzentzen...\n","287468032\n","385. esalditik aurrera zuzentzen...\n","287431680\n","397. esalditik aurrera zuzentzen...\n","287591424\n","409. esalditik aurrera zuzentzen...\n","287418880\n","421. esalditik aurrera zuzentzen...\n","287480832\n","433. esalditik aurrera zuzentzen...\n","287714304\n","445. esalditik aurrera zuzentzen...\n","287603712\n","457. esalditik aurrera zuzentzen...\n","287702016\n","469. esalditik aurrera zuzentzen...\n","287714304\n","481. esalditik aurrera zuzentzen...\n","288242688\n","493. esalditik aurrera zuzentzen...\n","287935488\n","505. esalditik aurrera zuzentzen...\n","287837184\n","517. esalditik aurrera zuzentzen...\n","288378368\n","529. esalditik aurrera zuzentzen...\n","287763456\n","541. esalditik aurrera zuzentzen...\n","287824896\n","553. esalditik aurrera zuzentzen...\n","287886336\n","565. esalditik aurrera zuzentzen...\n","288070656\n","577. esalditik aurrera zuzentzen...\n","288070656\n","589. esalditik aurrera zuzentzen...\n","288181248\n","601. esalditik aurrera zuzentzen...\n","287948288\n","613. esalditik aurrera zuzentzen...\n","288427520\n","625. esalditik aurrera zuzentzen...\n","288058880\n","637. esalditik aurrera zuzentzen...\n","288120320\n","649. esalditik aurrera zuzentzen...\n","288120320\n","661. esalditik aurrera zuzentzen...\n","288304640\n","673. esalditik aurrera zuzentzen...\n","288230912\n","685. esalditik aurrera zuzentzen...\n","288796672\n","697. esalditik aurrera zuzentzen...\n","289941504\n","709. esalditik aurrera zuzentzen...\n","288415232\n","721. esalditik aurrera zuzentzen...\n","288624128\n","733. esalditik aurrera zuzentzen...\n","288759808\n","745. esalditik aurrera zuzentzen...\n","288624128\n","757. esalditik aurrera zuzentzen...\n","288894464\n","769. esalditik aurrera zuzentzen...\n","289054720\n","781. esalditik aurrera zuzentzen...\n","288808448\n","793. esalditik aurrera zuzentzen...\n","288906752\n","805. esalditik aurrera zuzentzen...\n","288869888\n","817. esalditik aurrera zuzentzen...\n","289091584\n","829. esalditik aurrera zuzentzen...\n","289140224\n","841. esalditik aurrera zuzentzen...\n","289337344\n","853. esalditik aurrera zuzentzen...\n","289423872\n","865. esalditik aurrera zuzentzen...\n","290038272\n","877. esalditik aurrera zuzentzen...\n","289878528\n","889. esalditik aurrera zuzentzen...\n","290062848\n","901. esalditik aurrera zuzentzen...\n","291489280\n","913. esalditik aurrera zuzentzen...\n","290960896\n","925. esalditik aurrera zuzentzen...\n","290715136\n","937. esalditik aurrera zuzentzen...\n","291796992\n","949. esalditik aurrera zuzentzen...\n","291624960\n","961. esalditik aurrera zuzentzen...\n","293087744\n","973. esalditik aurrera zuzentzen...\n","292843008\n","985. esalditik aurrera zuzentzen...\n","294970368\n","997. esalditik aurrera zuzentzen...\n","1.0369073549906414 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EwJJMSD0XfFd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593623875761,"user_tz":-120,"elapsed":219868,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"77ff254c-2a88-46ee-dc61-f18bf6c35a64"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.864441292144402, 20.158996228593566, 14.575264698797607)"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FGYDWBgNkf5H"},"source":["### avg"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HRgSpKx4kf5I","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594540731967,"user_tz":-120,"elapsed":10877,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d46f665a-7dcd-46ba-960b-50e8ec595f0b"},"source":["model = batezbeste3('EhuHac/trainorig2-11.pt', 'EhuHac/trainorig2-12.pt', \n","                    'EhuHac/trainorig2-13.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U--LiyJPkf5S","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593627113268,"user_tz":-120,"elapsed":40294,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"25c32633-45b6-45c1-a0f5-993f403365b0"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["30.251888036727905 segundo behar izan ditu zuzentzeko.\n","8.830760478973389 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(12.66448762752195, 20.05259970734415, 14.42956275128919)"]},"metadata":{"tags":[]},"execution_count":97}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ppLiVXw2kf5V","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594541093663,"user_tz":-120,"elapsed":139929,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"50e0da1f-1d8d-41f7-fa0d-29efc371f8bd"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["572029440\n","1. esalditik aurrera zuzentzen...\n","572990976\n","13. esalditik aurrera zuzentzen...\n","573163008\n","25. esalditik aurrera zuzentzen...\n","573482496\n","37. esalditik aurrera zuzentzen...\n","573347328\n","49. esalditik aurrera zuzentzen...\n","573396480\n","61. esalditik aurrera zuzentzen...\n","573568512\n","73. esalditik aurrera zuzentzen...\n","573753344\n","85. esalditik aurrera zuzentzen...\n","573679104\n","97. esalditik aurrera zuzentzen...\n","574208000\n","109. esalditik aurrera zuzentzen...\n","574146560\n","121. esalditik aurrera zuzentzen...\n","574625792\n","133. esalditik aurrera zuzentzen...\n","574330880\n","145. esalditik aurrera zuzentzen...\n","574417408\n","157. esalditik aurrera zuzentzen...\n","574355968\n","169. esalditik aurrera zuzentzen...\n","574810624\n","181. esalditik aurrera zuzentzen...\n","574638592\n","193. esalditik aurrera zuzentzen...\n","574859776\n","205. esalditik aurrera zuzentzen...\n","574859776\n","217. esalditik aurrera zuzentzen...\n","576183296\n","229. esalditik aurrera zuzentzen...\n","575179264\n","241. esalditik aurrera zuzentzen...\n","575179264\n","253. esalditik aurrera zuzentzen...\n","576675328\n","265. esalditik aurrera zuzentzen...\n","575179264\n","277. esalditik aurrera zuzentzen...\n","575339008\n","289. esalditik aurrera zuzentzen...\n","576441344\n","301. esalditik aurrera zuzentzen...\n","576539648\n","313. esalditik aurrera zuzentzen...\n","576638464\n","325. esalditik aurrera zuzentzen...\n","576761344\n","337. esalditik aurrera zuzentzen...\n","576785920\n","349. esalditik aurrera zuzentzen...\n","576835072\n","361. esalditik aurrera zuzentzen...\n","576871424\n","373. esalditik aurrera zuzentzen...\n","576896512\n","385. esalditik aurrera zuzentzen...\n","577130496\n","397. esalditik aurrera zuzentzen...\n","577388544\n","409. esalditik aurrera zuzentzen...\n","577253376\n","421. esalditik aurrera zuzentzen...\n","577856000\n","433. esalditik aurrera zuzentzen...\n","577991168\n","445. esalditik aurrera zuzentzen...\n","578028032\n","457. esalditik aurrera zuzentzen...\n","578015744\n","469. esalditik aurrera zuzentzen...\n","577929728\n","481. esalditik aurrera zuzentzen...\n","578777600\n","493. esalditik aurrera zuzentzen...\n","578237440\n","505. esalditik aurrera zuzentzen...\n","579170816\n","517. esalditik aurrera zuzentzen...\n","578581504\n","529. esalditik aurrera zuzentzen...\n","579625984\n","541. esalditik aurrera zuzentzen...\n","578519552\n","553. esalditik aurrera zuzentzen...\n","578581504\n","565. esalditik aurrera zuzentzen...\n","578790400\n","577. esalditik aurrera zuzentzen...\n","578900992\n","589. esalditik aurrera zuzentzen...\n","579638784\n","601. esalditik aurrera zuzentzen...\n","579516416\n","613. esalditik aurrera zuzentzen...\n","579528704\n","625. esalditik aurrera zuzentzen...\n","578926592\n","637. esalditik aurrera zuzentzen...\n","578778624\n","649. esalditik aurrera zuzentzen...\n","579885568\n","661. esalditik aurrera zuzentzen...\n","580992512\n","673. esalditik aurrera zuzentzen...\n","579811840\n","685. esalditik aurrera zuzentzen...\n","579934720\n","697. esalditik aurrera zuzentzen...\n","579774976\n","709. esalditik aurrera zuzentzen...\n","580094464\n","721. esalditik aurrera zuzentzen...\n","579922432\n","733. esalditik aurrera zuzentzen...\n","579984384\n","745. esalditik aurrera zuzentzen...\n","579890176\n","757. esalditik aurrera zuzentzen...\n","580369920\n","769. esalditik aurrera zuzentzen...\n","580653056\n","781. esalditik aurrera zuzentzen...\n","581132288\n","793. esalditik aurrera zuzentzen...\n","581206016\n","805. esalditik aurrera zuzentzen...\n","582841344\n","817. esalditik aurrera zuzentzen...\n","581562368\n","829. esalditik aurrera zuzentzen...\n","582927872\n","841. esalditik aurrera zuzentzen...\n","583869952\n","853. esalditik aurrera zuzentzen...\n","583444992\n","865. esalditik aurrera zuzentzen...\n","583346688\n","877. esalditik aurrera zuzentzen...\n","588853760\n","889. esalditik aurrera zuzentzen...\n","583605248\n","901. esalditik aurrera zuzentzen...\n","583482368\n","913. esalditik aurrera zuzentzen...\n","590164992\n","925. esalditik aurrera zuzentzen...\n","588286464\n","937. esalditik aurrera zuzentzen...\n","589099520\n","949. esalditik aurrera zuzentzen...\n","588021760\n","961. esalditik aurrera zuzentzen...\n","589901824\n","973. esalditik aurrera zuzentzen...\n","592767488\n","985. esalditik aurrera zuzentzen...\n","593864704\n","997. esalditik aurrera zuzentzen...\n","2.314140764872233 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rLXLrlHFkf5X","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594541154787,"user_tz":-120,"elapsed":196803,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d4248166-d976-4e97-f3f3-a1ad4f611a83"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["572029440\n","1. esalditik aurrera zuzentzen...\n","572990976\n","13. esalditik aurrera zuzentzen...\n","573138432\n","25. esalditik aurrera zuzentzen...\n","573089280\n","37. esalditik aurrera zuzentzen...\n","573101568\n","49. esalditik aurrera zuzentzen...\n","573175296\n","61. esalditik aurrera zuzentzen...\n","573163008\n","73. esalditik aurrera zuzentzen...\n","573224448\n","85. esalditik aurrera zuzentzen...\n","573273600\n","97. esalditik aurrera zuzentzen...\n","573285888\n","109. esalditik aurrera zuzentzen...\n","573273600\n","121. esalditik aurrera zuzentzen...\n","573900800\n","133. esalditik aurrera zuzentzen...\n","573605888\n","145. esalditik aurrera zuzentzen...\n","573384192\n","157. esalditik aurrera zuzentzen...\n","573384192\n","169. esalditik aurrera zuzentzen...\n","573273600\n","181. esalditik aurrera zuzentzen...\n","573569024\n","193. esalditik aurrera zuzentzen...\n","573396480\n","205. esalditik aurrera zuzentzen...\n","573507072\n","217. esalditik aurrera zuzentzen...\n","573396480\n","229. esalditik aurrera zuzentzen...\n","573445632\n","241. esalditik aurrera zuzentzen...\n","573777920\n","253. esalditik aurrera zuzentzen...\n","573741056\n","265. esalditik aurrera zuzentzen...\n","573507072\n","277. esalditik aurrera zuzentzen...\n","573691904\n","289. esalditik aurrera zuzentzen...\n","573568512\n","301. esalditik aurrera zuzentzen...\n","573630464\n","313. esalditik aurrera zuzentzen...\n","573741056\n","325. esalditik aurrera zuzentzen...\n","573630464\n","337. esalditik aurrera zuzentzen...\n","573568512\n","349. esalditik aurrera zuzentzen...\n","573715968\n","361. esalditik aurrera zuzentzen...\n","573679104\n","373. esalditik aurrera zuzentzen...\n","573728256\n","385. esalditik aurrera zuzentzen...\n","573839360\n","397. esalditik aurrera zuzentzen...\n","573802496\n","409. esalditik aurrera zuzentzen...\n","573679104\n","421. esalditik aurrera zuzentzen...\n","573741056\n","433. esalditik aurrera zuzentzen...\n","573974528\n","445. esalditik aurrera zuzentzen...\n","574158848\n","457. esalditik aurrera zuzentzen...\n","573913088\n","469. esalditik aurrera zuzentzen...\n","574023680\n","481. esalditik aurrera zuzentzen...\n","574502912\n","493. esalditik aurrera zuzentzen...\n","574195712\n","505. esalditik aurrera zuzentzen...\n","574244864\n","517. esalditik aurrera zuzentzen...\n","575851008\n","529. esalditik aurrera zuzentzen...\n","574023680\n","541. esalditik aurrera zuzentzen...\n","574085120\n","553. esalditik aurrera zuzentzen...\n","574146560\n","565. esalditik aurrera zuzentzen...\n","574330880\n","577. esalditik aurrera zuzentzen...\n","574330880\n","589. esalditik aurrera zuzentzen...\n","574441472\n","601. esalditik aurrera zuzentzen...\n","574257664\n","613. esalditik aurrera zuzentzen...\n","574687744\n","625. esalditik aurrera zuzentzen...\n","574319104\n","637. esalditik aurrera zuzentzen...\n","574380544\n","649. esalditik aurrera zuzentzen...\n","574380544\n","661. esalditik aurrera zuzentzen...\n","574614016\n","673. esalditik aurrera zuzentzen...\n","574491136\n","685. esalditik aurrera zuzentzen...\n","575925248\n","697. esalditik aurrera zuzentzen...\n","574577152\n","709. esalditik aurrera zuzentzen...\n","574724608\n","721. esalditik aurrera zuzentzen...\n","574884352\n","733. esalditik aurrera zuzentzen...\n","576035840\n","745. esalditik aurrera zuzentzen...\n","574982656\n","757. esalditik aurrera zuzentzen...\n","575154688\n","769. esalditik aurrera zuzentzen...\n","576232448\n","781. esalditik aurrera zuzentzen...\n","575068672\n","793. esalditik aurrera zuzentzen...\n","575166976\n","805. esalditik aurrera zuzentzen...\n","575130112\n","817. esalditik aurrera zuzentzen...\n","576367616\n","829. esalditik aurrera zuzentzen...\n","575400448\n","841. esalditik aurrera zuzentzen...\n","576564224\n","853. esalditik aurrera zuzentzen...\n","576551936\n","865. esalditik aurrera zuzentzen...\n","577854976\n","877. esalditik aurrera zuzentzen...\n","576810496\n","889. esalditik aurrera zuzentzen...\n","577977856\n","901. esalditik aurrera zuzentzen...\n","577880576\n","913. esalditik aurrera zuzentzen...\n","579072512\n","925. esalditik aurrera zuzentzen...\n","577892864\n","937. esalditik aurrera zuzentzen...\n","578581504\n","949. esalditik aurrera zuzentzen...\n","578507776\n","961. esalditik aurrera zuzentzen...\n","579872256\n","973. esalditik aurrera zuzentzen...\n","579577856\n","985. esalditik aurrera zuzentzen...\n","581279744\n","997. esalditik aurrera zuzentzen...\n","1.0170383214950562 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9xsoJT3qkf5a","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593627319499,"user_tz":-120,"elapsed":243102,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d931d001-4735-4f95-fc73-47bd1b1982cf"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.979400812343725, 21.259590553014913, 14.909832091784182)"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"tlswo9RLCWFD","colab_type":"code","colab":{}},"source":["# BALIDAZIOKOAK FITXATEGI BATEAN GORDE\n","with open('EhuHac/HAConenaval.txt', 'w') as f:\n","    for candidate in candidates3:\n","        f.write(' '.join(candidate) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"J5wSaAlypVa7"},"source":["## hobea3"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xJ2iqsWcpVa-","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593678776214,"user_tz":-120,"elapsed":16465,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"17580ae2-8c32-46f5-e6e6-4bb952f7b4c4"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('EhuHac/trainhobea3-16.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3ihVPhU5pVbC","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593678808560,"user_tz":-120,"elapsed":45136,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"9c389de0-da79-47e3-88a7-f984e7835e0d"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["24.943997621536255 segundo behar izan ditu zuzentzeko.\n","7.827316045761108 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rvb-PchUpVbF","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593678809053,"user_tz":-120,"elapsed":39824,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"9e40d990-6d3b-4590-e1aa-d8dfc86a9635"},"source":["references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.29169461440857, 18.117164915150756, 13.729906659427426)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o2QRMeCQpVbI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593678970008,"user_tz":-120,"elapsed":194255,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"2d56fe0c-5f08-470c-d9e5-d9ca221897d5"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","144387584\n","13. esalditik aurrera zuzentzen...\n","143723520\n","25. esalditik aurrera zuzentzen...\n","143895552\n","37. esalditik aurrera zuzentzen...\n","144006144\n","49. esalditik aurrera zuzentzen...\n","144006144\n","61. esalditik aurrera zuzentzen...\n","144227328\n","73. esalditik aurrera zuzentzen...\n","144363008\n","85. esalditik aurrera zuzentzen...\n","144337920\n","97. esalditik aurrera zuzentzen...\n","144866816\n","109. esalditik aurrera zuzentzen...\n","144903680\n","121. esalditik aurrera zuzentzen...\n","145137152\n","133. esalditik aurrera zuzentzen...\n","144940544\n","145. esalditik aurrera zuzentzen...\n","145027072\n","157. esalditik aurrera zuzentzen...\n","144965632\n","169. esalditik aurrera zuzentzen...\n","145567744\n","181. esalditik aurrera zuzentzen...\n","145199104\n","193. esalditik aurrera zuzentzen...\n","145567744\n","205. esalditik aurrera zuzentzen...\n","145420288\n","217. esalditik aurrera zuzentzen...\n","145924608\n","229. esalditik aurrera zuzentzen...\n","145739776\n","241. esalditik aurrera zuzentzen...\n","145788928\n","253. esalditik aurrera zuzentzen...\n","146121216\n","265. esalditik aurrera zuzentzen...\n","145788928\n","277. esalditik aurrera zuzentzen...\n","145801216\n","289. esalditik aurrera zuzentzen...\n","146182656\n","301. esalditik aurrera zuzentzen...\n","146281472\n","313. esalditik aurrera zuzentzen...\n","146232320\n","325. esalditik aurrera zuzentzen...\n","147436544\n","337. esalditik aurrera zuzentzen...\n","146674176\n","349. esalditik aurrera zuzentzen...\n","146772992\n","361. esalditik aurrera zuzentzen...\n","147989504\n","373. esalditik aurrera zuzentzen...\n","147620864\n","385. esalditik aurrera zuzentzen...\n","146871808\n","397. esalditik aurrera zuzentzen...\n","147867136\n","409. esalditik aurrera zuzentzen...\n","147928576\n","421. esalditik aurrera zuzentzen...\n","148482048\n","433. esalditik aurrera zuzentzen...\n","147683328\n","445. esalditik aurrera zuzentzen...\n","148359168\n","457. esalditik aurrera zuzentzen...\n","147806208\n","469. esalditik aurrera zuzentzen...\n","147769344\n","481. esalditik aurrera zuzentzen...\n","148666368\n","493. esalditik aurrera zuzentzen...\n","148666368\n","505. esalditik aurrera zuzentzen...\n","148518912\n","517. esalditik aurrera zuzentzen...\n","148470272\n","529. esalditik aurrera zuzentzen...\n","149466112\n","541. esalditik aurrera zuzentzen...\n","148359168\n","553. esalditik aurrera zuzentzen...\n","148617728\n","565. esalditik aurrera zuzentzen...\n","149466112\n","577. esalditik aurrera zuzentzen...\n","148641792\n","589. esalditik aurrera zuzentzen...\n","149626880\n","601. esalditik aurrera zuzentzen...\n","149651456\n","613. esalditik aurrera zuzentzen...\n","149712384\n","625. esalditik aurrera zuzentzen...\n","149208576\n","637. esalditik aurrera zuzentzen...\n","149159424\n","649. esalditik aurrera zuzentzen...\n","149971456\n","661. esalditik aurrera zuzentzen...\n","151127040\n","673. esalditik aurrera zuzentzen...\n","150585856\n","685. esalditik aurrera zuzentzen...\n","150265856\n","697. esalditik aurrera zuzentzen...\n","150450688\n","709. esalditik aurrera zuzentzen...\n","151605760\n","721. esalditik aurrera zuzentzen...\n","150450176\n","733. esalditik aurrera zuzentzen...\n","153123840\n","745. esalditik aurrera zuzentzen...\n","150204928\n","757. esalditik aurrera zuzentzen...\n","152012288\n","769. esalditik aurrera zuzentzen...\n","151262720\n","781. esalditik aurrera zuzentzen...\n","151791616\n","793. esalditik aurrera zuzentzen...\n","152209920\n","805. esalditik aurrera zuzentzen...\n","153746944\n","817. esalditik aurrera zuzentzen...\n","152369152\n","829. esalditik aurrera zuzentzen...\n","153242624\n","841. esalditik aurrera zuzentzen...\n","152972288\n","853. esalditik aurrera zuzentzen...\n","154056192\n","865. esalditik aurrera zuzentzen...\n","154151936\n","877. esalditik aurrera zuzentzen...\n","159434752\n","889. esalditik aurrera zuzentzen...\n","153920512\n","901. esalditik aurrera zuzentzen...\n","154042368\n","913. esalditik aurrera zuzentzen...\n","158396416\n","925. esalditik aurrera zuzentzen...\n","158471680\n","937. esalditik aurrera zuzentzen...\n","157967872\n","949. esalditik aurrera zuzentzen...\n","159246848\n","961. esalditik aurrera zuzentzen...\n","161785344\n","973. esalditik aurrera zuzentzen...\n","164440064\n","985. esalditik aurrera zuzentzen...\n","163421696\n","997. esalditik aurrera zuzentzen...\n","2.673118603229523 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4hVstDn7pVbM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593679034237,"user_tz":-120,"elapsed":257642,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"8c82a5ed-fc9e-4144-e569-7864dbc5fde2"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","143649792\n","13. esalditik aurrera zuzentzen...\n","143600640\n","25. esalditik aurrera zuzentzen...\n","143649792\n","37. esalditik aurrera zuzentzen...\n","143809536\n","49. esalditik aurrera zuzentzen...\n","143932416\n","61. esalditik aurrera zuzentzen...\n","143772672\n","73. esalditik aurrera zuzentzen...\n","143834112\n","85. esalditik aurrera zuzentzen...\n","143883264\n","97. esalditik aurrera zuzentzen...\n","143944704\n","109. esalditik aurrera zuzentzen...\n","143883264\n","121. esalditik aurrera zuzentzen...\n","144215552\n","133. esalditik aurrera zuzentzen...\n","144166400\n","145. esalditik aurrera zuzentzen...\n","143944704\n","157. esalditik aurrera zuzentzen...\n","144043008\n","169. esalditik aurrera zuzentzen...\n","143883264\n","181. esalditik aurrera zuzentzen...\n","144375296\n","193. esalditik aurrera zuzentzen...\n","144055296\n","205. esalditik aurrera zuzentzen...\n","144116736\n","217. esalditik aurrera zuzentzen...\n","144055296\n","229. esalditik aurrera zuzentzen...\n","144055296\n","241. esalditik aurrera zuzentzen...\n","144338432\n","253. esalditik aurrera zuzentzen...\n","144645632\n","265. esalditik aurrera zuzentzen...\n","144165888\n","277. esalditik aurrera zuzentzen...\n","144301568\n","289. esalditik aurrera zuzentzen...\n","144178176\n","301. esalditik aurrera zuzentzen...\n","144289280\n","313. esalditik aurrera zuzentzen...\n","144350720\n","325. esalditik aurrera zuzentzen...\n","144338432\n","337. esalditik aurrera zuzentzen...\n","144129024\n","349. esalditik aurrera zuzentzen...\n","144276480\n","361. esalditik aurrera zuzentzen...\n","144337920\n","373. esalditik aurrera zuzentzen...\n","144387072\n","385. esalditik aurrera zuzentzen...\n","144350720\n","397. esalditik aurrera zuzentzen...\n","144412160\n","409. esalditik aurrera zuzentzen...\n","144239616\n","421. esalditik aurrera zuzentzen...\n","144350720\n","433. esalditik aurrera zuzentzen...\n","144584192\n","445. esalditik aurrera zuzentzen...\n","144571904\n","457. esalditik aurrera zuzentzen...\n","144571904\n","469. esalditik aurrera zuzentzen...\n","144633344\n","481. esalditik aurrera zuzentzen...\n","145456640\n","493. esalditik aurrera zuzentzen...\n","144854528\n","505. esalditik aurrera zuzentzen...\n","144805376\n","517. esalditik aurrera zuzentzen...\n","145641472\n","529. esalditik aurrera zuzentzen...\n","144633344\n","541. esalditik aurrera zuzentzen...\n","144694784\n","553. esalditik aurrera zuzentzen...\n","144805376\n","565. esalditik aurrera zuzentzen...\n","144940544\n","577. esalditik aurrera zuzentzen...\n","145038848\n","589. esalditik aurrera zuzentzen...\n","145100288\n","601. esalditik aurrera zuzentzen...\n","144867328\n","613. esalditik aurrera zuzentzen...\n","145297408\n","625. esalditik aurrera zuzentzen...\n","144928768\n","637. esalditik aurrera zuzentzen...\n","144941056\n","649. esalditik aurrera zuzentzen...\n","144941056\n","661. esalditik aurrera zuzentzen...\n","145027072\n","673. esalditik aurrera zuzentzen...\n","145248256\n","685. esalditik aurrera zuzentzen...\n","145568256\n","697. esalditik aurrera zuzentzen...\n","144990208\n","709. esalditik aurrera zuzentzen...\n","145334272\n","721. esalditik aurrera zuzentzen...\n","145395712\n","733. esalditik aurrera zuzentzen...\n","145875456\n","745. esalditik aurrera zuzentzen...\n","145690624\n","757. esalditik aurrera zuzentzen...\n","145863168\n","769. esalditik aurrera zuzentzen...\n","145875456\n","781. esalditik aurrera zuzentzen...\n","145678336\n","793. esalditik aurrera zuzentzen...\n","145825792\n","805. esalditik aurrera zuzentzen...\n","145788928\n","817. esalditik aurrera zuzentzen...\n","146010624\n","829. esalditik aurrera zuzentzen...\n","145960960\n","841. esalditik aurrera zuzentzen...\n","146256384\n","853. esalditik aurrera zuzentzen...\n","146244096\n","865. esalditik aurrera zuzentzen...\n","146612736\n","877. esalditik aurrera zuzentzen...\n","146650112\n","889. esalditik aurrera zuzentzen...\n","147866624\n","901. esalditik aurrera zuzentzen...\n","147720192\n","913. esalditik aurrera zuzentzen...\n","148666368\n","925. esalditik aurrera zuzentzen...\n","147486720\n","937. esalditik aurrera zuzentzen...\n","148666368\n","949. esalditik aurrera zuzentzen...\n","148494848\n","961. esalditik aurrera zuzentzen...\n","149416960\n","973. esalditik aurrera zuzentzen...\n","149958656\n","985. esalditik aurrera zuzentzen...\n","152135168\n","997. esalditik aurrera zuzentzen...\n","1.0740967551867167 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J4TT_GOLpVbP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593679034239,"user_tz":-120,"elapsed":254792,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"a42954a8-5a49-4b1a-d1f4-fb0693970d45"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.473784845910787, 18.876006194522084, 13.95776254537756)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x4oIZdDDpVbT"},"source":["### avg"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"83amO-l-pVbU","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593679080295,"user_tz":-120,"elapsed":14944,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"f706277c-5343-47d4-e0bc-66fe8cdd0cf0"},"source":["model = batezbeste3('EhuHac/trainhobea3-15.pt', 'EhuHac/trainhobea3-16.pt', \n","                    'EhuHac/trainhobea3-17.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"19ZcmIBopVbX","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593679111607,"user_tz":-120,"elapsed":41933,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"a6ff1ceb-35c1-45f2-a373-ad22809145aa"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["25.018686532974243 segundo behar izan ditu zuzentzeko.\n","7.183152914047241 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(12.21585083932414, 20.076386050173372, 14.040400902577968)"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"baRaeemOpVbZ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593679332480,"user_tz":-120,"elapsed":177747,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"7fe1f452-94b9-49dc-b942-cdd6d23209e1"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["715159552\n","1. esalditik aurrera zuzentzen...\n","716170240\n","13. esalditik aurrera zuzentzen...\n","716243968\n","25. esalditik aurrera zuzentzen...\n","716612608\n","37. esalditik aurrera zuzentzen...\n","716575744\n","49. esalditik aurrera zuzentzen...\n","716575744\n","61. esalditik aurrera zuzentzen...\n","716747776\n","73. esalditik aurrera zuzentzen...\n","716883456\n","85. esalditik aurrera zuzentzen...\n","716809216\n","97. esalditik aurrera zuzentzen...\n","717387264\n","109. esalditik aurrera zuzentzen...\n","717424128\n","121. esalditik aurrera zuzentzen...\n","717510144\n","133. esalditik aurrera zuzentzen...\n","717460992\n","145. esalditik aurrera zuzentzen...\n","717547520\n","157. esalditik aurrera zuzentzen...\n","717486080\n","169. esalditik aurrera zuzentzen...\n","717989888\n","181. esalditik aurrera zuzentzen...\n","717621248\n","193. esalditik aurrera zuzentzen...\n","717989888\n","205. esalditik aurrera zuzentzen...\n","717940736\n","217. esalditik aurrera zuzentzen...\n","718346752\n","229. esalditik aurrera zuzentzen...\n","718260224\n","241. esalditik aurrera zuzentzen...\n","718309376\n","253. esalditik aurrera zuzentzen...\n","718592512\n","265. esalditik aurrera zuzentzen...\n","718309376\n","277. esalditik aurrera zuzentzen...\n","718321664\n","289. esalditik aurrera zuzentzen...\n","718965760\n","301. esalditik aurrera zuzentzen...\n","718965760\n","313. esalditik aurrera zuzentzen...\n","718752768\n","325. esalditik aurrera zuzentzen...\n","719956992\n","337. esalditik aurrera zuzentzen...\n","720292864\n","349. esalditik aurrera zuzentzen...\n","719342592\n","361. esalditik aurrera zuzentzen...\n","720280576\n","373. esalditik aurrera zuzentzen...\n","720141312\n","385. esalditik aurrera zuzentzen...\n","719392256\n","397. esalditik aurrera zuzentzen...\n","720453120\n","409. esalditik aurrera zuzentzen...\n","720465920\n","421. esalditik aurrera zuzentzen...\n","720117760\n","433. esalditik aurrera zuzentzen...\n","720154624\n","445. esalditik aurrera zuzentzen...\n","720551936\n","457. esalditik aurrera zuzentzen...\n","720588800\n","469. esalditik aurrera zuzentzen...\n","720601088\n","481. esalditik aurrera zuzentzen...\n","720302080\n","493. esalditik aurrera zuzentzen...\n","720613376\n","505. esalditik aurrera zuzentzen...\n","721039360\n","517. esalditik aurrera zuzentzen...\n","721039872\n","529. esalditik aurrera zuzentzen...\n","722985984\n","541. esalditik aurrera zuzentzen...\n","721027584\n","553. esalditik aurrera zuzentzen...\n","721187328\n","565. esalditik aurrera zuzentzen...\n","722543616\n","577. esalditik aurrera zuzentzen...\n","721899520\n","589. esalditik aurrera zuzentzen...\n","722048512\n","601. esalditik aurrera zuzentzen...\n","723023360\n","613. esalditik aurrera zuzentzen...\n","722593280\n","625. esalditik aurrera zuzentzen...\n","722679296\n","637. esalditik aurrera zuzentzen...\n","722629632\n","649. esalditik aurrera zuzentzen...\n","723245568\n","661. esalditik aurrera zuzentzen...\n","728476672\n","673. esalditik aurrera zuzentzen...\n","723171328\n","685. esalditik aurrera zuzentzen...\n","723195392\n","697. esalditik aurrera zuzentzen...\n","723134464\n","709. esalditik aurrera zuzentzen...\n","723208192\n","721. esalditik aurrera zuzentzen...\n","723036160\n","733. esalditik aurrera zuzentzen...\n","723278336\n","745. esalditik aurrera zuzentzen...\n","722889216\n","757. esalditik aurrera zuzentzen...\n","723697152\n","769. esalditik aurrera zuzentzen...\n","724455424\n","781. esalditik aurrera zuzentzen...\n","724164096\n","793. esalditik aurrera zuzentzen...\n","724434944\n","805. esalditik aurrera zuzentzen...\n","726023168\n","817. esalditik aurrera zuzentzen...\n","724938752\n","829. esalditik aurrera zuzentzen...\n","725763072\n","841. esalditik aurrera zuzentzen...\n","725640704\n","853. esalditik aurrera zuzentzen...\n","729829376\n","865. esalditik aurrera zuzentzen...\n","725935616\n","877. esalditik aurrera zuzentzen...\n","732579328\n","889. esalditik aurrera zuzentzen...\n","726145024\n","901. esalditik aurrera zuzentzen...\n","726612480\n","913. esalditik aurrera zuzentzen...\n","731788800\n","925. esalditik aurrera zuzentzen...\n","732287488\n","937. esalditik aurrera zuzentzen...\n","731520000\n","949. esalditik aurrera zuzentzen...\n","731151872\n","961. esalditik aurrera zuzentzen...\n","733711360\n","973. esalditik aurrera zuzentzen...\n","735896576\n","985. esalditik aurrera zuzentzen...\n","736617984\n","997. esalditik aurrera zuzentzen...\n","2.944683337211609 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2lQY_xAbpVbc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593679400207,"user_tz":-120,"elapsed":244488,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"2bb9ce5a-9eb6-436c-8486-b2268b8be571"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["715159552\n","1. esalditik aurrera zuzentzen...\n","716121088\n","13. esalditik aurrera zuzentzen...\n","716170240\n","25. esalditik aurrera zuzentzen...\n","716268544\n","37. esalditik aurrera zuzentzen...\n","716280832\n","49. esalditik aurrera zuzentzen...\n","716452864\n","61. esalditik aurrera zuzentzen...\n","716342272\n","73. esalditik aurrera zuzentzen...\n","716354560\n","85. esalditik aurrera zuzentzen...\n","716452864\n","97. esalditik aurrera zuzentzen...\n","716416000\n","109. esalditik aurrera zuzentzen...\n","716403712\n","121. esalditik aurrera zuzentzen...\n","716981760\n","133. esalditik aurrera zuzentzen...\n","716686848\n","145. esalditik aurrera zuzentzen...\n","716514304\n","157. esalditik aurrera zuzentzen...\n","716563456\n","169. esalditik aurrera zuzentzen...\n","716403712\n","181. esalditik aurrera zuzentzen...\n","716895744\n","193. esalditik aurrera zuzentzen...\n","716526592\n","205. esalditik aurrera zuzentzen...\n","716637184\n","217. esalditik aurrera zuzentzen...\n","716575744\n","229. esalditik aurrera zuzentzen...\n","716575744\n","241. esalditik aurrera zuzentzen...\n","716858880\n","253. esalditik aurrera zuzentzen...\n","717166080\n","265. esalditik aurrera zuzentzen...\n","716637184\n","277. esalditik aurrera zuzentzen...\n","716871168\n","289. esalditik aurrera zuzentzen...\n","716698624\n","301. esalditik aurrera zuzentzen...\n","716809728\n","313. esalditik aurrera zuzentzen...\n","716871168\n","325. esalditik aurrera zuzentzen...\n","716809728\n","337. esalditik aurrera zuzentzen...\n","716649472\n","349. esalditik aurrera zuzentzen...\n","716796928\n","361. esalditik aurrera zuzentzen...\n","716907520\n","373. esalditik aurrera zuzentzen...\n","716907520\n","385. esalditik aurrera zuzentzen...\n","716969472\n","397. esalditik aurrera zuzentzen...\n","716932608\n","409. esalditik aurrera zuzentzen...\n","716809216\n","421. esalditik aurrera zuzentzen...\n","716871168\n","433. esalditik aurrera zuzentzen...\n","717153792\n","445. esalditik aurrera zuzentzen...\n","717043200\n","457. esalditik aurrera zuzentzen...\n","717043200\n","469. esalditik aurrera zuzentzen...\n","717153792\n","481. esalditik aurrera zuzentzen...\n","717927936\n","493. esalditik aurrera zuzentzen...\n","717374976\n","505. esalditik aurrera zuzentzen...\n","717325824\n","517. esalditik aurrera zuzentzen...\n","717916160\n","529. esalditik aurrera zuzentzen...\n","717202944\n","541. esalditik aurrera zuzentzen...\n","717215232\n","553. esalditik aurrera zuzentzen...\n","717325824\n","565. esalditik aurrera zuzentzen...\n","717460992\n","577. esalditik aurrera zuzentzen...\n","717460992\n","589. esalditik aurrera zuzentzen...\n","717571584\n","601. esalditik aurrera zuzentzen...\n","717387776\n","613. esalditik aurrera zuzentzen...\n","717867008\n","625. esalditik aurrera zuzentzen...\n","717547520\n","637. esalditik aurrera zuzentzen...\n","717608960\n","649. esalditik aurrera zuzentzen...\n","717658112\n","661. esalditik aurrera zuzentzen...\n","717596672\n","673. esalditik aurrera zuzentzen...\n","717719552\n","685. esalditik aurrera zuzentzen...\n","717990400\n","697. esalditik aurrera zuzentzen...\n","717559808\n","709. esalditik aurrera zuzentzen...\n","717854720\n","721. esalditik aurrera zuzentzen...\n","717916160\n","733. esalditik aurrera zuzentzen...\n","718346752\n","745. esalditik aurrera zuzentzen...\n","718063616\n","757. esalditik aurrera zuzentzen...\n","718432768\n","769. esalditik aurrera zuzentzen...\n","718445056\n","781. esalditik aurrera zuzentzen...\n","718198784\n","793. esalditik aurrera zuzentzen...\n","718297088\n","805. esalditik aurrera zuzentzen...\n","718211072\n","817. esalditik aurrera zuzentzen...\n","718531072\n","829. esalditik aurrera zuzentzen...\n","718481408\n","841. esalditik aurrera zuzentzen...\n","718825984\n","853. esalditik aurrera zuzentzen...\n","718764544\n","865. esalditik aurrera zuzentzen...\n","719133184\n","877. esalditik aurrera zuzentzen...\n","719121408\n","889. esalditik aurrera zuzentzen...\n","719551488\n","901. esalditik aurrera zuzentzen...\n","720551936\n","913. esalditik aurrera zuzentzen...\n","720613376\n","925. esalditik aurrera zuzentzen...\n","720564224\n","937. esalditik aurrera zuzentzen...\n","720613376\n","949. esalditik aurrera zuzentzen...\n","720916480\n","961. esalditik aurrera zuzentzen...\n","723084288\n","973. esalditik aurrera zuzentzen...\n","723036160\n","985. esalditik aurrera zuzentzen...\n","724934656\n","997. esalditik aurrera zuzentzen...\n","1.1265613675117492 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ov3NxqGfpVbg","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593679400211,"user_tz":-120,"elapsed":241523,"user":{"displayName":"Bittor2 Alkain2","photoUrl":"","userId":"05891003555011841047"}},"outputId":"b3590e1a-7e73-4b5b-e9cb-5f9e362cfaa5"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.697621211475651, 19.86639727430322, 14.346153245519764)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"sN66zMDEL2C7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lU-l7Ad8L2l9"},"source":["## origetaos2"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KLwG2L2lL2l-","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594465239684,"user_tz":-120,"elapsed":17017,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2597824a-c94c-4eaf-8fc2-eb98c5fedbc1"},"source":["model = SharedDualTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('HACOSDatuak/origetaos2-17.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedDualTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDualDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DualDecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (norm_4): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (dropout_4): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_3): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MoHpn9exL2mD","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594465283163,"user_tz":-120,"elapsed":57499,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"75ea112c-083a-4054-ee81-23a6a5766888"},"source":["zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["35.35762858390808 segundo behar izan ditu zuzentzeko.\n","8.061494827270508 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pbts2liKL2mF","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594465283595,"user_tz":-120,"elapsed":56928,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"7fe23a82-3366-45ee-c1e1-69d602178eeb"},"source":["references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12.347756219465131, 27.569530530585162, 15.875394073925994)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m2rGh553L2mI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594465466816,"user_tz":-120,"elapsed":238139,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"fbe29a02-e0e4-4c03-8bdb-227074da7279"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","143698944\n","13. esalditik aurrera zuzentzen...\n","143772672\n","25. esalditik aurrera zuzentzen...\n","143846400\n","37. esalditik aurrera zuzentzen...\n","143895552\n","49. esalditik aurrera zuzentzen...\n","143956992\n","61. esalditik aurrera zuzentzen...\n","144227328\n","73. esalditik aurrera zuzentzen...\n","144399872\n","85. esalditik aurrera zuzentzen...\n","144473600\n","97. esalditik aurrera zuzentzen...\n","144510464\n","109. esalditik aurrera zuzentzen...\n","144854528\n","121. esalditik aurrera zuzentzen...\n","145038848\n","133. esalditik aurrera zuzentzen...\n","144989696\n","145. esalditik aurrera zuzentzen...\n","145088512\n","157. esalditik aurrera zuzentzen...\n","145088512\n","169. esalditik aurrera zuzentzen...\n","145371136\n","181. esalditik aurrera zuzentzen...\n","145199104\n","193. esalditik aurrera zuzentzen...\n","145346560\n","205. esalditik aurrera zuzentzen...\n","145346560\n","217. esalditik aurrera zuzentzen...\n","145924608\n","229. esalditik aurrera zuzentzen...\n","145825792\n","241. esalditik aurrera zuzentzen...\n","145788928\n","253. esalditik aurrera zuzentzen...\n","146010624\n","265. esalditik aurrera zuzentzen...\n","145973760\n","277. esalditik aurrera zuzentzen...\n","145850368\n","289. esalditik aurrera zuzentzen...\n","146035200\n","301. esalditik aurrera zuzentzen...\n","146232320\n","313. esalditik aurrera zuzentzen...\n","146022400\n","325. esalditik aurrera zuzentzen...\n","146355200\n","337. esalditik aurrera zuzentzen...\n","146674176\n","349. esalditik aurrera zuzentzen...\n","146723840\n","361. esalditik aurrera zuzentzen...\n","146908160\n","373. esalditik aurrera zuzentzen...\n","147743744\n","385. esalditik aurrera zuzentzen...\n","147867136\n","397. esalditik aurrera zuzentzen...\n","147326976\n","409. esalditik aurrera zuzentzen...\n","148298240\n","421. esalditik aurrera zuzentzen...\n","147338752\n","433. esalditik aurrera zuzentzen...\n","147314176\n","445. esalditik aurrera zuzentzen...\n","147683328\n","457. esalditik aurrera zuzentzen...\n","148604928\n","469. esalditik aurrera zuzentzen...\n","147769344\n","481. esalditik aurrera zuzentzen...\n","147929088\n","493. esalditik aurrera zuzentzen...\n","148666880\n","505. esalditik aurrera zuzentzen...\n","148814336\n","517. esalditik aurrera zuzentzen...\n","149404672\n","529. esalditik aurrera zuzentzen...\n","149096960\n","541. esalditik aurrera zuzentzen...\n","148457472\n","553. esalditik aurrera zuzentzen...\n","149404672\n","565. esalditik aurrera zuzentzen...\n","149219840\n","577. esalditik aurrera zuzentzen...\n","148641792\n","589. esalditik aurrera zuzentzen...\n","149244928\n","601. esalditik aurrera zuzentzen...\n","149589504\n","613. esalditik aurrera zuzentzen...\n","149085184\n","625. esalditik aurrera zuzentzen...\n","148950016\n","637. esalditik aurrera zuzentzen...\n","149466112\n","649. esalditik aurrera zuzentzen...\n","149467136\n","661. esalditik aurrera zuzentzen...\n","152727552\n","673. esalditik aurrera zuzentzen...\n","150118400\n","685. esalditik aurrera zuzentzen...\n","150364672\n","697. esalditik aurrera zuzentzen...\n","150610432\n","709. esalditik aurrera zuzentzen...\n","150573056\n","721. esalditik aurrera zuzentzen...\n","150216704\n","733. esalditik aurrera zuzentzen...\n","150130688\n","745. esalditik aurrera zuzentzen...\n","150967808\n","757. esalditik aurrera zuzentzen...\n","150696960\n","769. esalditik aurrera zuzentzen...\n","152185344\n","781. esalditik aurrera zuzentzen...\n","151792128\n","793. esalditik aurrera zuzentzen...\n","151496192\n","805. esalditik aurrera zuzentzen...\n","152775680\n","817. esalditik aurrera zuzentzen...\n","154486272\n","829. esalditik aurrera zuzentzen...\n","152652800\n","841. esalditik aurrera zuzentzen...\n","153698816\n","853. esalditik aurrera zuzentzen...\n","153994752\n","865. esalditik aurrera zuzentzen...\n","152910336\n","877. esalditik aurrera zuzentzen...\n","159896064\n","889. esalditik aurrera zuzentzen...\n","154759680\n","901. esalditik aurrera zuzentzen...\n","154351104\n","913. esalditik aurrera zuzentzen...\n","154719232\n","925. esalditik aurrera zuzentzen...\n","159335936\n","937. esalditik aurrera zuzentzen...\n","158388736\n","949. esalditik aurrera zuzentzen...\n","157824512\n","961. esalditik aurrera zuzentzen...\n","160814080\n","973. esalditik aurrera zuzentzen...\n","164338688\n","985. esalditik aurrera zuzentzen...\n","164949504\n","997. esalditik aurrera zuzentzen...\n","3.0488203883171083 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EJRc4AEhL2mL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594465527711,"user_tz":-120,"elapsed":297159,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"0115a8d1-6417-4f5a-fed1-c7ae580ba04e"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142639104\n","1. esalditik aurrera zuzentzen...\n","143490048\n","13. esalditik aurrera zuzentzen...\n","143600640\n","25. esalditik aurrera zuzentzen...\n","143760384\n","37. esalditik aurrera zuzentzen...\n","143600640\n","49. esalditik aurrera zuzentzen...\n","143551488\n","61. esalditik aurrera zuzentzen...\n","143932416\n","73. esalditik aurrera zuzentzen...\n","143772672\n","85. esalditik aurrera zuzentzen...\n","143821824\n","97. esalditik aurrera zuzentzen...\n","143932416\n","109. esalditik aurrera zuzentzen...\n","143895552\n","121. esalditik aurrera zuzentzen...\n","143932416\n","133. esalditik aurrera zuzentzen...\n","144018944\n","145. esalditik aurrera zuzentzen...\n","144080384\n","157. esalditik aurrera zuzentzen...\n","143932416\n","169. esalditik aurrera zuzentzen...\n","143944704\n","181. esalditik aurrera zuzentzen...\n","143883264\n","193. esalditik aurrera zuzentzen...\n","144276992\n","205. esalditik aurrera zuzentzen...\n","144006144\n","217. esalditik aurrera zuzentzen...\n","144067584\n","229. esalditik aurrera zuzentzen...\n","144067584\n","241. esalditik aurrera zuzentzen...\n","144055296\n","253. esalditik aurrera zuzentzen...\n","144055296\n","265. esalditik aurrera zuzentzen...\n","144387584\n","277. esalditik aurrera zuzentzen...\n","144399872\n","289. esalditik aurrera zuzentzen...\n","144240128\n","301. esalditik aurrera zuzentzen...\n","144116736\n","313. esalditik aurrera zuzentzen...\n","144129024\n","325. esalditik aurrera zuzentzen...\n","144227328\n","337. esalditik aurrera zuzentzen...\n","144240128\n","349. esalditik aurrera zuzentzen...\n","144240128\n","361. esalditik aurrera zuzentzen...\n","144055296\n","373. esalditik aurrera zuzentzen...\n","144350720\n","385. esalditik aurrera zuzentzen...\n","144412160\n","397. esalditik aurrera zuzentzen...\n","144337920\n","409. esalditik aurrera zuzentzen...\n","144350720\n","421. esalditik aurrera zuzentzen...\n","145137152\n","433. esalditik aurrera zuzentzen...\n","144288768\n","445. esalditik aurrera zuzentzen...\n","144461312\n","457. esalditik aurrera zuzentzen...\n","144633344\n","469. esalditik aurrera zuzentzen...\n","144363008\n","481. esalditik aurrera zuzentzen...\n","144731648\n","493. esalditik aurrera zuzentzen...\n","144535040\n","505. esalditik aurrera zuzentzen...\n","144805376\n","517. esalditik aurrera zuzentzen...\n","144707072\n","529. esalditik aurrera zuzentzen...\n","145124864\n","541. esalditik aurrera zuzentzen...\n","144535040\n","553. esalditik aurrera zuzentzen...\n","144694784\n","565. esalditik aurrera zuzentzen...\n","144756224\n","577. esalditik aurrera zuzentzen...\n","144940544\n","589. esalditik aurrera zuzentzen...\n","144940544\n","601. esalditik aurrera zuzentzen...\n","145333760\n","613. esalditik aurrera zuzentzen...\n","145260544\n","625. esalditik aurrera zuzentzen...\n","145113088\n","637. esalditik aurrera zuzentzen...\n","145235968\n","649. esalditik aurrera zuzentzen...\n","145137664\n","661. esalditik aurrera zuzentzen...\n","144990208\n","673. esalditik aurrera zuzentzen...\n","145100800\n","685. esalditik aurrera zuzentzen...\n","145100800\n","697. esalditik aurrera zuzentzen...\n","145174528\n","709. esalditik aurrera zuzentzen...\n","145039360\n","721. esalditik aurrera zuzentzen...\n","145666048\n","733. esalditik aurrera zuzentzen...\n","145408000\n","745. esalditik aurrera zuzentzen...\n","145740288\n","757. esalditik aurrera zuzentzen...\n","145444864\n","769. esalditik aurrera zuzentzen...\n","145641472\n","781. esalditik aurrera zuzentzen...\n","145850880\n","793. esalditik aurrera zuzentzen...\n","145825792\n","805. esalditik aurrera zuzentzen...\n","145629184\n","817. esalditik aurrera zuzentzen...\n","145739776\n","829. esalditik aurrera zuzentzen...\n","146059776\n","841. esalditik aurrera zuzentzen...\n","145960960\n","853. esalditik aurrera zuzentzen...\n","146551296\n","865. esalditik aurrera zuzentzen...\n","145960960\n","877. esalditik aurrera zuzentzen...\n","146489856\n","889. esalditik aurrera zuzentzen...\n","147142144\n","901. esalditik aurrera zuzentzen...\n","148359168\n","913. esalditik aurrera zuzentzen...\n","147154432\n","925. esalditik aurrera zuzentzen...\n","147990528\n","937. esalditik aurrera zuzentzen...\n","148604928\n","949. esalditik aurrera zuzentzen...\n","149650432\n","961. esalditik aurrera zuzentzen...\n","148174848\n","973. esalditik aurrera zuzentzen...\n","149466624\n","985. esalditik aurrera zuzentzen...\n","152188416\n","997. esalditik aurrera zuzentzen...\n","1.0131633122762045 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9d7_P8huL2mN","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594465527714,"user_tz":-120,"elapsed":294916,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"40b20796-fe1d-4a23-f3b1-fa7fefb16505"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13.034375387912819, 27.743151924502975, 16.42441320189871)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5KM3wD2pL2mP"},"source":["### avg"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Oac2O4hjL2mQ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598092823046,"user_tz":-120,"elapsed":27843,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"eab53f24-dce3-49c6-a351-4cf5987854b8"},"source":["model = batezbeste3('HACOSDatuak/origetaos2-16.pt', 'HACOSDatuak/origetaos2-17.pt', \n","                    'HACOSDatuak/origetaos2-18.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"erc67M8HL2mS","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1594465583967,"user_tz":-120,"elapsed":346527,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"85e4ddee-dc29-40a1-ff22-84e005c735c0"},"source":["# P100 GPU\n","zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32.53010392189026 segundo behar izan ditu zuzentzeko.\n","8.845804452896118 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(12.807970813776826, 28.047251545815477, 16.320396343115636)"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"E98x8SPH-PUI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1594539750611,"user_tz":-120,"elapsed":41953,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"f549bd4a-8d2a-4fce-c016-423889e472a7"},"source":["# T4 GPU\n","zuzendua1 = zuzendu_zenbakitua(model, dev1, 50)\n","zuzendua2 = zuzendu_zenbakitua(model, dev2, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.18082308769226 segundo behar izan ditu zuzentzeko.\n","7.475852012634277 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(12.827110874577553, 28.092674742272, 16.345434744933815)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ivh6a1LcL2mV","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594539960672,"user_tz":-120,"elapsed":155016,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"215fa4ec-4bd8-484b-a8ca-ca4d89167621"},"source":["zuzendua1 = zuzendu_beam(model, dev1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["572029440\n","1. esalditik aurrera zuzentzen...\n","573089280\n","13. esalditik aurrera zuzentzen...\n","573163008\n","25. esalditik aurrera zuzentzen...\n","573285888\n","37. esalditik aurrera zuzentzen...\n","573285888\n","49. esalditik aurrera zuzentzen...\n","573396480\n","61. esalditik aurrera zuzentzen...\n","573617664\n","73. esalditik aurrera zuzentzen...\n","573790208\n","85. esalditik aurrera zuzentzen...\n","573863936\n","97. esalditik aurrera zuzentzen...\n","573802496\n","109. esalditik aurrera zuzentzen...\n","574195712\n","121. esalditik aurrera zuzentzen...\n","574527488\n","133. esalditik aurrera zuzentzen...\n","574380032\n","145. esalditik aurrera zuzentzen...\n","574429696\n","157. esalditik aurrera zuzentzen...\n","574577152\n","169. esalditik aurrera zuzentzen...\n","574663168\n","181. esalditik aurrera zuzentzen...\n","574589440\n","193. esalditik aurrera zuzentzen...\n","574687744\n","205. esalditik aurrera zuzentzen...\n","574736896\n","217. esalditik aurrera zuzentzen...\n","576134144\n","229. esalditik aurrera zuzentzen...\n","575216128\n","241. esalditik aurrera zuzentzen...\n","575228416\n","253. esalditik aurrera zuzentzen...\n","576416768\n","265. esalditik aurrera zuzentzen...\n","576330752\n","277. esalditik aurrera zuzentzen...\n","575289856\n","289. esalditik aurrera zuzentzen...\n","576392192\n","301. esalditik aurrera zuzentzen...\n","576589312\n","313. esalditik aurrera zuzentzen...\n","575412736\n","325. esalditik aurrera zuzentzen...\n","576712192\n","337. esalditik aurrera zuzentzen...\n","576785920\n","349. esalditik aurrera zuzentzen...\n","576835072\n","361. esalditik aurrera zuzentzen...\n","576921088\n","373. esalditik aurrera zuzentzen...\n","577953280\n","385. esalditik aurrera zuzentzen...\n","577241088\n","397. esalditik aurrera zuzentzen...\n","577831424\n","409. esalditik aurrera zuzentzen...\n","577819136\n","421. esalditik aurrera zuzentzen...\n","577646592\n","433. esalditik aurrera zuzentzen...\n","577425408\n","445. esalditik aurrera zuzentzen...\n","577942016\n","457. esalditik aurrera zuzentzen...\n","578126336\n","469. esalditik aurrera zuzentzen...\n","577880576\n","481. esalditik aurrera zuzentzen...\n","578384896\n","493. esalditik aurrera zuzentzen...\n","578483200\n","505. esalditik aurrera zuzentzen...\n","578875904\n","517. esalditik aurrera zuzentzen...\n","579515904\n","529. esalditik aurrera zuzentzen...\n","578863616\n","541. esalditik aurrera zuzentzen...\n","578863616\n","553. esalditik aurrera zuzentzen...\n","578926080\n","565. esalditik aurrera zuzentzen...\n","578445824\n","577. esalditik aurrera zuzentzen...\n","578606080\n","589. esalditik aurrera zuzentzen...\n","579651072\n","601. esalditik aurrera zuzentzen...\n","578963456\n","613. esalditik aurrera zuzentzen...\n","578950656\n","625. esalditik aurrera zuzentzen...\n","578963456\n","637. esalditik aurrera zuzentzen...\n","578692608\n","649. esalditik aurrera zuzentzen...\n","579086336\n","661. esalditik aurrera zuzentzen...\n","582247424\n","673. esalditik aurrera zuzentzen...\n","580131328\n","685. esalditik aurrera zuzentzen...\n","579935232\n","697. esalditik aurrera zuzentzen...\n","580230144\n","709. esalditik aurrera zuzentzen...\n","580291584\n","721. esalditik aurrera zuzentzen...\n","579738112\n","733. esalditik aurrera zuzentzen...\n","579750400\n","745. esalditik aurrera zuzentzen...\n","580161024\n","757. esalditik aurrera zuzentzen...\n","580037632\n","769. esalditik aurrera zuzentzen...\n","582001152\n","781. esalditik aurrera zuzentzen...\n","581231616\n","793. esalditik aurrera zuzentzen...\n","580886528\n","805. esalditik aurrera zuzentzen...\n","582705664\n","817. esalditik aurrera zuzentzen...\n","583481856\n","829. esalditik aurrera zuzentzen...\n","583256064\n","841. esalditik aurrera zuzentzen...\n","583137280\n","853. esalditik aurrera zuzentzen...\n","586244608\n","865. esalditik aurrera zuzentzen...\n","583087616\n","877. esalditik aurrera zuzentzen...\n","590531584\n","889. esalditik aurrera zuzentzen...\n","585960448\n","901. esalditik aurrera zuzentzen...\n","583790080\n","913. esalditik aurrera zuzentzen...\n","584356352\n","925. esalditik aurrera zuzentzen...\n","589085696\n","937. esalditik aurrera zuzentzen...\n","588587008\n","949. esalditik aurrera zuzentzen...\n","587538432\n","961. esalditik aurrera zuzentzen...\n","589486080\n","973. esalditik aurrera zuzentzen...\n","593912320\n","985. esalditik aurrera zuzentzen...\n","593537024\n","997. esalditik aurrera zuzentzen...\n","2.5662415266036986 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V6s6VxThL2mY","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594540026945,"user_tz":-120,"elapsed":218381,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c1657001-9a2f-488b-f9f0-b1c317fa749a"},"source":["zuzendua2 = zuzendu_beam(model, dev2, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["572029440\n","1. esalditik aurrera zuzentzen...\n","572880384\n","13. esalditik aurrera zuzentzen...\n","572990976\n","25. esalditik aurrera zuzentzen...\n","573249024\n","37. esalditik aurrera zuzentzen...\n","572990976\n","49. esalditik aurrera zuzentzen...\n","572941824\n","61. esalditik aurrera zuzentzen...\n","573322752\n","73. esalditik aurrera zuzentzen...\n","573212160\n","85. esalditik aurrera zuzentzen...\n","573212160\n","97. esalditik aurrera zuzentzen...\n","573224448\n","109. esalditik aurrera zuzentzen...\n","573285888\n","121. esalditik aurrera zuzentzen...\n","573322752\n","133. esalditik aurrera zuzentzen...\n","573409280\n","145. esalditik aurrera zuzentzen...\n","573519872\n","157. esalditik aurrera zuzentzen...\n","573322752\n","169. esalditik aurrera zuzentzen...\n","573335040\n","181. esalditik aurrera zuzentzen...\n","573224448\n","193. esalditik aurrera zuzentzen...\n","573667328\n","205. esalditik aurrera zuzentzen...\n","573396480\n","217. esalditik aurrera zuzentzen...\n","573507072\n","229. esalditik aurrera zuzentzen...\n","573457920\n","241. esalditik aurrera zuzentzen...\n","573445632\n","253. esalditik aurrera zuzentzen...\n","573445632\n","265. esalditik aurrera zuzentzen...\n","573777920\n","277. esalditik aurrera zuzentzen...\n","573642752\n","289. esalditik aurrera zuzentzen...\n","573630464\n","301. esalditik aurrera zuzentzen...\n","573507072\n","313. esalditik aurrera zuzentzen...\n","573519360\n","325. esalditik aurrera zuzentzen...\n","573666816\n","337. esalditik aurrera zuzentzen...\n","573630464\n","349. esalditik aurrera zuzentzen...\n","573581312\n","361. esalditik aurrera zuzentzen...\n","573445632\n","373. esalditik aurrera zuzentzen...\n","573839360\n","385. esalditik aurrera zuzentzen...\n","573753344\n","397. esalditik aurrera zuzentzen...\n","573728256\n","409. esalditik aurrera zuzentzen...\n","573741056\n","421. esalditik aurrera zuzentzen...\n","574527488\n","433. esalditik aurrera zuzentzen...\n","573679104\n","445. esalditik aurrera zuzentzen...\n","573900800\n","457. esalditik aurrera zuzentzen...\n","573974528\n","469. esalditik aurrera zuzentzen...\n","573802496\n","481. esalditik aurrera zuzentzen...\n","574121984\n","493. esalditik aurrera zuzentzen...\n","573974528\n","505. esalditik aurrera zuzentzen...\n","574195712\n","517. esalditik aurrera zuzentzen...\n","574048256\n","529. esalditik aurrera zuzentzen...\n","574466048\n","541. esalditik aurrera zuzentzen...\n","574023680\n","553. esalditik aurrera zuzentzen...\n","574085120\n","565. esalditik aurrera zuzentzen...\n","574146560\n","577. esalditik aurrera zuzentzen...\n","574330880\n","589. esalditik aurrera zuzentzen...\n","574330880\n","601. esalditik aurrera zuzentzen...\n","574724096\n","613. esalditik aurrera zuzentzen...\n","574601728\n","625. esalditik aurrera zuzentzen...\n","574503424\n","637. esalditik aurrera zuzentzen...\n","574626304\n","649. esalditik aurrera zuzentzen...\n","574478848\n","661. esalditik aurrera zuzentzen...\n","574380544\n","673. esalditik aurrera zuzentzen...\n","574491136\n","685. esalditik aurrera zuzentzen...\n","574441984\n","697. esalditik aurrera zuzentzen...\n","574663168\n","709. esalditik aurrera zuzentzen...\n","574429696\n","721. esalditik aurrera zuzentzen...\n","575007232\n","733. esalditik aurrera zuzentzen...\n","574798336\n","745. esalditik aurrera zuzentzen...\n","576097280\n","757. esalditik aurrera zuzentzen...\n","574786048\n","769. esalditik aurrera zuzentzen...\n","575031808\n","781. esalditik aurrera zuzentzen...\n","576306176\n","793. esalditik aurrera zuzentzen...\n","575216128\n","805. esalditik aurrera zuzentzen...\n","575117824\n","817. esalditik aurrera zuzentzen...\n","575179264\n","829. esalditik aurrera zuzentzen...\n","576416768\n","841. esalditik aurrera zuzentzen...\n","575400448\n","853. esalditik aurrera zuzentzen...\n","576515072\n","865. esalditik aurrera zuzentzen...\n","575351296\n","877. esalditik aurrera zuzentzen...\n","576798208\n","889. esalditik aurrera zuzentzen...\n","577007616\n","901. esalditik aurrera zuzentzen...\n","577880576\n","913. esalditik aurrera zuzentzen...\n","578199552\n","925. esalditik aurrera zuzentzen...\n","578101760\n","937. esalditik aurrera zuzentzen...\n","577929728\n","949. esalditik aurrera zuzentzen...\n","579662848\n","961. esalditik aurrera zuzentzen...\n","578236928\n","973. esalditik aurrera zuzentzen...\n","579184640\n","985. esalditik aurrera zuzentzen...\n","584719872\n","997. esalditik aurrera zuzentzen...\n","1.10320938428243 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hOtWXQWxL2ma","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594465833962,"user_tz":-120,"elapsed":592205,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"457e8a85-0de4-4c9d-ea5a-9b977db33626"},"source":["# P100 GPU\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13.715916442834212, 28.393689841302283, 17.083775150476797)"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"xHSAfbEq-tWV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594540037758,"user_tz":-120,"elapsed":856,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"2b66d421-7dfe-4033-a52b-51ddf1fc9d3b"},"source":["# T4 GPU\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13.711613352617388, 28.364849000486846, 17.074160544511326)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"C9IELksMNBH3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1594977125825,"user_tz":-120,"elapsed":9465,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"1b04a8df-8555-4d35-9ed4-d3d0b1c085f7"},"source":["itzultzeko = [['Ya lo había dicho.',\n","               'She had already said it.'],\n","              ['Ya lo había dicho.',\n","               'I had already said it.'],\n","              ['Fui solo una vez.',\n","               'I just went once.'],\n","              ['Fui solo una vez.',\n","               'I went alone once.'],\n","              ['El tiempo vuela como una flecha',\n","               'Time flies like an arrow'],\n","              ['A las moscas del tiempo les gusta una flecha',\n","               'Time flies like an arrow'],\n","              ['Todavía estaba tocando cuando yo llegué.',\n","               'He was still playing when I arrived.'],\n","              ['Todavía estaba jugando cuando yo llegué.',\n","               'He was still playing when I arrived.'],\n","              ['Esta alianza costó más de lo que esperaba.',\n","               'This ring cost more than I expected.'],\n","              ['Esta alianza costó más de lo que esperaba.',\n","               'This alliance cost more than he expected.'],\n","              ['Escondí rápidamente la carta.',\n","               'I quickly hid the letter.'],\n","              ['Escondí rápidamente la carta.',\n","               'I quickly hid the card.'],\n","              ['Le dio de comer a su gato.',\n","               'He fed her cat food.'],\n","              ['Le dio comida de gato a ella.',\n","               'He fed her cat food.'],\n","              ['Escuadrón ayuda a la víctima de mordedura de perro',\n","               'Squad helps dog bite victim'], # jatorrizkoan hitz guztiak larriz hasi\n","              ['Escuadrón ayuda a un perro a morder a su víctima',\n","               'Squad helps dog bite Victim'],\n","              ['Esta noche tendré sexo seguro',\n","               \"I'll have safe sex tonight\"],\n","              ['Esta noche tendré sexo seguro',\n","               \"I'm sure I'll have sex tonight\"],\n","              ['El cristal se rompió en pedazos.',\n","               'The glass broke into pieces.'],\n","              ['El vaso se rompió en pedazos.',\n","               'The glass broke into pieces.'],\n","              ['Nadie conocía el destino del avión secuestrado.',\n","               'No one knew the fate of the hijacked plane.'],\n","              ['Nadie conocía el destino del avión secuestrado.',\n","               'No one knew the destination of the hijacked plane.'],# HONAINO ANBIGUOAK\n","              ['Durante toda la semana, los desarrolladores de Apple han interactuado con más de 1.000 ingenieros de Apple a través de los nuevos foros para desarrolladores y las sesiones individuales, en las que han profundizado en las funciones más recientes que llegan con macOS Big Sur, iOS 14, iPadOS 14, watchOS 7 y tvOS 14.',\n","               'All week Apple developers have been engaging with more than 1,000 Apple engineers via the all-new Developer Forums and one-on-one Developer Labs, diving deep into the newest capabilities coming to macOS Big Sur, iOS 14, iPadOS 14, watchOS 7, and tvOS 14.'],\n","              ['Los juegos con la insignia Optimizado para Xbox Series X pueden contar con todo tipo de mejoras, desde prácticamente eliminar los tiempos de carga a través de la Arquitectura Xbox Velocity, mejorar los gráficos o trazado de rayos DirectX acelerado por hardware impulsado por nuestra GPU personalizada de próxima generación, hasta velocidades de cuadro más estables y a menudo, más altas, de hasta 120 fps.',\n","               'Games featuring the Optimized for Xbox Series X badge can showcase anything from virtually eliminating load times via the Xbox Velocity Architecture, heightened visuals and hardware-accelerated DirectX raytracing powered by our custom, next generation GPU, to steadier and often higher framerates up to 120fps.'],\n","              ['El Consejo de Ministros ha aprobado un Real Decreto-ley que recoge medidas para reactivar la economía en los ámbitos de los transportes y de la vivienda y afrontar el impacto del coronavirus.',\n","               'The Council of Ministers approved a Royal Decree-Law that contains measures to reactivate the economy in the fields of transport and housing and to address the impact of the coronavirus.']]\n","               \n","itzultzeko_tok = [[tokenizatu_str(jat[0]), tokenizatu_str(jat[1])] \n","                  for jat in itzultzeko]\n","\n","itzultzeko_zenb = [[bpe_hirurak.encode(jat[0]), bpe_hirurak.encode(jat[1])] \n","                   for jat in itzultzeko_tok]\n","\n","zuzendua = zuzendu_beam(model, itzultzeko_zenb, 4, batch_size_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["836490752\n","1. esalditik aurrera zuzentzen...\n","838374400\n","13. esalditik aurrera zuzentzen...\n","853184512\n","25. esalditik aurrera zuzentzen...\n","0.14983963171641032 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lEQZC8n2C4qp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":462},"executionInfo":{"status":"ok","timestamp":1594977130010,"user_tz":-120,"elapsed":471,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"a01185af-27b1-457f-c935-c7fb16ae6338"},"source":["destokenizer = pyonmttok.Tokenizer(\"conservative\", joiner_annotate=True, \n","                                    case_markup=True, soft_case_regions=True)\n","\n","for lerroa in zuzendua:\n","    lerroa = lerroa.replace('｟C', '｟mrk_case_modifier_C｠')\n","    lerroa = lerroa.replace('｟B', '｟mrk_begin_case_region_U｠')\n","    lerroa = lerroa.replace('｟E', '｟mrk_end_case_region_U｠')\n","    print(destokenizer.detokenize(lerroa.split()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Esan zuen lehen ere.\n","Esan dut lehen ere.\n","Behin bakarrik joan nintzen.\n","Behin bakarrik joan nintzen.\n","Denbora gezi batek bezala hegan doa.\n","Denboraren euliei gezi bat gustatzen zaie.\n","Oraindik jotzen ari zen ni iritsi nintzenean.\n","Jolasean ari zen ni iritsi nintzenean.\n","Eraztun hau espero nuena baino garestiagoa da.\n","Aliantza hau espero baino garestiagoa da.\n","Gutuna azkar ezkutatu nuen.\n","Azkar ezkutatu nuen karta.\n","Katuari jaten eman zion.\n","Katu-jana eman zion.\n","Eskuadroiak txakurren haginka egiten laguntzen dio.\n","Eskuadroiak txakurrari kosk egiten dio biktimari.\n","Sexu segurua izango dut gaur gauean.\n","Gaur gauean sexua izango dut.\n","Kristala pusketan puskatu zen.\n","Edalontzia puskatu egin zen.\n","Inork ez zekien hegazkin bahituaren patua.\n","Inork ez zekien hegazkin bahituaren helmuga.\n","Astero Appleko garatzaileak 1.000 ingeniari baino gehiagorekin sartu dira Appleteko foro berrietan eta saio indibidualetan zehar, zeinetan sakondu baitira MACHego Big Hego, 1000 Pad14, PADk, PADk, 7 eta 14 telebista.\n","Xbox Telesairako baikor Optimizatutako Jokoek, Xbox Dougeten arkitektura Xbox Velocity arkitektuaren garaiak kenduta, XAzelerare-ko grabatuak eta X transputamenduak, gure hurrengo belaunaldiek eraginda, hurrengo belaunaldi garaiak eta 120 f0era arte.\n","Ministroen Kontseiluak Errege Dekretu bat onartu du (neurriak hartzen ditu garraioetako eta etxebizitzen eremuetan ekonomia berreraikitzeko eta korovirusaren inpaktuari aurre egiteko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mOYM1nH8Ak7M","colab_type":"code","colab":{}},"source":["# P4 eta T4 GPU berdin-berdin\n","# Txakurrarena maiuskulekin: Txakurkumearen biktimari laguntza eskatu. Txakur bati lagundu Biktima hiltzen."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o5aglUfbi6u6","colab_type":"code","colab":{}},"source":["# ONENAREN BALIDAZIOKOAK FITXATEGI BATEAN GORDE\n","with open('HACOSDatuak/onenaval.txt', 'w') as f:\n","    for candidate in candidates3:\n","        f.write(' '.join(candidate) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zY0kUXDbsyWb","colab_type":"code","colab":{}},"source":["# avg eredua fitxategi batean gorde\n","\n","checkpoint = {'model': model.state_dict()}\n","torch.save(checkpoint, \"HACOSDatuak/parametroak.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3pOdmxe2sywU"},"source":["## esbakarrik"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BZ8ez0XwsywV","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720036686,"user_tz":-120,"elapsed":6153,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6fa006fd-4c9f-4037-82b9-8847c4bf4f8d"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('HACOSDatuak/esbakarrik-14.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LtrUS4N2sywZ","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594720140518,"user_tz":-120,"elapsed":26180,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"b3eced42-6963-4cbf-ea6f-e761c4009943"},"source":["zuzendua1 = zuzendu_zenbakitua_bakarra(model, dev1, 0, 50)\n","zuzendua2 = zuzendu_zenbakitua_bakarra(model, dev2, 0, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16.132766246795654 segundo behar izan ditu zuzentzeko.\n","9.198976516723633 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"POGTI6mSsywc","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594720152453,"user_tz":-120,"elapsed":1563,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"668d0782-3a7d-42a4-d8d0-59098429ff76"},"source":["references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10.76062569296596, 26.541126563185625, 14.484038843956112)"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x7g5zrjHsywf","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720487193,"user_tz":-120,"elapsed":126730,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"5fe07326-8ecf-46c7-ef9e-6ba7dc078fd6"},"source":["zuzendua1 = zuzendu_beam_bakarra(model, dev1, 0, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2238560768\n","1. esalditik aurrera zuzentzen...\n","2239398912\n","13. esalditik aurrera zuzentzen...\n","2239263744\n","25. esalditik aurrera zuzentzen...\n","2239423488\n","37. esalditik aurrera zuzentzen...\n","2239226368\n","49. esalditik aurrera zuzentzen...\n","2239435264\n","61. esalditik aurrera zuzentzen...\n","2239435264\n","73. esalditik aurrera zuzentzen...\n","2239435264\n","85. esalditik aurrera zuzentzen...\n","2239693312\n","97. esalditik aurrera zuzentzen...\n","2239558144\n","109. esalditik aurrera zuzentzen...\n","2239705600\n","121. esalditik aurrera zuzentzen...\n","2239914496\n","133. esalditik aurrera zuzentzen...\n","2239816192\n","145. esalditik aurrera zuzentzen...\n","2239927296\n","157. esalditik aurrera zuzentzen...\n","2239927296\n","169. esalditik aurrera zuzentzen...\n","2239988736\n","181. esalditik aurrera zuzentzen...\n","2240037888\n","193. esalditik aurrera zuzentzen...\n","2240234496\n","205. esalditik aurrera zuzentzen...\n","2240099328\n","217. esalditik aurrera zuzentzen...\n","2240209920\n","229. esalditik aurrera zuzentzen...\n","2240209920\n","241. esalditik aurrera zuzentzen...\n","2240222208\n","253. esalditik aurrera zuzentzen...\n","2240431104\n","265. esalditik aurrera zuzentzen...\n","2240332800\n","277. esalditik aurrera zuzentzen...\n","2240480256\n","289. esalditik aurrera zuzentzen...\n","2240443392\n","301. esalditik aurrera zuzentzen...\n","2240640512\n","313. esalditik aurrera zuzentzen...\n","2240553984\n","325. esalditik aurrera zuzentzen...\n","2240615424\n","337. esalditik aurrera zuzentzen...\n","2240771072\n","349. esalditik aurrera zuzentzen...\n","2240824832\n","361. esalditik aurrera zuzentzen...\n","2240935424\n","373. esalditik aurrera zuzentzen...\n","2241033728\n","385. esalditik aurrera zuzentzen...\n","2241054720\n","397. esalditik aurrera zuzentzen...\n","2241103872\n","409. esalditik aurrera zuzentzen...\n","2242192384\n","421. esalditik aurrera zuzentzen...\n","2241366016\n","433. esalditik aurrera zuzentzen...\n","2242032640\n","445. esalditik aurrera zuzentzen...\n","2241329152\n","457. esalditik aurrera zuzentzen...\n","2241329152\n","469. esalditik aurrera zuzentzen...\n","2242466816\n","481. esalditik aurrera zuzentzen...\n","2242811392\n","493. esalditik aurrera zuzentzen...\n","2242752512\n","505. esalditik aurrera zuzentzen...\n","2242491392\n","517. esalditik aurrera zuzentzen...\n","2242764800\n","529. esalditik aurrera zuzentzen...\n","2242777088\n","541. esalditik aurrera zuzentzen...\n","2242777088\n","553. esalditik aurrera zuzentzen...\n","2242762240\n","565. esalditik aurrera zuzentzen...\n","2242724864\n","577. esalditik aurrera zuzentzen...\n","2243328000\n","589. esalditik aurrera zuzentzen...\n","2243551744\n","601. esalditik aurrera zuzentzen...\n","2242799616\n","613. esalditik aurrera zuzentzen...\n","2243550208\n","625. esalditik aurrera zuzentzen...\n","2243008512\n","637. esalditik aurrera zuzentzen...\n","2243589120\n","649. esalditik aurrera zuzentzen...\n","2243476480\n","661. esalditik aurrera zuzentzen...\n","2244276736\n","673. esalditik aurrera zuzentzen...\n","2243331072\n","685. esalditik aurrera zuzentzen...\n","2243057664\n","697. esalditik aurrera zuzentzen...\n","2243343360\n","709. esalditik aurrera zuzentzen...\n","2243279360\n","721. esalditik aurrera zuzentzen...\n","2243587072\n","733. esalditik aurrera zuzentzen...\n","2243451392\n","745. esalditik aurrera zuzentzen...\n","2243415040\n","757. esalditik aurrera zuzentzen...\n","2243476480\n","769. esalditik aurrera zuzentzen...\n","2243636736\n","781. esalditik aurrera zuzentzen...\n","2243764736\n","793. esalditik aurrera zuzentzen...\n","2243641344\n","805. esalditik aurrera zuzentzen...\n","2244195328\n","817. esalditik aurrera zuzentzen...\n","2244318208\n","829. esalditik aurrera zuzentzen...\n","2244924416\n","841. esalditik aurrera zuzentzen...\n","2244663296\n","853. esalditik aurrera zuzentzen...\n","2244933632\n","865. esalditik aurrera zuzentzen...\n","2245044736\n","877. esalditik aurrera zuzentzen...\n","2245660160\n","889. esalditik aurrera zuzentzen...\n","2245598208\n","901. esalditik aurrera zuzentzen...\n","2245931008\n","913. esalditik aurrera zuzentzen...\n","2246324224\n","925. esalditik aurrera zuzentzen...\n","2247796224\n","937. esalditik aurrera zuzentzen...\n","2246964224\n","949. esalditik aurrera zuzentzen...\n","2247579648\n","961. esalditik aurrera zuzentzen...\n","2250926080\n","973. esalditik aurrera zuzentzen...\n","2252124672\n","985. esalditik aurrera zuzentzen...\n","2251705856\n","997. esalditik aurrera zuzentzen...\n","2.093845244248708 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QoIgWb9ssywi","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720551180,"user_tz":-120,"elapsed":63946,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c59d1a48-9ba6-4664-9d49-57ae46963dd9"},"source":["zuzendua2 = zuzendu_beam_bakarra(model, dev2, 0, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2238461952\n","1. esalditik aurrera zuzentzen...\n","2239042048\n","13. esalditik aurrera zuzentzen...\n","2239054336\n","25. esalditik aurrera zuzentzen...\n","2239152640\n","37. esalditik aurrera zuzentzen...\n","2239054336\n","49. esalditik aurrera zuzentzen...\n","2239054336\n","61. esalditik aurrera zuzentzen...\n","2239054336\n","73. esalditik aurrera zuzentzen...\n","2239164928\n","85. esalditik aurrera zuzentzen...\n","2239263232\n","97. esalditik aurrera zuzentzen...\n","2239164928\n","109. esalditik aurrera zuzentzen...\n","2239164928\n","121. esalditik aurrera zuzentzen...\n","2239214080\n","133. esalditik aurrera zuzentzen...\n","2239164928\n","145. esalditik aurrera zuzentzen...\n","2239226368\n","157. esalditik aurrera zuzentzen...\n","2239373824\n","169. esalditik aurrera zuzentzen...\n","2239275520\n","181. esalditik aurrera zuzentzen...\n","2239226368\n","193. esalditik aurrera zuzentzen...\n","2239275520\n","205. esalditik aurrera zuzentzen...\n","2239275520\n","217. esalditik aurrera zuzentzen...\n","2239275520\n","229. esalditik aurrera zuzentzen...\n","2239275520\n","241. esalditik aurrera zuzentzen...\n","2239226368\n","253. esalditik aurrera zuzentzen...\n","2239275520\n","265. esalditik aurrera zuzentzen...\n","2244696064\n","277. esalditik aurrera zuzentzen...\n","2239386112\n","289. esalditik aurrera zuzentzen...\n","2239435264\n","301. esalditik aurrera zuzentzen...\n","2239386112\n","313. esalditik aurrera zuzentzen...\n","2239336960\n","325. esalditik aurrera zuzentzen...\n","2239435264\n","337. esalditik aurrera zuzentzen...\n","2239336960\n","349. esalditik aurrera zuzentzen...\n","2239386112\n","361. esalditik aurrera zuzentzen...\n","2239386112\n","373. esalditik aurrera zuzentzen...\n","2239336960\n","385. esalditik aurrera zuzentzen...\n","2239595008\n","397. esalditik aurrera zuzentzen...\n","2239496704\n","409. esalditik aurrera zuzentzen...\n","2239447552\n","421. esalditik aurrera zuzentzen...\n","2239545856\n","433. esalditik aurrera zuzentzen...\n","2239447552\n","445. esalditik aurrera zuzentzen...\n","2239545856\n","457. esalditik aurrera zuzentzen...\n","2239496704\n","469. esalditik aurrera zuzentzen...\n","2239496704\n","481. esalditik aurrera zuzentzen...\n","2239558144\n","493. esalditik aurrera zuzentzen...\n","2239607296\n","505. esalditik aurrera zuzentzen...\n","2239656448\n","517. esalditik aurrera zuzentzen...\n","2239558144\n","529. esalditik aurrera zuzentzen...\n","2239558144\n","541. esalditik aurrera zuzentzen...\n","2239656448\n","553. esalditik aurrera zuzentzen...\n","2239717888\n","565. esalditik aurrera zuzentzen...\n","2239668736\n","577. esalditik aurrera zuzentzen...\n","2239717888\n","589. esalditik aurrera zuzentzen...\n","2239717888\n","601. esalditik aurrera zuzentzen...\n","2239717888\n","613. esalditik aurrera zuzentzen...\n","2239779840\n","625. esalditik aurrera zuzentzen...\n","2239828992\n","637. esalditik aurrera zuzentzen...\n","2239828992\n","649. esalditik aurrera zuzentzen...\n","2239779840\n","661. esalditik aurrera zuzentzen...\n","2239878144\n","673. esalditik aurrera zuzentzen...\n","2239939584\n","685. esalditik aurrera zuzentzen...\n","2239988736\n","697. esalditik aurrera zuzentzen...\n","2239988736\n","709. esalditik aurrera zuzentzen...\n","2239988736\n","721. esalditik aurrera zuzentzen...\n","2240001024\n","733. esalditik aurrera zuzentzen...\n","2240001024\n","745. esalditik aurrera zuzentzen...\n","2240050176\n","757. esalditik aurrera zuzentzen...\n","2240111616\n","769. esalditik aurrera zuzentzen...\n","2240357376\n","781. esalditik aurrera zuzentzen...\n","2240111616\n","793. esalditik aurrera zuzentzen...\n","2240222208\n","805. esalditik aurrera zuzentzen...\n","2240320512\n","817. esalditik aurrera zuzentzen...\n","2240332800\n","829. esalditik aurrera zuzentzen...\n","2240381952\n","841. esalditik aurrera zuzentzen...\n","2240541696\n","853. esalditik aurrera zuzentzen...\n","2240553984\n","865. esalditik aurrera zuzentzen...\n","2240603136\n","877. esalditik aurrera zuzentzen...\n","2240832512\n","889. esalditik aurrera zuzentzen...\n","2242060800\n","901. esalditik aurrera zuzentzen...\n","2241103872\n","913. esalditik aurrera zuzentzen...\n","2241116160\n","925. esalditik aurrera zuzentzen...\n","2241316864\n","937. esalditik aurrera zuzentzen...\n","2242466816\n","949. esalditik aurrera zuzentzen...\n","2242540544\n","961. esalditik aurrera zuzentzen...\n","2242872832\n","973. esalditik aurrera zuzentzen...\n","2243193344\n","985. esalditik aurrera zuzentzen...\n","2244047872\n","997. esalditik aurrera zuzentzen...\n","1.0393765767415364 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ywTDTMarsywm","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594720551186,"user_tz":-120,"elapsed":63920,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"09b5d5f0-ac72-4c5d-d78c-f796f94d1b36"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11.533217684550252, 27.085844762340162, 15.155209641017658)"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8axVkgZdsywp"},"source":["### avg"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PlX9YjF2sywp","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720749236,"user_tz":-120,"elapsed":7130,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"02e97361-bf47-4bb4-971e-1d72d7d3a79d"},"source":["model = batezbeste3_bakarra('HACOSDatuak/esbakarrik-13.pt', \n","                            'HACOSDatuak/esbakarrik-14.pt', \n","                            'HACOSDatuak/esbakarrik-15.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o3dYGradsyws","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1594720773072,"user_tz":-120,"elapsed":27135,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ad02693d-2b4c-455b-9d56-03ff096023b0"},"source":["zuzendua1 = zuzendu_zenbakitua_bakarra(model, dev1, 0, 50)\n","zuzendua2 = zuzendu_zenbakitua_bakarra(model, dev2, 0, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17.478880643844604 segundo behar izan ditu zuzentzeko.\n","5.762083053588867 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(11.36545416924762, 27.009868155737948, 15.00886253474821)"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ofG8giWUsywu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720895149,"user_tz":-120,"elapsed":148633,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"518004e6-0553-47cf-b499-d53707fb9f3e"},"source":["zuzendua1 = zuzendu_beam_bakarra(model, dev1, 0, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4219015168\n","1. esalditik aurrera zuzentzen...\n","4219656704\n","13. esalditik aurrera zuzentzen...\n","4219718144\n","25. esalditik aurrera zuzentzen...\n","4219730432\n","37. esalditik aurrera zuzentzen...\n","4219779584\n","49. esalditik aurrera zuzentzen...\n","4219890176\n","61. esalditik aurrera zuzentzen...\n","4219988480\n","73. esalditik aurrera zuzentzen...\n","4219988480\n","85. esalditik aurrera zuzentzen...\n","4220049920\n","97. esalditik aurrera zuzentzen...\n","4220111360\n","109. esalditik aurrera zuzentzen...\n","4220209664\n","121. esalditik aurrera zuzentzen...\n","4220467712\n","133. esalditik aurrera zuzentzen...\n","4220369408\n","145. esalditik aurrera zuzentzen...\n","4220431360\n","157. esalditik aurrera zuzentzen...\n","4220480512\n","169. esalditik aurrera zuzentzen...\n","4220541952\n","181. esalditik aurrera zuzentzen...\n","4220591104\n","193. esalditik aurrera zuzentzen...\n","4221181440\n","205. esalditik aurrera zuzentzen...\n","4220652544\n","217. esalditik aurrera zuzentzen...\n","4220763136\n","229. esalditik aurrera zuzentzen...\n","4220812288\n","241. esalditik aurrera zuzentzen...\n","4220873728\n","253. esalditik aurrera zuzentzen...\n","4220935168\n","265. esalditik aurrera zuzentzen...\n","4220886016\n","277. esalditik aurrera zuzentzen...\n","4220984320\n","289. esalditik aurrera zuzentzen...\n","4220996608\n","301. esalditik aurrera zuzentzen...\n","4221148160\n","313. esalditik aurrera zuzentzen...\n","4221156352\n","325. esalditik aurrera zuzentzen...\n","4221611520\n","337. esalditik aurrera zuzentzen...\n","4221324800\n","349. esalditik aurrera zuzentzen...\n","4221672960\n","361. esalditik aurrera zuzentzen...\n","4221393920\n","373. esalditik aurrera zuzentzen...\n","4221734400\n","385. esalditik aurrera zuzentzen...\n","4221800448\n","397. esalditik aurrera zuzentzen...\n","4221800448\n","409. esalditik aurrera zuzentzen...\n","4221865984\n","421. esalditik aurrera zuzentzen...\n","4222214144\n","433. esalditik aurrera zuzentzen...\n","4222164992\n","445. esalditik aurrera zuzentzen...\n","4222177280\n","457. esalditik aurrera zuzentzen...\n","4222226432\n","469. esalditik aurrera zuzentzen...\n","4222238720\n","481. esalditik aurrera zuzentzen...\n","4222308352\n","493. esalditik aurrera zuzentzen...\n","4222251008\n","505. esalditik aurrera zuzentzen...\n","4222214144\n","517. esalditik aurrera zuzentzen...\n","4222263296\n","529. esalditik aurrera zuzentzen...\n","4222345216\n","541. esalditik aurrera zuzentzen...\n","4222345216\n","553. esalditik aurrera zuzentzen...\n","4222829056\n","565. esalditik aurrera zuzentzen...\n","4222738944\n","577. esalditik aurrera zuzentzen...\n","4223160320\n","589. esalditik aurrera zuzentzen...\n","4222963712\n","601. esalditik aurrera zuzentzen...\n","4223185920\n","613. esalditik aurrera zuzentzen...\n","4223198208\n","625. esalditik aurrera zuzentzen...\n","4223198208\n","637. esalditik aurrera zuzentzen...\n","4223210496\n","649. esalditik aurrera zuzentzen...\n","4223222784\n","661. esalditik aurrera zuzentzen...\n","4223534592\n","673. esalditik aurrera zuzentzen...\n","4223419392\n","685. esalditik aurrera zuzentzen...\n","4223546368\n","697. esalditik aurrera zuzentzen...\n","4223432192\n","709. esalditik aurrera zuzentzen...\n","4223542784\n","721. esalditik aurrera zuzentzen...\n","4223780352\n","733. esalditik aurrera zuzentzen...\n","4223694336\n","745. esalditik aurrera zuzentzen...\n","4223776768\n","757. esalditik aurrera zuzentzen...\n","4224739328\n","769. esalditik aurrera zuzentzen...\n","4224752128\n","781. esalditik aurrera zuzentzen...\n","4224776704\n","793. esalditik aurrera zuzentzen...\n","4224243712\n","805. esalditik aurrera zuzentzen...\n","4224814080\n","817. esalditik aurrera zuzentzen...\n","4224838144\n","829. esalditik aurrera zuzentzen...\n","4226039296\n","841. esalditik aurrera zuzentzen...\n","4225610240\n","853. esalditik aurrera zuzentzen...\n","4225339392\n","865. esalditik aurrera zuzentzen...\n","4225400832\n","877. esalditik aurrera zuzentzen...\n","4226164224\n","889. esalditik aurrera zuzentzen...\n","4225905152\n","901. esalditik aurrera zuzentzen...\n","4226237440\n","913. esalditik aurrera zuzentzen...\n","4226729984\n","925. esalditik aurrera zuzentzen...\n","4227185152\n","937. esalditik aurrera zuzentzen...\n","4227566592\n","949. esalditik aurrera zuzentzen...\n","4229033472\n","961. esalditik aurrera zuzentzen...\n","4230500864\n","973. esalditik aurrera zuzentzen...\n","4232454656\n","985. esalditik aurrera zuzentzen...\n","4232652288\n","997. esalditik aurrera zuzentzen...\n","2.03258429368337 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zOoULDbVsywx","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720957930,"user_tz":-120,"elapsed":210938,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"1b11143f-d71f-4c66-b16f-e02ad7e853ac"},"source":["zuzendua2 = zuzendu_beam_bakarra(model, dev2, 0, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4219015168\n","1. esalditik aurrera zuzentzen...\n","4219546112\n","13. esalditik aurrera zuzentzen...\n","4219705856\n","25. esalditik aurrera zuzentzen...\n","4219705856\n","37. esalditik aurrera zuzentzen...\n","4219656704\n","49. esalditik aurrera zuzentzen...\n","4219607552\n","61. esalditik aurrera zuzentzen...\n","4219607552\n","73. esalditik aurrera zuzentzen...\n","4219668992\n","85. esalditik aurrera zuzentzen...\n","4219816448\n","97. esalditik aurrera zuzentzen...\n","4219718144\n","109. esalditik aurrera zuzentzen...\n","4219718144\n","121. esalditik aurrera zuzentzen...\n","4219767296\n","133. esalditik aurrera zuzentzen...\n","4219767296\n","145. esalditik aurrera zuzentzen...\n","4219779584\n","157. esalditik aurrera zuzentzen...\n","4219927040\n","169. esalditik aurrera zuzentzen...\n","4219828736\n","181. esalditik aurrera zuzentzen...\n","4219730432\n","193. esalditik aurrera zuzentzen...\n","4219828736\n","205. esalditik aurrera zuzentzen...\n","4219828736\n","217. esalditik aurrera zuzentzen...\n","4219828736\n","229. esalditik aurrera zuzentzen...\n","4219828736\n","241. esalditik aurrera zuzentzen...\n","4219828736\n","253. esalditik aurrera zuzentzen...\n","4219828736\n","265. esalditik aurrera zuzentzen...\n","4225249280\n","277. esalditik aurrera zuzentzen...\n","4219890176\n","289. esalditik aurrera zuzentzen...\n","4219939328\n","301. esalditik aurrera zuzentzen...\n","4219939328\n","313. esalditik aurrera zuzentzen...\n","4219841024\n","325. esalditik aurrera zuzentzen...\n","4219988480\n","337. esalditik aurrera zuzentzen...\n","4219939328\n","349. esalditik aurrera zuzentzen...\n","4219939328\n","361. esalditik aurrera zuzentzen...\n","4219939328\n","373. esalditik aurrera zuzentzen...\n","4220086784\n","385. esalditik aurrera zuzentzen...\n","4220148224\n","397. esalditik aurrera zuzentzen...\n","4220049920\n","409. esalditik aurrera zuzentzen...\n","4220000768\n","421. esalditik aurrera zuzentzen...\n","4220049920\n","433. esalditik aurrera zuzentzen...\n","4220000768\n","445. esalditik aurrera zuzentzen...\n","4220099072\n","457. esalditik aurrera zuzentzen...\n","4220000768\n","469. esalditik aurrera zuzentzen...\n","4220049920\n","481. esalditik aurrera zuzentzen...\n","4220258816\n","493. esalditik aurrera zuzentzen...\n","4220160512\n","505. esalditik aurrera zuzentzen...\n","4220209664\n","517. esalditik aurrera zuzentzen...\n","4220160512\n","529. esalditik aurrera zuzentzen...\n","4220160512\n","541. esalditik aurrera zuzentzen...\n","4220160512\n","553. esalditik aurrera zuzentzen...\n","4220221952\n","565. esalditik aurrera zuzentzen...\n","4220271104\n","577. esalditik aurrera zuzentzen...\n","4220221952\n","589. esalditik aurrera zuzentzen...\n","4220221952\n","601. esalditik aurrera zuzentzen...\n","4220271104\n","613. esalditik aurrera zuzentzen...\n","4220382208\n","625. esalditik aurrera zuzentzen...\n","4220333056\n","637. esalditik aurrera zuzentzen...\n","4220382208\n","649. esalditik aurrera zuzentzen...\n","4220382208\n","661. esalditik aurrera zuzentzen...\n","4220431360\n","673. esalditik aurrera zuzentzen...\n","4220492800\n","685. esalditik aurrera zuzentzen...\n","4220443648\n","697. esalditik aurrera zuzentzen...\n","4220492800\n","709. esalditik aurrera zuzentzen...\n","4220492800\n","721. esalditik aurrera zuzentzen...\n","4220554240\n","733. esalditik aurrera zuzentzen...\n","4220554240\n","745. esalditik aurrera zuzentzen...\n","4220603392\n","757. esalditik aurrera zuzentzen...\n","4220664832\n","769. esalditik aurrera zuzentzen...\n","4220763136\n","781. esalditik aurrera zuzentzen...\n","4220664832\n","793. esalditik aurrera zuzentzen...\n","4220775424\n","805. esalditik aurrera zuzentzen...\n","4220824576\n","817. esalditik aurrera zuzentzen...\n","4220836864\n","829. esalditik aurrera zuzentzen...\n","4220935168\n","841. esalditik aurrera zuzentzen...\n","4221094912\n","853. esalditik aurrera zuzentzen...\n","4221550080\n","865. esalditik aurrera zuzentzen...\n","4221156352\n","877. esalditik aurrera zuzentzen...\n","4221332480\n","889. esalditik aurrera zuzentzen...\n","4221734400\n","901. esalditik aurrera zuzentzen...\n","4221800448\n","913. esalditik aurrera zuzentzen...\n","4221865984\n","925. esalditik aurrera zuzentzen...\n","4222164992\n","937. esalditik aurrera zuzentzen...\n","4222189568\n","949. esalditik aurrera zuzentzen...\n","4222263296\n","961. esalditik aurrera zuzentzen...\n","4222738944\n","973. esalditik aurrera zuzentzen...\n","4223407616\n","985. esalditik aurrera zuzentzen...\n","4224814080\n","997. esalditik aurrera zuzentzen...\n","1.0442055503527323 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"flpo1HtIsywz","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594720957936,"user_tz":-120,"elapsed":210461,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"23af63ed-3f9f-49b8-b86d-3d42e836d5fa"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11.746426333776919, 27.258517441536167, 15.351013327004425)"]},"metadata":{"tags":[]},"execution_count":76}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WRhCDcwJsyw3","colab":{}},"source":["# BALIDAZIOKOAK FITXATEGI BATEAN GORDE\n","with open('HACOSDatuak/esonenaval.txt', 'w') as f:\n","    for candidate in candidates3:\n","        f.write(' '.join(candidate) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zz608oNz7Kbh"},"source":["## enbakarrik"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jagwY94q7Kbk","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594975185237,"user_tz":-120,"elapsed":19221,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"56d623ec-7c91-401b-9d64-bfdb1c96487a"},"source":["model = SharedTransformer(vocab_size, d_model, N, heads)\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n","if fp16:\n","    model, optim = amp.initialize(model, optim, opt_level='O2')\n","\n","model.load_state_dict(torch.load('HACOSDatuak/enbakarrik-19.pt')['model'])\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["SharedTransformer(\n","  (embed): Embedder(\n","    (embed): Embedding(20000, 512)\n","  )\n","  (encoder): SharedEncoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): EncoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (attn): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (decoder): SharedDecoder(\n","    (pe): PositionalEncoder()\n","    (layers): ModuleList(\n","      (0): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (1): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (2): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (3): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (4): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","      (5): DecoderLayer(\n","        (norm_1): Norm()\n","        (norm_2): Norm()\n","        (norm_3): Norm()\n","        (dropout_1): Dropout(p=0.1, inplace=False)\n","        (dropout_2): Dropout(p=0.1, inplace=False)\n","        (dropout_3): Dropout(p=0.1, inplace=False)\n","        (attn_1): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (attn_2): MultiHeadAttention(\n","          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (out): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ff): FeedForward(\n","          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm): Norm()\n","  )\n","  (out): Linear(in_features=512, out_features=20000, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oypgh0YA7Kbs","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594976212763,"user_tz":-120,"elapsed":28282,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d707f81a-03ea-4e41-cdb6-f5920620952f"},"source":["zuzendua1 = zuzendu_zenbakitua_bakarra(model, dev1, 1, 50)\n","zuzendua2 = zuzendu_zenbakitua_bakarra(model, dev2, 1, 50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["22.41313076019287 segundo behar izan ditu zuzentzeko.\n","5.351198673248291 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RDj57DUZ7Kbv","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594976213009,"user_tz":-120,"elapsed":28054,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"e9a880d2-1e20-4174-ac96-80e2279fd00f"},"source":["references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10.011336192645903, 22.70125219775395, 12.95351706800183)"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-oXg4f037Kb0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594976393423,"user_tz":-120,"elapsed":151366,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c29efbb2-7113-4e15-ec5f-c2ae3d21d5fd"},"source":["zuzendua1 = zuzendu_beam_bakarra(model, dev1, 1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["130019328\n","1. esalditik aurrera zuzentzen...\n","130710016\n","13. esalditik aurrera zuzentzen...\n","130869760\n","25. esalditik aurrera zuzentzen...\n","130832896\n","37. esalditik aurrera zuzentzen...\n","130894336\n","49. esalditik aurrera zuzentzen...\n","130894336\n","61. esalditik aurrera zuzentzen...\n","130943488\n","73. esalditik aurrera zuzentzen...\n","131152384\n","85. esalditik aurrera zuzentzen...\n","131164672\n","97. esalditik aurrera zuzentzen...\n","131508736\n","109. esalditik aurrera zuzentzen...\n","131373568\n","121. esalditik aurrera zuzentzen...\n","131275264\n","133. esalditik aurrera zuzentzen...\n","131422720\n","145. esalditik aurrera zuzentzen...\n","131582976\n","157. esalditik aurrera zuzentzen...\n","131447808\n","169. esalditik aurrera zuzentzen...\n","131693568\n","181. esalditik aurrera zuzentzen...\n","131656704\n","193. esalditik aurrera zuzentzen...\n","131755008\n","205. esalditik aurrera zuzentzen...\n","131668992\n","217. esalditik aurrera zuzentzen...\n","131816448\n","229. esalditik aurrera zuzentzen...\n","133156352\n","241. esalditik aurrera zuzentzen...\n","132025344\n","253. esalditik aurrera zuzentzen...\n","132136448\n","265. esalditik aurrera zuzentzen...\n","131988480\n","277. esalditik aurrera zuzentzen...\n","132086784\n","289. esalditik aurrera zuzentzen...\n","132148224\n","301. esalditik aurrera zuzentzen...\n","132443648\n","313. esalditik aurrera zuzentzen...\n","132259328\n","325. esalditik aurrera zuzentzen...\n","132172800\n","337. esalditik aurrera zuzentzen...\n","132431360\n","349. esalditik aurrera zuzentzen...\n","133463552\n","361. esalditik aurrera zuzentzen...\n","133524992\n","373. esalditik aurrera zuzentzen...\n","132591104\n","385. esalditik aurrera zuzentzen...\n","133440512\n","397. esalditik aurrera zuzentzen...\n","132554752\n","409. esalditik aurrera zuzentzen...\n","133648896\n","421. esalditik aurrera zuzentzen...\n","133648384\n","433. esalditik aurrera zuzentzen...\n","133709824\n","445. esalditik aurrera zuzentzen...\n","132935680\n","457. esalditik aurrera zuzentzen...\n","133771264\n","469. esalditik aurrera zuzentzen...\n","133292544\n","481. esalditik aurrera zuzentzen...\n","133894144\n","493. esalditik aurrera zuzentzen...\n","133894144\n","505. esalditik aurrera zuzentzen...\n","133218304\n","517. esalditik aurrera zuzentzen...\n","134017536\n","529. esalditik aurrera zuzentzen...\n","134017536\n","541. esalditik aurrera zuzentzen...\n","133538304\n","553. esalditik aurrera zuzentzen...\n","136309760\n","565. esalditik aurrera zuzentzen...\n","133796352\n","577. esalditik aurrera zuzentzen...\n","134201856\n","589. esalditik aurrera zuzentzen...\n","134018560\n","601. esalditik aurrera zuzentzen...\n","134264320\n","613. esalditik aurrera zuzentzen...\n","134325248\n","625. esalditik aurrera zuzentzen...\n","134386688\n","637. esalditik aurrera zuzentzen...\n","134042624\n","649. esalditik aurrera zuzentzen...\n","134202880\n","661. esalditik aurrera zuzentzen...\n","133968896\n","673. esalditik aurrera zuzentzen...\n","134509568\n","685. esalditik aurrera zuzentzen...\n","137233920\n","697. esalditik aurrera zuzentzen...\n","134485504\n","709. esalditik aurrera zuzentzen...\n","134694400\n","721. esalditik aurrera zuzentzen...\n","134706688\n","733. esalditik aurrera zuzentzen...\n","135027200\n","745. esalditik aurrera zuzentzen...\n","135076352\n","757. esalditik aurrera zuzentzen...\n","138590208\n","769. esalditik aurrera zuzentzen...\n","135544320\n","781. esalditik aurrera zuzentzen...\n","135211520\n","793. esalditik aurrera zuzentzen...\n","135174656\n","805. esalditik aurrera zuzentzen...\n","135543808\n","817. esalditik aurrera zuzentzen...\n","137243648\n","829. esalditik aurrera zuzentzen...\n","137761280\n","841. esalditik aurrera zuzentzen...\n","136109568\n","853. esalditik aurrera zuzentzen...\n","137908736\n","865. esalditik aurrera zuzentzen...\n","137230336\n","877. esalditik aurrera zuzentzen...\n","136909824\n","889. esalditik aurrera zuzentzen...\n","136884736\n","901. esalditik aurrera zuzentzen...\n","137315840\n","913. esalditik aurrera zuzentzen...\n","137685504\n","925. esalditik aurrera zuzentzen...\n","138768896\n","937. esalditik aurrera zuzentzen...\n","138275840\n","949. esalditik aurrera zuzentzen...\n","139346944\n","961. esalditik aurrera zuzentzen...\n","139961344\n","973. esalditik aurrera zuzentzen...\n","142620160\n","985. esalditik aurrera zuzentzen...\n","144049664\n","997. esalditik aurrera zuzentzen...\n","2.511456314722697 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rcClxnMn7Kb4","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594976447758,"user_tz":-120,"elapsed":204177,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"e64bfc8f-a570-4d27-ba43-36c002f38ef3"},"source":["zuzendua2 = zuzendu_beam_bakarra(model, dev2, 1, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["130019328\n","1. esalditik aurrera zuzentzen...\n","130648576\n","13. esalditik aurrera zuzentzen...\n","130648576\n","25. esalditik aurrera zuzentzen...\n","130759168\n","37. esalditik aurrera zuzentzen...\n","130710016\n","49. esalditik aurrera zuzentzen...\n","130660864\n","61. esalditik aurrera zuzentzen...\n","130611712\n","73. esalditik aurrera zuzentzen...\n","130771456\n","85. esalditik aurrera zuzentzen...\n","130869760\n","97. esalditik aurrera zuzentzen...\n","130722304\n","109. esalditik aurrera zuzentzen...\n","130722304\n","121. esalditik aurrera zuzentzen...\n","130722304\n","133. esalditik aurrera zuzentzen...\n","130869760\n","145. esalditik aurrera zuzentzen...\n","130771456\n","157. esalditik aurrera zuzentzen...\n","130783744\n","169. esalditik aurrera zuzentzen...\n","131078656\n","181. esalditik aurrera zuzentzen...\n","130832896\n","193. esalditik aurrera zuzentzen...\n","130980352\n","205. esalditik aurrera zuzentzen...\n","130832896\n","217. esalditik aurrera zuzentzen...\n","130882048\n","229. esalditik aurrera zuzentzen...\n","130832896\n","241. esalditik aurrera zuzentzen...\n","130894336\n","253. esalditik aurrera zuzentzen...\n","130845184\n","265. esalditik aurrera zuzentzen...\n","130943488\n","277. esalditik aurrera zuzentzen...\n","130992640\n","289. esalditik aurrera zuzentzen...\n","131140096\n","301. esalditik aurrera zuzentzen...\n","130894336\n","313. esalditik aurrera zuzentzen...\n","130894336\n","325. esalditik aurrera zuzentzen...\n","131250688\n","337. esalditik aurrera zuzentzen...\n","131004928\n","349. esalditik aurrera zuzentzen...\n","131103232\n","361. esalditik aurrera zuzentzen...\n","131004928\n","373. esalditik aurrera zuzentzen...\n","131004928\n","385. esalditik aurrera zuzentzen...\n","130955776\n","397. esalditik aurrera zuzentzen...\n","131152384\n","409. esalditik aurrera zuzentzen...\n","131115520\n","421. esalditik aurrera zuzentzen...\n","131213824\n","433. esalditik aurrera zuzentzen...\n","131164672\n","445. esalditik aurrera zuzentzen...\n","131213824\n","457. esalditik aurrera zuzentzen...\n","131213824\n","469. esalditik aurrera zuzentzen...\n","131066368\n","481. esalditik aurrera zuzentzen...\n","131164672\n","493. esalditik aurrera zuzentzen...\n","131422720\n","505. esalditik aurrera zuzentzen...\n","131176960\n","517. esalditik aurrera zuzentzen...\n","131176960\n","529. esalditik aurrera zuzentzen...\n","131324416\n","541. esalditik aurrera zuzentzen...\n","131373568\n","553. esalditik aurrera zuzentzen...\n","131275264\n","565. esalditik aurrera zuzentzen...\n","131435520\n","577. esalditik aurrera zuzentzen...\n","131337216\n","589. esalditik aurrera zuzentzen...\n","131288064\n","601. esalditik aurrera zuzentzen...\n","131435520\n","613. esalditik aurrera zuzentzen...\n","131386368\n","625. esalditik aurrera zuzentzen...\n","131386368\n","637. esalditik aurrera zuzentzen...\n","131496960\n","649. esalditik aurrera zuzentzen...\n","131447808\n","661. esalditik aurrera zuzentzen...\n","131496960\n","673. esalditik aurrera zuzentzen...\n","131496960\n","685. esalditik aurrera zuzentzen...\n","131558400\n","697. esalditik aurrera zuzentzen...\n","131607552\n","709. esalditik aurrera zuzentzen...\n","131558400\n","721. esalditik aurrera zuzentzen...\n","131718144\n","733. esalditik aurrera zuzentzen...\n","131619840\n","745. esalditik aurrera zuzentzen...\n","131877888\n","757. esalditik aurrera zuzentzen...\n","131730432\n","769. esalditik aurrera zuzentzen...\n","131791872\n","781. esalditik aurrera zuzentzen...\n","131890176\n","793. esalditik aurrera zuzentzen...\n","131988480\n","805. esalditik aurrera zuzentzen...\n","132000768\n","817. esalditik aurrera zuzentzen...\n","132111360\n","829. esalditik aurrera zuzentzen...\n","132160512\n","841. esalditik aurrera zuzentzen...\n","132320768\n","853. esalditik aurrera zuzentzen...\n","133402112\n","865. esalditik aurrera zuzentzen...\n","133463552\n","877. esalditik aurrera zuzentzen...\n","132443648\n","889. esalditik aurrera zuzentzen...\n","132849664\n","901. esalditik aurrera zuzentzen...\n","133709824\n","913. esalditik aurrera zuzentzen...\n","132677632\n","925. esalditik aurrera zuzentzen...\n","133771264\n","937. esalditik aurrera zuzentzen...\n","133415424\n","949. esalditik aurrera zuzentzen...\n","134017536\n","961. esalditik aurrera zuzentzen...\n","134263808\n","973. esalditik aurrera zuzentzen...\n","134793216\n","985. esalditik aurrera zuzentzen...\n","136344064\n","997. esalditik aurrera zuzentzen...\n","0.9035996119181315 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F8RMHWjv7Kb9","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594976447765,"user_tz":-120,"elapsed":201908,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9298280c-5671-497f-89fc-b55b740eee8e"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10.203939134405841, 22.187631597155768, 12.96313803392538)"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bZwsE_3i7KcB"},"source":["### avg"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i9320odO7KcB","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594976461657,"user_tz":-120,"elapsed":13848,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"d8d7aff8-c97a-407f-ec7b-1d1004e5f89a"},"source":["model = batezbeste3_bakarra('HACOSDatuak/enbakarrik-18.pt', \n","                            'HACOSDatuak/enbakarrik-19.pt', \n","                            'HACOSDatuak/enbakarrik-20.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O2\n","cast_model_type        : torch.float16\n","patch_torch_functions  : False\n","keep_batchnorm_fp32    : True\n","master_weights         : True\n","loss_scale             : dynamic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9zs41DQS7KcG","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1594976491211,"user_tz":-120,"elapsed":43372,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"81058538-bfe2-4b2b-93bf-d6c8f15cb1af"},"source":["zuzendua1 = zuzendu_zenbakitua_bakarra(model, dev1, 1, 50)\n","zuzendua2 = zuzendu_zenbakitua_bakarra(model, dev2, 1, 50)\n","\n","references1 = [[esaldia[2].split()] for esaldia in dev1]\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100\n","\n","references2 = [[esaldia[2].split()] for esaldia in dev2]\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100\n","\n","references3 = references1 + references2\n","candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["23.50482678413391 segundo behar izan ditu zuzentzeko.\n","5.448307514190674 segundo behar izan ditu zuzentzeko.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(10.269153934254998, 23.162687482579194, 13.248817288867587)"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-DEbwpuL7KcJ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594976623927,"user_tz":-120,"elapsed":176068,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"6f51d8ad-324a-485f-887d-38d7056b426e"},"source":["zuzendua1 = zuzendu_beam_bakarra(model, dev1, 1, 4, batch_size_val)\n","candidates1 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua1]\n","bleu1 = nltk.translate.bleu_score.corpus_bleu(references1, candidates1)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["654518272\n","1. esalditik aurrera zuzentzen...\n","655208960\n","13. esalditik aurrera zuzentzen...\n","655270400\n","25. esalditik aurrera zuzentzen...\n","655331840\n","37. esalditik aurrera zuzentzen...\n","655393280\n","49. esalditik aurrera zuzentzen...\n","266026496\n","61. esalditik aurrera zuzentzen...\n","264402944\n","73. esalditik aurrera zuzentzen...\n","264611840\n","85. esalditik aurrera zuzentzen...\n","264624128\n","97. esalditik aurrera zuzentzen...\n","264722432\n","109. esalditik aurrera zuzentzen...\n","264833024\n","121. esalditik aurrera zuzentzen...\n","264783872\n","133. esalditik aurrera zuzentzen...\n","264882176\n","145. esalditik aurrera zuzentzen...\n","265042432\n","157. esalditik aurrera zuzentzen...\n","264907264\n","169. esalditik aurrera zuzentzen...\n","265153024\n","181. esalditik aurrera zuzentzen...\n","265165312\n","193. esalditik aurrera zuzentzen...\n","265165312\n","205. esalditik aurrera zuzentzen...\n","265226752\n","217. esalditik aurrera zuzentzen...\n","265275904\n","229. esalditik aurrera zuzentzen...\n","265780224\n","241. esalditik aurrera zuzentzen...\n","265435648\n","253. esalditik aurrera zuzentzen...\n","265398784\n","265. esalditik aurrera zuzentzen...\n","265349632\n","277. esalditik aurrera zuzentzen...\n","265546240\n","289. esalditik aurrera zuzentzen...\n","265558528\n","301. esalditik aurrera zuzentzen...\n","265706496\n","313. esalditik aurrera zuzentzen...\n","265718784\n","325. esalditik aurrera zuzentzen...\n","265730560\n","337. esalditik aurrera zuzentzen...\n","266923008\n","349. esalditik aurrera zuzentzen...\n","265989120\n","361. esalditik aurrera zuzentzen...\n","266247168\n","373. esalditik aurrera zuzentzen...\n","266984448\n","385. esalditik aurrera zuzentzen...\n","266653184\n","397. esalditik aurrera zuzentzen...\n","266653184\n","409. esalditik aurrera zuzentzen...\n","266665984\n","421. esalditik aurrera zuzentzen...\n","266173952\n","433. esalditik aurrera zuzentzen...\n","266333696\n","445. esalditik aurrera zuzentzen...\n","266296832\n","457. esalditik aurrera zuzentzen...\n","266345984\n","469. esalditik aurrera zuzentzen...\n","266850304\n","481. esalditik aurrera zuzentzen...\n","267501056\n","493. esalditik aurrera zuzentzen...\n","266714624\n","505. esalditik aurrera zuzentzen...\n","266677760\n","517. esalditik aurrera zuzentzen...\n","266887168\n","529. esalditik aurrera zuzentzen...\n","267230720\n","541. esalditik aurrera zuzentzen...\n","266898944\n","553. esalditik aurrera zuzentzen...\n","267059200\n","565. esalditik aurrera zuzentzen...\n","267206656\n","577. esalditik aurrera zuzentzen...\n","267021824\n","589. esalditik aurrera zuzentzen...\n","267182592\n","601. esalditik aurrera zuzentzen...\n","267379200\n","613. esalditik aurrera zuzentzen...\n","267244032\n","625. esalditik aurrera zuzentzen...\n","267993600\n","637. esalditik aurrera zuzentzen...\n","267846144\n","649. esalditik aurrera zuzentzen...\n","267908096\n","661. esalditik aurrera zuzentzen...\n","268018176\n","673. esalditik aurrera zuzentzen...\n","267969024\n","685. esalditik aurrera zuzentzen...\n","268030976\n","697. esalditik aurrera zuzentzen...\n","268240384\n","709. esalditik aurrera zuzentzen...\n","268153856\n","721. esalditik aurrera zuzentzen...\n","268067840\n","733. esalditik aurrera zuzentzen...\n","268535808\n","745. esalditik aurrera zuzentzen...\n","268683776\n","757. esalditik aurrera zuzentzen...\n","270667776\n","769. esalditik aurrera zuzentzen...\n","269151232\n","781. esalditik aurrera zuzentzen...\n","268670976\n","793. esalditik aurrera zuzentzen...\n","268781568\n","805. esalditik aurrera zuzentzen...\n","268953600\n","817. esalditik aurrera zuzentzen...\n","271097856\n","829. esalditik aurrera zuzentzen...\n","269396480\n","841. esalditik aurrera zuzentzen...\n","269618688\n","853. esalditik aurrera zuzentzen...\n","269790720\n","865. esalditik aurrera zuzentzen...\n","269950464\n","877. esalditik aurrera zuzentzen...\n","270270464\n","889. esalditik aurrera zuzentzen...\n","270590464\n","901. esalditik aurrera zuzentzen...\n","270479872\n","913. esalditik aurrera zuzentzen...\n","270898176\n","925. esalditik aurrera zuzentzen...\n","271784960\n","937. esalditik aurrera zuzentzen...\n","271982080\n","949. esalditik aurrera zuzentzen...\n","272757248\n","961. esalditik aurrera zuzentzen...\n","274207232\n","973. esalditik aurrera zuzentzen...\n","276611584\n","985. esalditik aurrera zuzentzen...\n","277259264\n","997. esalditik aurrera zuzentzen...\n","2.2079314986864724 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qa3kYy347KcL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594976675688,"user_tz":-120,"elapsed":227810,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"7bd113df-946b-4d73-95e3-f1dd264bcaee"},"source":["zuzendua2 = zuzendu_beam_bakarra(model, dev2, 1, 4, batch_size_val)\n","candidates2 = [berrezarri_maiuskulak(lerroa) for lerroa in zuzendua2]\n","bleu2 = nltk.translate.bleu_score.corpus_bleu(references2, candidates2)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["263478784\n","1. esalditik aurrera zuzentzen...\n","264009728\n","13. esalditik aurrera zuzentzen...\n","264108032\n","25. esalditik aurrera zuzentzen...\n","264218624\n","37. esalditik aurrera zuzentzen...\n","264169472\n","49. esalditik aurrera zuzentzen...\n","264120320\n","61. esalditik aurrera zuzentzen...\n","264169472\n","73. esalditik aurrera zuzentzen...\n","264280064\n","85. esalditik aurrera zuzentzen...\n","264329216\n","97. esalditik aurrera zuzentzen...\n","264181760\n","109. esalditik aurrera zuzentzen...\n","264181760\n","121. esalditik aurrera zuzentzen...\n","264181760\n","133. esalditik aurrera zuzentzen...\n","264329216\n","145. esalditik aurrera zuzentzen...\n","264230912\n","157. esalditik aurrera zuzentzen...\n","264341504\n","169. esalditik aurrera zuzentzen...\n","264538112\n","181. esalditik aurrera zuzentzen...\n","264243200\n","193. esalditik aurrera zuzentzen...\n","264292352\n","205. esalditik aurrera zuzentzen...\n","264243200\n","217. esalditik aurrera zuzentzen...\n","264341504\n","229. esalditik aurrera zuzentzen...\n","264292352\n","241. esalditik aurrera zuzentzen...\n","264353792\n","253. esalditik aurrera zuzentzen...\n","264353792\n","265. esalditik aurrera zuzentzen...\n","264402944\n","277. esalditik aurrera zuzentzen...\n","264353792\n","289. esalditik aurrera zuzentzen...\n","264550400\n","301. esalditik aurrera zuzentzen...\n","264353792\n","313. esalditik aurrera zuzentzen...\n","264353792\n","325. esalditik aurrera zuzentzen...\n","264562688\n","337. esalditik aurrera zuzentzen...\n","264562688\n","349. esalditik aurrera zuzentzen...\n","264513536\n","361. esalditik aurrera zuzentzen...\n","264464384\n","373. esalditik aurrera zuzentzen...\n","264464384\n","385. esalditik aurrera zuzentzen...\n","264366080\n","397. esalditik aurrera zuzentzen...\n","264513536\n","409. esalditik aurrera zuzentzen...\n","264574976\n","421. esalditik aurrera zuzentzen...\n","264673280\n","433. esalditik aurrera zuzentzen...\n","264624128\n","445. esalditik aurrera zuzentzen...\n","264722432\n","457. esalditik aurrera zuzentzen...\n","264624128\n","469. esalditik aurrera zuzentzen...\n","264624128\n","481. esalditik aurrera zuzentzen...\n","264574976\n","493. esalditik aurrera zuzentzen...\n","264882176\n","505. esalditik aurrera zuzentzen...\n","264636416\n","517. esalditik aurrera zuzentzen...\n","264636416\n","529. esalditik aurrera zuzentzen...\n","264833024\n","541. esalditik aurrera zuzentzen...\n","264636416\n","553. esalditik aurrera zuzentzen...\n","264734720\n","565. esalditik aurrera zuzentzen...\n","264894976\n","577. esalditik aurrera zuzentzen...\n","264796672\n","589. esalditik aurrera zuzentzen...\n","264944128\n","601. esalditik aurrera zuzentzen...\n","264894976\n","613. esalditik aurrera zuzentzen...\n","264845824\n","625. esalditik aurrera zuzentzen...\n","264845824\n","637. esalditik aurrera zuzentzen...\n","264956416\n","649. esalditik aurrera zuzentzen...\n","264907264\n","661. esalditik aurrera zuzentzen...\n","264956416\n","673. esalditik aurrera zuzentzen...\n","265054720\n","685. esalditik aurrera zuzentzen...\n","264968704\n","697. esalditik aurrera zuzentzen...\n","265017856\n","709. esalditik aurrera zuzentzen...\n","264968704\n","721. esalditik aurrera zuzentzen...\n","265128448\n","733. esalditik aurrera zuzentzen...\n","265079296\n","745. esalditik aurrera zuzentzen...\n","265337344\n","757. esalditik aurrera zuzentzen...\n","265288192\n","769. esalditik aurrera zuzentzen...\n","265251328\n","781. esalditik aurrera zuzentzen...\n","265300480\n","793. esalditik aurrera zuzentzen...\n","265398784\n","805. esalditik aurrera zuzentzen...\n","265460224\n","817. esalditik aurrera zuzentzen...\n","265521664\n","829. esalditik aurrera zuzentzen...\n","265619968\n","841. esalditik aurrera zuzentzen...\n","265681408\n","853. esalditik aurrera zuzentzen...\n","265730560\n","865. esalditik aurrera zuzentzen...\n","265792000\n","877. esalditik aurrera zuzentzen...\n","265952256\n","889. esalditik aurrera zuzentzen...\n","266014208\n","901. esalditik aurrera zuzentzen...\n","266235392\n","913. esalditik aurrera zuzentzen...\n","266137088\n","925. esalditik aurrera zuzentzen...\n","266395136\n","937. esalditik aurrera zuzentzen...\n","266677760\n","949. esalditik aurrera zuzentzen...\n","267034624\n","961. esalditik aurrera zuzentzen...\n","267231744\n","973. esalditik aurrera zuzentzen...\n","268153344\n","985. esalditik aurrera zuzentzen...\n","269557248\n","997. esalditik aurrera zuzentzen...\n","0.8647865017255147 minutu behar izan ditu.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AGTuyjKl7KcO","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594976676028,"user_tz":-120,"elapsed":228132,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ddffcc2d-6a10-402f-c765-8109288707b2"},"source":["candidates3 = candidates1 + candidates2\n","bleu3 = nltk.translate.bleu_score.corpus_bleu(references3, candidates3)*100\n","bleu1, bleu2, bleu3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10.464666607692772, 23.43027558677219, 13.459263472295898)"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9-YPsRdk7KcR","colab":{}},"source":["# BALIDAZIOKOAK FITXATEGI BATEAN GORDE\n","with open('HACOSDatuak/enonenaval.txt', 'w') as f:\n","    for candidate in candidates3:\n","        f.write(' '.join(candidate) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-wQFwXADiA2","colab_type":"text"},"source":["# Luzeren konparazioa"]},{"cell_type":"code","metadata":{"id":"HKjXsVvuDmvg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585935197050,"user_tz":-120,"elapsed":12641,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"009ac05e-5a74-40d3-a365-79e2a6644184"},"source":["with open('EhuHac/EhuHac-trainorig-tok-es.txt') as fitx:\n","    testua = fitx.read()\n","enc = bpe_hirurak.encode(testua.split('\\n'), output_type=yttm.OutputType.ID)\n","print(len(enc))\n","luzerak_orig_es = [len(lerroa) for lerroa in enc]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["647925\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFZpBkk0FeoD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1585935599089,"user_tz":-120,"elapsed":98935,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"71f31edd-c384-4fe7-c836-bd8b7c2c4e5f"},"source":["with open('EhuHac/EhuHac-trainorig-tok-en.txt') as fitx:\n","    testua = fitx.read()\n","enc = bpe_hirurak.encode(testua.split('\\n'), output_type=yttm.OutputType.ID)\n","print(len(enc))\n","luzerak_orig_en = [len(lerroa) for lerroa in enc]\n","\n","with open('EhuHac/EhuHac-trainorig-tok-eu.txt') as fitx:\n","    testua = fitx.read()\n","enc = bpe_hirurak.encode(testua.split('\\n'), output_type=yttm.OutputType.ID)\n","print(len(enc))\n","luzerak_orig_eu = [len(lerroa) for lerroa in enc]\n","\n","with open('EhuHac/EhuHac-trainhobea-tok-es.txt') as fitx:\n","    testua = fitx.read()\n","enc = bpe_hirurak.encode(testua.split('\\n'), output_type=yttm.OutputType.ID)\n","print(len(enc))\n","luzerak_hobea_es = [len(lerroa) for lerroa in enc]\n","\n","with open('EhuHac/EhuHac-trainhobea-tok-en.txt') as fitx:\n","    testua = fitx.read()\n","enc = bpe_hirurak.encode(testua.split('\\n'), output_type=yttm.OutputType.ID)\n","print(len(enc))\n","luzerak_hobea_en = [len(lerroa) for lerroa in enc]\n","\n","with open('EhuHac/EhuHac-trainhobea-tok-eu.txt') as fitx:\n","    testua = fitx.read()\n","enc = bpe_hirurak.encode(testua.split('\\n'), output_type=yttm.OutputType.ID)\n","print(len(enc))\n","luzerak_hobea_eu = [len(lerroa) for lerroa in enc]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["647925\n","647925\n","571150\n","571150\n","571150\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qB1iLhEpH0Jd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"status":"ok","timestamp":1585937949410,"user_tz":-120,"elapsed":1953,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"71385ca3-047a-4bf8-fd13-e01a46221231"},"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_es, luzerak_hobea_es], bins=range(-9, 200, 10), histtype='step')\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACPMAAAReCAYAAAC4+OdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdX4im5XnH8d9Vh1hP4po6iKwua9pN\nIUpZ4lKEYBBtqSal2pKmSsG1lViJgZ61Kz2IlAa2lBIItAZTxbW0atA2CiqtaIkg3bYrijElraM1\nuItRuxvNQba2JncP5tn23emMs45b3ovx84GXed7r+TP3e/7luWuMEQAAAAAAAAAAYP5+bN4LAAAA\nAAAAAAAAlol5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcA\nAAAAAAAAAJpYmPcCTrYzzzxzbN++fd7LAAAAAAAAAACAVT311FP/PsZYXO3cpot5tm/fngMHDsx7\nGQAAAAAAAAAAsKqq+s5a52yzBQAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAA\nAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAA\nAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcA\nAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEP\nAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNi\nHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAm\nxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAA\nTYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAA\nAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAA\nAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAA\nAAAAaELMAwAAAAAAAAAATSzMewEALPv43sdz6I2j814GK2zdclqe3HPpvJcBAAAAAAAAvE+IeQCa\nOPTG0by091PzXgYrbN/z0LyXAAAAAAAAALyP2GYLAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAA\nAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAA\nAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAA\nAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMA\nAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHm\nAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhC\nzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQ\nhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAA\noAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAA\nAEATYh4AAAAAAAAAAGhi3Zinqu6oqteq6rmZ2b1V9cz0eamqnpnm26vq6My5r8zcc2FVfbOqlqrq\ny1VV0/xDVfVoVT0//T1jmtd03VJVPVtVHzv5Px8AAAAAAAAAAPo4kTfz3Jnk8tnBGOPXxhg7xxg7\nk9yf5K9mTr9w7NwY48aZ+a1JPptkx/Q59sw9SR4bY+xI8tj0PUmumLn2hul+AAAAAAAAAADYtNaN\necYYTyQ5stq56e06n0ly9zs9o6rOTvLBMcb+McZIcleSq6bTVybZNx3vWzG/ayzbn2TL9BwAAAAA\nAAAAANiUTuTNPO/k4iSvjjGen5mdV1VPV9U3quriabY1ycGZaw5OsyQ5a4zxynT83SRnzdzz8hr3\nAAAAAAAAAADAprPwHu+/Jse/leeVJNvGGIer6sIkX6+q80/0YWOMUVXj3S6iqm7I8lZc2bZt27u9\nHQAAAAAAAAAAWtjwm3mqaiHJryS599hsjPHWGOPwdPxUkheSfCTJoSTnzNx+zjRLklePbZ81/X1t\nmh9Kcu4a9xxnjHHbGGPXGGPX4uLiRn8SAAAAAAAAAADM1XvZZuvnknx7jPE/22dV1WJVnTIdfzjJ\njiQvTttofb+qLqqqSnJtkgem2x5Msns63r1ifm0tuyjJmzPbcQEAAAAAAAAAwKazbsxTVXcn+fsk\nP11VB6vq+unU1Tl+i60k+USSZ6vqmST3JblxjHFkOve5JH+WZCnLb+x5ZJrvTfLzVfV8lgOhvdP8\n4SQvTtd/dbofAAAAAAAAAAA2rYX1LhhjXLPG/LpVZvcnuX+N6w8kuWCV+eEkl60yH0luWm99AAAA\nAAAAAACwWbyXbbYAAAAAAAAAAICTSMwDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh\n5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABo\nQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA\n0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAA\nAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAA\nAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAA\nAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAA\nAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAA\nAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8A\nAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2Ie\nAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbE\nPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABN\niHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAA\nmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAA\nADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAA\nAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAA\nAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAA\nAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAA\nAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEA\nAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswD\nAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISY\nBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJ\nMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCYW5r0AAGbccvq8V8D/8ZfzXgAAAAAAAADwPiLmAejkljfn\nvQJW2vPQvFcAAAAAAAAAvI/YZgsAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAA\nAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcA\nAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEP\nAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNi\nHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgiXVjnqq6o6peq6rnZma3VNWhqnpm+nxy\n5tzNVbVUVf9SVb8wM798mi1V1Z6Z+XlV9Q/T/N6q+sA0P3X6vjSd336yfjQAAAAAAAAAAHR0Im/m\nuTPJ5avMvzTG2Dl9Hk6SqvpokquTnD/d86dVdUpVnZLkT5JckeSjSa6Zrk2SP5ye9VNJvpfk+ml+\nfZLvTfMvTdcBAAAAAAAAAMCmtW7MM8Z4IsmRE3zelUnuGWO8Ncb4tyRLSX52+iyNMV4cY/xnknuS\nXFlVleTSJPdN9+9LctXMs/ZNx/cluWy6HgAAAAAAAAAANqUTeTPPWj5fVc9O23CdMc22Jnl55pqD\n02yt+U8keWOM8faK+XHPms6/OV0PAAAAAAAAAACb0kZjnluT/GSSnUleSfLHJ21FG1BVN1TVgao6\n8Prrr89zKQAAAAAAAAAAsGEbinnGGK+OMX44xvhRkq9meRutJDmU5NyZS8+ZZmvNDyfZUlULK+bH\nPWs6f/p0/WrruW2MsWuMsWtxcXEjPwkAAAAAAAAAAOZuQzFPVZ098/WXkzw3HT+Y5OqqOrWqzkuy\nI8k/JvmnJDuq6ryq+kCSq5M8OMYYSf4uyaen+3cneWDmWbun408neXy6HgAAAAAAAAAANqWF9S6o\nqruTXJLkzKo6mOQLSS6pqp1JRpKXkvxWkowxvlVVX0vyz0neTnLTGOOH03M+n+RvkpyS5I4xxrem\nf/G7Se6pqj9I8nSS26f57Un+vKqWkhzJcgAEAAAAAAAAAACb1roxzxjjmlXGt68yO3b9F5N8cZX5\nw0keXmX+Yv53m67Z+X8k+dX11gcAAAAAAAAAAJvFhrbZAgAAAAAAAAAATj4xDwAAAAAAAAAANCHm\nAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhC\nzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQ\nhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAA\noAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAA\nAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAA\nAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAA\nAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAA\nAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAA\nAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4A\nAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8\nAAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2I\neQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACa\nEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAA\nNCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAA\nAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAA\nAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAA\nAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAA\nAAAAAEATYh4AAAAAAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAA\nAAAAAACAJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATYh4AAAAAAAAAAGhiYd4L\nAObj43sfz6E3js57GczYmtfnvQQAAAAAAAAA5kzMA+9Th944mpf2fmrey2DWLacnuW7eqwAAAAAA\nAABgjmyzBQAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAA\nAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAA\nAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAA\nAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYB\nAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELM\nAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCE\nmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACg\nCTEPAAAAAAAAAAA0sW7MU1V3VNVrVfXczOyPqurbVfVsVf11VW2Z5tur6mhVPTN9vjJzz4VV9c2q\nWqqqL1dVTfMPVdWjVfX89PeMaV7TdUvT//nYyf/5AAAAAAAAAADQx4m8mefOJJevmD2a5IIxxs8k\n+dckN8+ce2GMsXP63DgzvzXJZ5PsmD7HnrknyWNjjB1JHpu+J8kVM9feMN0PAAAAAAAAAACb1rox\nzxjjiSRHVsz+dozx9vR1f5Jz3ukZVXV2kg+OMfaPMUaSu5JcNZ2+Msm+6XjfivldY9n+JFum5wAA\nAAAAAAAAwKZ0Im/mWc9vJnlk5vt5VfV0VX2jqi6eZluTHJy55uA0S5KzxhivTMffTXLWzD0vr3EP\nAAAAAAAAAABsOgvv5eaq+r0kbyf5i2n0SpJtY4zDVXVhkq9X1fkn+rwxxqiqsYF13JDlrbiybdu2\nd3s7AAAAAAAAAAC0sOE381TVdUl+McmvT1tnZYzx1hjj8HT8VJIXknwkyaEcvxXXOdMsSV49tn3W\n9Pe1aX4oyblr3HOcMcZtY4xdY4xdi4uLG/1JAAAAAAAAAAAwVxuKearq8iS/k+SXxhg/mJkvVtUp\n0/GHk+xI8uK0jdb3q+qiqqok1yZ5YLrtwSS7p+PdK+bX1rKLkrw5sx0XAAAAAAAAAABsOutus1VV\ndye5JMmZVXUwyReS3Jzk1CSPLrc52T/GuDHJJ5L8flX9V5IfJblxjHFketTnktyZ5LQkj0yfJNmb\n5GtVdX2S7yT5zDR/OMknkywl+UGS33gvPxQAAAAAAAAAALpbN+YZY1yzyvj2Na69P8n9a5w7kOSC\nVeaHk1y2ynwkuWm99QEAAAAAAAAAwGaxoW22AAAAAAAAAACAk0/MAwAAAAAAAAAATYh5AAAAAAAA\nAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJpYmPcCAKCz\nrXk92/c8NO9lMGPrltPy5J5L570MAAAAAAAA+H8h5gGAd/Dkj/92csub814GM8RVAAAAAAAAbGa2\n2QIA/pu9Owr9/a7rOP5648ESye1kpyGbI6kRWBdDD3MXXZTSPPOiGYTMi3YQcUEK5VWnq41MqCAC\noQZGw+1CzQJx4GodRhAIK1eJ00h2MsUN3Q7OJiQU2qeL8139PP53PO7/P/1f/ns84Mfv+39/P9/v\n9/O/f/L7AgAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAA\nAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAA\nAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAA\nAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAA\nAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAA\nAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwAAAAA\nAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAA\nAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAA\nAAAAAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUELMAwAA\nAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAA\nAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMA\nAAAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwA\nAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswD\nAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAAAAAAACXEPAAAAAAAAAAAUOLYYW8AAKpddX1y91WH\nvQu+zQcPewMAAAAAAABwxYh5AOBS3v3YYe+Ai535+GHvAAAAAAAAAK4Yr9kCAAAAAAAAAIASYh4A\nAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYB\nAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIe\nAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHm\nAQAAAAAAAACAEscOewPAIbr7qsPeAbuuuv6wdwAAAAAAAADAIRPzwP9ndz972DsAAAAAAAAAAHZ4\nzRYAAAAAAAAAAJQQ8wAAAAAAAAAAQAkxDwAAAAAAAAAAlBDzAAAAAAAAAABACTEPAAAAAAAAAACU\nEPMAAAAAAAAAAEAJMQ8AAAAAAAAAAJQQ8wAAAAAAAAAAQAkxDwAAAAAAAAAAlBDzAAAAAAAAAABA\nCTEPAAAAAAAAAACUEPMAAAAAAAAAAEAJMQ8AAAAAAAAAAJQQ8wAAAAAAAAAAQAkxDwAAAAAAAAAA\nlBDzAAAAAAAAAABACTEPAAAAAAAAAACUEPMAAAAAAAAAAEAJMQ8AAAAAAAAAAJQQ8wAAAAAAAAAA\nQAkxDwAAAAAAAAAAlBDzAAAAAAAAAABACTEPAAAAAAAAAACUEPMAAAAAAAAAAEAJMQ8AAAAAAAAA\nAJQQ8wAAAAAAAAAAQAkxDwAAAAAAAAAAlBDzAAAAAAAAAABACTEPAAAAAAAAAACUEPMAAAAAAAAA\nAEAJMQ8AAAAAAAAAAJQQ8wAAAAAAAAAAQAkxDwAAAAAAAAAAlBDzAAAAAAAAAABAicuKeWbm3pl5\nemY+szP74Zk5OzOPb9/Htx2W/Q8AACAASURBVPnMzPtm5tzMfHpmXrNzzelt/eMzc3pn/tqZeWy7\n5n0zM5d6BgAAAAAAAAAAHEWX+8s8H0hy6qLZmSQPr7VuSPLw9neS3Jrkhu1zZ5J7kgthTpK7krwu\nyU1J7tqJc+5J8o6d6059l2cAAAAAAAAAAMCRc1kxz1rrb5I8c9H4tiT3bcf3JXnzzvz+dcEjSa6e\nmVckeWOSs2utZ9ZaX0tyNsmp7dzL1lqPrLVWkvsvutdezwAAAAAAAAAAgCPncn+ZZy/XrLW+vB1/\nJck12/G1Sb60s+6JbXap+RN7zC/1DAAAAAAAAAAAOHL2E/P8j+0XddZB3OuFPGNm7pyZR2fm0fPn\nz1/JbQAAAAAAAAAAwBWzn5jnqe0VWdm+n97mTyZ55c6667bZpebX7TG/1DO+zVrr/Wutk2utkydO\nnNjHvwQAAAAAAAAAAIdnPzHPA0lOb8enk3xsZ37HXHBzkme3V2U9lOSWmTk+M8eT3JLkoe3c12fm\n5pmZJHdcdK+9ngEAAAAAAAAAAEfOsctZNDMfSvKzSX5kZp5IcleS30nykZl5e5IvJnnLtvzBJG9K\nci7JN5K8LUnWWs/MzHuSfHJb91trrWe2419N8oEkL0nyF9snl3gGAAAAAAAAAAAcOZcV86y13vo8\np96wx9qV5J3Pc597k9y7x/zRJD+9x/yrez0DAAAAAAAAAACOov28ZgsAAAAAAAAAADhAYh4AAAAA\nAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAA\nAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAA\nAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAA\nAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAA\nAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEA\nAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4A\nAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYB\nAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIe\nAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHm\nAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJi\nHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh\n5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIAS\nYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAo\nIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACA\nEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAA\nKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAA\ngBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAA\nACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAA\nAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAA\nAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAA\nAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAA\nAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAAAAAAACgh5gEAAAAA\nAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAAAAAAAIASYh4AAAAA\nAAAAACgh5gEAAAAAAAAAgBJiHgAAAAAAAAAAKCHmAQAAAAAAAACAEmIeAAAAAAAAAAAoIeYBAAAA\nAAAAAIASYh4AAAAAAAAAACgh5gEAAAAAAAAAgBLHDnsDAADfi2tzPj925uOHvQ0ucu3VL8knzrz+\nsLcBAAAAAADwfU/MAwB8X/nED/5acvezh70NLiKwAgAAAAAAOBheswUAAAAAAAAAACXEPAAAAAAA\nAAAAUELMAwAAAAAAAAAAJcQ8AAAAAAAAAABQQswDAAAAAAAAAAAlxDwAAAAAAAAAAFBCzAMAAAAA\nAAAAACVecMwzMz85M5/a+Xx9Zn59Zu6emSd35m/aueY3Z+bczHxuZt64Mz+1zc7NzJmd+atm5m+3\n+Z/OzItf+L8KAAAAAAAAAADdXnDMs9b63FrrxrXWjUlem+QbST66nf6D586ttR5Mkpl5dZLbk/xU\nklNJ/mhmXjQzL0ryh0luTfLqJG/d1ibJ7273+okkX0vy9he6XwAAAAAAAAAAaHdQr9l6Q5J/WWt9\n8RJrbkvy4bXWf6y1/jXJuSQ3bZ9za63Pr7X+M8mHk9w2M5Pk9Un+fLv+viRvPqD9AgAAAAAAAABA\nnYOKeW5P8qGdv981M5+emXtn5vg2uzbJl3bWPLHNnm/+8iT/ttb65kVzAAAAAAAAAAA4kvYd88zM\ni5P8QpI/20b3JPnxJDcm+XKS39/vMy5jD3fOzKMz8+j58+ev9OMAAAAAAAAAAOCKOIhf5rk1yT+s\ntZ5KkrXWU2utb621/ivJH+fCa7SS5Mkkr9y57rpt9nzzrya5emaOXTT/Dmut96+1Tq61Tp44ceIA\n/iUAAAAAAAAAAPi/dxAxz1uz84qtmXnFzrlfTPKZ7fiBJLfPzA/MzKuS3JDk75J8MskNM/Oq7Vd+\nbk/ywFprJfnrJL+0XX86yccOYL8AAAAAAAAAAFDp2Hdf8vxm5qVJfj7Jr+yMf29mbkyyknzhuXNr\nrc/OzEeS/FOSbyZ551rrW9t93pXkoSQvSnLvWuuz271+I8mHZ+a3k/xjkj/Zz34BAAAAAAAAAKDZ\nvmKetda/J3n5RbNfvsT69yZ57x7zB5M8uMf88/nf13QBAAAAAAAAAMCRdhCv2QIAAAAAAAAAAA6A\nmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABK\niHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoMSxw94AAMD35Krrk7uvOuxd8B0+eNgb\nAAAAAAAAOBLEPADA95d3P3bYO2AvZz5+2DsAAAAAAAA4ErxmCwAAAAAAAAAASoh5AAAAAAAAAACg\nhJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAA\nSoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAA\noISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAA\nAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAA\nAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAA\nAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAA\nAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAA\nAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAA\nAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAA\nAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAA\nAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAA\nAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAA\nAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAA\nAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAA\nAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcA\nAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkA\nAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgH\nAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5\nAAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISY\nBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqI\neQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABKiHkAAAAAAAAAAKCE\nmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACghJgHAAAAAAAAAABK\niHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAASoh5AAAAAAAAAACg\nhJgHAAAAAAAAAABKiHkAAAAAAAAAAKCEmAcAAAAAAAAAAEqIeQAAAAAAAAAAoISYBwAAAAAAAAAA\nSuw75pmZL8zMYzPzqZl5dJv98MycnZnHt+/j23xm5n0zc25mPj0zr9m5z+lt/eMzc3pn/trt/ue2\na2e/ewYAAAAAAAAAgEYH9cs8P7fWunGtdXL7+0ySh9daNyR5ePs7SW5NcsP2uTPJPcmF+CfJXUle\nl+SmJHc9FwBta96xc92pA9ozAAAAAAAAAABUuVKv2botyX3b8X1J3rwzv39d8EiSq2fmFUnemOTs\nWuuZtdbXkpxNcmo797K11iNrrZXk/p17AQAAAAAAAADAkXIQMc9K8lcz8/czc+c2u2at9eXt+CtJ\nrtmOr03ypZ1rn9hml5o/scccAAAAAAAAAACOnGMHcI+fWWs9OTM/muTszPzz7sm11pqZdQDPeV5b\nRHRnklx//fVX8lEAAAAAAAAAAHDF7PuXedZaT27fTyf5aJKbkjy1vSIr2/fT2/Ink7xy5/Lrttml\n5tftMb94D+9fa51ca508ceLEfv8lAAAAAAAAAAA4FPuKeWbmpTPzQ88dJ7klyWeSPJDk9LbsdJKP\nbccPJLljLrg5ybPb67geSnLLzByfmePbfR7azn19Zm6emUlyx869AAAAAAAAAADgSNnva7auSfLR\nC51NjiX54FrrL2fmk0k+MjNvT/LFJG/Z1j+Y5E1JziX5RpK3Jcla65mZeU/+u737j7H8rus9/np3\nR3Bz1VlUQrhD1+3VaoKaWwwBE67GVNGChurNjWmjCGqC5rYGem9yHfSPO5f4o6hoaoIalEZMgMJV\nCI1bRQ1E4yRgCzYuLaJrLaGb3lJBFomot+XjH3OKp+PMUmbO7vc95zweyWTPfGZm++aPD99z9jzn\n+0nunH3fq8YYH589/u9JfjPJ8SS/N/sAAAAAAAAAAIClc6iYZ4xxX5L/vMf6x5J86x7rI8kN+/xd\ntya5dY/1u5J83WHmBAAAAAAAAACAo+BQx2wBAAAAAAAAAACLI+YBAAAAAAAAAIAmxDwAAAAAAAAA\nANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAA\nAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANDE2tQDAABw9G3k4ZzaPD31GMzZ\nOHE825tXTz0GAAAAAADweRLzAABwaNtf+PJk6/zUYzBHXAUAAAAAAEeTY7YAAAAAAAAAAKAJMQ8A\nAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0MTa1AMAALAE1k8mW+tTT8HjvGnqAQAAAAAA\ngAMQ8wAAcHg3nZl6AnbbPD31BAAAAAAAwAE4ZgsAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAA\nAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAA\nAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAA\nAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAA\nAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYB\nAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELM\nAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCE\nmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACg\nCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAA\nQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAA\nAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAA\nAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAA\nAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAA\nAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAA\nAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwA\nAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5\nAAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ\n8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0\nIeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAA\naELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAA\nANCEmAcAAAAAAAAAAJpYm3oAAADgItlan3oCdls/mdx0ZuopAAAAAABoTMwDAADLauv81BOwm8AK\nAAAAAIDPwTFbAAAAAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATa1MPAAAALN7GieM5tXl6\n6jHYZSO3ZHvqIQAAAAAAaE3MAwAAS2h78+qpR2APAisAAAAAAD4Xx2wBAAAAAAAAAEATYh4AAAAA\nAAAAAGhCzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAA\nAAAAAADQhJgHAAAAAAAAAACaEPMAAAAAAAAAAEATB455quryqnp3Vd1bVfdU1ctn61tVda6q7p59\nvHDuZ15ZVWer6kNV9R1z69fM1s5W1ebc+hVV9d7Z+luq6kkHnRcAAAAAAAAAALo7zJ15HknyP8cY\nz0zyjUluqKpnzr72S2OMq2YfdyTJ7GvXJfnaJNck+ZWqOlZVx5K8NskLkjwzyfVzf8+rZ3/XVyX5\n+yQ/fIh5AQAAAAAAAACgtQPHPGOMB8cY7589/ockH0yycYEfuTbJbWOMfx5j/G2Ss0meM/s4O8a4\nb4zxL0luS3JtVVWSq5P89uzn35Dkuw86LwAAAAAAAAAAdHeYO/N8VlWdSvKsJO+dLd1YVX9RVbdW\n1VNmaxtJPjL3Yw/M1vZb/7IknxhjPLJrHQAAAAAAAAAAltKhY56q+qIkv5PkFWOMTyb51SRfmeSq\nJA8mec1h/xtPYIaXVdVdVXXXww8/fLH/cwAAAAAAAAAAcFEcKuapqi/ITsjzxjHG25JkjPHQGOPR\nMcZnkvx6do7RSpJzSS6f+/FnzNb2W/9YkhNVtbZr/d8ZY7xujPHsMcazn/rUpx7mfxIAAAAAAAAA\nAEzmwDFPVVWS1yf54BjjF+fWnz73bd+T5AOzx7cnua6qnlxVVyS5MsmfJbkzyZVVdUVVPSnJdUlu\nH2OMJO9O8t9mP/+SJO846LwAAAAAAAAAANDd2uf+ln09L8mLk5ypqrtnaz+R5PqquirJSHJ/kh9J\nkjHGPVX11iT3JnkkyQ1jjEeTpKpuTPLOJMeS3DrGuGf29/14ktuq6qeS/Hl24iEAAAAAAAAAAFhK\nB455xhh/mqT2+NIdF/iZn07y03us37HXz40x7su/HdMFAAAAAAAAAABL7cDHbAEAAAAAAAAAAIsl\n5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABo\nQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA\n0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAA\nAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAA\nAABAE2IeAAAAAAAAAABoQswDAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAA\nAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAA\nAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAAADQh5gEAAAAAAAAAgCbWph4AAABgpWytTz0B89ZP\nJjedmXoKAAAAAIDPEvMAAABcSlvnp56AeeIqAAAAAKAZx2wBAAAAAAAAAEATYh4AAAAAAAAAAGhC\nzAMAAAAAAAAAAE2IeQAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQ\nhJgHAAAAAAAAAACaWJt6AAAAgFWxceJ4Tm2ennoM5mzklmxPPQQAAAAAwBwxDwAAwCWyvXn11COw\ni7gKAAAAAOjGMVsAAAAAAAAAANCEmAcAAAAAAAAAAJpwzBaXxPNuflfOfeLTU4/BnI08PPUIAAAA\nAAAAAMAuYh4uiXOf+HTuv/k7px6DeVvrSV469RQAAAAAAAAAwBzHbAEAAAAAAAAAQBNiHgAAAAAA\nAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAA\nAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAA\nAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAA\nAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYB\nAAAAAAAAAIAm1qYeK12w4gAAC79JREFUAAAAACa1tT71BOy2fjK56czUUwAAAADAJMQ8AAAArLat\n81NPwG4CKwAAAABWmGO2AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAA\nANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAAQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATaxNPQAAAABM\nZePE8ZzaPD31GOyykVuyPfUQAAAAADARMQ8AAAAra3vz6qlHYA8CKwAAAABWmWO2AAAAAAAAAACg\nCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcAAAAAAAAAAJoQ8wAAAAAAAAAA\nQBNiHgAAAAAAAAAAaELMAwAAAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAA\nAIAm1qYeAAAAAODf2VqfegLmrZ9Mbjoz9RQAAAAAK0HMAwAAAPSzdX7qCZgnrgIAAAC4ZByzBQAA\nAAAAAAAATYh5AAAAAAAAAACgCTEPAAAAAAAAAAA0IeYBAAAAAAAAAIAmxDwAAAAAAAAAANCEmAcA\nAAAAAAAAAJpYm3oAAAAAgHkbJ47n1ObpqcdgzkZuyfbUQwAAAACsCDEPAAAA0Mr25tVTj8Au4ioA\nAACAS8cxWwAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAAAABoQswDAAAA\nAAAAAABNrE09AAAAAABHwNb61BOw2/rJ5KYzU08BAAAALJiYBwAAAIDPbev81BOwm8AKAAAAlpJj\ntgAAAAAAAAAAoAkxDwAAAAAAAAAANCHmAQAAAAAAAACAJsQ8AAAAAAAAAADQxNrUAwAAAADQ28aJ\n4zm1eXrqMdhlI7dke+ohAAAAgIUT8wAAAABwQdubV089AnsQWAEAAMByEvMAAAAAwFG1tT71BMxb\nP5ncdGbqKQAAADjixDwAAAAAcFRtnZ96AuaJqwAAAFiAy6YeAAAAAAAAAAAA2CHmAQAAAAAAAACA\nJsQ8AAAAAAAAAADQhJgHAAAAAAAAAACaWJt6AAAAAADg87dx4nhObZ6eegzmbFz22mxvrU89BvPW\nTyY3nZl6CgAAgM+LmAcAAAAAjqDtzaunHoFdTm2eTrbOTz0G88RVAADAEeSYLQAAAAAAAAAAaMKd\neQAAAAAAWE7rJ92dpyPHnwEAwAWJeQAAAAAAFmDjxPGdo7ZoY+PELdneciRdOwIrAAC4IDEPAAAA\nAMACbG+KRroRVwEAAEeRmAcAAAAAgKXkbkk9bVz22my7O08vjj4DAGhFzAMAAAAAwFJyt6SeTm2e\nTrbOTz0G88RVAACttI95quqaJLckOZbkN8YYN088EgAAAAAAcEDumNSPuyU15Y5JALCyWsc8VXUs\nyWuTPD/JA0nurKrbxxj3TjsZAAAAAABwEO6Y1I+7JTX1S1/vrknwRAjfgCXUOuZJ8pwkZ8cY9yVJ\nVd2W5NokYh4AAAAAAIAFcLekrhxW0c3GieOCxI6Eb/0IrODQusc8G0k+Mvf5A0meO9EsAAAAAAAA\nS0ecAE/M825+l/CtJeFbO/+UxF5pZ+Oyv8/2z3z/1GPwBHWPeZ6QqnpZkpfNPv1UVX1oynnYW716\n6glWxpcn+bsn9J3/py7uJMCl8MT3PLAs7HtYPfY9rBZ7HlaPfQ+rx76H1WLP08KHk9TPvnjqMVbF\nE933X7HfF7rHPOeSXD73+TNma48zxnhdktddqqGgs6q6a4zx7KnnAC4Nex5Wj30Pq8e+h9Viz8Pq\nse9h9dj3sFrseVg9i9j3ly1qmIvkziRXVtUVVfWkJNcluX3imQAAAAAAAAAA4KJofWeeMcYjVXVj\nkncmOZbk1jHGPROPBQAAAAAAAAAAF0XrmCdJxhh3JLlj6jngCHHkHKwWex5Wj30Pq8e+h9Viz8Pq\nse9h9dj3sFrseVg9h973NcZYxCAAAAAAAAAAAMAhXTb1AAAAAAAAAAAAwA4xDyyJqrqmqj5UVWer\nanPqeYDFq6rLq+rdVXVvVd1TVS+frW9V1bmqunv28cKpZwUWp6rur6ozs/1912ztS6vqD6vqr2d/\nPmXqOYHDq6qvmbue311Vn6yqV7jWw3Kpqlur6qNV9YG5tT2v7bXjl2ev9f+iqr5husmBg9pn3/98\nVf3lbG+/vapOzNZPVdWn5677vzbd5MBB7LPn931OX1WvnF3rP1RV3zHN1MBh7LPv3zK35++vqrtn\n6671cMRd4P26hb62d8wWLIGqOpbkr5I8P8kDSe5Mcv0Y495JBwMWqqqenuTpY4z3V9UXJ3lfku9O\n8r1JPjXG+IVJBwQuiqq6P8mzxxh/N7f2c0k+Psa4eRbxPmWM8eNTzQgs3uw5/rkkz03yg3Gth6VR\nVd+c5FNJfmuM8XWztT2v7bM3+n4syQuz8/8Ht4wxnjvV7MDB7LPvvz3Ju8YYj1TVq5Nktu9PJfnd\nx74POHr22fNb2eM5fVU9M8mbkzwnyX9M8kdJvnqM8eglHRo4lL32/a6vvybJ+THGq1zr4ei7wPt1\nL80CX9u7Mw8sh+ckOTvGuG+M8S9Jbkty7cQzAQs2xnhwjPH+2eN/SPLBJBvTTgVM5Nokb5g9fkN2\nXigAy+Vbk/zNGOPDUw8CLNYY40+SfHzX8n7X9muz84bAGGO8J8mJ2T8aAkfIXvt+jPEHY4xHZp++\nJ8kzLvlgwEWxz7V+P9cmuW2M8c9jjL9NcjY7/94PHCEX2vdVVdn5hdw3X9KhgIvmAu/XLfS1vZgH\nlsNGko/Mff5AvMEPS21W7z8ryXtnSzfObs13q+N2YOmMJH9QVe+rqpfN1p42xnhw9vj/JXnaNKMB\nF9F1efw/9LnWw3Lb79ru9T6shh9K8ntzn19RVX9eVX9cVd801VDAwu31nN61HpbfNyV5aIzx13Nr\nrvWwJHa9X7fQ1/ZiHgA4Yqrqi5L8TpJXjDE+meRXk3xlkquSPJjkNROOByzefxljfEOSFyS5YXbb\n3s8aO+fmOjsXlkhVPSnJi5L839mSaz2sENd2WC1V9ZNJHknyxtnSg0lOjjGeleR/JHlTVX3JVPMB\nC+M5Payu6/P4X9ZxrYclscf7dZ+1iNf2Yh5YDueSXD73+TNma8CSqaovyM4TgzeOMd6WJGOMh8YY\nj44xPpPk1+NWvLBUxhjnZn9+NMnbs7PHH3rsNpyzPz863YTARfCCJO8fYzyUuNbDitjv2u71Piyx\nqnppku9K8n2zf+zP7Kidj80evy/J3yT56smGBBbiAs/pXethiVXVWpL/muQtj6251sNy2Ov9uiz4\ntb2YB5bDnUmurKorZr/Fe12S2yeeCViw2dm6r0/ywTHGL86tz5+r+T1JPnCpZwMujqr6D1X1xY89\nTvLt2dnjtyd5yezbXpLkHdNMCFwkj/utPdd6WAn7XdtvT/IDteMbk5yfu2U3cIRV1TVJ/leSF40x\n/nFu/alVdWz2+D8luTLJfdNMCSzKBZ7T357kuqp6clVdkZ09/2eXej7govm2JH85xnjgsQXXejj6\n9nu/Lgt+bb+2wJmBiYwxHqmqG5O8M8mxJLeOMe6ZeCxg8Z6X5MVJzlTV3bO1n0hyfVVdlZ3b9d2f\n5EemGQ+4CJ6W5O07rw2yluRNY4zfr6o7k7y1qn44yYeTfO+EMwILNAv3np/HX89/zrUelkdVvTnJ\ntyT58qp6IMn/TnJz9r6235HkhUnOJvnHJD94yQcGDm2fff/KJE9O8oez5/vvGWP8aJJvTvKqqvr/\nST6T5EfHGB+fZHDgQPbZ89+y13P6McY9VfXWJPdm58i9G8YYj04xN3Bwe+37Mcbrs/PL92/e9e2u\n9XD07fd+3UJf29fs7p0AAAAAAAAAAMDEHLMFAAAAAAAAAABNiHkAAAAAAAAAAKAJMQ8AAAAAAAAA\nADQh5gEAAAAAAAAAgCbEPAAAAAAAAAAA0ISYBwAAAAAAAAAAmhDzAAAAAAAAAABAE2IeAAAAAAAA\nAABo4l8B1SjdmP/F8DcAAAAASUVORK5CYII=\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"EgRVdvVmPfns","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1585938378796,"user_tz":-120,"elapsed":1438,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"ead74008-e556-47c2-ea78-7089ad925dec"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_es, luzerak_hobea_es], bins=range(121, 400, 10), histtype='step')\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACOYAAARhCAYAAACMUxiNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgA7+D8ilXfX6xI7LAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dqymE5GVRWa7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"status":"ok","timestamp":1585938596423,"user_tz":-120,"elapsed":1432,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c7ab8e1a-a31a-4859-a932-c82851b4dd7c"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_en, luzerak_hobea_en], bins=range(-9, 200, 10), histtype='step')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACPMAAAReCAYAAAC4+OdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"3bHuAOt6Tnvy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":628},"executionInfo":{"status":"ok","timestamp":1585938794876,"user_tz":-120,"elapsed":1375,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"0ea7a941-3f22-429e-afe0-228614b72ea3"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_en, luzerak_hobea_en], bins=range(121, 400, 10), histtype='step')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACOYAAAReCAYAAAB5f631AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"54sSpotHUYOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"status":"ok","timestamp":1585939032752,"user_tz":-120,"elapsed":1721,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"a3cdb608-b9d1-4048-c1fe-ecc277018bb2"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_eu, luzerak_hobea_eu], bins=range(-9, 200, 10), histtype='step')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACPMAAAReCAYAAAC4+OdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAABiHmAQAAAAAAAACAQfw/dFyZ6WG79FMAAAAASUVORK5CYII=\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Y7NkRLcDVSLp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1585939164215,"user_tz":-120,"elapsed":1627,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"5b34bd18-7ecc-418d-bc1a-6c143367ba6d"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_eu, luzerak_hobea_eu], bins=range(121, 400, 10), histtype='step')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACOAAAAReCAYAAAB0Yd2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAECH/wMg8G9SjqyM2QAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"iOC2CqgeaCcz","colab_type":"code","colab":{}},"source":["labels = ['ES', 'EN', 'EU']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X73RfYt8Vvog","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"status":"ok","timestamp":1585940414928,"user_tz":-120,"elapsed":1604,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"9507c785-931e-48ef-d755-7441c6364169"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_es, luzerak_orig_en, luzerak_orig_eu], bins=range(-9, 200, 10), histtype='step', label=labels)\n","plt.legend(prop={'size': 50})\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACPMAAAReCAYAAAC4+OdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"NZCZbFvhZPj5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1585940792889,"user_tz":-120,"elapsed":1520,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"c671baa8-d8ec-4ddd-da85-40dce15bb9f3"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_orig_es, luzerak_orig_en, luzerak_orig_eu], bins=range(121, 400, 10), histtype='step', label=labels)\n","plt.legend(prop={'size': 50})\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACOAAAAReCAYAAAB0Yd2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdfWzddf338ff3tNtaTtfuhjJC3Siy\ngEGJVeYcoMy78LuIhOsSEZAlkugihHAjRHARgYGQMb2CEAyGnyJg4sgU8HYsgpGpIBkUdMglIndj\nGxtj7IatZ63Y9nv98asktYOt+7R8z2kfj2TJ9jnnfM6rS/bXnjkny/M8AAAAAAAAAACA/VMqegAA\nAAAAAAAAANQyAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDgAAAAAAAAAABAAgEO\nAAAAAAAAAAAkqC96QETEgQcemLe3txc9AwAAAAAAAAAA9ujxxx9/Lc/z1j09VhUBTnt7e3R2dhY9\nAwAAAAAAAAAA9ijLspfe6jFfQQUAAAAAAAAAAAkEOAAAAAAAAAAAkECAAwAAAAAAAAAACQQ4AAAA\nAAAAAACQQIADAAAAAAAAAAAJBDgAAAAAAAAAAJBAgAMAAAAAAAAAAAkEOAAAAAAAAAAAkECAAwAA\nAAAAAAAACQQ4AAAAAAAAAACQQIADAAAAAAAAAAAJBDgAAAAAAAAAAJBAgAMAAAAAAAAAAAkEOAAA\nAAAAAAAAkECAAwAAAAAAAAAACQQ4AAAAAAAAAACQQIADAAAAAAAAAAAJBDgAAAAAAAAAAJBAgAMA\nAAAAAAAAAAkEOAAAAAAAAAAAkECAAwAAAAAAAAAACQQ4AAAAAAAAAACQQIADAAAAAAAAAAAJ6ose\nAAAAAAAAAABF6O/vj66urti1a1d0d3dHX19f9Pf3Fz0L+A+lUinq6uqisbExJk+eHE1NTVEqVddn\nzghwAAAAAAAAABhXent7Y/PmzdHV1fXmf+i3trZGXV1dlEqlyLKs6InAgDzPo7+/P/r6+qJSqcT2\n7dtj06ZN0dTUFDNmzIj6+upIX6pjBQAAAAAAAAC8A3p7e2PdunVRLpfj8MMPr5r/vAf2LMuyqKur\ni7q6upg4cWJMnTo1ent7Y+vWrbFu3bqYNWtWVfw7rq7P4wEAAAAAAACAUfLv+KapqSkOOuigqvhP\ne2D46uvr46CDDoqmpqZYt25d9Pb2Fj1JgAMAAAAAAADA+LB58+Yol8vR2trqa6agxmVZFq2trVEu\nl2Pz5s1FzxHgAAAAAAAAADD29ff3R1dXV0yfPl18A2NElmUxffr06Orqiv7+/kK3CHAAAAAAAAAA\nGPO6urqisbHR107BGFNfXx8NDQ1RqVQK3SHAAQAAAAAAAGDM27VrV0yePLnoGcAoaG5ujp07dxa6\nQYADAAAAAAAAwJjX3d0d5XK56BnAKCiXy9Hd3V3oBgEOAAAAAAAAAGNeX19f1NXVFT0DGAV1dXXR\n19dX6AYBDgAAAAAAAABjXn9/f5RK/oscxqJSqRT9/f3Fbij03QEAAAAAAADgHZJlWdETgFFQDf+2\nBTgAAAAAAAAAAJBAgAMAAAAAAAAAAAkEOAAAAAAAAAAAkECAAwAAAAAAAAAACQQ4AAAAAAAAAACQ\nQIADAAAAAAAAAAAJBDgAAAAAAAAAAJBAgAMAAAAAAAAAAAkEOAAAAAAAAAAAkECAAwAAAAAAAAAA\nCQQ4AAAAAAAAAACQoL7oAQAAAAAAAABQa/7r7v+KjZWNRc9gwCHlQ+I3p/2m6BnDsnbt2jjssMNG\n5e6WlpbYsWPHWz6eZdmQszzPk993Tz/ToYceGmvXrk2+u9oJcAAAAAAAAABgmDZWNsZfz/5r0TMY\ncPSdRxc9gXHOV1ABAAAAAAAAAEACn4DDWzr++t/Fyzu6i55RE9qmNMbDiz5R9AwAAAAAAAAAali5\nXI7Zs2cn3zN58uQRWMNwCHB4Sy/v6I6113+66Bk1oX3RiqInAAAAAAAAAFDj5syZE6tWrSp6BvvB\nV1ABAAAAAAAAAEACAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDgAAAAAAAAAABA\nAgEOAAAAAAAAAAAkEOAAAAAAAAAAAEACAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIBDgAAAAAAAAAA\nJKgvegAAAAAAAAAAABGdnZ3R0dGRfM/y5cvjyCOPHIFF7CsBDgAAAAAAAABAFahUKrFmzZrke7q7\nu0dgDcPhK6gAAAAAAAAAACCBAAcAAAAAAAAAABL4CioAAAAAAAAAgCowf/78WLVqVdEz2A8+AQcA\nAAAAAAAAABIIcAAAAAAAAAAAIIEABwAAAAAAAABgHKmrqxty1tPTk3xvd3f3kLP6+vrke2uBAAcA\nAAAAAAAAYByZMmXKkLOurq7ke/d0x9SpU5PvrQUCHAAAAAAAAACAcWRPUcyOHTuS793THQIcAAAA\nAAAAAADGnAMPPHDI2d///vfke59++ul9eq+xSIADAAAAAAAAADCOfPCDHxxy9uSTTybf+9RTTw05\nO+aYY5LvrQUCHAAAAAAAAACAceT4448fcrZixYqkO/v7+2PlypX79F5jkQAHAAAAAAAAAGAcmT9/\nfpRKg5ORRx55JJ5//vn9vvPBBx+MDRs2DDpraWnZ46ftjEUCHAAAAAAAAACAcaStrS0+85nPDDrL\n8zwuueSS/bqvr68vvvrVrw45P+ecc2LixIn7dWetEeAAAAAAAAAAAIwzewpmfvnLX8Y3v/nNYd3T\n19cX5557bvzlL38ZdD5x4sS48MILkzbWEgEOAAAAAAAAAMA4M2/evDj33HOHnF955ZVx+umnxz/+\n8Y+93vH444/HiSeeGD/4wQ+GPLZkyZJoa2sbka21oL7oAQAAAAAAAAAARHR2dkZHR8eI3HXNNdfE\nKaec8rbPufHGG6OzszM6OzsHnf/0pz+Ne++9N+bMmRPz58+PQw89NKZNmxZ5nsfWrVvj+eefjwcf\nfDDWrFmzx3s/+9nP7vfXWdUqAQ4AAAAAAAAAQBWoVCpvGbUM17Zt2/b6nEmTJsUDDzwQCxYsiPvu\nu2/QY319fbF69epYvXr1sN534cKF8d3vfndYrxkLfAUVAAAAAAAAAMA4NWXKlPjVr34VS5cujenT\np+/3PTNnzow77rgjvv/978ekSZNGcGFt8Ak4AAAAAAAAADBMh5QPiaPvPLroGQw4pHxI0RNqWqlU\nissuuyzOP//8uO222+Luu++ORx99NHp6et72dU1NTXHsscfGggUL4qyzzooJEya8Q4urjwAHAAAA\nAAAAAIbpN6f9pugJ1Lj29vbI87zoGYMccMABccEFF8QFF1wQb7zxRjzxxBOxfv362LZtW2zfvj2y\nLItp06bFtGnT4rDDDov3v//9UVdXV/TsqiDAAQAAAAAAAABgkIkTJ8a8efNi3rx5RU+pCaWiBwAA\nAAAAAAAAQC0T4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDgAAAAAAAAAABAAgEOAAAAAAAAAAAkEOAA\nAAAAAAAAAEACAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDgAAAAAAAAAABAAgEO\nAAAAAAAAAAAkEOAAAAAAAAAAAEACAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDg\nAAAAAAAAAABAAgEOAAAAAAAAAAAkEOAAAAAAAAAAAEACAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIB\nDgAAAAAAAAAAJBDgAAAAAAAAAABAAgEOAAAAAAAAAAAkEOAAAAAAAAAAAEACAQ4AAAAAAAAAACQQ\n4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDgAAAAAAAAAABAAgEOAAAAAAAAAAAkEOAAAAAAAAAAAEAC\nAQ4AAAAAAAAAACQQ4AAAAAAAAAAAQAIBDgAAAAAAAAAAJBDgAAAAAAAAAABAAgEOAAAAAAAAAMA7\nbO3atZFl2aj8mjJlytu+9+LFi9/ytbfffnvSz7Vw4cIhd65duzbpzlpQX/QAAAAAAAAAAKg53zk6\n4vV1Ra/g31pmRVz816JXjAlXXXVVfP7zn4+Ghoaip9QUAQ4AAAAAAAAADNfr6yIWv170Cv5tcUvR\nC8aM9evXx8033xyXXnpp0VNqigAHAAAAAAAAAKAKlMvlmD17dvI9kydPTnr9kiVLYuHChTF16tTk\nLeOFAAcAAAAAAAAAoArMmTMnVq1aVfSM2L59eyxZsiS+9a1vFT2lZpSKHgAAAAAAAAAAQHW5+eab\nY/369UXPqBkCHAAAAAAAAACAce6zn/3soD/39PTElVdeWdCa2iPAAQAAAAAAAAAY584777xob28f\ndPajH/0onnrqqWIG1RgBDgAAAAAAAADAODdx4sS49tprB5319/fHokWLClpUWwQ4AAAAAAAAAADE\nWWedFR0dHYPOVqxYEX/4wx8KWlQ7BDgAAAAAAAAAAESWZbF06dIh55dddlkBa2qLAAcAAAAAAAAA\ngIiIOPHEE+OTn/zkoLPVq1fHPffcU9Ci2iDAAQAAAAAAAADgTUuXLo0sywadff3rX4/e3t6CFlU/\nAQ4AAAAAAAAAAG865phj4owzzhh09o9//CN+8IMfFLSo+glwAAAAAAAAAAAY5LrrrosJEyYMOrv6\n6qujUqkUtKi61Rc9AAAAAAAAAACAiM7Ozujo6Ei+Z/ny5XHkkUcm3fHud787zj333Lj55pvfPHvl\nlVfihhtuiCuuuCJ14pgjwAEAAAAAAAAAqAKVSiXWrFmTfE93d/cIrIm44oor4o477ohdu3a9efbt\nb387zj333GhtbR2R9xgrfAUVAAAAAAAAAABDtLa2xqWXXjrobNeuXfHNb36zoEXVS4ADAAAAAAAA\nAMAeXXLJJXHwwQcPOrv11lvjhRdeKGhRdRLgAAAAAAAAAABUgfnz50ee58m/Ojo6RmxTuVyOq666\natDZG2+8EZdffvmIvcdYIMABAAAAAAAAAOAtLVy4MI444ohBZ8uXL48nnniioEXVR4ADAAAAAAAA\nAMBbqq+vj+uuu27QWZ7n8bWvfa2gRdVHgAMAAAAAAAAAwNs67bTT4sMf/vCgs9/+9rdx//33F7So\nughwAAAAAAAAAADYq6VLlw45W7RoUeR5XsCa6iLAAQAAAAAAAABgr+bPnx+f/vSnB539+c9/jmXL\nlhW0qHoIcAAAAAAAAAAA2CfXX399lEqDc5Mrrrgi3njjjYIWVQcBDgAAAAAAAAAA++R973tffOEL\nXxh09uKLL8Ytt9xS0KLqIMABAAAAAAAAAGCfXXPNNdHQ0DDo7LrrroudO3cWtKh4AhwAAAAAAAAA\nAPbZzJkz4/zzzx909tprr8XSpUsLWlQ8AQ4AAAAAAAAAAMPy9a9/PaZOnTro7MYbb4xNmzYVtKhY\nAhwAAAAAAAAAAIZl6tSpsWjRokFnu3fvjvvuu6+gRcUS4AAAAAAAAAAAMGwXXnhhzJw5s+gZVaG+\n6AEAAAAAAAAAAER0dnZGR0fHiNx1zTXXxCmnnDIid72VhoaGuPrqq+OLX/ziqL5PLRDgAAAAAAAA\nAABUgUqlEmvWrBmRu7Zt2zYi9+zN2WefHTfccEM89dRT78j7VStfQQUAAAAAAAAAwH4plUqxZMmS\nomcUToADAAAAAAAAAMB+O/nkk+OEE04oekahfAUVAAAAAAAAAAxXy6yIxS1Fr+DfWmYVvWDY2tvb\nI8/zQt578eLFsXjx4hG98/e///2I3ldrBDgAAAAAAAAAMFwX/7XoBUAV8RVUAAAAAAAAAACQQIAD\nAAAAAAAAAAAJBDgAAAAAAAAAAJBAgAMAAAAAAAAAAAkEOAAAAAAAAAAAkECAAwAAAAAAAAAACQQ4\nAAAAAAAAAACQQIADAAAAAAAAAAAJBDgAAAAAAAAAAJBAgAMAAAAAAAAAAAkEOAAAAAAAAAAAkECA\nAwAAAAAAAAAACQQ4AAAAAAAAAACQoL7oAVS5xS1FL6gRy4oeAAAAAAAAAAAURIDD21v8etELasOi\nFUUvAAAAAAAAAAAK4iuoAAAAAAAAAAAggQAHAAAAAAAAAAASCHAAAAAAAAAAACCBAAcAAAAAAAAA\nABIIcAAAAAAAAAAAIIEABwAAAAAAAAAAEghwAAAAAAAAAAAggQAHAAAAAAAAAAASCHAAAAAAAAAA\nACCBAAcAAAAAAAAAABIIcAAAAAAAAAAAIIEABwAAAAAAAAAAEghwAAAAAAAAAAAggQAHAAAAAAAA\nAAASCHAAAAAAAAAAACCBAAcAAAAAAAAAABIIcAAAAAAAAAAAIIEABwAAAAAAAAAAEghwAAAAAAAA\nAAAgQX3RAwAAAAAAAAAAqA6vv/56PPHEE7F+/fp4/fXXY+fOnTFhwoQol8sxderUOPTQQ6O9vT3a\n2tqKnlpVBDgAAAAAAAAAAO+wtWvXxmGHHTYqd7e0tMSOHTv2+fkbNmyI22+/PZYtWxbPPPNM5Hm+\n19dMmzYtjjnmmJg7d26ceOKJcdxxx0V9/fjNUMbvTw4AAAAAAAAA++n4638XL+/oLnoGA9qmNMbD\niz5R9Iyas3v37rjyyivjxhtvjL6+vmG9dtu2bfHAAw/EAw88ENddd100NzfHr371qzjhhBNGaW11\nE+AAAAAAAAAAwDC9vKM71l7/6aJnMKB90YqiJ9ScdevWxac+9al49tlnR+S+nTt3xrZt20bkrlok\nwAEAAAAAAAAAqALlcjlmz56dfM/kyZPf9vGNGzfGxz72sXjxxReHPFYqleLYY4+ND33oQ3HEEUdE\nS0tLTJgwIbZt2xavvfZaPPnkk9HZ2RkvvPBC8s6xRIADAAAAAAAAAFAF5syZE6tWrRr19znvvPOG\nxDdZlsU555wT3/jGN6KtrW2vd7z00ktx7733xj333BMPP/zwaE2tGaWiBwAAAAAAAAAA8M5YtWpV\n/OIXvxh0ViqV4q677orvfe97+xTfREQceuihcfHFF8dDDz0UTz75ZHz5y1+Ocrk8GpNrgk/AAQAA\nAAAAAAAYJ3784x8POTv//PPjjDPO2O87jz766Lj11ltTZtU8n4ADAAAAAAAAADBOrFy5csjZBRdc\nUMCSsUWAAwAAAAAAAAAwDvT29sbGjRsHnTU3N8fs2bMLWjR2CHAAAAAAAAAAAMaBLVu2RJ7ng87K\n5XJBa8YWAQ4AAAAAAAAAwDjQ0NAw5GzLli2xe/fuAtaMLQIcAAAAAAAAAIBxYMqUKTFp0qRBZ729\nvfGzn/2soEVjhwAHAAAAAAAAAGAcyLIsjj322CHnX/3qV+PZZ58tYNHYIcABAAAAAAAAABgnTjvt\ntCFnr7zySnzgAx+IxYsXx8aNGwtYVfsEOAAAAAAAAAAA48TChQtj5syZQ84rlUpcffXV8a53vSs+\n/OEPx6JFi+LnP/95bNiwoYCVtae+6AEAAAAAAAAAAER0dnZGR0dH8j3Lly+PI488co+PTZo0KX7y\nk5/Exz/+8ejp6RnyeJ7n8eijj8ajjz765tlBBx0UxxxzTBx//PFxwgknxNy5c2PSpEnJO8cSAQ4A\nAAAAAAAAQBWoVCqxZs2a5Hu6u7vf9vF58+bF/fffH2eccUZs2rRpr/e9+uqrsXLlyli5cmVERDQ3\nN8dpp50WX/rSl+K4445L3jsW+AoqAAAAAAAAAIBx5qMf/Wg8+eST8ZWvfCUaGhqG9dqdO3fGD3/4\nwzj++OPj5JNPjmeeeWaUVtaOfQpwsiy7OMuy/5dl2VNZlt2VZVlDlmWHZVm2Osuy57IsW55l2cSB\n504a+PNzA4+3j+YPAAAAAAAAAADA8B144IHxne98J1566aW46aabYt68eVEqDe+zXFasWBFz5syJ\ne++9d5RW1oa9/q1lWdYWERdGxJw8z98XEXURcWZELI2I7+R5PjsitkfElwZe8qWI2D5w/p2B5wEA\nAAAAAAAA8Dbmz58feZ4n/+ro6BjW+x500EFx4YUXxiOPPBLbtm2L++67Ly6//PI46aST4uCDD97r\n67u6uuJzn/tc/PrXv97fH73m7Wu2VB8RjVmW1UfEARGxKSI+ERF3Dzx+Z0T8n4Hf/++BP8fA45/M\nsiwbmbkAAAAAAAAAAIyWlpaWOOmkk+Laa6+N++67LzZt2hQbNmyIu+66K84+++xobm7e4+v6+/tj\nwYIF8fLLL7/Di6vDXgOcPM9fjoj/GxHr4n/Cm9cj4vGI2JHnee/A0zZERNvA79siYv3Aa3sHnj/9\nP+/NsuzLWZZ1ZlnWuWXLltSfAwAAAAAAAACAUdDW1hZnnnlm3HHHHbFx48ZYsmRJNDY2Dnnezp07\nY8mSJQUsLN6+fAXV1PifT7U5LCIOiYhyRPyv1DfO8/y/8zyfk+f5nNbW1tTrAAAAAAAAAAAYZeVy\nORYtWhR/+tOfYsqUKUMev/POO6O3t3cPrxzb9uUrqD4VES/meb4lz/N/RcS9EXF8REwZ+EqqiIh3\nRcS/P0Po5YiYGREx8HhLRGwd0dUAAAAAAAAAABSmo6MjbrnlliHnXV1dsXr16gIWFWtfApx1ETEv\ny7IDsizLIuKTEfG3iHgwIk4beM7ZEfGLgd//cuDPMfD47/I8z0duMgAAAAAAAAAARTvzzDNjT996\n9MwzzxSwplh7DXDyPF8dEXdHxBMR8deB1/x3RHwtIi7Jsuy5iJgeEbcNvOS2iJg+cH5JRCwahd0A\nAAAAAAAAABQoy7L40Ic+NOT8tddeK2BNser3/pSIPM+vioir/uP4hYiYu4fn9kTE59KnAQAAAAAA\nAABQzVpaWoac1dfvU44ypuzLV1ABAAAAAAAAAMAQmzdvHnI2Y8aMApYUS4ADAAAAAAAAAMCw7d69\nO1avXj3k/PDDDy9gTbEEOAAAAAAAAAAA48Stt94aPT09I3LXTTfdFJVKZdBZa2trzJ07d0TuryUC\nHAAAAAAAAACAceKiiy6Kd7/73XHjjTdGV1fXft9zzz33xOLFi4ecn3HGGVEqjb8cZfz9xAAAAAAA\nAAAA49imTZvi4osvjhkzZsSCBQti5cqV+/ypOC+++GIsXLgwTj/99HjjjTcGPTZ9+vQ9RjnjQX3R\nAwAAAAAAAAAAiOjs7IyOjo4Rueuaa66JU0455W2fs3v37li2bFksW7YsJkyYEB0dHTF37tyYNWtW\nTJ8+PaZMmRI9PT2xffv2+Pvf/x6PPvpoPPbYY3u8a8KECXHbbbfF9OnTR2R/rRHgAAAAAAAAAABU\ngUqlEmvWrBmRu7Zt2zas5//rX/+Kxx577C0Dm7dzwAEHxF133bXX4Gcs8xVUAAAAAAAAAADjxNKl\nS+MjH/lIlEojk4yceuqp8fTTT4/r+CbCJ+AAAAAAAAAAAIwbF110UVx00UWxZcuWeOCBB+KPf/xj\nPPTQQ/G3v/0t+vv79/r6urq6eM973hOnnnpqLFiwII488sh3YHX1E+AAAAAAAAAAwDC1TWmM9kUr\nip7BgLYpjUVPGLb29vbI87yw929tbY2zzjorzjrrrIiI+Oc//xnPP/98PPfcc7F58+bYtWtX7N69\nOxoaGqK5uTmam5tj9uzZ8d73vjcaG2vv73u0CXAAAAAAAAAAYJgeXvSJoifAiJo0aVIcddRRcdRR\nRxU9pSaNzBd6AQAAAAAAAADAOCXAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwA\nAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMAB\nAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIc\nAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAADGhTzP\ni54AjIJq+LctwAEAAAAAAABgzCuVStHf31/0DGAU9Pf3R6lUbAIjwAEAAAAAAABgzKurq4u+vr6i\nZwCjoK+vL+rq6grdIMABAAAAAAAAYMxrbGyMSqVS9AxgFFQqlWhsbCx0gwAHAAAAAAAAgDFv8uTJ\nsWvXrqJnAKNg586d0dzcXOgGAQ4AAAAAAAAAY15TU1N0d3dHb29v0VOAEdTb2xs9PT1RLpcL3SHA\nAQAAAAAAAGDMK5VK0dTUFFu3bo08z4ueA4yAPM9j69at0dTUFKVSsQmMAAcAAAAAAACAcWHGjBlR\nqVRiy5YtIhyocXmex5YtW6JSqcSMGTOKniPAAQAAAAAAAGB8qK+vj1mzZkVXV1e8+uqrvo4KalRv\nb2+8+uqr0dXVFbNmzYr6+vqiJ0XxCwAAAAAAAADgHfLvCGfz5s3x/PPPR0NDQzQ3N0e5XI66uroo\nlUqRZVnRM4EBeZ5Hf39/9PX1RaVSiZ07d0ZPT080NTVVTXwTIcABAAAAAAAAYJypr6+Ptra26O/v\nf/M/9Ldu3Rp9fX3R399f9DzgP5RKpairq4vGxsaYNm1alMvlKJWq60ufBDgAAAAAAAAAjEulUikm\nT54ckydPLnoKUOOqKwcCAAAAAAAAAIAaI8ABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAA\ngAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAA\nAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAA\nAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAA\nAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAA\nAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAA\nAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAA\nAAAAgAQCHAAAAAAAAAAASNv85fEAACAASURBVCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAA\nAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAA\nAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAA\nAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAA\nAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEA\nAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwA\nAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAAAAAAAAAABIIMAB\nAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDAAQAAAAAAAACABAIc\nAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQCHAAAAAAAAAAASCDA\nAQAAAAAAAACABAIcAAAAAAAAAABIIMABAAAAAAAAAIAEAhwAAAAAAAAAAEggwAEAAAAAAAAAgAQC\nHAAAAAAAAAAASCDAAQAAAAAAAACABAIcAP4/e3cQ4nlZx3H88+BgitBuySLtrLFCUpclkiWKoINe\nyiI9WARBSwheIiQPNd322snsIogSGyQUXpQ2WkLzspCwYbSQQYsQ7pI5hO6hiIieDvurVjB39DP6\nn5l9vWCY3/P7Pf/5f+f+5vcAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAA\nABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAA\nUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABA\nQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAF\nAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQE\nOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDg\nAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYAD\nAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4A\nAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAA\nAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAA\nAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAA\nAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAA\nAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAA\nAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAA\nAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAA\nAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAA\nABQEOAAAAAAAAAAAUBDgAAAAAAAAAABAQYADAAAAAAAAAAAFAQ4AAAAAAAAAABS2FOCMMfaPMZ4Y\nY/x+jPHCGOOTY4z3jzF+Mcb4w/L7fcveMcb4/hjj3Bjjt2OM297ZfwEAAAAAAAAAAFZnq2/AeSjJ\nz+ecH0ny0SQvJNlI8vSc89YkTy/rJPlskluXn/uSPLytEwMAAAAAAAAAwA5yxQBnjLEvyaeTPJYk\nc85/zDlfS3JXkhPLthNJ7l6u70ryw3nJr5LsH2N8YNsnBwAAAAAAAACAHWArb8C5Jclmkh+MMZ4f\nYzw6xrghyU1zzj8te15OctNyvZ7kpcs+f3659zpjjPvGGGfGGGc2Nzff/n8AAAAAAAAAAAArtJUA\nZy3JbUkennN+LMlf87/jppIkc86ZZL6VL55zPjLnPDrnPHrgwIG38lEAAAAAAAAAANgxthLgnE9y\nfs753LJ+IpeCnD//52ip5fcry/MLSW6+7POHlnsAAAAAAAAAALDnXDHAmXO+nOSlMcaHl1t3JPld\nkqeSHFvuHUvy5HL9VJKvjks+keTiZUdVAQAAAAAAAADAnrK2xX3fSPKjMca1SV5M8rVcind+Msa4\nN8kfk3xp2fuzJHcmOZfkb8teAAAAAAAAAADYk7YU4Mw5f5Pk6Bs8uuMN9s4kXy/nAgAAAAAAAACA\nXeGKR1ABAAAAAAAAAAD/nwAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAA\nAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAwtqqB4C9YD2b\nObxxctVj7Arr+6/P6Y3bVz0GAAAAAAAAAGwbAQ5sg9PX3Z8cv7jqMXYFoRIAAAAAAAAAe40jqAAA\nAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAA\nAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAA\nAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAA\nAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAA\nAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAA\nAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAA\nAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAA\nACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAA\noCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACA\nggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAK\nAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACis\nrXoA2BP2fTA5vm/VU+wSj696AAAAAAAAAADYVgIc2A7fPLvqCXaPjZOrngAAAAAAAAAAtpUjqAAA\nAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAA\nAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAA\nAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAA\nAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKa6segJ3tyIkjqx5hVzh4w8Gc\nuufUqscAAAAAAAAAAFZAgMObOnvs7KpH2BWESgAAAAAAAABw9XIEFQAAAAAAAAAAFAQ4AAAAAAAA\nAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAA\nAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAA\nAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAA\nFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQ\nEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBB\ngAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUB\nDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4\nAAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAA\nAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMA\nAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAA\nAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAA\nAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAA\nAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAA\nAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAA\nAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAA\nAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAA\nAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAA\nAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAA\nFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQ\nEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBB\ngAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUB\nDgAAAAAAAAAAFAQ4AAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFAQ4\nAAAAAAAAAABQEOAAAAAAAAAAAEBBgAMAAAAAAAAAAAUBDgAAAAAAAAAAFNZWPQBwdVnPZg5vnFz1\nGLvC+v7rc3rj9lWPAQAAAAAAAMAVCHCAd9Xp6+5Pjl9c9Ri7glAJAAAAAAAAYHfY8hFUY4xrxhjP\njzF+uqxvGWM8N8Y4N8b48Rjj2uX+e5b1ueX54XdmdAAAAAAAAAAAWL0tBzhJ7k/ywmXr7yZ5cM75\noSSvJrl3uX9vkleX+w8u+wAAAAAAAAAAYE/aUoAzxjiU5HNJHl3WI8ntSZ5YtpxIcvdyfdeyzvL8\njmU/AAAAAAAAAADsOVt9A873knwryb+W9Y1JXptz/nNZn0+yvlyvJ3kpSZbnF5f9rzPGuG+McWaM\ncWZzc/Ntjg8AAAAAAAAAAKt1xQBnjPH5JK/MOX+9nV8853xkznl0znn0wIED2/mnAQAAAAAAAADg\nXbO2hT2fSvKFMcadSa5L8t4kDyXZP8ZYW95ycyjJhWX/hSQ3Jzk/xlhLsi/JX7Z9cgAAAAAAAAAA\n2AGu+AacOed35pyH5pyHk3w5yTNzzq8k+WWSe5Ztx5I8uVw/tayzPH9mzjm3dWoAAAAAAAAAANgh\nrhjgvIlvJ3lgjHEuyY1JHlvuP5bkxuX+A0k2uhEBAAAAAAAAAGDn2soRVP8153w2ybPL9YtJPv4G\ne/6e5IvbMBsAAAAAAAAAAOx4zRtwAAAAAAAAAADgqifAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwA\nAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAA\nAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAA\nAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAA\nAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAA\nAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAA\nAAAAoCDAAQAAAAAAAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAA\nAACAggAHAAAAAAAAAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAggAHAAAAAAAA\nAAAKAhwAAAAAAAAAACgIcAAAAAAAAAAAoCDAAQAAAAAAAACAwtqqB4C94OANB3PkxJFVj7ErnF31\nAAAAAAAAAACwzQQ4sA1O3XNq1SPsHsf3rXoCAAAAAAAAANhWjqACAAAAAAAAAICCAAcAAAAAAAAA\nAAoCHAAAAAAAAAAAKAhwAAAAAAAAAACgIMABAAAAAAAAAICCAAcAAAAAAAAAAAoCHAAAAAAAAAAA\nKAhwAAAAAAAAAACgIMABAAAAAAAAAICCAAcAAAAAAAAAAAoCHAAAAAAAAAAAKAhwAAAAAAAAAACg\nIMABAAAAAAAAAICCAAcAAAAAAAAAAAoCHAAAAAAAAAAAKAhwAAAAAAAAAACgIMABAAAAAAAAAICC\nAAcAAAAAAAAAAAoCHAAAAAAAAAAAKAhwAAAAAAAAAACgIMABAAAAAAAAAICCAAcAAAAAAAAAAAoC\nHAAAAAAAAAAAKAhwAAAAAAAAAACgIMABAAAAAAAAAICCAAcAAAAAAAAAAAoCHAAAAAAAAAAAKKyt\negDg6nJh7ZqsH9+36jF2icdXPQAAAAAAAAAAWyDAAd5Vn7l5PWePnV31GLvDxslVTwAAAAAAAADA\nFjiCCgAAAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAA\nCgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAACgIcAAAAAAAAAAAo\nCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAg\nwAEAAAAAAAAAgIIABwAAAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIA\nBwAAAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAACgIc\nAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAACgIcAAAAAAAAAAAoCHAA\nAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEA\nAAAAAAAAgIIABwAAAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAA\nAAAAAAAACgIcAAAAAAAAAAAoCHAAAAAAAAAAAKAgwAEAAAAAAAAAgIIABwAAAAAAAAAACgIcAAAA\nAAAAAAAoCHAAAAAAAADg3+3df4ylV13H8c/pTstulmRWsGGZadch0mjQidUg1PQfs4a0orGYbAzE\n4EYx1QSSpSHaAWMcE4nLH4qQKAkqdv2xIqkmNk7jhFAS4ySgqNWBVsIqBbrb0kVg+aVA8fjHPMVh\n2e3e5czMmefO65VM5t7n3tn57mRy9tk773kOAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAA\nAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAECDmd4DAHBp8zmfhaWV3mOM\nwvyhA1lbOtp7DAAAAAAAAGCPEuAA7FJr+08kyxd6jzEKQiUAAAAAAACgJ1tQAQAAAAAAAABAAwEO\nAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDg\nAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMB\nDgAAAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ\n4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEAD\nAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0\nEOAAAAAAAAAAAECDmd4DAHvL3MG5LJ5a7D3GKKz3HgAAAAAAAACAiQhwgB21emy19wjjsTzbewIA\nAAAAAAAAJmALKgAAAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwA\nAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMAB\nAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAAAAAAAACABgIc\nAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDA\nAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYC\nHAAAAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGgg\nwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAG\nAhwAAAAAAAAAAGgw03sAAC7t7My+zC/P9h5jJE73HgAAAAAAAADYwwQ4ALvU7TfOZ/34eu8xxmFp\npfcEAAAAAAAAwB5mCyoAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAAAAAAAACA\nBgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAA\naCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAA\ngAYCHAAAAAAAAAAAaHDFAKeUcmMp5b2llIdKKR8qpZwYjj+rlPLuUspHhvffNhwvpZS3llLOlFL+\nrZTyA9v9lwAAAAAAAAAAgF4muQLOk0leV2t9QZJbkry6lPKCJEtJ3lNrvSnJe4b7SfKjSW4a3u5M\n8rYtnxoAAAAAAAAAAHaJKwY4tdbHaq3/PNz+fJKHk8wnuSPJqeFpp5K8bLh9R5I/rhvel+RQKeW5\nWz45AAAAAAAAAADsApNcAefrSikLSb4/yfuTPKfW+tjw0ONJnjPcnk/yiU0f9uhwDAAAAAAAAAAA\nps7EAU4p5ZlJ/jLJa2utn9v8WK21JqlX84lLKXeWUj5QSvnA+fPnr+ZDAQAAAAAAAABg15gowCml\nXJuN+ObPaq1/NRz+5FNbSw3vnxiOn01y46YPv2E49g1qrW+vtb6w1vrC66+//ludHwAAAAAAAAAA\nurpigFNKKUn+MMnDtdbf3vTQfUmOD7ePJ/nrTcd/pmy4JcmFTVtVAQAAAAAAAADAVJmZ4Dm3Jnll\nkvVSyoPDsTckOZnkXaWUVyX5WJKfGh67P8lLk5xJ8qUkP7ulEwPAReZzPgtLK73HGIX5QweytnS0\n9xgAAAAAAAAwVa4Y4NRa/z5JuczDP3KJ59ckr26cCwAmtrb/RLJ8ofcYoyBUAgAAAAAAgK13xS2o\nAAAAAAAAAACAyxPgOibyUgAAFMFJREFUAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEAD\nAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0\nEOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABA\nAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAA\nNBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADSY6T0AADSbPZIs\nz/aeYiRO9x4AAAAAAAAApo4AB4Dxu2u99wTjsbTSewIAAAAAAACYOragAgAAAAAAAACABgIcAAAA\nAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAA\nAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAA\nAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGM70HAODS5g7OZfHUYu8x\nRmHu4FxWj632HgMAAAAAAADYowQ4ALuUoGRyQiUAAAAAAACgJ1tQAQAAAAAAAABAAwEOAAAAAAAA\nAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAA\nAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAA\nAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAA\nAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAg5neAwAAO2c+57OwtNJ7jFGYP3Qga0tHe48BAAAA\nAADACAhwAGAPWdt/Ilm+0HuMURAqAQAAAAAAMClbUAEAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAA\nAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAA\nAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAA\nAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4A\nAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAAwEOAAAAAAAAAAA0EOAA\nAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQAMBDgAAAAAAAAAANBDgAAAAAAAAAABAAwEO\nAAAAAAAAAAA0EOAAAAAAAAAAAEADAQ4AAAAAAAAAADSY6T0AALSaOziXxVOLvccYhfXeAwAAAAAA\nAMAUEuAAMHqrx1Z7jzAey7O9JwAAAAAAAICpYwsqAAAAAAAAAABoIMABAAAAAAAAAIAGtqACgD3k\n7My+zNuGakKnew8AAAAAAADASAhwAGAPuf3G+awfX+89xijML92ThaWV3mOMxvyhA1lbOtp7DAAA\nAAAAgC4EOAAAl7C2/0SyfKH3GKMhVgIAAAAAAPaya3oPAAAAAAAAAAAAYybAAQAAAAAAAACABgIc\nAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDA\nAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYC\nHAAAAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGgg\nwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAAAAAAAACABgIcAAAAAAAAAABoMNN7AACAXWn2SLI8\n23uKETndewAAAAAAAIBuBDgAAJdy13rvCcZlaaX3BAAAAAAAAN3YggoAAAAAAAAAABoIcAAAAAAA\nAAAAoIEABwAAAAAAAAAAGghwAAAAAAAAAACggQAHAAAAAAAAAAAaCHAAAAAAAAAAAKCBAAcAAAAA\nAAAAABrM9B4AAIDxm8/5LCyt9B5jFOYPHcja0tHeYwAAAAAAAFtIgAMAQLO1/SeS5Qu9xxgFoRIA\nAAAAAEwfW1ABAAAAAAAAAEADAQ4AAAAAAAAAADQQ4AAAAAAAAAAAQIOZ3gMAADtn7uBcFk8t9h5j\nFOYOzmX12GrvMQAAAAAAABgBAQ4A7CGCkskJlQAAAAAAAJiULagAAAAAAAAAAKCBAAcAAAAAAAAA\nABoIcAAAAAAAAAAAoIEABwAAAAAAAAAAGghwAAAAAAAAAACggQAHAAAAAAAAAAAaCHAAAAAAAAAA\nAKCBAAcAAAAAAAAAABoIcAAAAAAAAAAAoIEABwAAAAAAAAAAGghwAAAAAAAAAACggQAHAAAAAAAA\nAAAaCHAAAAAAAAAAAKDBTO8BAACYArNHkuXZ3lOMxOneAwAAAAAAAFtMgAMAQLu71ntPMB5LK70n\nAAAAAAAAtpgABwCAZrfde1vOffFc7zFG4mTvAQAAAAAAgC0mwAEAoNm5L57L+nFXwZnEgivgAAAA\nAADA1Lmm9wAAAAAAAAAAADBmAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYCHAAAAAAAAAAAaCDAAQAA\nAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAAAAAAAGggwAEAAAAAAAAAgAYzvQcA\nAIC9ZD7ns7C00nuMUZg/dCBrS0d7jwEAAAAAAFckwAEAuIS5g3NZPLXYe4zRmDs413uE0VjbfyJZ\nvtB7jFEQKgEAAAAAMBYCHACAS1g9ttp7BAAAAAAAAEbimt4DAAAAAAAAAADAmAlwAAAAAAAAAACg\ngQAHAAAAAAAAAAAaCHAAAAAAAAAAAKCBAAcAAAAAAAAAABrM9B4AAADgspZne08wDrNHkrvWe08B\nAAAAALBnCXAAAIDda/lC7wnGQagEAAAAANCVLagAAAAAAAAAAKCBAAcAAAAAAAAAABrYggoAAHbY\n4qnF3iOMxMneAwAAAAAAwEQEOAAAsMPWj6/3HmEUbl26JwtLK73HGIX5vCVrvYcAAAAAANjDBDgA\nAMCutLb/RLJ8ofcYoyBUAgAAAADoS4ADAAA7afZIsjzbe4pRODuzL/O9hwAAAAAAgAkIcAAAYCfd\nZfupSd1+ajG+WgAAAAAAjME1vQcAAAAAAAAAAIAxcwUcAACAaWBrs8nMHnElKgAAAABgywlwAAAA\npsHyhd4TjINQCQAAAADYBragAgAAAAAAAACABgIcAAAAAAAAAABoIMABAAAAAAAAAIAGAhwAAAAA\nAAAAAGggwAEAAAAAAAAAgAYzvQcAAAC4lLmDc1k8tdh7jJE42XsAAAAAAIA9TYADAADsSqvHVnuP\nMBrP+9U/zcLSSu8xRuJ04ms1kflDB7K2dLT3GAAAAAAwCgIcAACAkXvm89+U9ePrvccYhcffeH0O\nf/UrvccYhYXPnu49AgAAAACMhgAHAACAPeMlNxwWK01ofukeV1aakKsFAQAAACDAAQAAAL7J2v4T\nyfKF3mOMglAJAAAAgGt6DwAAAAAAAAAAAGPmCjgAAAAAjRZPLfYeYTTmDs5l9dhq7zEAAAAAtpQA\nBwAAYOTmDs754f+E5g7O9R5hVHxfTepk1o+v9x5iNHxfAQAAANNIgAMAADByriTBdhGVTObWkw9k\nYWml9xijUa69u/cIAAAAAFtOgAMAAADQYG3paO8RRkWsBAAAAEwjAQ4AAADwzWaPJMuzvacYh9kj\nyV2uFgQAAACwlwlwAAAAgG8mKJmcUAkAAABgzxPgAAAAAMAudOvJB3L2s//de4xRmD90wHZwAAAA\ndCXAAQAAAGhhu66rcri8NQtLK73HGIWZ6z6XR06+ovcYo+B7CgAAgN4EOAAAAAAtbNd1Vd63PJss\nX+g9xigsnlpMIsABAACAMRDgAAAAAMAu9LefOOvqShM7PQRLXMncwbmsHlvtPQYAAMDUEeAAAAAA\nwC40/+TXXC1oUksrWT/ualSTECoBAABsj2t6DwAAAAAAAAAAAGPmCjgAAAAAwKjN53wWllZ6jzEK\nM9e9wVVwJmS7LgAA4GoIcAAAAADYObNHkuXZ3lOMwuPXXpeXCCUmsr7/47brmtCC7bomdvY3nmW9\nmtTskeQu31cAAOxtAhwAAAAAdo4f0E7scBJfrQmJJCY2f+iAqwVN7E96DzAa8/9zPmu9hxiR2+69\nLee+eK73GKPgSlQA0+fxN16fw1/9Su8xRuPxa6/L4V8533sMJrQtAU4p5fYkb0myL8kf1FpPbsfn\nAQAAAABgcmtLR3uPMB7Ls66sNCFR19U598VzrkQ1IVvmAUyfw1/9inOsq3DYLxuMypYHOKWUfUl+\nN8lLkjya5B9LKffVWh/a6s8FAAAAAMBVePNicuHjvacYhbMz+zLfe4gx8cOhif3tzL7eI4zGF87c\nLfCa0PyhAyLLSfm3kO1gO0Yg23MFnBclOVNr/c8kKaW8M8kdSQQ4AAAAAMDWmz3ih/+Tmj3iN44n\n9HP33pZzrr4xkXLt3Vn4n9O9xxiNw+VTeZ81ayL1q6fzyMkf6z3GKAiVJnfrJ1+Xs7m+9xijUK79\nTJ75/Df1HmMU1j8q6gK2J8CZT/KJTfcfTfLibfg8AAAAAAB+25htsXpstfcITKmFpRUh3KREJRM7\nXD4lwpnQ4VLyyG8KuyZx68kHcvbhk73HGIWFxJo1sdO+VldhPm/JWu8hmFiptW7tH1jKsSS311p/\nfrj/yiQvrrW+5qLn3ZnkzuHudyX58JYOArD7fXuST/UeAoAtZ30HmE7Wd4DpZH0HmD7WdoDptFvW\n9++otV7yUmrbcQWcs0lu3HT/huHYN6i1vj3J27fh8wOMQinlA7XWF/aeA4CtZX0HmE7Wd4DpZH0H\nmD7WdoDpNIb1/Zpt+DP/MclNpZTnlVKuS/LyJPdtw+cBAAAAAAAAAIDutvwKOLXWJ0spr0mymmRf\nknfUWj+01Z8HAAAAAAAAAAB2g+3Ygiq11vuT3L8dfzbAFLENH8B0sr4DTCfrO8B0sr4DTB9rO8B0\n2vXre6m19p4BAAAAAAAAAABG65reAwAAAAAAAAAAwJgJcAC2SSnlHaWUJ0opH9x0bLmUcraU8uDw\n9tJNj72+lHKmlPLhUsptfaYG4EpKKTeWUt5bSnmolPKhUsqJ4fizSinvLqV8ZHj/bcPxUkp567DG\n/1sp5Qf6/g0AuNjTrO3O3wFGrJSyv5TyD6WUfx3W918fjj+vlPL+YR3/i1LKdcPxZwz3zwyPL/Sc\nH4BLe5r1/Z5Sykc3nb/fPBz32gzASJRS9pVS/qWU8jfD/VGduwtwALbPPUluv8TxN9dabx7e7k+S\nUsoLkrw8yfcMH/N7pZR9OzYpAFfjySSvq7W+IMktSV49rONLSd5Ta70pyXuG+0nyo0luGt7uTPK2\nnR8ZgCu43NqeOH8HGLMvJzlaa/2+JDcnub2UckuSN2VjfX9+ks8kedXw/Fcl+cxw/M3D8wDYfS63\nvifJL206f39wOOa1GYDxOJHk4U33R3XuLsAB2Ca11r9L8ukJn35HknfWWr9ca/1okjNJXrRtwwHw\nLau1PlZr/efh9uez8Z+B+Wys5aeGp51K8rLh9h1J/rhueF+SQ6WU5+7w2AA8jadZ2y/H+TvACAzn\n4F8Y7l47vNUkR5PcOxy/+Nz9qXP6e5P8SCml7NC4AEzoadb3y/HaDMAIlFJuSPJjSf5guF8ysnN3\nAQ7AznvNcJnLdzy1PUk2Xtz/xKbnPJqnf8EfgF1guKzl9yd5f5Ln1FofGx56PMlzhtvWeIARuWht\nT5y/A4zacAn7B5M8keTdSf4jyWdrrU8OT9m8hn99fR8ev5Dk2Ts7MQCTuHh9r7U+df7+xuH8/c2l\nlGcMx5y/A4zD7yT55ST/O9x/dkZ27i7AAdhZb0vyndm4LOZjSX6r7zgAfKtKKc9M8pdJXltr/dzm\nx2qtNU//m1cA7EKXWNudvwOMXK31a7XWm5PckI2rlX1355EA2AIXr++llO9N8vpsrPM/mORZSe7u\nOCIAV6GU8uNJnqi1/lPvWVoIcAB2UK31k8N/DP43ye/n/y9TfzbJjZueesNwDIBdqJRybTZ+QPtn\ntda/Gg5/8qnLFw/vnxiOW+MBRuBSa7vzd4DpUWv9bJL3JvmhbGw9MjM8tHkN//r6Pjw+m+S/dnhU\nAK7CpvX99mFr2Vpr/XKSP4rzd4AxuTXJT5RSHknyzmxsPfWWjOzcXYADsIMu2lf2J5N8cLh9X5KX\nl1KeUUp5XpKbkvzDTs8HwJUN+8j+YZKHa62/vemh+5IcH24fT/LXm47/TNlwS5ILm7aqAmAXuNza\n7vwdYNxKKdeXUg4Ntw8keUmSh7Pxg9pjw9MuPnd/6pz+WJIHhqtbArCLXGZ9//dNvxhVkrws33j+\n7rUZgF2s1vr6WusNtdaFJC/Pxrn4T2dk5+4zV34KAN+KUsqfJ/nhJN9eSnk0ya8l+eFSys3Z2Jbk\nkSS/kCS11g+VUt6V5KEkTyZ5da31az3mBuCKbk3yyiTrw17jSfKGJCeTvKuU8qokH0vyU8Nj9yd5\naZIzSb6U5Gd3dlwAJnC5tf0Vzt8BRu25SU6VUvZl45dR31Vr/ZtSykNJ3llK+Y0k/5KNCDPD+z8p\npZxJ8ulsvPAPwO5zufX9gVLK9UlKkgeT/OLwfK/NAIzX3RnRuXvZBREQAAAAAAAAAACMli2oAAAA\nAAAAAACggQAHAAAAAAAAAAAaCHAAAAAAAAAAAKCBAAcAAAAAAAAAABoIcAAAAAAAAAAAoIEABwAA\nAAAAAAAAGghwAAAAAAAAAACggQAHAAAAAAAAAAAa/B/HOw3oEcUo/gAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"B0IPGVqXZoTj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"status":"ok","timestamp":1585940645046,"user_tz":-120,"elapsed":2486,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"efd9937d-5170-4225-fd59-e96a2db3d989"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_hobea_es, luzerak_hobea_en, luzerak_hobea_eu], bins=range(-9, 200, 10), histtype='step', label=labels)\n","plt.legend(prop={'size': 50})\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACPMAAAReCAYAAAC4+OdZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGv9Rlhf5AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"OMLHewDPbbos","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1585940873648,"user_tz":-120,"elapsed":1875,"user":{"displayName":"Bittor Alkain","photoUrl":"","userId":"06778993163287366029"}},"outputId":"0757d438-9c59-4ab6-b76a-a275cc37cd99"},"source":["plt.figure(figsize=(40, 20))\n","plt.hist([luzerak_hobea_es, luzerak_hobea_en, luzerak_hobea_eu], bins=range(121, 400, 10), histtype='step', label=labels)\n","plt.legend(prop={'size': 50})\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAACOYAAARhCAYAAACMUxiNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 2880x1440 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"8xuZnb0AcTmT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}